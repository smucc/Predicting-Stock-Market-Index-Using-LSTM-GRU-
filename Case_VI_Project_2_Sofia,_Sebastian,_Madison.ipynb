{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0ZD4RaLy1ta"
      },
      "source": [
        "#Predicting Stock Market Index Using LSTM & GRU #\n",
        "\n",
        "**Authors:** Sofia Mucci, Sebastion Tardieu, Madison Klinefelter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Abstract##\n",
        "This project focuses on predicting stock market behavior using a comprehensive approach that includes data preprocessing, exploratory data analysis, dimensionality reduction, and the application of Long Short-Term Memory (LSTM) neural network models. The dataset, sourced from NEPSE (Nepal Stock Exchange), undergoes preprocessing steps such as date conversion, feature engineering (50 and 200-day moving averages), and correlation analysis. Dimensionality reduction using Principal Component Analysis (PCA) is employed to capture essential features for model training. The LSTM models are constructed and tuned through hyperparameter optimization, considering different neuron configurations, optimizers (Adam, Adagrad, Nadam), learning rates, and batch sizes. The performance is evaluated using metrics such as root mean square error (RMSE) and mean absolute percentage error (MAPE). The project emphasizes the significance of selecting appropriate neural network architectures for time series prediction tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "jziCPr_0gZWT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhN_FHG-vAzK",
        "outputId": "31cb6eb0-2fc0-4c5e-f1a5-10f918e6ddd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_8vizEIvgLK"
      },
      "outputs": [],
      "source": [
        "#data path for Sofia\n",
        "data_path = \"/content/drive/MyDrive/DSC 201/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JDE79gPvgQk"
      },
      "outputs": [],
      "source": [
        "#data path for Madison\n",
        "#data_path = \"/content/drive/MyDrive/fall23/dsc201/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4dO8RFrvgTK"
      },
      "outputs": [],
      "source": [
        "#data path for Sebastian\n",
        "#data_path = \"/content/drive/MyDrive/NEPSE/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q1gdOARyHkr"
      },
      "outputs": [],
      "source": [
        "#importing required libaries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "plt.style.use('ggplot')\n",
        "import tensorflow as tf\n",
        "%load_ext tensorboard\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import datetime as dt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "import time\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDvl6f7JvYPC"
      },
      "source": [
        "##Data Visualization##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "d4lMobStx8OJ",
        "outputId": "3e6982b8-6d5d-4150-a08a-1121af7a6ac2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Unnamed: 0     Open     High      Low    Close   Volume  \\\n",
              "Date                                                                  \n",
              "2016-07-17           0  1718.15  1749.96  1715.14  1745.74  2272045   \n",
              "2016-07-18           1  1745.74  1786.68  1745.74  1786.59  2870497   \n",
              "2016-07-19           2  1786.59  1813.42  1785.33  1800.47  2902127   \n",
              "2016-07-20           3  1800.47  1813.44  1782.57  1786.84  3474801   \n",
              "2016-07-21           4  1786.84  1804.75  1779.71  1798.83  3154492   \n",
              "\n",
              "                 MACD        RSI        ATR        MFI    CPI     USDX   IR  \\\n",
              "Date                                                                          \n",
              "2016-07-17 -37.509420  74.940143  23.122890  70.196510  112.9  107.519  8.6   \n",
              "2016-07-18 -41.071885  82.962838  24.395540  67.197424  112.9  107.519  8.6   \n",
              "2016-07-19 -44.502170  84.862752  24.659430  65.486818  112.9  107.519  8.6   \n",
              "2016-07-20 -45.595275  75.342839  25.103042  55.037084  112.9  107.519  8.6   \n",
              "2016-07-21 -46.888559  77.863404  25.098539  67.326060  112.9  107.519  8.6   \n",
              "\n",
              "              TB  EFFR    RMT    Score  \n",
              "Date                                    \n",
              "2016-07-17  0.44  0.82  51.94  0.20955  \n",
              "2016-07-18  0.44  0.82  51.94  0.21927  \n",
              "2016-07-19  0.44  0.82  51.94 -0.02642  \n",
              "2016-07-20  0.44  0.82  51.94  0.15107  \n",
              "2016-07-21  0.44  0.82  51.94  0.12900  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9594202-6b9a-4165-8456-2e51fef4fb7a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>MACD</th>\n",
              "      <th>RSI</th>\n",
              "      <th>ATR</th>\n",
              "      <th>MFI</th>\n",
              "      <th>CPI</th>\n",
              "      <th>USDX</th>\n",
              "      <th>IR</th>\n",
              "      <th>TB</th>\n",
              "      <th>EFFR</th>\n",
              "      <th>RMT</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-07-17</th>\n",
              "      <td>0</td>\n",
              "      <td>1718.15</td>\n",
              "      <td>1749.96</td>\n",
              "      <td>1715.14</td>\n",
              "      <td>1745.74</td>\n",
              "      <td>2272045</td>\n",
              "      <td>-37.509420</td>\n",
              "      <td>74.940143</td>\n",
              "      <td>23.122890</td>\n",
              "      <td>70.196510</td>\n",
              "      <td>112.9</td>\n",
              "      <td>107.519</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>51.94</td>\n",
              "      <td>0.20955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-18</th>\n",
              "      <td>1</td>\n",
              "      <td>1745.74</td>\n",
              "      <td>1786.68</td>\n",
              "      <td>1745.74</td>\n",
              "      <td>1786.59</td>\n",
              "      <td>2870497</td>\n",
              "      <td>-41.071885</td>\n",
              "      <td>82.962838</td>\n",
              "      <td>24.395540</td>\n",
              "      <td>67.197424</td>\n",
              "      <td>112.9</td>\n",
              "      <td>107.519</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>51.94</td>\n",
              "      <td>0.21927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-19</th>\n",
              "      <td>2</td>\n",
              "      <td>1786.59</td>\n",
              "      <td>1813.42</td>\n",
              "      <td>1785.33</td>\n",
              "      <td>1800.47</td>\n",
              "      <td>2902127</td>\n",
              "      <td>-44.502170</td>\n",
              "      <td>84.862752</td>\n",
              "      <td>24.659430</td>\n",
              "      <td>65.486818</td>\n",
              "      <td>112.9</td>\n",
              "      <td>107.519</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>51.94</td>\n",
              "      <td>-0.02642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-20</th>\n",
              "      <td>3</td>\n",
              "      <td>1800.47</td>\n",
              "      <td>1813.44</td>\n",
              "      <td>1782.57</td>\n",
              "      <td>1786.84</td>\n",
              "      <td>3474801</td>\n",
              "      <td>-45.595275</td>\n",
              "      <td>75.342839</td>\n",
              "      <td>25.103042</td>\n",
              "      <td>55.037084</td>\n",
              "      <td>112.9</td>\n",
              "      <td>107.519</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>51.94</td>\n",
              "      <td>0.15107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-21</th>\n",
              "      <td>4</td>\n",
              "      <td>1786.84</td>\n",
              "      <td>1804.75</td>\n",
              "      <td>1779.71</td>\n",
              "      <td>1798.83</td>\n",
              "      <td>3154492</td>\n",
              "      <td>-46.888559</td>\n",
              "      <td>77.863404</td>\n",
              "      <td>25.098539</td>\n",
              "      <td>67.326060</td>\n",
              "      <td>112.9</td>\n",
              "      <td>107.519</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>51.94</td>\n",
              "      <td>0.12900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9594202-6b9a-4165-8456-2e51fef4fb7a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9594202-6b9a-4165-8456-2e51fef4fb7a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9594202-6b9a-4165-8456-2e51fef4fb7a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-725c2ebf-29ce-407a-82f4-538461b25a4f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-725c2ebf-29ce-407a-82f4-538461b25a4f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-725c2ebf-29ce-407a-82f4-538461b25a4f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "nepse_data= pd.read_csv(data_path + 'nepse_data.csv')\n",
        "#converting Date columns to datetime and only extracting the date\n",
        "nepse_data['Date']=pd.to_datetime(nepse_data['Date']).dt.date\n",
        "#setting 'Date' column as the index\n",
        "nepse_data.set_index(\"Date\",inplace=True)\n",
        "nepse_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "OqyuPTaJvgVf",
        "outputId": "ddc2db82-274d-42eb-cc5d-2a33f20e2288"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Unnamed: 0     Open     High      Low    Close    Volume  \\\n",
              "Date                                                                   \n",
              "2021-03-04        1046  2425.20  2506.68  2427.25  2506.68  16622763   \n",
              "2021-03-07        1047  2519.96  2525.30  2473.57  2485.09  11778820   \n",
              "2021-03-09        1048  2494.05  2494.05  2453.53  2461.88  12482428   \n",
              "2021-03-10        1049  2476.93  2477.71  2446.33  2458.48   7816874   \n",
              "2021-03-14        1050  2466.26  2467.20  2397.52  2407.25   9903704   \n",
              "\n",
              "                 MACD        RSI        ATR        MFI     CPI    USDX   IR  \\\n",
              "Date                                                                          \n",
              "2021-03-04 -25.944387  48.236208  66.381959  49.993970  136.41  116.35  2.7   \n",
              "2021-03-07 -21.572364  44.946087  65.335390  50.318028  136.41  116.35  2.7   \n",
              "2021-03-09 -16.049640  41.439954  63.562863  43.013458  136.41  116.35  2.7   \n",
              "2021-03-10 -11.268593  40.900669  61.264087  36.180473  136.41  116.35  2.7   \n",
              "2021-03-14  -3.307618  33.354209  61.865223  29.587046  136.41  116.35  3.1   \n",
              "\n",
              "              TB  EFFR     RMT    Score  \n",
              "Date                                     \n",
              "2021-03-04  2.03  1.26  567.70  0.20650  \n",
              "2021-03-07  2.03  1.26  567.70  0.31411  \n",
              "2021-03-09  2.03  1.26  567.70  0.28296  \n",
              "2021-03-10  2.03  1.26  567.70  0.16062  \n",
              "2021-03-14  2.03  1.26  729.02  0.31583  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06ae1c22-da64-4206-a64e-e33b056cbe24\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>MACD</th>\n",
              "      <th>RSI</th>\n",
              "      <th>ATR</th>\n",
              "      <th>MFI</th>\n",
              "      <th>CPI</th>\n",
              "      <th>USDX</th>\n",
              "      <th>IR</th>\n",
              "      <th>TB</th>\n",
              "      <th>EFFR</th>\n",
              "      <th>RMT</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-03-04</th>\n",
              "      <td>1046</td>\n",
              "      <td>2425.20</td>\n",
              "      <td>2506.68</td>\n",
              "      <td>2427.25</td>\n",
              "      <td>2506.68</td>\n",
              "      <td>16622763</td>\n",
              "      <td>-25.944387</td>\n",
              "      <td>48.236208</td>\n",
              "      <td>66.381959</td>\n",
              "      <td>49.993970</td>\n",
              "      <td>136.41</td>\n",
              "      <td>116.35</td>\n",
              "      <td>2.7</td>\n",
              "      <td>2.03</td>\n",
              "      <td>1.26</td>\n",
              "      <td>567.70</td>\n",
              "      <td>0.20650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-03-07</th>\n",
              "      <td>1047</td>\n",
              "      <td>2519.96</td>\n",
              "      <td>2525.30</td>\n",
              "      <td>2473.57</td>\n",
              "      <td>2485.09</td>\n",
              "      <td>11778820</td>\n",
              "      <td>-21.572364</td>\n",
              "      <td>44.946087</td>\n",
              "      <td>65.335390</td>\n",
              "      <td>50.318028</td>\n",
              "      <td>136.41</td>\n",
              "      <td>116.35</td>\n",
              "      <td>2.7</td>\n",
              "      <td>2.03</td>\n",
              "      <td>1.26</td>\n",
              "      <td>567.70</td>\n",
              "      <td>0.31411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-03-09</th>\n",
              "      <td>1048</td>\n",
              "      <td>2494.05</td>\n",
              "      <td>2494.05</td>\n",
              "      <td>2453.53</td>\n",
              "      <td>2461.88</td>\n",
              "      <td>12482428</td>\n",
              "      <td>-16.049640</td>\n",
              "      <td>41.439954</td>\n",
              "      <td>63.562863</td>\n",
              "      <td>43.013458</td>\n",
              "      <td>136.41</td>\n",
              "      <td>116.35</td>\n",
              "      <td>2.7</td>\n",
              "      <td>2.03</td>\n",
              "      <td>1.26</td>\n",
              "      <td>567.70</td>\n",
              "      <td>0.28296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-03-10</th>\n",
              "      <td>1049</td>\n",
              "      <td>2476.93</td>\n",
              "      <td>2477.71</td>\n",
              "      <td>2446.33</td>\n",
              "      <td>2458.48</td>\n",
              "      <td>7816874</td>\n",
              "      <td>-11.268593</td>\n",
              "      <td>40.900669</td>\n",
              "      <td>61.264087</td>\n",
              "      <td>36.180473</td>\n",
              "      <td>136.41</td>\n",
              "      <td>116.35</td>\n",
              "      <td>2.7</td>\n",
              "      <td>2.03</td>\n",
              "      <td>1.26</td>\n",
              "      <td>567.70</td>\n",
              "      <td>0.16062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-03-14</th>\n",
              "      <td>1050</td>\n",
              "      <td>2466.26</td>\n",
              "      <td>2467.20</td>\n",
              "      <td>2397.52</td>\n",
              "      <td>2407.25</td>\n",
              "      <td>9903704</td>\n",
              "      <td>-3.307618</td>\n",
              "      <td>33.354209</td>\n",
              "      <td>61.865223</td>\n",
              "      <td>29.587046</td>\n",
              "      <td>136.41</td>\n",
              "      <td>116.35</td>\n",
              "      <td>3.1</td>\n",
              "      <td>2.03</td>\n",
              "      <td>1.26</td>\n",
              "      <td>729.02</td>\n",
              "      <td>0.31583</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06ae1c22-da64-4206-a64e-e33b056cbe24')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06ae1c22-da64-4206-a64e-e33b056cbe24 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06ae1c22-da64-4206-a64e-e33b056cbe24');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fbc109f0-53ee-4e50-932b-98dd30bc3ba3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fbc109f0-53ee-4e50-932b-98dd30bc3ba3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fbc109f0-53ee-4e50-932b-98dd30bc3ba3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "nepse_data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "lK5PLefpvgX1",
        "outputId": "af5d768a-67db-493d-c8e3-fb3a5800aa71"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "df = nepse_data.copy()\n",
        "#calculating 50 and 200 day moving average and add it as columns to dataset\n",
        "df['MA_50'] = df['Close'].rolling(50).mean()\n",
        "df['MA_200'] = df['Close'].rolling(200).mean()\n",
        "\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "fig.set(facecolor = \"white\")\n",
        "#plotting the close price\n",
        "plt.plot(df['Close'], 'mediumblue',label=['S&P 500 Close Price'], linewidth = 2.2)\n",
        "#plotting the 50 day moving average\n",
        "plt.plot(df['MA_50'],'red', label=['50-day MA'], linewidth = 2.2)\n",
        "#plotting on the 200 dat moving average\n",
        "plt.plot(df['MA_200'],'darkgreen', label=['200-day MA'], linewidth = 2.2)\n",
        "plt.legend(['S&P 500 Close Price', '50-day Moving Average', '200-day Moving Average'], loc='upper left')\n",
        "plt.title('')\n",
        "plt.xlabel('Time (years)')\n",
        "plt.ylabel('Close price')\n",
        "#fig.savefig(output_dir_path+ \"original_data_plus_moving_averages.png\",dpi=600)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "pgNfyxokvgaL",
        "outputId": "1dcf1e87-f5c0-4a6f-bef8-98705cf4272b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = plt.figure(figsize= (10,5))\n",
        "sns.heatmap(nepse_data.corr(), annot=True)\n",
        "sns.set_style(\"whitegrid\")\n",
        "#fig.savefig(output_dir_path+\"correlation_heatmap.png\",dpi=600)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "wShf3g5R0Wd-",
        "outputId": "83becf12-0f02-42e0-b989-ad667f681e8d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Extracting Nepse data for a heatmap starting at column 5\n",
        "data = nepse_data.iloc[:, 4:]\n",
        "fig = plt.figure(figsize= (10,5))\n",
        "sns.heatmap(data.corr(), annot=True)\n",
        "sns.set_style(\"whitegrid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezR6zrOO5fLJ"
      },
      "outputs": [],
      "source": [
        "# Create a lower triangular mask\n",
        "mask = np.triu(np.ones_like(data.corr(), dtype=bool))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "3X2u4NZZ5fHv",
        "outputId": "3cd3af2b-a354-4eb2-972f-875892e61b2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "data = nepse_data.iloc[:, 4:]\n",
        "sns.set_style(\"white\")  # Set the style to plain white background\n",
        "sns.set(style=\"white\", rc={\"axes.grid\": False})\n",
        "fig = plt.figure(figsize= (10,5))\n",
        "sns.heatmap(data.corr(), annot=True, mask=mask, cbar = False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "1x8zaTu_2fBC",
        "outputId": "bec4cf15-9593-4f9e-ee6a-6a2cc47a8ca0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0         Open         High          Low        Close  \\\n",
              "count  1051.00000  1051.000000  1051.000000  1051.000000  1051.000000   \n",
              "mean    525.00000  1448.737869  1459.018934  1437.164500  1447.630276   \n",
              "std     303.54187   307.807762   310.701300   301.714343   306.109743   \n",
              "min       0.00000  1100.950000  1104.610000  1098.950000  1100.580000   \n",
              "25%     262.50000  1216.750000  1223.540000  1208.295000  1216.595000   \n",
              "50%     525.00000  1363.010000  1379.750000  1353.400000  1363.010000   \n",
              "75%     787.50000  1585.080000  1593.445000  1573.570000  1583.585000   \n",
              "max    1050.00000  2667.270000  2673.850000  2619.580000  2640.340000   \n",
              "\n",
              "             Volume         MACD          RSI          ATR          MFI  \\\n",
              "count  1.051000e+03  1051.000000  1051.000000  1051.000000  1051.000000   \n",
              "mean   3.075432e+06    -5.688622    50.311171    21.973611    46.365407   \n",
              "std    4.118234e+06    32.078118    20.565716    12.266440    18.039663   \n",
              "min    1.052600e+04  -111.082111     4.915743     7.554095     5.915355   \n",
              "25%    9.654130e+05   -20.560546    35.013842    13.014211    32.978412   \n",
              "50%    1.428838e+06     1.054089    47.947597    18.259245    45.692971   \n",
              "75%    2.912336e+06    15.415869    65.549847    26.573129    58.997668   \n",
              "max    2.594538e+07    66.304566    98.794827    66.381959    94.462971   \n",
              "\n",
              "               CPI         USDX           IR           TB         EFFR  \\\n",
              "count  1051.000000  1051.000000  1051.000000  1051.000000  1051.000000   \n",
              "mean    124.495661   110.601642     4.631637     2.687612     2.749324   \n",
              "std       7.970687     5.346846     1.508347     1.784712     2.010138   \n",
              "min     112.400000   101.744400     2.300000     0.130000     0.020000   \n",
              "25%     118.300000   105.430500     3.490000     0.900000     0.780000   \n",
              "50%     124.000000   111.183500     4.200000     2.550000     2.680000   \n",
              "75%     132.400000   114.355500     6.000000     4.380000     4.520000   \n",
              "max     138.190000   121.095300     8.600000     5.820000     6.910000   \n",
              "\n",
              "               RMT        Score  \n",
              "count  1051.000000  1051.000000  \n",
              "mean    404.179343     0.261034  \n",
              "std     223.679126     0.119946  \n",
              "min      51.940000    -0.119790  \n",
              "25%     228.950000     0.182805  \n",
              "50%     394.570000     0.262810  \n",
              "75%     567.700000     0.338935  \n",
              "max     879.270000     0.608340  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7aff9c0-4599-4994-abf0-feb9b9236576\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>MACD</th>\n",
              "      <th>RSI</th>\n",
              "      <th>ATR</th>\n",
              "      <th>MFI</th>\n",
              "      <th>CPI</th>\n",
              "      <th>USDX</th>\n",
              "      <th>IR</th>\n",
              "      <th>TB</th>\n",
              "      <th>EFFR</th>\n",
              "      <th>RMT</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1051.00000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1.051000e+03</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>525.00000</td>\n",
              "      <td>1448.737869</td>\n",
              "      <td>1459.018934</td>\n",
              "      <td>1437.164500</td>\n",
              "      <td>1447.630276</td>\n",
              "      <td>3.075432e+06</td>\n",
              "      <td>-5.688622</td>\n",
              "      <td>50.311171</td>\n",
              "      <td>21.973611</td>\n",
              "      <td>46.365407</td>\n",
              "      <td>124.495661</td>\n",
              "      <td>110.601642</td>\n",
              "      <td>4.631637</td>\n",
              "      <td>2.687612</td>\n",
              "      <td>2.749324</td>\n",
              "      <td>404.179343</td>\n",
              "      <td>0.261034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>303.54187</td>\n",
              "      <td>307.807762</td>\n",
              "      <td>310.701300</td>\n",
              "      <td>301.714343</td>\n",
              "      <td>306.109743</td>\n",
              "      <td>4.118234e+06</td>\n",
              "      <td>32.078118</td>\n",
              "      <td>20.565716</td>\n",
              "      <td>12.266440</td>\n",
              "      <td>18.039663</td>\n",
              "      <td>7.970687</td>\n",
              "      <td>5.346846</td>\n",
              "      <td>1.508347</td>\n",
              "      <td>1.784712</td>\n",
              "      <td>2.010138</td>\n",
              "      <td>223.679126</td>\n",
              "      <td>0.119946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>1100.950000</td>\n",
              "      <td>1104.610000</td>\n",
              "      <td>1098.950000</td>\n",
              "      <td>1100.580000</td>\n",
              "      <td>1.052600e+04</td>\n",
              "      <td>-111.082111</td>\n",
              "      <td>4.915743</td>\n",
              "      <td>7.554095</td>\n",
              "      <td>5.915355</td>\n",
              "      <td>112.400000</td>\n",
              "      <td>101.744400</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>51.940000</td>\n",
              "      <td>-0.119790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>262.50000</td>\n",
              "      <td>1216.750000</td>\n",
              "      <td>1223.540000</td>\n",
              "      <td>1208.295000</td>\n",
              "      <td>1216.595000</td>\n",
              "      <td>9.654130e+05</td>\n",
              "      <td>-20.560546</td>\n",
              "      <td>35.013842</td>\n",
              "      <td>13.014211</td>\n",
              "      <td>32.978412</td>\n",
              "      <td>118.300000</td>\n",
              "      <td>105.430500</td>\n",
              "      <td>3.490000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>228.950000</td>\n",
              "      <td>0.182805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>525.00000</td>\n",
              "      <td>1363.010000</td>\n",
              "      <td>1379.750000</td>\n",
              "      <td>1353.400000</td>\n",
              "      <td>1363.010000</td>\n",
              "      <td>1.428838e+06</td>\n",
              "      <td>1.054089</td>\n",
              "      <td>47.947597</td>\n",
              "      <td>18.259245</td>\n",
              "      <td>45.692971</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>111.183500</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>2.550000</td>\n",
              "      <td>2.680000</td>\n",
              "      <td>394.570000</td>\n",
              "      <td>0.262810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>787.50000</td>\n",
              "      <td>1585.080000</td>\n",
              "      <td>1593.445000</td>\n",
              "      <td>1573.570000</td>\n",
              "      <td>1583.585000</td>\n",
              "      <td>2.912336e+06</td>\n",
              "      <td>15.415869</td>\n",
              "      <td>65.549847</td>\n",
              "      <td>26.573129</td>\n",
              "      <td>58.997668</td>\n",
              "      <td>132.400000</td>\n",
              "      <td>114.355500</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.380000</td>\n",
              "      <td>4.520000</td>\n",
              "      <td>567.700000</td>\n",
              "      <td>0.338935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1050.00000</td>\n",
              "      <td>2667.270000</td>\n",
              "      <td>2673.850000</td>\n",
              "      <td>2619.580000</td>\n",
              "      <td>2640.340000</td>\n",
              "      <td>2.594538e+07</td>\n",
              "      <td>66.304566</td>\n",
              "      <td>98.794827</td>\n",
              "      <td>66.381959</td>\n",
              "      <td>94.462971</td>\n",
              "      <td>138.190000</td>\n",
              "      <td>121.095300</td>\n",
              "      <td>8.600000</td>\n",
              "      <td>5.820000</td>\n",
              "      <td>6.910000</td>\n",
              "      <td>879.270000</td>\n",
              "      <td>0.608340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7aff9c0-4599-4994-abf0-feb9b9236576')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7aff9c0-4599-4994-abf0-feb9b9236576 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7aff9c0-4599-4994-abf0-feb9b9236576');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-98c6f9d2-0383-42da-bbde-64d6a3fd7cc8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-98c6f9d2-0383-42da-bbde-64d6a3fd7cc8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-98c6f9d2-0383-42da-bbde-64d6a3fd7cc8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "nepse_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYW0Q2J92wFd",
        "outputId": "ded2e9b1-0937-4e9b-863b-745570432062"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Open', 'High', 'Low', 'Close', 'Volume', 'MACD', 'RSI',\n",
              "       'ATR', 'MFI', 'CPI', 'USDX', 'IR', 'TB', 'EFFR', 'RMT', 'Score'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "nepse_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6cecehbKRWs"
      },
      "outputs": [],
      "source": [
        "#dropping unecessary columns\n",
        "nepse = nepse_data.drop(\"Unnamed: 0\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "vCwOr-ku6AKZ",
        "outputId": "9b7a4ce9-54eb-4d05-8408-06566f7e1b86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Open     High      Low    Close   Volume       MACD        RSI  \\\n",
              "Date                                                                            \n",
              "2016-07-17  1718.15  1749.96  1715.14  1745.74  2272045 -37.509420  74.940143   \n",
              "2016-07-18  1745.74  1786.68  1745.74  1786.59  2870497 -41.071885  82.962838   \n",
              "2016-07-19  1786.59  1813.42  1785.33  1800.47  2902127 -44.502170  84.862752   \n",
              "2016-07-20  1800.47  1813.44  1782.57  1786.84  3474801 -45.595275  75.342839   \n",
              "2016-07-21  1786.84  1804.75  1779.71  1798.83  3154492 -46.888559  77.863404   \n",
              "\n",
              "                  ATR        MFI    CPI     USDX   IR    TB  EFFR    RMT  \\\n",
              "Date                                                                       \n",
              "2016-07-17  23.122890  70.196510  112.9  107.519  8.6  0.44  0.82  51.94   \n",
              "2016-07-18  24.395540  67.197424  112.9  107.519  8.6  0.44  0.82  51.94   \n",
              "2016-07-19  24.659430  65.486818  112.9  107.519  8.6  0.44  0.82  51.94   \n",
              "2016-07-20  25.103042  55.037084  112.9  107.519  8.6  0.44  0.82  51.94   \n",
              "2016-07-21  25.098539  67.326060  112.9  107.519  8.6  0.44  0.82  51.94   \n",
              "\n",
              "              Score  \n",
              "Date                 \n",
              "2016-07-17  0.20955  \n",
              "2016-07-18  0.21927  \n",
              "2016-07-19 -0.02642  \n",
              "2016-07-20  0.15107  \n",
              "2016-07-21  0.12900  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15a2315c-e136-4982-bc54-15c9c6dd954e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>MACD</th>\n",
              "      <th>RSI</th>\n",
              "      <th>ATR</th>\n",
              "      <th>MFI</th>\n",
              "      <th>CPI</th>\n",
              "      <th>USDX</th>\n",
              "      <th>IR</th>\n",
              "      <th>TB</th>\n",
              "      <th>EFFR</th>\n",
              "      <th>RMT</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-07-17</th>\n",
              "      <td>1718.15</td>\n",
              "      <td>1749.96</td>\n",
              "      <td>1715.14</td>\n",
              "      <td>1745.74</td>\n",
              "      <td>2272045</td>\n",
              "      <td>-37.509420</td>\n",
              "      <td>74.940143</td>\n",
              "      <td>23.122890</td>\n",
              "      <td>70.196510</td>\n",
              "      <td>112.9</td>\n",
              "      <td>107.519</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>51.94</td>\n",
              "      <td>0.20955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-18</th>\n",
              "      <td>1745.74</td>\n",
              "      <td>1786.68</td>\n",
              "      <td>1745.74</td>\n",
              "      <td>1786.59</td>\n",
              "      <td>2870497</td>\n",
              "      <td>-41.071885</td>\n",
              "      <td>82.962838</td>\n",
              "      <td>24.395540</td>\n",
              "      <td>67.197424</td>\n",
              "      <td>112.9</td>\n",
              "      <td>107.519</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>51.94</td>\n",
              "      <td>0.21927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-19</th>\n",
              "      <td>1786.59</td>\n",
              "      <td>1813.42</td>\n",
              "      <td>1785.33</td>\n",
              "      <td>1800.47</td>\n",
              "      <td>2902127</td>\n",
              "      <td>-44.502170</td>\n",
              "      <td>84.862752</td>\n",
              "      <td>24.659430</td>\n",
              "      <td>65.486818</td>\n",
              "      <td>112.9</td>\n",
              "      <td>107.519</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>51.94</td>\n",
              "      <td>-0.02642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-20</th>\n",
              "      <td>1800.47</td>\n",
              "      <td>1813.44</td>\n",
              "      <td>1782.57</td>\n",
              "      <td>1786.84</td>\n",
              "      <td>3474801</td>\n",
              "      <td>-45.595275</td>\n",
              "      <td>75.342839</td>\n",
              "      <td>25.103042</td>\n",
              "      <td>55.037084</td>\n",
              "      <td>112.9</td>\n",
              "      <td>107.519</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>51.94</td>\n",
              "      <td>0.15107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-21</th>\n",
              "      <td>1786.84</td>\n",
              "      <td>1804.75</td>\n",
              "      <td>1779.71</td>\n",
              "      <td>1798.83</td>\n",
              "      <td>3154492</td>\n",
              "      <td>-46.888559</td>\n",
              "      <td>77.863404</td>\n",
              "      <td>25.098539</td>\n",
              "      <td>67.326060</td>\n",
              "      <td>112.9</td>\n",
              "      <td>107.519</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>51.94</td>\n",
              "      <td>0.12900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15a2315c-e136-4982-bc54-15c9c6dd954e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-15a2315c-e136-4982-bc54-15c9c6dd954e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-15a2315c-e136-4982-bc54-15c9c6dd954e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e3e0178-a0b2-4db4-b0ce-270ed8a4a78f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e3e0178-a0b2-4db4-b0ce-270ed8a4a78f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e3e0178-a0b2-4db4-b0ce-270ed8a4a78f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "nepse.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "mslCLarWKZzn",
        "outputId": "18c6a3a1-2a6b-46d2-a42c-562cc9b0174b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Open         High          Low        Close        Volume  \\\n",
              "count  1051.000000  1051.000000  1051.000000  1051.000000  1.051000e+03   \n",
              "mean   1448.737869  1459.018934  1437.164500  1447.630276  3.075432e+06   \n",
              "std     307.807762   310.701300   301.714343   306.109743  4.118234e+06   \n",
              "min    1100.950000  1104.610000  1098.950000  1100.580000  1.052600e+04   \n",
              "25%    1216.750000  1223.540000  1208.295000  1216.595000  9.654130e+05   \n",
              "50%    1363.010000  1379.750000  1353.400000  1363.010000  1.428838e+06   \n",
              "75%    1585.080000  1593.445000  1573.570000  1583.585000  2.912336e+06   \n",
              "max    2667.270000  2673.850000  2619.580000  2640.340000  2.594538e+07   \n",
              "\n",
              "              MACD          RSI          ATR          MFI          CPI  \\\n",
              "count  1051.000000  1051.000000  1051.000000  1051.000000  1051.000000   \n",
              "mean     -5.688622    50.311171    21.973611    46.365407   124.495661   \n",
              "std      32.078118    20.565716    12.266440    18.039663     7.970687   \n",
              "min    -111.082111     4.915743     7.554095     5.915355   112.400000   \n",
              "25%     -20.560546    35.013842    13.014211    32.978412   118.300000   \n",
              "50%       1.054089    47.947597    18.259245    45.692971   124.000000   \n",
              "75%      15.415869    65.549847    26.573129    58.997668   132.400000   \n",
              "max      66.304566    98.794827    66.381959    94.462971   138.190000   \n",
              "\n",
              "              USDX           IR           TB         EFFR          RMT  \\\n",
              "count  1051.000000  1051.000000  1051.000000  1051.000000  1051.000000   \n",
              "mean    110.601642     4.631637     2.687612     2.749324   404.179343   \n",
              "std       5.346846     1.508347     1.784712     2.010138   223.679126   \n",
              "min     101.744400     2.300000     0.130000     0.020000    51.940000   \n",
              "25%     105.430500     3.490000     0.900000     0.780000   228.950000   \n",
              "50%     111.183500     4.200000     2.550000     2.680000   394.570000   \n",
              "75%     114.355500     6.000000     4.380000     4.520000   567.700000   \n",
              "max     121.095300     8.600000     5.820000     6.910000   879.270000   \n",
              "\n",
              "             Score  \n",
              "count  1051.000000  \n",
              "mean      0.261034  \n",
              "std       0.119946  \n",
              "min      -0.119790  \n",
              "25%       0.182805  \n",
              "50%       0.262810  \n",
              "75%       0.338935  \n",
              "max       0.608340  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10704b68-8ccd-4905-b314-50a4aec6d4d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>MACD</th>\n",
              "      <th>RSI</th>\n",
              "      <th>ATR</th>\n",
              "      <th>MFI</th>\n",
              "      <th>CPI</th>\n",
              "      <th>USDX</th>\n",
              "      <th>IR</th>\n",
              "      <th>TB</th>\n",
              "      <th>EFFR</th>\n",
              "      <th>RMT</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1.051000e+03</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "      <td>1051.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1448.737869</td>\n",
              "      <td>1459.018934</td>\n",
              "      <td>1437.164500</td>\n",
              "      <td>1447.630276</td>\n",
              "      <td>3.075432e+06</td>\n",
              "      <td>-5.688622</td>\n",
              "      <td>50.311171</td>\n",
              "      <td>21.973611</td>\n",
              "      <td>46.365407</td>\n",
              "      <td>124.495661</td>\n",
              "      <td>110.601642</td>\n",
              "      <td>4.631637</td>\n",
              "      <td>2.687612</td>\n",
              "      <td>2.749324</td>\n",
              "      <td>404.179343</td>\n",
              "      <td>0.261034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>307.807762</td>\n",
              "      <td>310.701300</td>\n",
              "      <td>301.714343</td>\n",
              "      <td>306.109743</td>\n",
              "      <td>4.118234e+06</td>\n",
              "      <td>32.078118</td>\n",
              "      <td>20.565716</td>\n",
              "      <td>12.266440</td>\n",
              "      <td>18.039663</td>\n",
              "      <td>7.970687</td>\n",
              "      <td>5.346846</td>\n",
              "      <td>1.508347</td>\n",
              "      <td>1.784712</td>\n",
              "      <td>2.010138</td>\n",
              "      <td>223.679126</td>\n",
              "      <td>0.119946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1100.950000</td>\n",
              "      <td>1104.610000</td>\n",
              "      <td>1098.950000</td>\n",
              "      <td>1100.580000</td>\n",
              "      <td>1.052600e+04</td>\n",
              "      <td>-111.082111</td>\n",
              "      <td>4.915743</td>\n",
              "      <td>7.554095</td>\n",
              "      <td>5.915355</td>\n",
              "      <td>112.400000</td>\n",
              "      <td>101.744400</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>51.940000</td>\n",
              "      <td>-0.119790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1216.750000</td>\n",
              "      <td>1223.540000</td>\n",
              "      <td>1208.295000</td>\n",
              "      <td>1216.595000</td>\n",
              "      <td>9.654130e+05</td>\n",
              "      <td>-20.560546</td>\n",
              "      <td>35.013842</td>\n",
              "      <td>13.014211</td>\n",
              "      <td>32.978412</td>\n",
              "      <td>118.300000</td>\n",
              "      <td>105.430500</td>\n",
              "      <td>3.490000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>228.950000</td>\n",
              "      <td>0.182805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1363.010000</td>\n",
              "      <td>1379.750000</td>\n",
              "      <td>1353.400000</td>\n",
              "      <td>1363.010000</td>\n",
              "      <td>1.428838e+06</td>\n",
              "      <td>1.054089</td>\n",
              "      <td>47.947597</td>\n",
              "      <td>18.259245</td>\n",
              "      <td>45.692971</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>111.183500</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>2.550000</td>\n",
              "      <td>2.680000</td>\n",
              "      <td>394.570000</td>\n",
              "      <td>0.262810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1585.080000</td>\n",
              "      <td>1593.445000</td>\n",
              "      <td>1573.570000</td>\n",
              "      <td>1583.585000</td>\n",
              "      <td>2.912336e+06</td>\n",
              "      <td>15.415869</td>\n",
              "      <td>65.549847</td>\n",
              "      <td>26.573129</td>\n",
              "      <td>58.997668</td>\n",
              "      <td>132.400000</td>\n",
              "      <td>114.355500</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.380000</td>\n",
              "      <td>4.520000</td>\n",
              "      <td>567.700000</td>\n",
              "      <td>0.338935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2667.270000</td>\n",
              "      <td>2673.850000</td>\n",
              "      <td>2619.580000</td>\n",
              "      <td>2640.340000</td>\n",
              "      <td>2.594538e+07</td>\n",
              "      <td>66.304566</td>\n",
              "      <td>98.794827</td>\n",
              "      <td>66.381959</td>\n",
              "      <td>94.462971</td>\n",
              "      <td>138.190000</td>\n",
              "      <td>121.095300</td>\n",
              "      <td>8.600000</td>\n",
              "      <td>5.820000</td>\n",
              "      <td>6.910000</td>\n",
              "      <td>879.270000</td>\n",
              "      <td>0.608340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10704b68-8ccd-4905-b314-50a4aec6d4d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-10704b68-8ccd-4905-b314-50a4aec6d4d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-10704b68-8ccd-4905-b314-50a4aec6d4d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2763b02-e7c9-4cd2-a560-29ce1b6a5625\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2763b02-e7c9-4cd2-a560-29ce1b6a5625')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2763b02-e7c9-4cd2-a560-29ce1b6a5625 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "nepse.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        },
        "id": "pHsmwSQuK5Tt",
        "outputId": "9a45f21f-2933-41ec-b816-fd77a9ef7e93"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 13 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = plt.figure(figsize = (20, 12))\n",
        "#fig.axes.get_yaxis().set_visible(False)\n",
        "data.plot(subplots = True, figsize = (12,10),grid=False)\n",
        "sns.set_style(\"whitegrid\")\n",
        "#fig.savefig(output_dir_path+\"timeseries.png\",dpi=600)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb9TptSbvrSS"
      },
      "source": [
        "##Dimensionality Reduction##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkAeFYIpsj3o"
      },
      "outputs": [],
      "source": [
        "#from operator import index\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "dvLFmEOUyIe2",
        "outputId": "dad3b7c2-6151-4391-c784-55727dc99558"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Open     High      Low    Close   Volume       MACD        RSI  \\\n",
              "Date                                                                            \n",
              "2016-07-17  1718.15  1749.96  1715.14  1745.74  2272045 -37.509420  74.940143   \n",
              "2016-07-18  1745.74  1786.68  1745.74  1786.59  2870497 -41.071885  82.962838   \n",
              "2016-07-19  1786.59  1813.42  1785.33  1800.47  2902127 -44.502170  84.862752   \n",
              "2016-07-20  1800.47  1813.44  1782.57  1786.84  3474801 -45.595275  75.342839   \n",
              "2016-07-21  1786.84  1804.75  1779.71  1798.83  3154492 -46.888559  77.863404   \n",
              "\n",
              "                  ATR        MFI    CPI     USDX   IR    TB  EFFR    RMT  \\\n",
              "Date                                                                       \n",
              "2016-07-17  23.122890  70.196510  112.9  107.519  8.6  0.44  0.82  51.94   \n",
              "2016-07-18  24.395540  67.197424  112.9  107.519  8.6  0.44  0.82  51.94   \n",
              "2016-07-19  24.659430  65.486818  112.9  107.519  8.6  0.44  0.82  51.94   \n",
              "2016-07-20  25.103042  55.037084  112.9  107.519  8.6  0.44  0.82  51.94   \n",
              "2016-07-21  25.098539  67.326060  112.9  107.519  8.6  0.44  0.82  51.94   \n",
              "\n",
              "              Score  \n",
              "Date                 \n",
              "2016-07-17  0.20955  \n",
              "2016-07-18  0.21927  \n",
              "2016-07-19 -0.02642  \n",
              "2016-07-20  0.15107  \n",
              "2016-07-21  0.12900  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64d8c65c-29e2-48e0-8e32-bd92a8b90785\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>MACD</th>\n",
              "      <th>RSI</th>\n",
              "      <th>ATR</th>\n",
              "      <th>MFI</th>\n",
              "      <th>CPI</th>\n",
              "      <th>USDX</th>\n",
              "      <th>IR</th>\n",
              "      <th>TB</th>\n",
              "      <th>EFFR</th>\n",
              "      <th>RMT</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-07-17</th>\n",
              "      <td>1718.15</td>\n",
              "      <td>1749.96</td>\n",
              "      <td>1715.14</td>\n",
              "      <td>1745.74</td>\n",
              "      <td>2272045</td>\n",
              "      <td>-37.509420</td>\n",
              "      <td>74.940143</td>\n",
              "      <td>23.122890</td>\n",
              "      <td>70.196510</td>\n",
              "      <td>112.9</td>\n",
              "      <td>107.519</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>51.94</td>\n",
              "      <td>0.20955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-18</th>\n",
              "      <td>1745.74</td>\n",
              "      <td>1786.68</td>\n",
              "      <td>1745.74</td>\n",
              "      <td>1786.59</td>\n",
              "      <td>2870497</td>\n",
              "      <td>-41.071885</td>\n",
              "      <td>82.962838</td>\n",
              "      <td>24.395540</td>\n",
              "      <td>67.197424</td>\n",
              "      <td>112.9</td>\n",
              "      <td>107.519</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>51.94</td>\n",
              "      <td>0.21927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-19</th>\n",
              "      <td>1786.59</td>\n",
              "      <td>1813.42</td>\n",
              "      <td>1785.33</td>\n",
              "      <td>1800.47</td>\n",
              "      <td>2902127</td>\n",
              "      <td>-44.502170</td>\n",
              "      <td>84.862752</td>\n",
              "      <td>24.659430</td>\n",
              "      <td>65.486818</td>\n",
              "      <td>112.9</td>\n",
              "      <td>107.519</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>51.94</td>\n",
              "      <td>-0.02642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-20</th>\n",
              "      <td>1800.47</td>\n",
              "      <td>1813.44</td>\n",
              "      <td>1782.57</td>\n",
              "      <td>1786.84</td>\n",
              "      <td>3474801</td>\n",
              "      <td>-45.595275</td>\n",
              "      <td>75.342839</td>\n",
              "      <td>25.103042</td>\n",
              "      <td>55.037084</td>\n",
              "      <td>112.9</td>\n",
              "      <td>107.519</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>51.94</td>\n",
              "      <td>0.15107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-21</th>\n",
              "      <td>1786.84</td>\n",
              "      <td>1804.75</td>\n",
              "      <td>1779.71</td>\n",
              "      <td>1798.83</td>\n",
              "      <td>3154492</td>\n",
              "      <td>-46.888559</td>\n",
              "      <td>77.863404</td>\n",
              "      <td>25.098539</td>\n",
              "      <td>67.326060</td>\n",
              "      <td>112.9</td>\n",
              "      <td>107.519</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>51.94</td>\n",
              "      <td>0.12900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64d8c65c-29e2-48e0-8e32-bd92a8b90785')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-64d8c65c-29e2-48e0-8e32-bd92a8b90785 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-64d8c65c-29e2-48e0-8e32-bd92a8b90785');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-23f8f7fb-7f00-44c6-af2e-929522805b2e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-23f8f7fb-7f00-44c6-af2e-929522805b2e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-23f8f7fb-7f00-44c6-af2e-929522805b2e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "nepse.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXwZBXSvjrSB"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh510JrzjCW7"
      },
      "outputs": [],
      "source": [
        "scaler=StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elMJ1HqDi8T7",
        "outputId": "e3053455-8b9e-4acb-fbae-c8d070f09205"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.8756777 ,  0.93684698,  0.92175876, ..., -0.96025412,\n",
              "        -1.57550256, -0.42943027],\n",
              "       [ 0.96535424,  1.0550875 ,  1.02322748, ..., -0.96025412,\n",
              "        -1.57550256, -0.34835518],\n",
              "       [ 1.09813012,  1.14119184,  1.15450678, ..., -0.96025412,\n",
              "        -1.57550256, -2.39766991],\n",
              "       ...,\n",
              "       [ 3.39760691,  3.33285963,  3.37023875, ..., -0.74125943,\n",
              "         0.73139818,  0.18288685],\n",
              "       [ 3.3419613 ,  3.28024389,  3.34636375, ..., -0.74125943,\n",
              "         0.73139818, -0.83755828],\n",
              "       [ 3.30728031,  3.24640108,  3.1845112 , ..., -0.74125943,\n",
              "         1.45295322,  0.45705746]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "#calculate parameters needed for normalization\n",
        "nepse_normalized=scaler.fit(nepse)\n",
        "#apply the normalization transformation to the Nepse data\n",
        "nepse_normalized=scaler.transform(nepse)\n",
        "nepse_normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7GkumkHuj8f"
      },
      "outputs": [],
      "source": [
        "#create a PCA object with 95% variance\n",
        "pca = PCA(n_components=0.95, svd_solver='full')\n",
        "# you can try both 0.95 and 0.99"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOpAIwiMyjMx"
      },
      "outputs": [],
      "source": [
        "X_pca = pca.fit_transform(nepse_normalized)\n",
        "#X_pca = pca.fit(nepse.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ldnDbn70zWE",
        "outputId": "da80ed82-7e37-4bb5-b60c-cde5e4fe1fc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1051, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#print the shape of the after applying PCA\n",
        "X_pca.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rGClDkgy5pW",
        "outputId": "2cadb62e-6d35-41c0-c896-a6c5e1e606c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.98905314, -0.81932092, -0.75841077, ...,  1.53655513,\n",
              "        -0.48403268, -0.24408457],\n",
              "       [ 2.29965747, -0.77191487, -0.66255152, ...,  1.56335573,\n",
              "        -0.55543441,  0.07303038],\n",
              "       [ 2.3922143 , -0.7097521 , -0.55378168, ...,  1.19778126,\n",
              "        -0.5795444 ,  0.22989557],\n",
              "       ...,\n",
              "       [ 7.10373573, -1.13228951,  2.0343545 , ..., -0.07235327,\n",
              "         1.05035434, -0.41184385],\n",
              "       [ 6.46312534, -1.40105137,  1.88928154, ..., -0.05042317,\n",
              "         0.98151247, -0.1360254 ],\n",
              "       [ 6.2804184 , -1.37349962,  2.27270526, ...,  0.51379841,\n",
              "         0.60052276, -0.44140933]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "X_pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF6blPRyy_cv",
        "outputId": "ddb7282f-1791-47cd-d5af-2a580378af9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.43212577, 0.14646813, 0.10448407, 0.0825473 , 0.06388735,\n",
              "       0.0607044 , 0.03640986, 0.02305484, 0.01498773])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "pca.explained_variance_ratio_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQI7g1mJ6Nov"
      },
      "outputs": [],
      "source": [
        "#trying with n_componenets set to 0.95\n",
        "pca = PCA(n_components=0.95, svd_solver='full')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQTA31TIyMfK"
      },
      "outputs": [],
      "source": [
        "#fit the PCA model to normalized Nepse data\n",
        "X_pca = pca.fit_transform(nepse_normalized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41wxHwugyO0K",
        "outputId": "83aa8805-84a8-48ff-ca3f-43a953684857"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1051, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "X_pca.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm4JKhr9yq7m"
      },
      "source": [
        "##Data Normalization and Input Preperation##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIagLiUVwMZY"
      },
      "outputs": [],
      "source": [
        "# defining a function that gives a dataset and a time step, which then returns the input and output data\n",
        "def DatasetCreation(dataX,dataY, time_step = 1):\n",
        "   DataX, DataY = [], []\n",
        "   for i in range(len(dataX)- time_step -1):\n",
        "         a = dataX[i:(i+ time_step), ]\n",
        "         DataX.append(a)\n",
        "         b= dataY[i + time_step, ]\n",
        "         DataY.append(b)\n",
        "   return np.array(DataX), np.array(DataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jURkX6Zp8eYw"
      },
      "outputs": [],
      "source": [
        "X = X_pca\n",
        "y = nepse['Close'].values\n",
        "#reshape 'y' to have a single column\n",
        "y=y.reshape(len(y),1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92cfYP12w4UB"
      },
      "outputs": [],
      "source": [
        "#creating a dataset using DatasetCreation\n",
        "X,y=DatasetCreation(X,y, time_step = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k86ULkokyxbS",
        "outputId": "cf519444-7afa-47c4-ce71-9ced721cfd93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1045, 5, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# shape is (None, time_step, #number of features)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iurp3CUxzOn9",
        "outputId": "a4a643da-aeaf-464b-f27e-6c946a65c049"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1045, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5ve5paos-o5"
      },
      "outputs": [],
      "source": [
        "def data_split(data, split = 0.2):\n",
        "  # creating training and test data\n",
        "  l1   = int(len(data) * (1- split))\n",
        "  l2    = len(data) - l1\n",
        "  train  = data[0:l1,:]\n",
        "  test   = data[l1:len(data),:]\n",
        "  return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZwukCdQAZSs"
      },
      "outputs": [],
      "source": [
        "X_train, X_test=data_split(X, split = 0.2)\n",
        "y_train, y_test=data_split(y, split = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZzSnO7hvmKA",
        "outputId": "a4f9c72d-01ba-412b-cc77-be2d40e6545d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape (836, 5, 9)\n",
            "y_train shape (836, 1)\n",
            "X_test shape (209, 5, 9)\n",
            "y_test shape (209, 1)\n"
          ]
        }
      ],
      "source": [
        "print('X_train shape',X_train.shape)\n",
        "print('y_train shape',y_train.shape)\n",
        "print('X_test shape',X_test.shape)\n",
        "print('y_test shape',y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb4-ve45vroO",
        "outputId": "e19ab715-3871-425d-9f60-1fff29e9d4b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1838.49])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRb015kUzoZy"
      },
      "outputs": [],
      "source": [
        "X_val= data_split(X_train, 0.2)\n",
        "y_val= data_split(y_train, 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NegrQdL_-2wl"
      },
      "outputs": [],
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    return (np.mean(np.abs((y_true - y_pred)/(y_true))*100)) #some issues with zero denominator\n",
        "\n",
        "def calculate_scores(y_true, y_pred):\n",
        "  rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "  #R2_score = r2_score(y_true, y_pred)\n",
        "  R = np.corrcoef(y_true, y_pred)\n",
        "  #mae = mean_absolute_error(y_true, y_pred)\n",
        "  mape = mean_absolute_percentage_error(y_true, y_pred)\n",
        "  #dic = {'rmse':rmse, 'R2_score': R2_score, 'R':R[0,1], 'mae': mae, 'mape': mape}\n",
        "  dic = {'rmse':rmse, 'R': R[0,1], 'mape': mape}\n",
        "  return (dic)\n",
        "\n",
        "\n",
        "def min_max_transform(data, feature_range=(0, 1)):\n",
        "   scaler = MinMaxScaler(feature_range)\n",
        "   return scaler.fit_transform(data)\n",
        "\n",
        "def min_max_inverse_transform(data_scaled, min_original, max_original):\n",
        "    return min_original +  data_scaled*(max_original - min_original)\n",
        "\n",
        "\n",
        "\n",
        "def write_dic_to_file(dic_name, file_name):\n",
        "  file = open(file_name, 'w')\n",
        "  file.write(str(dic_name))\n",
        "  file.close()\n",
        "\n",
        "import ast\n",
        "def read_dic_from_file(file_name):\n",
        "  file = open(file_name, \"r\")\n",
        "  contents = file.read()\n",
        "  dictionary = ast.literal_eval(contents)\n",
        "  file.close()\n",
        "  return dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teTq9ETtGLV6"
      },
      "source": [
        "#### Build the LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmLUjc_CBxoI"
      },
      "outputs": [],
      "source": [
        "def build_lstm_model(layers, optimizer = 'Adam', learning_rate = 0.001, verbose = 1):\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  for i in range(len(layers)):\n",
        "    if len(layers)==1:\n",
        "      model.add(LSTM(np.int(layers[i]), input_shape = (5, 9)))\n",
        "    else:\n",
        "      if i < len(layers)-1:\n",
        "        if i == 0:\n",
        "          model.add(LSTM(np.int(layers[i]), input_shape=(5, 9), return_sequences= True))\n",
        "          #model.add(Dropout(0.10))\n",
        "        else:\n",
        "          model.add(LSTM(np.int(layers[i]), return_sequences=True))\n",
        "          #model.add(Dropout(0.10))\n",
        "      else:\n",
        "        model.add(LSTM(np.int(layers[i])))\n",
        "        #model.add(Dropout(0.10))\n",
        "  model.add(Dense(1, activation = 'linear'))\n",
        "\n",
        "  if optimizer == 'Adam':\n",
        "    opt = optimizers.Adam(learning_rate = learning_rate)\n",
        "  elif optimizer == 'Adagrad':\n",
        "    opt = optimizers.Adagrad(learning_rate = learning_rate)\n",
        "  elif optimizer == 'Nadam':\n",
        "    opt = optimizers.Nadam(learning_rate = learning_rate)\n",
        "  elif optimizer == 'Adadelta':\n",
        "    opt = optimizers.Adadelta(learning_rate= learning_rate)\n",
        "  elif optimizer == 'RMSprop':\n",
        "    opt = optimizers.RMSprop(learning_rate= learning_rate)\n",
        "  else:\n",
        "    print(\"No optimizer found in the list(['Adam', 'Adagrad','Nadam', 'Adadelta', 'RMSprop'])! Please apply your optimizer manually...\")\n",
        "\n",
        "  model.compile(loss='mean_squared_error', optimizer= opt)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzm6tx82-rBa"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2zlQfUnB_qK",
        "outputId": "3f1f5fd9-7ad0-4160-eb85-053a1174c808"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.engine.sequential.Sequential at 0x787bb47cfb80>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "#test model on 'Adam', 'Adagrad', and 'Nadam' optimizers\n",
        "optimizers_names = ['Adam', 'Adagrad', 'Nadam']\n",
        "\n",
        "build_lstm_model([250], optimizers_names[2], 0.001, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fALL6lKZC3UT"
      },
      "outputs": [],
      "source": [
        "#perform hyperparameter tuning for neural network model\n",
        "def hyper_parameter_tuning(layers, optimizers_names, learning_rates, batch_sizes, epochs, num_replicates = 2):\n",
        "\n",
        "\n",
        "  best_avg_rmse = 99999999999\n",
        "\n",
        "  collect_rmse = []\n",
        "\n",
        "  all_avg_rmse = np.zeros((len(optimizers_names), len(learning_rates), len(batch_sizes)))\n",
        "\n",
        "  best_hyper_parameters = {\"model\": layers,\n",
        "                           \"optimizer\": None,\n",
        "                           \"learning_rate\": None,\n",
        "                           \"batch_size\": None,\n",
        "                           \"best_avg_rmse\": None}\n",
        "\n",
        "  for opt in range(len(optimizers_names)):\n",
        "\n",
        "    for lr in range(len(learning_rates)):\n",
        "\n",
        "      for batch_size in range(len(batch_sizes)):\n",
        "\n",
        "        for i in range(num_replicates):\n",
        "\n",
        "          print(\"Running for \" + optimizers_names[opt] + \" optimizer \" + str(learning_rates[lr]) +  \" learning_rate \" +  str(batch_sizes[batch_size]) + \" batch_size and \" + str(i) +  \" replicate \" +  \"\\n\")\n",
        "\n",
        "          model = build_lstm_model(layers,  optimizers_names[opt], learning_rate = learning_rates[lr], verbose = 0)\n",
        "\n",
        "          callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience= 5)\n",
        "\n",
        "          history = model.fit(X_train, y_train, batch_size = batch_sizes[batch_size], epochs= epochs, validation_data = (X_test, y_test), callbacks=[callback])\n",
        "\n",
        "\n",
        "          y_pred=model.predict(X_test)\n",
        "          collect_rmse.append(math.sqrt(mean_squared_error(y_test,y_pred)))\n",
        "\n",
        "        avg_rmse = np.mean(np.array(collect_rmse))\n",
        "        all_avg_rmse[opt][lr][batch_size] = avg_rmse\n",
        "\n",
        "        if avg_rmse < best_avg_rmse:\n",
        "          best_avg_rmse = avg_rmse\n",
        "          best_hyper_parameters = {\"model\": layers,\n",
        "                                   \"optimizer\": optimizers_names[opt],\n",
        "                                   \"learning_rate\": learning_rates[lr],\n",
        "                                   \"batch_size\": batch_sizes[batch_size],\n",
        "                                   \"best_avg_rmse\": best_avg_rmse}\n",
        "\n",
        "\n",
        "  output_dictionary = {\n",
        "      \"best_hyper_parameters\":  best_hyper_parameters,\n",
        "      \"all_avg_rmse\": all_avg_rmse\n",
        "       }\n",
        "\n",
        "  #writing output dictionary in the file\n",
        "\n",
        "  file_name = data_path+ \"sl-lstm-\" + str(layers[0])+ \"-neurons-validation_results\"+ str(time.time())+ \".txt\"\n",
        "  write_dic_to_file(output_dictionary, file_name)\n",
        "\n",
        "  print(\"Best_hyper_parameters: \\n\", output_dictionary['best_hyper_parameters'])\n",
        "  print(\"all_avg_rmse: \\n\", output_dictionary['all_avg_rmse'])\n",
        "\n",
        "  return output_dictionary['best_hyper_parameters']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUKrH1billzQ"
      },
      "source": [
        "### Case I: Tuning parameters of 8 neuron single layer LSTM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeX3OJlIGtf9",
        "outputId": "7c372e48-22cd-4973-9236-a612e6c39b45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1308966.0000 - val_loss: 3154175.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1261084.6250 - val_loss: 3141588.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1214355.0000 - val_loss: 3129306.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1168749.6250 - val_loss: 3116584.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1124226.5000 - val_loss: 3103426.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1080764.3750 - val_loss: 3090413.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1038360.8125 - val_loss: 3077481.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 996969.5000 - val_loss: 3057182.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 956619.2500 - val_loss: 3037903.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 917272.1250 - val_loss: 3016918.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 878905.8125 - val_loss: 2996217.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 841531.5000 - val_loss: 2974899.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 805122.5000 - val_loss: 2957494.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 769668.5000 - val_loss: 2941880.0000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 735154.7500 - val_loss: 2924279.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 701584.7500 - val_loss: 2910329.5000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 668953.5625 - val_loss: 2897877.5000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 637259.0000 - val_loss: 2881863.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 606501.5625 - val_loss: 2867063.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 576666.7500 - val_loss: 2851830.2500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 547758.8125 - val_loss: 2838043.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 519746.9375 - val_loss: 2825699.0000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 492620.9375 - val_loss: 2814068.7500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 466419.4375 - val_loss: 2802853.0000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 441100.9062 - val_loss: 2792547.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 416671.4375 - val_loss: 2779258.2500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 393120.3125 - val_loss: 2757064.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 370437.6250 - val_loss: 2735667.7500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 348625.2188 - val_loss: 2719862.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 327689.1562 - val_loss: 2708172.2500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 307615.2812 - val_loss: 2697839.5000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 288386.6875 - val_loss: 2687948.5000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 269993.5000 - val_loss: 2678022.0000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 252437.8750 - val_loss: 2666805.5000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 235701.5312 - val_loss: 2654606.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 219786.2188 - val_loss: 2643387.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 204699.1562 - val_loss: 2623270.5000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 190409.8750 - val_loss: 2607745.0000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 176892.3281 - val_loss: 2596274.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 164130.1406 - val_loss: 2580969.0000\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 1870577.2500 - val_loss: 3263470.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1802482.5000 - val_loss: 3255494.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1741085.8750 - val_loss: 3243339.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1682076.5000 - val_loss: 3230922.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1624852.0000 - val_loss: 3218797.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1569193.5000 - val_loss: 3203594.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1515021.0000 - val_loss: 3189941.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1462199.2500 - val_loss: 3176308.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1410673.6250 - val_loss: 3163126.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1360374.6250 - val_loss: 3148982.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1311280.1250 - val_loss: 3133941.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1263360.8750 - val_loss: 3113133.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1216603.3750 - val_loss: 3092420.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1170941.0000 - val_loss: 3072853.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1126345.1250 - val_loss: 3054934.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1082830.3750 - val_loss: 3039119.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1040389.0000 - val_loss: 3024607.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 998990.0625 - val_loss: 3010374.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 958588.3125 - val_loss: 2997008.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 919174.5625 - val_loss: 2977222.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 880773.0000 - val_loss: 2960245.2500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 843352.6250 - val_loss: 2946113.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 806896.3125 - val_loss: 2932463.7500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 771363.1875 - val_loss: 2919177.0000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 736819.6875 - val_loss: 2903439.2500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 703199.9375 - val_loss: 2885900.2500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 670544.5625 - val_loss: 2870681.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 638803.5000 - val_loss: 2857232.5000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 608002.1250 - val_loss: 2844464.0000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 578127.0625 - val_loss: 2831737.2500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 549163.4375 - val_loss: 2819457.5000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 521103.4375 - val_loss: 2807602.0000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 493953.5625 - val_loss: 2795235.7500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 467707.1250 - val_loss: 2774736.7500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 442346.0000 - val_loss: 2752485.7500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 417884.2812 - val_loss: 2734141.7500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 394289.5000 - val_loss: 2721473.0000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 371569.0000 - val_loss: 2709971.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 349724.0312 - val_loss: 2698564.0000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 328759.7188 - val_loss: 2684974.5000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 308637.2188 - val_loss: 2671747.7500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 289370.2812 - val_loss: 2660113.2500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 270941.5312 - val_loss: 2647030.2500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 253349.5000 - val_loss: 2631262.2500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 236576.7812 - val_loss: 2615858.2500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 220620.3281 - val_loss: 2601248.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 205464.2031 - val_loss: 2585357.7500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 191120.5312 - val_loss: 2569637.0000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 177556.4062 - val_loss: 2548860.2500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 164786.0156 - val_loss: 2537527.5000\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 12ms/step - loss: 1888112.2500 - val_loss: 3265499.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1846874.1250 - val_loss: 3261418.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1813361.0000 - val_loss: 3257121.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1781507.5000 - val_loss: 3252503.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1750551.8750 - val_loss: 3247877.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1720296.6250 - val_loss: 3243088.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1690584.7500 - val_loss: 3237969.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1661363.2500 - val_loss: 3232918.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1632575.3750 - val_loss: 3227835.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1604214.6250 - val_loss: 3222084.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1576244.6250 - val_loss: 3216786.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1548659.6250 - val_loss: 3211488.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1521421.7500 - val_loss: 3206069.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1494551.0000 - val_loss: 3200735.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1468031.1250 - val_loss: 3195282.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1441844.3750 - val_loss: 3190358.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1415970.6250 - val_loss: 3184941.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1390427.2500 - val_loss: 3179794.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1365197.6250 - val_loss: 3174971.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1340252.7500 - val_loss: 3169624.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1315637.3750 - val_loss: 3163358.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1291300.1250 - val_loss: 3156810.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1267257.1250 - val_loss: 3150832.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1243516.2500 - val_loss: 3145593.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1220052.0000 - val_loss: 3138745.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1196879.5000 - val_loss: 3132302.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1173993.0000 - val_loss: 3126262.7500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1151388.5000 - val_loss: 3120574.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1129037.7500 - val_loss: 3114896.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1106953.5000 - val_loss: 3108805.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1085164.5000 - val_loss: 3102565.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1063639.3750 - val_loss: 3095823.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1042373.1875 - val_loss: 3090194.0000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1021365.8125 - val_loss: 3084613.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1000611.8750 - val_loss: 3078825.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 980108.6250 - val_loss: 3072905.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 959873.7500 - val_loss: 3067107.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 939904.0625 - val_loss: 3061420.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 920167.4375 - val_loss: 3055768.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 900694.9375 - val_loss: 3050684.0000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 881468.0000 - val_loss: 3045516.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 862482.8125 - val_loss: 3040426.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 843752.6250 - val_loss: 3035308.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 825250.6875 - val_loss: 3030092.0000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 807004.5000 - val_loss: 3025253.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 788979.3750 - val_loss: 3019961.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 771221.0625 - val_loss: 3014783.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 753709.6875 - val_loss: 3009828.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 736430.2500 - val_loss: 3004669.2500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 719385.4375 - val_loss: 2999703.5000\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 11ms/step - loss: 1885906.1250 - val_loss: 3265530.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1845762.0000 - val_loss: 3261106.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1812758.2500 - val_loss: 3256293.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1781166.2500 - val_loss: 3251172.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1750382.5000 - val_loss: 3245947.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1720225.1250 - val_loss: 3240601.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1690582.8750 - val_loss: 3235039.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1661431.8750 - val_loss: 3229309.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1632718.8750 - val_loss: 3223953.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1604413.5000 - val_loss: 3218339.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1576495.0000 - val_loss: 3212815.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1548920.7500 - val_loss: 3207884.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1521730.7500 - val_loss: 3202623.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1494867.1250 - val_loss: 3197157.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1468361.5000 - val_loss: 3191702.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1442172.1250 - val_loss: 3186530.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1416301.0000 - val_loss: 3181216.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1390768.5000 - val_loss: 3176048.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1365540.5000 - val_loss: 3170804.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1340629.3750 - val_loss: 3165455.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1316007.6250 - val_loss: 3160317.2500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1291708.0000 - val_loss: 3155040.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1267670.7500 - val_loss: 3149776.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1243932.3750 - val_loss: 3144348.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1220494.5000 - val_loss: 3137668.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1197328.3750 - val_loss: 3131070.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1174427.7500 - val_loss: 3125335.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1151827.6250 - val_loss: 3119394.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1129494.5000 - val_loss: 3112534.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1107424.1250 - val_loss: 3106272.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1085619.8750 - val_loss: 3099562.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1064074.0000 - val_loss: 3094048.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1042810.6250 - val_loss: 3087635.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1021799.2500 - val_loss: 3081859.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1001046.5625 - val_loss: 3075361.7500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 980567.5000 - val_loss: 3068704.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 960322.6250 - val_loss: 3062565.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 940327.6250 - val_loss: 3056688.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 920598.6875 - val_loss: 3050657.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 901104.9375 - val_loss: 3045045.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 881861.4375 - val_loss: 3039306.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 862889.4375 - val_loss: 3033697.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 844152.7500 - val_loss: 3028167.0000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 825657.6250 - val_loss: 3022771.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 807418.3125 - val_loss: 3017448.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 789411.0000 - val_loss: 3012089.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 771642.0000 - val_loss: 3006824.5000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 754138.9375 - val_loss: 3001618.0000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 736838.8125 - val_loss: 2996422.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 719794.4375 - val_loss: 2990962.7500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 11ms/step - loss: 1883523.2500 - val_loss: 3266182.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1844047.0000 - val_loss: 3262081.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1811330.2500 - val_loss: 3257857.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1779872.7500 - val_loss: 3253411.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1749228.0000 - val_loss: 3248963.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1719157.6250 - val_loss: 3244263.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1689606.7500 - val_loss: 3239877.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1660510.1250 - val_loss: 3234936.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1631849.1250 - val_loss: 3230198.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1603577.8750 - val_loss: 3225403.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1575688.7500 - val_loss: 3220802.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1548158.3750 - val_loss: 3216309.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1520968.8750 - val_loss: 3212027.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1494151.0000 - val_loss: 3207654.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1467653.6250 - val_loss: 3202811.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1441495.2500 - val_loss: 3198188.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1415667.2500 - val_loss: 3193132.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1390147.8750 - val_loss: 3188083.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1364935.6250 - val_loss: 3183150.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1340034.2500 - val_loss: 3178175.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1315449.1250 - val_loss: 3173447.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1291154.6250 - val_loss: 3168672.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1267150.6250 - val_loss: 3163942.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1243404.8750 - val_loss: 3159293.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1219965.5000 - val_loss: 3153861.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1196789.0000 - val_loss: 3149394.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1173901.1250 - val_loss: 3143666.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1151312.1250 - val_loss: 3135225.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1128996.5000 - val_loss: 3128900.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1106953.0000 - val_loss: 3122885.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1085172.6250 - val_loss: 3116986.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1063624.8750 - val_loss: 3110592.5000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1042357.5000 - val_loss: 3103962.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1021356.1250 - val_loss: 3097567.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1000609.7500 - val_loss: 3092362.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 980126.6250 - val_loss: 3087085.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 959891.3750 - val_loss: 3081816.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 939911.6250 - val_loss: 3076196.7500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 920181.3125 - val_loss: 3069618.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 900704.8125 - val_loss: 3063024.0000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 881462.1250 - val_loss: 3056627.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 862480.0000 - val_loss: 3051130.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 843751.1250 - val_loss: 3045645.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 825268.1875 - val_loss: 3040347.0000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 807026.5000 - val_loss: 3035106.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 789025.6875 - val_loss: 3029662.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 771275.6875 - val_loss: 3024195.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 753741.9375 - val_loss: 3018885.2500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 736455.6250 - val_loss: 3013748.2500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 719409.0625 - val_loss: 3008912.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 12ms/step - loss: 1885229.1250 - val_loss: 3267024.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1845220.1250 - val_loss: 3263273.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1812255.2500 - val_loss: 3259164.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1780695.2500 - val_loss: 3254706.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1749949.1250 - val_loss: 3249904.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1719837.2500 - val_loss: 3244961.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1690242.1250 - val_loss: 3239726.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1661113.7500 - val_loss: 3234861.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1632409.8750 - val_loss: 3229979.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1604107.7500 - val_loss: 3224880.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1576160.6250 - val_loss: 3219360.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1548604.0000 - val_loss: 3214205.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1521409.1250 - val_loss: 3209412.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1494560.5000 - val_loss: 3204281.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1468050.6250 - val_loss: 3199154.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1441857.8750 - val_loss: 3193825.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1415996.1250 - val_loss: 3188911.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1390464.7500 - val_loss: 3184226.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1365259.3750 - val_loss: 3179025.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1340352.1250 - val_loss: 3174093.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1315742.0000 - val_loss: 3169657.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1291410.8750 - val_loss: 3162709.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1267402.1250 - val_loss: 3156477.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1243663.8750 - val_loss: 3151499.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1220215.3750 - val_loss: 3145906.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1197042.3750 - val_loss: 3139612.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1174161.2500 - val_loss: 3133405.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1151554.8750 - val_loss: 3127561.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1129222.8750 - val_loss: 3122172.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1107157.6250 - val_loss: 3117170.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1085366.6250 - val_loss: 3111841.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1063827.0000 - val_loss: 3106769.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1042547.3125 - val_loss: 3100582.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1021521.2500 - val_loss: 3093855.7500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1000772.0000 - val_loss: 3087685.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 980278.4375 - val_loss: 3082463.2500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 960062.2500 - val_loss: 3077148.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 940080.3125 - val_loss: 3072248.7500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 920362.5000 - val_loss: 3067339.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 900868.6875 - val_loss: 3062607.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 881634.6875 - val_loss: 3057436.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 862659.6250 - val_loss: 3050923.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 843930.8750 - val_loss: 3045344.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 825412.1250 - val_loss: 3040268.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 807167.7500 - val_loss: 3035583.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 789157.3125 - val_loss: 3030914.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 771408.1250 - val_loss: 3026465.5000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 753883.2500 - val_loss: 3022015.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 736593.6875 - val_loss: 3017504.2500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 719531.8125 - val_loss: 3012983.7500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 12ms/step - loss: 1882806.6250 - val_loss: 3268230.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1843321.3750 - val_loss: 3265018.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1810662.2500 - val_loss: 3261514.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1779269.0000 - val_loss: 3257857.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1748628.2500 - val_loss: 3254024.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1718595.5000 - val_loss: 3250019.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1689054.3750 - val_loss: 3245842.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1659960.0000 - val_loss: 3241417.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1631302.6250 - val_loss: 3236508.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1603035.3750 - val_loss: 3231726.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1575162.1250 - val_loss: 3226845.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1547625.3750 - val_loss: 3221674.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1520457.6250 - val_loss: 3216721.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1493641.7500 - val_loss: 3211609.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1467163.3750 - val_loss: 3206701.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1441017.3750 - val_loss: 3201907.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1415185.1250 - val_loss: 3196818.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1389662.3750 - val_loss: 3192125.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1364462.7500 - val_loss: 3186454.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1339572.8750 - val_loss: 3179707.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1314978.8750 - val_loss: 3173953.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1290669.6250 - val_loss: 3168535.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1266647.7500 - val_loss: 3163307.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1242931.2500 - val_loss: 3158125.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1219501.6250 - val_loss: 3153076.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1196350.8750 - val_loss: 3148145.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1173469.1250 - val_loss: 3142910.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1150860.1250 - val_loss: 3137966.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1128525.3750 - val_loss: 3133158.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1106474.0000 - val_loss: 3128282.2500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1084683.3750 - val_loss: 3123073.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1063159.8750 - val_loss: 3114946.5000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1041888.5625 - val_loss: 3108972.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1020903.3750 - val_loss: 3103975.7500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1000146.6875 - val_loss: 3099074.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 979667.1875 - val_loss: 3093820.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 959440.6875 - val_loss: 3088206.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 939476.5625 - val_loss: 3080190.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 919743.2500 - val_loss: 3074036.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 900263.1250 - val_loss: 3068028.0000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 881056.8125 - val_loss: 3063083.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 862079.1875 - val_loss: 3058030.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 843360.2500 - val_loss: 3052820.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 824888.4375 - val_loss: 3047121.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 806646.9375 - val_loss: 3040215.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 788645.0000 - val_loss: 3032885.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 770900.4375 - val_loss: 3027564.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 753395.8125 - val_loss: 3022344.0000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 736128.3125 - val_loss: 3016860.2500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 719090.5000 - val_loss: 3010930.5000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 11ms/step - loss: 1888882.8750 - val_loss: 3265462.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1848730.1250 - val_loss: 3261077.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1815452.0000 - val_loss: 3256738.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1783681.3750 - val_loss: 3252417.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1752768.6250 - val_loss: 3247613.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1722515.0000 - val_loss: 3242660.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1692791.0000 - val_loss: 3238017.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1663567.7500 - val_loss: 3232874.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1634785.8750 - val_loss: 3227355.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1606408.3750 - val_loss: 3221544.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1578418.8750 - val_loss: 3215721.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1550811.3750 - val_loss: 3210113.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1523575.2500 - val_loss: 3203210.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1496716.3750 - val_loss: 3197372.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1470183.0000 - val_loss: 3191267.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1443983.7500 - val_loss: 3184851.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1418121.1250 - val_loss: 3178808.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1392564.2500 - val_loss: 3172861.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1367321.6250 - val_loss: 3166789.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1342394.5000 - val_loss: 3160758.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1317764.0000 - val_loss: 3154510.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1293440.7500 - val_loss: 3148709.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1269390.1250 - val_loss: 3142703.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1245635.6250 - val_loss: 3137063.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1222173.8750 - val_loss: 3131532.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1198984.6250 - val_loss: 3125723.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1176059.5000 - val_loss: 3119957.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1153413.1250 - val_loss: 3114334.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1131044.1250 - val_loss: 3108605.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1108955.7500 - val_loss: 3103024.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1087134.3750 - val_loss: 3097152.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1065577.7500 - val_loss: 3091176.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1044271.6250 - val_loss: 3085011.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1023246.3125 - val_loss: 3079266.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1002473.5000 - val_loss: 3073115.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 981963.8750 - val_loss: 3067687.2500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 961709.2500 - val_loss: 3062010.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 941687.8750 - val_loss: 3056409.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 921926.0000 - val_loss: 3050881.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 902428.2500 - val_loss: 3045226.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 883172.7500 - val_loss: 3039782.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 864165.8750 - val_loss: 3034378.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 845412.6875 - val_loss: 3028445.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 826888.4375 - val_loss: 3022464.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 808607.3750 - val_loss: 3016251.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 790580.3750 - val_loss: 3009543.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 772783.1875 - val_loss: 3002911.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 755246.5000 - val_loss: 2994475.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 737943.9375 - val_loss: 2985017.2500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 720882.9375 - val_loss: 2975111.7500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 12ms/step - loss: 1885921.2500 - val_loss: 3267963.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1848011.7500 - val_loss: 3264905.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1815472.1250 - val_loss: 3261430.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1784136.0000 - val_loss: 3257629.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1753536.2500 - val_loss: 3253610.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1723499.5000 - val_loss: 3249365.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1693961.5000 - val_loss: 3245019.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1664863.3750 - val_loss: 3240652.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1636192.8750 - val_loss: 3236221.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1607893.7500 - val_loss: 3231707.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1579978.1250 - val_loss: 3227189.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1552406.8750 - val_loss: 3222368.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1525227.0000 - val_loss: 3217266.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1498388.8750 - val_loss: 3212011.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1471874.8750 - val_loss: 3206712.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1445685.7500 - val_loss: 3201111.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1419825.8750 - val_loss: 3195386.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1394262.0000 - val_loss: 3190523.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1369018.5000 - val_loss: 3185786.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1344078.3750 - val_loss: 3181100.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1319421.1250 - val_loss: 3176091.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1295084.3750 - val_loss: 3171697.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1271036.1250 - val_loss: 3166355.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1247273.3750 - val_loss: 3160035.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1223799.3750 - val_loss: 3153850.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1200596.6250 - val_loss: 3146726.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1177685.8750 - val_loss: 3139677.7500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1155028.0000 - val_loss: 3133433.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1132658.0000 - val_loss: 3128335.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1110542.6250 - val_loss: 3122883.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1088705.5000 - val_loss: 3117650.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1067143.7500 - val_loss: 3112526.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1045833.5000 - val_loss: 3107502.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1024794.6875 - val_loss: 3102344.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1004011.2500 - val_loss: 3096423.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 983477.3750 - val_loss: 3088258.2500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 963203.7500 - val_loss: 3081095.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 943183.6875 - val_loss: 3074740.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 923427.6875 - val_loss: 3069483.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 903916.6875 - val_loss: 3064430.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 884672.2500 - val_loss: 3058524.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 865640.3750 - val_loss: 3050495.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 846873.9375 - val_loss: 3043795.2500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 828339.8125 - val_loss: 3038254.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 810061.2500 - val_loss: 3032952.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 792023.5625 - val_loss: 3027606.7500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 774230.7500 - val_loss: 3022139.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 756666.4375 - val_loss: 3015494.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 739354.1250 - val_loss: 3008925.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 722291.0000 - val_loss: 3003012.0000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 12ms/step - loss: 1886860.5000 - val_loss: 3268458.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1845981.5000 - val_loss: 3265461.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1812692.0000 - val_loss: 3262263.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1780912.7500 - val_loss: 3258907.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1750011.1250 - val_loss: 3255223.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1719777.1250 - val_loss: 3250948.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1690106.7500 - val_loss: 3246476.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1660905.6250 - val_loss: 3241663.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1632159.8750 - val_loss: 3236808.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1603832.6250 - val_loss: 3232091.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1575915.6250 - val_loss: 3227279.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1548340.0000 - val_loss: 3222228.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1521142.6250 - val_loss: 3216655.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1494298.6250 - val_loss: 3210743.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1467771.0000 - val_loss: 3205290.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1441593.7500 - val_loss: 3199979.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1415731.1250 - val_loss: 3195035.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1390186.3750 - val_loss: 3189505.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1364962.2500 - val_loss: 3184145.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1340047.8750 - val_loss: 3178761.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1315444.6250 - val_loss: 3173509.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1291121.8750 - val_loss: 3167477.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1267091.2500 - val_loss: 3161642.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1243349.7500 - val_loss: 3155122.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1219888.1250 - val_loss: 3148479.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1196719.1250 - val_loss: 3139837.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1173834.5000 - val_loss: 3132789.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1151211.5000 - val_loss: 3125265.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1128875.1250 - val_loss: 3118895.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1106788.7500 - val_loss: 3112981.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1085006.2500 - val_loss: 3106428.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1063477.6250 - val_loss: 3100078.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1042215.8125 - val_loss: 3093536.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1021226.6250 - val_loss: 3087460.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1000481.4375 - val_loss: 3081544.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 979994.1875 - val_loss: 3075848.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 959751.5000 - val_loss: 3070311.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 939768.8125 - val_loss: 3064876.7500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 920036.4375 - val_loss: 3059540.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 900556.0000 - val_loss: 3053911.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 881315.0625 - val_loss: 3048738.2500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 862328.0625 - val_loss: 3043728.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 843595.2500 - val_loss: 3038668.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 825097.3125 - val_loss: 3033779.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 806847.3750 - val_loss: 3028852.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 788834.3750 - val_loss: 3023982.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 771067.4375 - val_loss: 3018775.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 753546.2500 - val_loss: 3013698.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 736282.5625 - val_loss: 3008182.2500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 719243.1250 - val_loss: 3002103.7500\n",
            "7/7 [==============================] - 1s 3ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 9s 13ms/step - loss: 1884527.5000 - val_loss: 3264947.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1844177.8750 - val_loss: 3262265.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1811200.7500 - val_loss: 3259602.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1779638.2500 - val_loss: 3256154.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1748898.2500 - val_loss: 3252370.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1718763.1250 - val_loss: 3248263.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1689167.1250 - val_loss: 3244146.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1660040.0000 - val_loss: 3239558.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1631343.0000 - val_loss: 3234916.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1603045.6250 - val_loss: 3229927.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1575138.0000 - val_loss: 3224795.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1547568.8750 - val_loss: 3219607.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1520360.0000 - val_loss: 3213803.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1493527.7500 - val_loss: 3207937.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1467044.2500 - val_loss: 3202295.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1440867.5000 - val_loss: 3195982.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1415035.8750 - val_loss: 3190726.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1389515.1250 - val_loss: 3184618.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1364315.2500 - val_loss: 3179120.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1339408.2500 - val_loss: 3173467.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1314804.3750 - val_loss: 3167970.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1290500.2500 - val_loss: 3162831.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1266498.1250 - val_loss: 3157464.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1242781.1250 - val_loss: 3152001.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1219350.5000 - val_loss: 3146364.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1196198.6250 - val_loss: 3139277.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1173316.3750 - val_loss: 3133397.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1150729.3750 - val_loss: 3127257.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1128398.7500 - val_loss: 3121213.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1106328.6250 - val_loss: 3114620.2500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1084544.1250 - val_loss: 3108304.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1063023.8750 - val_loss: 3101668.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1041778.0625 - val_loss: 3095813.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1020777.6250 - val_loss: 3089937.7500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1000031.3125 - val_loss: 3083800.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 979557.6875 - val_loss: 3078194.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 959350.8125 - val_loss: 3071483.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 939382.9375 - val_loss: 3064840.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 919656.9375 - val_loss: 3058632.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 900190.0625 - val_loss: 3052865.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 880970.0000 - val_loss: 3047461.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 861986.6875 - val_loss: 3042171.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 843254.1250 - val_loss: 3036888.0000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 824769.5000 - val_loss: 3031818.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 806547.0625 - val_loss: 3025989.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 788545.0625 - val_loss: 3019770.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 770789.7500 - val_loss: 3012709.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 753261.5000 - val_loss: 3007644.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 735972.5625 - val_loss: 3002761.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 718912.8125 - val_loss: 2997816.7500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 15ms/step - loss: 1884152.0000 - val_loss: 3266488.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1843390.0000 - val_loss: 3261784.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1810387.5000 - val_loss: 3256592.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1778802.2500 - val_loss: 3251420.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1748034.0000 - val_loss: 3246144.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1717909.7500 - val_loss: 3240932.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1688320.6250 - val_loss: 3236079.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1659188.6250 - val_loss: 3231232.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1630498.6250 - val_loss: 3226317.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1602200.2500 - val_loss: 3221696.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1574292.5000 - val_loss: 3217138.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1546752.0000 - val_loss: 3212351.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1519577.8750 - val_loss: 3207805.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1492732.6250 - val_loss: 3202656.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1466253.1250 - val_loss: 3197835.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1440104.6250 - val_loss: 3192823.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1414268.7500 - val_loss: 3188097.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1388771.6250 - val_loss: 3182886.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1363569.1250 - val_loss: 3177974.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1338669.3750 - val_loss: 3172570.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1314075.5000 - val_loss: 3166961.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1289783.8750 - val_loss: 3160280.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1265765.0000 - val_loss: 3154191.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1242058.6250 - val_loss: 3148617.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1218634.8750 - val_loss: 3142535.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1195469.8750 - val_loss: 3135781.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1172607.7500 - val_loss: 3129730.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1150016.8750 - val_loss: 3123855.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1127706.1250 - val_loss: 3118393.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1105662.2500 - val_loss: 3112227.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1083869.0000 - val_loss: 3106353.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1062356.5000 - val_loss: 3100615.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1041112.2500 - val_loss: 3094403.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1020126.0000 - val_loss: 3088800.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 999398.4375 - val_loss: 3083457.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 978935.4375 - val_loss: 3078273.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 958705.0625 - val_loss: 3072991.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 938736.6875 - val_loss: 3067862.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 919013.5625 - val_loss: 3062770.2500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 899528.5000 - val_loss: 3057428.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 880296.2500 - val_loss: 3052376.2500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 861331.0625 - val_loss: 3047017.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 842628.0000 - val_loss: 3042018.2500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 824149.7500 - val_loss: 3036682.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 805921.0625 - val_loss: 3030917.2500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 787924.6875 - val_loss: 3025186.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 770184.4375 - val_loss: 3018702.5000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 752664.5000 - val_loss: 3011982.0000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 735392.1250 - val_loss: 3005403.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 718359.1250 - val_loss: 2997525.5000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 25ms/step - loss: 1896867.3750 - val_loss: 3269232.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1871570.8750 - val_loss: 3267399.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1853388.7500 - val_loss: 3265493.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1836407.0000 - val_loss: 3263500.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1819971.8750 - val_loss: 3261470.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1803865.6250 - val_loss: 3259379.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1788026.1250 - val_loss: 3257297.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1772392.8750 - val_loss: 3255149.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1756923.0000 - val_loss: 3253021.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1741598.3750 - val_loss: 3250880.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1726404.0000 - val_loss: 3248669.0000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1711340.5000 - val_loss: 3246489.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1696415.2500 - val_loss: 3244304.2500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1681613.0000 - val_loss: 3242030.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1666953.1250 - val_loss: 3239886.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1652370.8750 - val_loss: 3237667.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1637904.3750 - val_loss: 3235458.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1623533.8750 - val_loss: 3233221.2500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1609249.2500 - val_loss: 3230859.2500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1595101.0000 - val_loss: 3228433.5000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1581016.0000 - val_loss: 3226078.5000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1567042.6250 - val_loss: 3223785.7500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1553158.2500 - val_loss: 3221283.0000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1539347.0000 - val_loss: 3218908.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1525634.1250 - val_loss: 3216453.0000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1511988.8750 - val_loss: 3214196.2500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1498459.7500 - val_loss: 3211625.7500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1484997.2500 - val_loss: 3209308.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1471621.8750 - val_loss: 3206830.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1458344.0000 - val_loss: 3204146.5000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1445144.6250 - val_loss: 3201570.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1432047.5000 - val_loss: 3198920.5000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1419003.1250 - val_loss: 3196371.2500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1406038.5000 - val_loss: 3193989.2500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1393177.8750 - val_loss: 3191594.7500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1380399.8750 - val_loss: 3189317.5000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1367697.6250 - val_loss: 3186862.0000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1355075.2500 - val_loss: 3184314.2500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1342531.0000 - val_loss: 3181900.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1330048.2500 - val_loss: 3179620.5000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1317652.6250 - val_loss: 3177145.2500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1305339.5000 - val_loss: 3174884.5000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1293093.5000 - val_loss: 3172555.7500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1280887.1250 - val_loss: 3170007.0000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1268805.8750 - val_loss: 3167667.5000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1256777.7500 - val_loss: 3164700.7500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1244834.8750 - val_loss: 3162299.0000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1232953.6250 - val_loss: 3159964.5000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1221145.1250 - val_loss: 3157249.2500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1209395.0000 - val_loss: 3154193.2500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 23ms/step - loss: 1898747.1250 - val_loss: 3267409.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1874002.2500 - val_loss: 3265164.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1855653.2500 - val_loss: 3262847.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1838569.0000 - val_loss: 3260614.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1822068.8750 - val_loss: 3258346.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1805936.8750 - val_loss: 3256084.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1790067.1250 - val_loss: 3253676.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1774391.0000 - val_loss: 3251322.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1758911.8750 - val_loss: 3248951.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1743594.6250 - val_loss: 3246677.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1728406.0000 - val_loss: 3244078.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1713338.5000 - val_loss: 3241702.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1698386.5000 - val_loss: 3239039.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1683551.7500 - val_loss: 3236640.5000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1668863.5000 - val_loss: 3234137.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1654276.8750 - val_loss: 3231667.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1639790.3750 - val_loss: 3229024.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1625391.1250 - val_loss: 3226717.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1611119.0000 - val_loss: 3224135.0000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1596927.1250 - val_loss: 3221661.5000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1582837.6250 - val_loss: 3219204.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1568808.8750 - val_loss: 3216727.5000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1554901.1250 - val_loss: 3214253.7500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1541090.0000 - val_loss: 3211912.0000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1527382.3750 - val_loss: 3209472.5000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1513706.1250 - val_loss: 3206769.2500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1500173.3750 - val_loss: 3204295.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1486735.1250 - val_loss: 3201834.0000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1473348.5000 - val_loss: 3199203.7500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1460049.5000 - val_loss: 3197169.0000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1446848.1250 - val_loss: 3194402.5000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1433734.6250 - val_loss: 3192093.5000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1420673.1250 - val_loss: 3189696.0000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1407741.1250 - val_loss: 3187167.0000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1394852.8750 - val_loss: 3184604.5000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1382066.8750 - val_loss: 3181842.7500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1369343.3750 - val_loss: 3179181.2500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1356705.5000 - val_loss: 3176543.5000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1344135.6250 - val_loss: 3173421.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1331637.3750 - val_loss: 3170232.2500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1319229.2500 - val_loss: 3166666.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1306891.0000 - val_loss: 3163168.2500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1294631.2500 - val_loss: 3159964.7500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1282429.5000 - val_loss: 3157508.2500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1270300.5000 - val_loss: 3154054.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1258277.1250 - val_loss: 3150925.2500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1246305.7500 - val_loss: 3148294.0000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1234394.2500 - val_loss: 3145173.2500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1222575.2500 - val_loss: 3142516.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1210836.8750 - val_loss: 3139349.7500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 18ms/step - loss: 1899365.6250 - val_loss: 3269317.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1874362.0000 - val_loss: 3268032.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1855776.8750 - val_loss: 3266515.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1838562.1250 - val_loss: 3264872.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1821992.0000 - val_loss: 3263094.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1805808.7500 - val_loss: 3261185.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1789853.1250 - val_loss: 3259182.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1774144.7500 - val_loss: 3257102.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1758614.2500 - val_loss: 3254963.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1743249.1250 - val_loss: 3252774.5000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1728025.7500 - val_loss: 3250501.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1712973.0000 - val_loss: 3248231.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1698046.6250 - val_loss: 3245788.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1683222.8750 - val_loss: 3243432.7500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1668518.1250 - val_loss: 3241029.7500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1653927.0000 - val_loss: 3238596.0000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1639428.6250 - val_loss: 3236186.7500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1625030.7500 - val_loss: 3233778.2500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1610756.8750 - val_loss: 3231277.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1596596.5000 - val_loss: 3228903.0000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1582507.6250 - val_loss: 3226374.0000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1568514.1250 - val_loss: 3224050.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1554591.2500 - val_loss: 3221452.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1540772.6250 - val_loss: 3218930.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1527042.1250 - val_loss: 3216361.2500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1513397.2500 - val_loss: 3213890.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1499852.1250 - val_loss: 3211413.7500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1486404.7500 - val_loss: 3209082.5000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1473026.5000 - val_loss: 3206741.5000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1459720.7500 - val_loss: 3204414.5000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1446536.1250 - val_loss: 3202080.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1433406.0000 - val_loss: 3199781.0000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1420370.3750 - val_loss: 3197501.7500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1407392.5000 - val_loss: 3195227.0000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1394521.6250 - val_loss: 3192940.7500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1381728.6250 - val_loss: 3190674.2500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1368989.0000 - val_loss: 3188411.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1356354.7500 - val_loss: 3186165.5000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1343795.5000 - val_loss: 3183939.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1331308.7500 - val_loss: 3181697.5000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1318888.6250 - val_loss: 3179461.5000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1306553.6250 - val_loss: 3177195.5000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1294274.2500 - val_loss: 3174956.5000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1282089.3750 - val_loss: 3172486.7500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1269981.7500 - val_loss: 3169818.7500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1257946.0000 - val_loss: 3167461.2500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1245980.3750 - val_loss: 3164812.5000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1234090.6250 - val_loss: 3161689.5000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1222282.3750 - val_loss: 3159285.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1210509.2500 - val_loss: 3157026.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 19ms/step - loss: 1899378.2500 - val_loss: 3268227.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1874383.5000 - val_loss: 3265367.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1854774.8750 - val_loss: 3263349.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1837155.0000 - val_loss: 3261487.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1820329.6250 - val_loss: 3259755.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1803962.3750 - val_loss: 3258079.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1787933.0000 - val_loss: 3256362.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1772126.8750 - val_loss: 3254486.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1756542.0000 - val_loss: 3252514.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1741127.3750 - val_loss: 3250349.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1725881.7500 - val_loss: 3248208.5000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1710730.3750 - val_loss: 3246139.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1695731.7500 - val_loss: 3243962.2500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1680858.3750 - val_loss: 3241596.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1666138.1250 - val_loss: 3239394.2500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1651517.5000 - val_loss: 3237115.0000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1636998.1250 - val_loss: 3234782.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1622626.8750 - val_loss: 3232530.7500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1608344.6250 - val_loss: 3230020.5000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1594148.7500 - val_loss: 3227755.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1580052.6250 - val_loss: 3225450.5000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1566058.6250 - val_loss: 3223312.2500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1552153.6250 - val_loss: 3221024.2500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1538321.8750 - val_loss: 3218757.2500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1524582.6250 - val_loss: 3216481.0000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1510943.3750 - val_loss: 3214181.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1497394.5000 - val_loss: 3211868.7500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1483957.6250 - val_loss: 3209459.5000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1470608.5000 - val_loss: 3207164.7500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1457310.3750 - val_loss: 3204794.2500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1444085.8750 - val_loss: 3202384.5000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1430969.7500 - val_loss: 3200075.2500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1417953.3750 - val_loss: 3197514.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1405012.6250 - val_loss: 3194726.2500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1392157.5000 - val_loss: 3191845.7500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1379341.0000 - val_loss: 3189135.2500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1366627.8750 - val_loss: 3186420.2500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1354004.0000 - val_loss: 3183108.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1341436.0000 - val_loss: 3180146.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1328957.7500 - val_loss: 3177181.5000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1316551.0000 - val_loss: 3174489.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1304224.0000 - val_loss: 3171488.2500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1291962.1250 - val_loss: 3168082.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1279794.8750 - val_loss: 3164947.5000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1267702.3750 - val_loss: 3162055.7500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1255678.7500 - val_loss: 3158884.5000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1243703.5000 - val_loss: 3156171.7500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1231813.5000 - val_loss: 3153644.7500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1220011.7500 - val_loss: 3150987.7500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1208268.2500 - val_loss: 3148369.5000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 18ms/step - loss: 1899495.3750 - val_loss: 3268028.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1876369.1250 - val_loss: 3266166.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1857985.3750 - val_loss: 3264246.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1840923.8750 - val_loss: 3262284.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1824404.2500 - val_loss: 3260286.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1808248.0000 - val_loss: 3258243.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1792347.8750 - val_loss: 3256174.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1776667.2500 - val_loss: 3254096.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1761166.2500 - val_loss: 3252003.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1745800.7500 - val_loss: 3249874.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1730589.1250 - val_loss: 3247734.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1715513.3750 - val_loss: 3245603.2500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1700577.6250 - val_loss: 3243467.2500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1685766.2500 - val_loss: 3241252.7500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1671078.3750 - val_loss: 3239131.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1656471.7500 - val_loss: 3236942.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1641979.1250 - val_loss: 3234814.5000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1627582.1250 - val_loss: 3232616.7500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1613286.6250 - val_loss: 3230448.0000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1599120.8750 - val_loss: 3228290.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1585029.3750 - val_loss: 3226078.5000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1571017.6250 - val_loss: 3223836.2500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1557103.6250 - val_loss: 3221458.7500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1543297.1250 - val_loss: 3219019.7500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1529566.8750 - val_loss: 3216464.7500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1515927.8750 - val_loss: 3213931.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1502381.3750 - val_loss: 3211569.0000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1488912.2500 - val_loss: 3208979.5000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1475548.3750 - val_loss: 3206534.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1462245.0000 - val_loss: 3204081.2500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1449044.3750 - val_loss: 3201363.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1435895.2500 - val_loss: 3198523.0000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1422833.5000 - val_loss: 3195824.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1409845.2500 - val_loss: 3193010.2500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1396956.5000 - val_loss: 3190557.5000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1384135.2500 - val_loss: 3187969.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1371400.2500 - val_loss: 3185489.2500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1358722.1250 - val_loss: 3183155.2500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1346129.0000 - val_loss: 3180669.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1333618.6250 - val_loss: 3178205.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1321186.2500 - val_loss: 3175975.5000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1308843.1250 - val_loss: 3173265.5000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1296568.2500 - val_loss: 3170826.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1284380.3750 - val_loss: 3168434.5000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1272273.1250 - val_loss: 3166110.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1260216.5000 - val_loss: 3163821.7500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1248229.3750 - val_loss: 3161627.7500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1236338.6250 - val_loss: 3159257.0000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1224513.8750 - val_loss: 3156873.2500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1212760.7500 - val_loss: 3154572.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 16ms/step - loss: 1898871.2500 - val_loss: 3269762.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1872797.5000 - val_loss: 3268176.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1854259.0000 - val_loss: 3266705.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1837094.2500 - val_loss: 3265144.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1820537.2500 - val_loss: 3263540.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1804334.5000 - val_loss: 3261826.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1788427.1250 - val_loss: 3260080.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1772725.6250 - val_loss: 3258275.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1757213.3750 - val_loss: 3256388.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1741851.3750 - val_loss: 3254471.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1726669.8750 - val_loss: 3252415.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1711598.3750 - val_loss: 3250344.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1696663.8750 - val_loss: 3248218.2500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1681857.8750 - val_loss: 3246037.5000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1667146.6250 - val_loss: 3243935.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1652564.5000 - val_loss: 3241664.2500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1638071.8750 - val_loss: 3239463.0000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1623720.2500 - val_loss: 3237212.7500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1609462.6250 - val_loss: 3234924.5000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1595248.7500 - val_loss: 3232688.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1581144.5000 - val_loss: 3230381.0000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1567142.1250 - val_loss: 3228000.5000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1553246.8750 - val_loss: 3225631.0000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1539443.0000 - val_loss: 3223271.2500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1525730.8750 - val_loss: 3220807.0000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1512115.1250 - val_loss: 3218396.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1498559.7500 - val_loss: 3216064.0000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1485127.0000 - val_loss: 3213719.0000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1471744.2500 - val_loss: 3211322.7500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1458450.5000 - val_loss: 3209011.7500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1445270.5000 - val_loss: 3206468.5000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1432193.3750 - val_loss: 3203835.0000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1419165.3750 - val_loss: 3201252.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1406202.3750 - val_loss: 3198886.5000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1393334.5000 - val_loss: 3196243.5000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1380524.2500 - val_loss: 3193678.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1367797.6250 - val_loss: 3191323.2500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1355161.0000 - val_loss: 3189014.7500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1342599.6250 - val_loss: 3186727.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1330087.7500 - val_loss: 3184439.5000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1317679.8750 - val_loss: 3182185.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1305336.3750 - val_loss: 3179898.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1293082.0000 - val_loss: 3177673.5000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1280886.8750 - val_loss: 3175446.7500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1268799.8750 - val_loss: 3173206.2500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1256774.2500 - val_loss: 3170987.2500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1244845.1250 - val_loss: 3168698.7500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1232961.0000 - val_loss: 3166212.5000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1221139.8750 - val_loss: 3163727.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1209419.5000 - val_loss: 3161554.0000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 17ms/step - loss: 1897393.1250 - val_loss: 3269603.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1871922.8750 - val_loss: 3267908.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1853697.2500 - val_loss: 3266175.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1836687.8750 - val_loss: 3264358.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1820230.6250 - val_loss: 3262474.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1804108.5000 - val_loss: 3260528.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1788227.6250 - val_loss: 3258531.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1772579.5000 - val_loss: 3256493.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1757098.3750 - val_loss: 3254396.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1741783.7500 - val_loss: 3252296.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1726616.7500 - val_loss: 3250151.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1711593.5000 - val_loss: 3248001.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1696667.1250 - val_loss: 3245843.2500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1681843.5000 - val_loss: 3243680.5000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1667143.2500 - val_loss: 3241509.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1652553.3750 - val_loss: 3239330.0000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1638086.7500 - val_loss: 3237120.0000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1623716.2500 - val_loss: 3234933.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1609452.1250 - val_loss: 3232728.5000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1595296.0000 - val_loss: 3230535.0000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1581216.0000 - val_loss: 3228362.0000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1567240.8750 - val_loss: 3226162.5000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1553343.7500 - val_loss: 3223963.2500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1539528.1250 - val_loss: 3221754.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1525825.6250 - val_loss: 3219536.5000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1512211.1250 - val_loss: 3217229.2500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1498686.5000 - val_loss: 3214831.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1485242.5000 - val_loss: 3212323.0000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1471885.7500 - val_loss: 3209642.5000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1458624.0000 - val_loss: 3206920.0000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1445421.6250 - val_loss: 3204472.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1432310.8750 - val_loss: 3202143.0000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1419268.0000 - val_loss: 3199572.0000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1406340.2500 - val_loss: 3197219.7500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1393452.8750 - val_loss: 3194737.5000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1380667.0000 - val_loss: 3191688.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1367973.0000 - val_loss: 3188794.0000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1355336.1250 - val_loss: 3186217.7500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1342773.3750 - val_loss: 3183516.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1330269.2500 - val_loss: 3180571.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1317840.2500 - val_loss: 3177868.2500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1305520.8750 - val_loss: 3175441.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1293235.5000 - val_loss: 3172915.7500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1281061.1250 - val_loss: 3170521.0000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1268973.3750 - val_loss: 3168021.2500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1256965.5000 - val_loss: 3165662.0000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1244994.6250 - val_loss: 3163356.5000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1233126.2500 - val_loss: 3161050.7500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1221312.2500 - val_loss: 3158769.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1209560.5000 - val_loss: 3156460.7500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 17ms/step - loss: 1897685.3750 - val_loss: 3268763.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1873231.1250 - val_loss: 3266504.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1855037.3750 - val_loss: 3264393.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1838039.3750 - val_loss: 3262261.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1821587.8750 - val_loss: 3260077.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1805473.1250 - val_loss: 3257886.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1789610.7500 - val_loss: 3255689.7500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1773979.7500 - val_loss: 3253426.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1758531.5000 - val_loss: 3251187.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1743225.7500 - val_loss: 3248927.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1728072.1250 - val_loss: 3246667.0000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1713012.8750 - val_loss: 3244445.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1698095.2500 - val_loss: 3242188.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1683289.7500 - val_loss: 3239938.5000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1668600.6250 - val_loss: 3237715.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1654026.7500 - val_loss: 3235433.2500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1639546.6250 - val_loss: 3233202.5000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1625184.5000 - val_loss: 3230956.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1610884.1250 - val_loss: 3228697.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1596701.7500 - val_loss: 3226465.0000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1582628.7500 - val_loss: 3224217.0000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1568620.2500 - val_loss: 3221928.7500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1554727.2500 - val_loss: 3219685.7500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1540932.6250 - val_loss: 3217429.2500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1527204.6250 - val_loss: 3215176.0000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1513586.6250 - val_loss: 3212909.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1500035.3750 - val_loss: 3210670.0000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1486602.2500 - val_loss: 3208420.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1473220.1250 - val_loss: 3206193.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1459934.1250 - val_loss: 3203968.0000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1446742.3750 - val_loss: 3201758.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1433622.2500 - val_loss: 3199548.0000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1420578.2500 - val_loss: 3197242.2500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1407621.2500 - val_loss: 3194722.0000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1394749.5000 - val_loss: 3192320.2500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1381967.1250 - val_loss: 3189116.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1369246.1250 - val_loss: 3186869.5000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1356589.0000 - val_loss: 3183970.2500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1344026.7500 - val_loss: 3181391.5000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1331534.2500 - val_loss: 3179085.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1319119.1250 - val_loss: 3176730.0000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1306797.8750 - val_loss: 3174487.5000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1294511.2500 - val_loss: 3172240.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1282334.1250 - val_loss: 3169839.2500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1270223.5000 - val_loss: 3167247.2500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1258182.3750 - val_loss: 3164117.7500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1246220.2500 - val_loss: 3160645.2500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1234296.1250 - val_loss: 3158068.7500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1222472.6250 - val_loss: 3155364.2500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1210733.3750 - val_loss: 3152367.2500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 17ms/step - loss: 1897873.2500 - val_loss: 3267580.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1870011.0000 - val_loss: 3265233.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1851264.5000 - val_loss: 3262892.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1834013.7500 - val_loss: 3260611.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1817419.3750 - val_loss: 3258430.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1801218.2500 - val_loss: 3256395.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1785271.7500 - val_loss: 3254361.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1769570.6250 - val_loss: 3252276.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1754025.6250 - val_loss: 3250114.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1738664.6250 - val_loss: 3247994.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1723445.3750 - val_loss: 3245956.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1708394.7500 - val_loss: 3243768.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1693456.1250 - val_loss: 3241586.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1678632.6250 - val_loss: 3239527.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1663927.8750 - val_loss: 3237210.2500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1649327.0000 - val_loss: 3234977.0000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1634853.8750 - val_loss: 3232643.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1620502.0000 - val_loss: 3230205.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1606228.3750 - val_loss: 3227996.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1592051.8750 - val_loss: 3225504.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1577959.0000 - val_loss: 3223318.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1563966.0000 - val_loss: 3220999.7500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1550073.3750 - val_loss: 3218621.0000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1536273.0000 - val_loss: 3216325.2500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1522572.7500 - val_loss: 3213915.2500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1508933.6250 - val_loss: 3211482.2500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1495404.1250 - val_loss: 3209105.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1481979.7500 - val_loss: 3206687.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1468622.3750 - val_loss: 3204383.7500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1455349.3750 - val_loss: 3202071.5000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1442170.1250 - val_loss: 3199349.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1429085.0000 - val_loss: 3196986.7500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1416076.0000 - val_loss: 3194457.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1403129.7500 - val_loss: 3192201.5000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1390263.2500 - val_loss: 3189519.0000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1377492.8750 - val_loss: 3186750.7500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1364783.2500 - val_loss: 3184354.0000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1352138.7500 - val_loss: 3181591.2500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1339603.5000 - val_loss: 3178988.5000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1327139.5000 - val_loss: 3176430.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1314753.8750 - val_loss: 3173864.0000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1302441.1250 - val_loss: 3171422.2500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1290199.3750 - val_loss: 3168879.7500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1278015.7500 - val_loss: 3166511.5000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1265925.6250 - val_loss: 3164072.5000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1253902.8750 - val_loss: 3161612.2500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1241962.1250 - val_loss: 3159282.2500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1230043.7500 - val_loss: 3156916.0000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1218258.5000 - val_loss: 3154532.5000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1206554.1250 - val_loss: 3152243.2500\n",
            "7/7 [==============================] - 1s 3ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 16ms/step - loss: 1898134.3750 - val_loss: 3268931.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1872362.6250 - val_loss: 3266931.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1853962.2500 - val_loss: 3265056.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1836873.5000 - val_loss: 3263085.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1820373.3750 - val_loss: 3261028.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1804203.0000 - val_loss: 3258905.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1788317.3750 - val_loss: 3256740.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1772607.2500 - val_loss: 3254609.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1757100.5000 - val_loss: 3252398.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1741756.3750 - val_loss: 3250137.5000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1726560.5000 - val_loss: 3247829.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1711480.0000 - val_loss: 3245577.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1696530.8750 - val_loss: 3243294.2500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1681732.2500 - val_loss: 3240931.5000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1667053.8750 - val_loss: 3238551.2500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1652481.6250 - val_loss: 3236201.0000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1637992.6250 - val_loss: 3233879.0000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1623593.1250 - val_loss: 3231527.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1609283.6250 - val_loss: 3229162.2500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1595097.0000 - val_loss: 3226716.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1581013.2500 - val_loss: 3224274.0000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1567019.7500 - val_loss: 3221904.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1553134.8750 - val_loss: 3219514.0000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1539347.6250 - val_loss: 3217115.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1525634.6250 - val_loss: 3214794.0000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1512033.3750 - val_loss: 3212177.5000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1498504.8750 - val_loss: 3209834.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1485031.5000 - val_loss: 3207441.5000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1471678.8750 - val_loss: 3204856.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1458410.6250 - val_loss: 3202387.2500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1445211.0000 - val_loss: 3200002.7500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1432091.0000 - val_loss: 3197326.7500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1419058.5000 - val_loss: 3194852.7500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1406084.8750 - val_loss: 3192371.7500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1393219.2500 - val_loss: 3189733.2500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1380425.0000 - val_loss: 3187283.5000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1367703.0000 - val_loss: 3184736.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1355076.2500 - val_loss: 3182290.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1342520.5000 - val_loss: 3179903.5000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1329996.1250 - val_loss: 3177528.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1317569.1250 - val_loss: 3174963.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1305232.3750 - val_loss: 3172494.0000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1292959.5000 - val_loss: 3170037.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1280784.1250 - val_loss: 3167352.7500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1268679.2500 - val_loss: 3164768.5000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1256672.0000 - val_loss: 3162135.2500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1244717.0000 - val_loss: 3159328.2500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1232852.0000 - val_loss: 3157023.7500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1221049.3750 - val_loss: 3154523.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1209325.7500 - val_loss: 3152067.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 8ms/step - loss: 1906478.7500 - val_loss: 3269616.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1893381.6250 - val_loss: 3269539.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1880829.5000 - val_loss: 3268863.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1872957.0000 - val_loss: 3268149.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1865840.5000 - val_loss: 3267388.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1859061.1250 - val_loss: 3266580.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1852478.0000 - val_loss: 3265705.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1846020.1250 - val_loss: 3264801.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1839655.6250 - val_loss: 3263837.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1833355.1250 - val_loss: 3262836.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1827110.0000 - val_loss: 3261807.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1820906.6250 - val_loss: 3260728.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1814738.6250 - val_loss: 3259617.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1808602.7500 - val_loss: 3258440.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1802495.3750 - val_loss: 3257297.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1796411.2500 - val_loss: 3256054.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1790349.3750 - val_loss: 3254804.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1784302.5000 - val_loss: 3253528.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1778272.5000 - val_loss: 3252161.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1772260.1250 - val_loss: 3250809.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1766262.6250 - val_loss: 3249364.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1760279.3750 - val_loss: 3247899.5000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1754308.6250 - val_loss: 3246472.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1748350.3750 - val_loss: 3244874.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1742405.5000 - val_loss: 3243358.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1736469.7500 - val_loss: 3241902.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1730547.5000 - val_loss: 3240434.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1724636.6250 - val_loss: 3238964.7500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1718735.5000 - val_loss: 3237471.0000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1712847.7500 - val_loss: 3236036.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1706971.7500 - val_loss: 3234557.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1701106.2500 - val_loss: 3233101.2500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1695250.6250 - val_loss: 3231602.0000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1689406.7500 - val_loss: 3230045.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1683571.8750 - val_loss: 3228531.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1677751.2500 - val_loss: 3227007.5000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1671941.8750 - val_loss: 3225440.2500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1666141.2500 - val_loss: 3223810.7500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1660349.2500 - val_loss: 3222234.2500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1654569.0000 - val_loss: 3220626.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1648799.1250 - val_loss: 3218993.0000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1643038.7500 - val_loss: 3217228.7500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1637293.3750 - val_loss: 3215365.5000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1631555.3750 - val_loss: 3213600.7500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1625829.2500 - val_loss: 3211828.0000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1620112.7500 - val_loss: 3210026.7500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1614407.3750 - val_loss: 3208189.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1608713.0000 - val_loss: 3206367.7500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1603029.0000 - val_loss: 3204454.2500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1597353.7500 - val_loss: 3202091.5000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 7ms/step - loss: 1906062.1250 - val_loss: 3269660.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1890163.0000 - val_loss: 3269388.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1879341.0000 - val_loss: 3268521.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1871746.0000 - val_loss: 3267715.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1864763.1250 - val_loss: 3266884.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1858064.7500 - val_loss: 3266009.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1851537.7500 - val_loss: 3265112.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1845123.3750 - val_loss: 3264186.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1838785.5000 - val_loss: 3263209.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1832510.0000 - val_loss: 3262220.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1826284.0000 - val_loss: 3261200.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1820098.2500 - val_loss: 3260147.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1813947.1250 - val_loss: 3259069.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1807820.1250 - val_loss: 3257948.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1801717.7500 - val_loss: 3256820.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1795641.0000 - val_loss: 3255609.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1789583.7500 - val_loss: 3254381.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1783543.3750 - val_loss: 3253109.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1777515.3750 - val_loss: 3251792.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1771502.3750 - val_loss: 3250441.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1765508.2500 - val_loss: 3249038.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1759527.6250 - val_loss: 3247553.0000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1753560.7500 - val_loss: 3246104.7500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1747603.1250 - val_loss: 3244611.2500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1741659.1250 - val_loss: 3243079.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1735729.2500 - val_loss: 3241479.2500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1729806.8750 - val_loss: 3239936.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1723896.5000 - val_loss: 3238358.0000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1717998.7500 - val_loss: 3236696.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1712111.6250 - val_loss: 3235110.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1706237.5000 - val_loss: 3233499.7500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1700372.5000 - val_loss: 3231930.2500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1694519.2500 - val_loss: 3230332.0000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1688677.3750 - val_loss: 3228797.7500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1682847.1250 - val_loss: 3227329.0000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1677026.5000 - val_loss: 3225853.7500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1671217.5000 - val_loss: 3224346.2500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1665418.7500 - val_loss: 3222888.7500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1659629.5000 - val_loss: 3221437.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1653849.2500 - val_loss: 3219976.2500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1648083.1250 - val_loss: 3218523.5000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1642328.7500 - val_loss: 3217091.2500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1636582.6250 - val_loss: 3215648.7500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1630844.6250 - val_loss: 3214115.0000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1625115.7500 - val_loss: 3212563.2500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1619401.1250 - val_loss: 3210982.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1613699.3750 - val_loss: 3209319.2500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1608004.6250 - val_loss: 3207645.0000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1602321.2500 - val_loss: 3205879.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1596648.2500 - val_loss: 3204056.7500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 9ms/step - loss: 1906500.5000 - val_loss: 3268037.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1893577.5000 - val_loss: 3268460.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1881828.6250 - val_loss: 3267485.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1873940.6250 - val_loss: 3266582.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1866835.1250 - val_loss: 3265703.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1860066.0000 - val_loss: 3264808.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1853484.2500 - val_loss: 3263908.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1847032.3750 - val_loss: 3262997.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1840671.5000 - val_loss: 3262073.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1834376.8750 - val_loss: 3261140.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1828135.0000 - val_loss: 3260174.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1821936.3750 - val_loss: 3259192.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1815771.5000 - val_loss: 3258179.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1809636.5000 - val_loss: 3257150.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1803527.0000 - val_loss: 3256077.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1797439.8750 - val_loss: 3254973.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1791375.5000 - val_loss: 3253851.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1785328.5000 - val_loss: 3252669.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1779299.5000 - val_loss: 3251481.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1773281.8750 - val_loss: 3250265.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1767281.6250 - val_loss: 3249000.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1761296.5000 - val_loss: 3247675.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1755322.7500 - val_loss: 3246245.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1749364.2500 - val_loss: 3244845.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1743416.0000 - val_loss: 3243370.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1737481.0000 - val_loss: 3241913.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1731559.2500 - val_loss: 3240350.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1725648.2500 - val_loss: 3238777.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1719748.8750 - val_loss: 3237235.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1713858.2500 - val_loss: 3235695.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1707980.5000 - val_loss: 3234049.7500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1702114.5000 - val_loss: 3232548.7500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1696259.6250 - val_loss: 3231028.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1690412.2500 - val_loss: 3229450.7500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1684576.5000 - val_loss: 3227940.5000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1678750.7500 - val_loss: 3226436.5000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1672937.0000 - val_loss: 3224894.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1667136.5000 - val_loss: 3223341.2500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1661341.8750 - val_loss: 3221771.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1655556.7500 - val_loss: 3220194.2500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1649783.7500 - val_loss: 3218718.0000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1644024.2500 - val_loss: 3217037.2500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1638278.6250 - val_loss: 3215433.5000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1632540.0000 - val_loss: 3213766.7500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1626812.0000 - val_loss: 3212129.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1621094.0000 - val_loss: 3210352.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1615386.3750 - val_loss: 3208611.2500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1609688.5000 - val_loss: 3206760.5000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1604000.8750 - val_loss: 3204774.2500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1598325.1250 - val_loss: 3203066.2500\n",
            "7/7 [==============================] - 1s 3ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 8ms/step - loss: 1905953.2500 - val_loss: 3269668.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1892429.5000 - val_loss: 3268815.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1881069.0000 - val_loss: 3267785.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1873342.5000 - val_loss: 3266875.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1866293.0000 - val_loss: 3265988.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1859554.7500 - val_loss: 3265114.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1852996.5000 - val_loss: 3264214.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1846556.3750 - val_loss: 3263301.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1840200.3750 - val_loss: 3262360.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1833913.6250 - val_loss: 3261389.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1827677.8750 - val_loss: 3260335.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1821480.2500 - val_loss: 3259246.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1815317.6250 - val_loss: 3258110.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1809185.1250 - val_loss: 3256916.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1803078.8750 - val_loss: 3255645.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1796994.0000 - val_loss: 3254335.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1790928.2500 - val_loss: 3252980.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1784883.2500 - val_loss: 3251577.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1778858.0000 - val_loss: 3250079.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1772843.6250 - val_loss: 3248601.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1766845.3750 - val_loss: 3247092.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1760862.1250 - val_loss: 3245572.0000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1754892.1250 - val_loss: 3244100.5000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1748934.3750 - val_loss: 3242602.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1742986.6250 - val_loss: 3241139.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1737049.7500 - val_loss: 3239653.2500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1731125.7500 - val_loss: 3238164.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1725215.3750 - val_loss: 3236658.5000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1719316.6250 - val_loss: 3235215.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1713428.0000 - val_loss: 3233752.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1707550.5000 - val_loss: 3232297.2500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1701684.6250 - val_loss: 3230824.0000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1695829.2500 - val_loss: 3229421.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1689983.1250 - val_loss: 3227952.0000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1684145.6250 - val_loss: 3226538.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1678321.1250 - val_loss: 3225006.2500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1672508.1250 - val_loss: 3223629.2500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1666704.7500 - val_loss: 3222077.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1660913.7500 - val_loss: 3220509.0000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1655133.0000 - val_loss: 3219050.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1649361.5000 - val_loss: 3217366.7500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1643603.5000 - val_loss: 3215698.2500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1637854.5000 - val_loss: 3213895.0000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1632114.6250 - val_loss: 3212143.2500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1626386.2500 - val_loss: 3210436.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1620669.8750 - val_loss: 3208800.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1614962.8750 - val_loss: 3207043.2500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1609266.3750 - val_loss: 3205350.5000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1603580.1250 - val_loss: 3203512.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1597904.7500 - val_loss: 3201672.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 8ms/step - loss: 1906317.7500 - val_loss: 3271186.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1891799.0000 - val_loss: 3270078.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1881126.1250 - val_loss: 3269550.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1873546.8750 - val_loss: 3268984.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1866571.1250 - val_loss: 3268364.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1859879.2500 - val_loss: 3267699.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1853351.6250 - val_loss: 3266990.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1846933.0000 - val_loss: 3266234.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1840597.6250 - val_loss: 3265443.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1834322.6250 - val_loss: 3264596.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1828094.6250 - val_loss: 3263709.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1821907.2500 - val_loss: 3262795.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1815751.7500 - val_loss: 3261848.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1809624.5000 - val_loss: 3260854.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1803523.6250 - val_loss: 3259851.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1797443.3750 - val_loss: 3258791.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1791380.8750 - val_loss: 3257667.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1785336.0000 - val_loss: 3256494.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1779308.0000 - val_loss: 3255215.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1773295.6250 - val_loss: 3253893.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1767298.6250 - val_loss: 3252477.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1761315.3750 - val_loss: 3251047.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1755343.5000 - val_loss: 3249592.2500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1749383.7500 - val_loss: 3248071.0000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1743436.3750 - val_loss: 3246616.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1737501.0000 - val_loss: 3244967.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1731577.1250 - val_loss: 3243368.5000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1725664.5000 - val_loss: 3241471.7500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1719763.7500 - val_loss: 3239666.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1713873.0000 - val_loss: 3237655.2500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1707994.1250 - val_loss: 3235764.2500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1702127.0000 - val_loss: 3233842.7500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1696270.5000 - val_loss: 3232105.0000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1690423.6250 - val_loss: 3230335.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1684587.3750 - val_loss: 3228791.5000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1678761.6250 - val_loss: 3227168.5000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1672948.2500 - val_loss: 3225585.0000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1667147.0000 - val_loss: 3223948.0000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1661356.7500 - val_loss: 3222298.0000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1655574.6250 - val_loss: 3220715.2500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1649802.7500 - val_loss: 3219111.5000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1644042.3750 - val_loss: 3217548.0000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1638291.7500 - val_loss: 3215954.0000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1632550.1250 - val_loss: 3214297.0000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1626818.7500 - val_loss: 3212588.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1621100.7500 - val_loss: 3210686.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1615394.2500 - val_loss: 3208648.5000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1609697.6250 - val_loss: 3206833.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1604009.5000 - val_loss: 3204909.2500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1598333.2500 - val_loss: 3202975.5000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 10ms/step - loss: 1906490.0000 - val_loss: 3269010.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1894392.2500 - val_loss: 3267416.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1882681.1250 - val_loss: 3266407.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1874899.8750 - val_loss: 3265482.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1867830.2500 - val_loss: 3264555.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1861073.5000 - val_loss: 3263613.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1854502.1250 - val_loss: 3262661.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1848054.8750 - val_loss: 3261693.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1841698.1250 - val_loss: 3260703.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1835405.3750 - val_loss: 3259691.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1829166.5000 - val_loss: 3258651.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1822965.8750 - val_loss: 3257571.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1816801.3750 - val_loss: 3256475.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1810668.0000 - val_loss: 3255338.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1804561.6250 - val_loss: 3254164.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1798474.7500 - val_loss: 3252930.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1792408.3750 - val_loss: 3251680.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1786357.8750 - val_loss: 3250387.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1780326.8750 - val_loss: 3249044.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1774309.5000 - val_loss: 3247674.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1768307.5000 - val_loss: 3246259.2500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1762319.0000 - val_loss: 3244795.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1756342.6250 - val_loss: 3243263.5000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1750380.2500 - val_loss: 3241750.0000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1744431.7500 - val_loss: 3240204.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1738496.6250 - val_loss: 3238671.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1732572.7500 - val_loss: 3237136.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1726662.3750 - val_loss: 3235638.0000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1720759.3750 - val_loss: 3234193.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1714866.2500 - val_loss: 3232705.7500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1708986.1250 - val_loss: 3231301.2500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1703118.5000 - val_loss: 3229855.0000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1697260.7500 - val_loss: 3228379.7500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1691415.3750 - val_loss: 3226952.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1685578.0000 - val_loss: 3225467.7500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1679749.5000 - val_loss: 3223966.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1673936.3750 - val_loss: 3222525.7500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1668132.8750 - val_loss: 3220914.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1662338.7500 - val_loss: 3219275.0000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1656555.7500 - val_loss: 3217562.0000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1650781.1250 - val_loss: 3215783.7500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1645019.2500 - val_loss: 3214085.2500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1639268.0000 - val_loss: 3212253.0000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1633524.5000 - val_loss: 3210458.2500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1627794.8750 - val_loss: 3208708.2500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1622074.6250 - val_loss: 3207031.0000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1616365.1250 - val_loss: 3205223.7500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1610664.8750 - val_loss: 3203386.0000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1604975.2500 - val_loss: 3201475.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1599297.8750 - val_loss: 3199556.2500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 1905386.2500 - val_loss: 3270518.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1892124.7500 - val_loss: 3269685.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1882923.1250 - val_loss: 3269008.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1875600.2500 - val_loss: 3268289.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1868744.0000 - val_loss: 3267544.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1862122.8750 - val_loss: 3266780.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1855643.5000 - val_loss: 3265995.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1849264.2500 - val_loss: 3265187.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1842953.3750 - val_loss: 3264350.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1836694.5000 - val_loss: 3263495.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1830476.8750 - val_loss: 3262593.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1824296.2500 - val_loss: 3261675.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1818147.2500 - val_loss: 3260699.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1812021.3750 - val_loss: 3259680.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1805920.2500 - val_loss: 3258588.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1799841.1250 - val_loss: 3257439.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1793780.5000 - val_loss: 3256216.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1787737.2500 - val_loss: 3254943.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1781709.5000 - val_loss: 3253603.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1775696.2500 - val_loss: 3252235.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1769694.7500 - val_loss: 3250760.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1763709.0000 - val_loss: 3249314.2500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1757734.7500 - val_loss: 3247809.2500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1751772.7500 - val_loss: 3246296.0000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1745823.3750 - val_loss: 3244769.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1739884.3750 - val_loss: 3243242.5000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1733957.3750 - val_loss: 3241812.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1728043.1250 - val_loss: 3240308.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1722139.3750 - val_loss: 3238897.0000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1716245.7500 - val_loss: 3237410.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1710365.8750 - val_loss: 3235964.2500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1704495.0000 - val_loss: 3234486.0000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1698634.0000 - val_loss: 3232947.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1692783.6250 - val_loss: 3231267.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1686945.2500 - val_loss: 3229533.5000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1681118.3750 - val_loss: 3227511.7500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1675303.6250 - val_loss: 3225555.2500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1669498.5000 - val_loss: 3223628.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1663702.0000 - val_loss: 3221829.2500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1657917.3750 - val_loss: 3220146.5000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1652143.1250 - val_loss: 3218482.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1646377.5000 - val_loss: 3216889.5000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1640625.7500 - val_loss: 3215332.5000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1634881.2500 - val_loss: 3213820.0000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1629148.0000 - val_loss: 3212300.2500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1623424.2500 - val_loss: 3210829.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1617714.2500 - val_loss: 3209321.2500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1612013.5000 - val_loss: 3207831.5000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1606323.5000 - val_loss: 3206302.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1600644.0000 - val_loss: 3204775.0000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 8ms/step - loss: 1905405.5000 - val_loss: 3268547.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1890475.1250 - val_loss: 3267820.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1877992.0000 - val_loss: 3266586.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1870141.0000 - val_loss: 3265420.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1863048.0000 - val_loss: 3264275.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1856280.2500 - val_loss: 3263132.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1849704.2500 - val_loss: 3261976.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1843259.2500 - val_loss: 3260799.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1836903.2500 - val_loss: 3259639.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1830613.6250 - val_loss: 3258446.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1824377.2500 - val_loss: 3257272.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1818184.3750 - val_loss: 3256074.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1812028.0000 - val_loss: 3254877.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1805899.7500 - val_loss: 3253645.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1799797.6250 - val_loss: 3252402.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1793718.8750 - val_loss: 3251139.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1787659.3750 - val_loss: 3249828.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1781618.8750 - val_loss: 3248523.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1775594.1250 - val_loss: 3247149.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1769584.7500 - val_loss: 3245787.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1763590.3750 - val_loss: 3244405.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1757608.7500 - val_loss: 3242997.0000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1751645.0000 - val_loss: 3241618.7500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1745687.8750 - val_loss: 3240292.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1739747.3750 - val_loss: 3238924.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1733818.7500 - val_loss: 3237570.2500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1727898.7500 - val_loss: 3236229.5000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1721990.0000 - val_loss: 3234910.5000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1716094.6250 - val_loss: 3233678.0000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1710208.8750 - val_loss: 3232398.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1704333.8750 - val_loss: 3230991.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1698470.6250 - val_loss: 3229789.5000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1692619.6250 - val_loss: 3228474.5000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1686781.1250 - val_loss: 3227224.2500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1680951.7500 - val_loss: 3225856.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1675134.8750 - val_loss: 3224600.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1669328.1250 - val_loss: 3223180.0000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1663531.1250 - val_loss: 3221826.2500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1657746.8750 - val_loss: 3220518.5000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1651971.3750 - val_loss: 3219147.0000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1646208.8750 - val_loss: 3217663.7500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1640455.7500 - val_loss: 3216174.7500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1634711.2500 - val_loss: 3214677.2500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1628977.7500 - val_loss: 3213123.0000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1623254.5000 - val_loss: 3211461.7500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1617540.7500 - val_loss: 3209751.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1611843.2500 - val_loss: 3207989.2500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1606151.3750 - val_loss: 3206370.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1600469.8750 - val_loss: 3204588.5000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1594801.7500 - val_loss: 3202929.0000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 9ms/step - loss: 1906797.3750 - val_loss: 3266954.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1892446.5000 - val_loss: 3266225.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1880255.8750 - val_loss: 3265036.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1872448.8750 - val_loss: 3263904.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1865368.0000 - val_loss: 3262832.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1858607.5000 - val_loss: 3261777.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1852037.3750 - val_loss: 3260736.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1845588.6250 - val_loss: 3259716.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1839229.7500 - val_loss: 3258708.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1832939.3750 - val_loss: 3257696.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1826701.8750 - val_loss: 3256685.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1820502.8750 - val_loss: 3255674.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1814340.5000 - val_loss: 3254669.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1808208.5000 - val_loss: 3253642.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1802103.0000 - val_loss: 3252605.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1796020.8750 - val_loss: 3251533.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1789957.6250 - val_loss: 3250446.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1783914.6250 - val_loss: 3249344.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1777885.7500 - val_loss: 3248197.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1771872.6250 - val_loss: 3247020.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1765874.6250 - val_loss: 3245777.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1759889.0000 - val_loss: 3244517.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1753916.6250 - val_loss: 3243259.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1747957.7500 - val_loss: 3241849.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1742013.2500 - val_loss: 3240465.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1736081.5000 - val_loss: 3239059.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1730162.2500 - val_loss: 3237605.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1724253.0000 - val_loss: 3236156.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1718352.2500 - val_loss: 3234746.7500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1712462.8750 - val_loss: 3233222.7500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1706587.2500 - val_loss: 3231778.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1700723.1250 - val_loss: 3230301.5000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1694870.6250 - val_loss: 3228724.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1689027.2500 - val_loss: 3227302.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1683192.6250 - val_loss: 3225755.5000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1677369.2500 - val_loss: 3224287.2500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1671558.8750 - val_loss: 3222734.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1665759.7500 - val_loss: 3221157.7500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1659969.5000 - val_loss: 3219673.0000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1654190.8750 - val_loss: 3218099.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1648418.6250 - val_loss: 3216448.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1642659.3750 - val_loss: 3214812.5000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1636913.5000 - val_loss: 3213391.2500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1631178.3750 - val_loss: 3211558.0000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1625450.7500 - val_loss: 3209897.7500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1619734.3750 - val_loss: 3208348.2500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1614031.2500 - val_loss: 3206688.7500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1608336.5000 - val_loss: 3204963.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1602651.2500 - val_loss: 3203325.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1596977.6250 - val_loss: 3201640.0000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 10ms/step - loss: 1906245.8750 - val_loss: 3268596.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1891848.0000 - val_loss: 3266934.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1879848.3750 - val_loss: 3265717.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1872051.1250 - val_loss: 3264556.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1864982.5000 - val_loss: 3263314.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1858226.5000 - val_loss: 3262036.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1851654.7500 - val_loss: 3260707.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1845210.0000 - val_loss: 3259321.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1838854.8750 - val_loss: 3257892.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1832565.0000 - val_loss: 3256412.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1826325.1250 - val_loss: 3254917.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1820130.0000 - val_loss: 3253351.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1813970.8750 - val_loss: 3251782.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1807840.1250 - val_loss: 3250177.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1801736.7500 - val_loss: 3248535.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1795651.5000 - val_loss: 3246891.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1789587.0000 - val_loss: 3245229.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1783543.7500 - val_loss: 3243571.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1777516.7500 - val_loss: 3241849.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1771504.3750 - val_loss: 3240124.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1765505.8750 - val_loss: 3238426.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1759520.5000 - val_loss: 3236701.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1753550.1250 - val_loss: 3234983.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1747592.3750 - val_loss: 3233212.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1741648.8750 - val_loss: 3231427.2500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1735716.8750 - val_loss: 3229656.2500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1729797.3750 - val_loss: 3227974.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1723887.6250 - val_loss: 3226138.7500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1717987.8750 - val_loss: 3224378.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1712103.3750 - val_loss: 3222604.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1706229.0000 - val_loss: 3220796.2500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1700367.5000 - val_loss: 3219005.7500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1694516.3750 - val_loss: 3217141.5000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1688677.0000 - val_loss: 3215283.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1682848.5000 - val_loss: 3213398.7500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1677031.2500 - val_loss: 3211524.5000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1671223.0000 - val_loss: 3209569.7500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1665423.2500 - val_loss: 3207660.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1659632.8750 - val_loss: 3205679.5000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1653854.5000 - val_loss: 3203767.5000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1648086.5000 - val_loss: 3201695.0000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1642329.7500 - val_loss: 3199616.2500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1636581.5000 - val_loss: 3197513.2500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1630845.7500 - val_loss: 3195411.5000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1625120.2500 - val_loss: 3193208.0000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1619407.5000 - val_loss: 3190934.2500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1613701.5000 - val_loss: 3188661.5000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1608008.3750 - val_loss: 3186376.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1602325.7500 - val_loss: 3184371.2500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1596652.5000 - val_loss: 3182200.7500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 12ms/step - loss: 1907591.7500 - val_loss: 3268823.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1902947.0000 - val_loss: 3268553.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1893817.8750 - val_loss: 3268404.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1886151.6250 - val_loss: 3267983.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1881414.8750 - val_loss: 3267595.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1877393.0000 - val_loss: 3267212.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1873654.8750 - val_loss: 3266829.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1870072.6250 - val_loss: 3266427.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1866593.3750 - val_loss: 3266017.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1863189.6250 - val_loss: 3265594.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1859838.6250 - val_loss: 3265164.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1856531.6250 - val_loss: 3264725.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1853259.1250 - val_loss: 3264269.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1850016.0000 - val_loss: 3263809.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1846797.3750 - val_loss: 3263327.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1843600.1250 - val_loss: 3262847.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1840422.1250 - val_loss: 3262354.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1837258.3750 - val_loss: 3261842.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1834108.6250 - val_loss: 3261326.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1830970.6250 - val_loss: 3260798.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1827840.6250 - val_loss: 3260278.2500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1824721.6250 - val_loss: 3259715.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1821614.3750 - val_loss: 3259165.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1818514.8750 - val_loss: 3258598.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1815420.1250 - val_loss: 3258025.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1812333.7500 - val_loss: 3257444.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1809254.3750 - val_loss: 3256887.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1806181.5000 - val_loss: 3256267.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1803112.3750 - val_loss: 3255676.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1800050.5000 - val_loss: 3255084.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1796994.6250 - val_loss: 3254466.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1793943.8750 - val_loss: 3253833.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1790896.8750 - val_loss: 3253200.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1787854.8750 - val_loss: 3252579.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1784817.7500 - val_loss: 3251946.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1781783.2500 - val_loss: 3251334.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1778753.3750 - val_loss: 3250717.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1775726.7500 - val_loss: 3250099.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1772704.5000 - val_loss: 3249475.2500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1769685.1250 - val_loss: 3248859.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1766669.0000 - val_loss: 3248227.2500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1763657.1250 - val_loss: 3247632.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1760648.0000 - val_loss: 3246986.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1757642.1250 - val_loss: 3246380.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1754641.1250 - val_loss: 3245781.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1751641.1250 - val_loss: 3245124.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1748645.0000 - val_loss: 3244545.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1745650.8750 - val_loss: 3243960.0000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1742660.8750 - val_loss: 3243291.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1739674.1250 - val_loss: 3242670.0000\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 13ms/step - loss: 1907954.3750 - val_loss: 3269242.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1903014.0000 - val_loss: 3269194.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1893216.7500 - val_loss: 3268354.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1885906.3750 - val_loss: 3267435.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1881243.7500 - val_loss: 3266840.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1877258.7500 - val_loss: 3266298.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1873534.5000 - val_loss: 3265757.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1869960.0000 - val_loss: 3265233.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1866486.0000 - val_loss: 3264699.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1863086.3750 - val_loss: 3264172.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1859739.8750 - val_loss: 3263643.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1856435.7500 - val_loss: 3263116.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1853169.6250 - val_loss: 3262591.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1849931.1250 - val_loss: 3262031.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1846714.0000 - val_loss: 3261499.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1843518.3750 - val_loss: 3260940.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1840339.2500 - val_loss: 3260385.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1837175.1250 - val_loss: 3259835.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1834026.1250 - val_loss: 3259257.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1830889.5000 - val_loss: 3258694.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1827763.5000 - val_loss: 3258109.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1824645.3750 - val_loss: 3257525.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1821538.0000 - val_loss: 3256935.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1818439.5000 - val_loss: 3256326.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1815348.2500 - val_loss: 3255707.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1812266.0000 - val_loss: 3255082.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1809186.0000 - val_loss: 3254452.7500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1806113.8750 - val_loss: 3253773.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1803047.3750 - val_loss: 3253160.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1799987.5000 - val_loss: 3252510.2500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1796930.6250 - val_loss: 3251820.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1793880.2500 - val_loss: 3251127.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1790832.2500 - val_loss: 3250475.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1787789.3750 - val_loss: 3249796.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1784751.6250 - val_loss: 3249111.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1781718.3750 - val_loss: 3248361.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1778687.1250 - val_loss: 3247752.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1775662.1250 - val_loss: 3247080.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1772639.3750 - val_loss: 3246439.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1769621.0000 - val_loss: 3245827.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1766606.2500 - val_loss: 3245176.2500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1763594.7500 - val_loss: 3244553.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1760584.7500 - val_loss: 3243925.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1757578.2500 - val_loss: 3243356.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1754575.7500 - val_loss: 3242745.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1751574.6250 - val_loss: 3242159.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1748578.6250 - val_loss: 3241601.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1745587.0000 - val_loss: 3240972.0000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1742597.5000 - val_loss: 3240373.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1739612.1250 - val_loss: 3239742.7500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 13ms/step - loss: 1908277.7500 - val_loss: 3269725.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1903651.5000 - val_loss: 3269087.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1893375.2500 - val_loss: 3268860.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1886990.8750 - val_loss: 3268604.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1882614.2500 - val_loss: 3268281.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1878726.6250 - val_loss: 3267935.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1875064.2500 - val_loss: 3267556.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1871529.7500 - val_loss: 3267173.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1868087.7500 - val_loss: 3266770.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1864710.6250 - val_loss: 3266363.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1861382.7500 - val_loss: 3265951.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1858094.7500 - val_loss: 3265528.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1854836.2500 - val_loss: 3265096.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1851609.0000 - val_loss: 3264650.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1848399.0000 - val_loss: 3264200.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1845210.6250 - val_loss: 3263748.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1842037.3750 - val_loss: 3263279.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1838878.8750 - val_loss: 3262801.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1835731.8750 - val_loss: 3262325.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1832598.2500 - val_loss: 3261832.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1829475.2500 - val_loss: 3261333.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1826362.3750 - val_loss: 3260816.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1823257.6250 - val_loss: 3260297.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1820159.2500 - val_loss: 3259767.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1817069.6250 - val_loss: 3259242.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1813985.1250 - val_loss: 3258689.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1810908.1250 - val_loss: 3258130.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1807835.0000 - val_loss: 3257569.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1804769.2500 - val_loss: 3256998.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1801706.7500 - val_loss: 3256426.2500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1798652.0000 - val_loss: 3255843.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1795599.1250 - val_loss: 3255260.5000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1792552.7500 - val_loss: 3254665.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1789511.5000 - val_loss: 3254090.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1786473.5000 - val_loss: 3253475.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1783440.7500 - val_loss: 3252892.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1780410.5000 - val_loss: 3252271.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1777385.0000 - val_loss: 3251668.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1774361.1250 - val_loss: 3251062.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1771340.8750 - val_loss: 3250462.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1768323.3750 - val_loss: 3249862.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1765306.7500 - val_loss: 3249238.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1762296.3750 - val_loss: 3248644.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1759289.8750 - val_loss: 3248005.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1756284.5000 - val_loss: 3247398.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1753284.2500 - val_loss: 3246790.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1750287.7500 - val_loss: 3246138.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1747295.2500 - val_loss: 3245495.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1744304.2500 - val_loss: 3244869.2500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1741316.2500 - val_loss: 3244267.5000\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 12ms/step - loss: 1907964.1250 - val_loss: 3268817.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1903752.1250 - val_loss: 3269746.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1893317.6250 - val_loss: 3269101.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1885277.8750 - val_loss: 3268589.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1880551.2500 - val_loss: 3268184.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1876504.7500 - val_loss: 3267781.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1872738.7500 - val_loss: 3267363.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1869137.1250 - val_loss: 3266951.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1865642.1250 - val_loss: 3266527.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1862225.1250 - val_loss: 3266090.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1858866.2500 - val_loss: 3265649.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1855551.7500 - val_loss: 3265200.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1852271.8750 - val_loss: 3264750.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1849023.1250 - val_loss: 3264297.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1845797.3750 - val_loss: 3263845.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1842594.0000 - val_loss: 3263377.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1839413.6250 - val_loss: 3262901.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1836246.8750 - val_loss: 3262424.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1833093.6250 - val_loss: 3261940.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1829951.8750 - val_loss: 3261443.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1826823.0000 - val_loss: 3260952.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1823706.0000 - val_loss: 3260453.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1820595.1250 - val_loss: 3259945.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1817495.0000 - val_loss: 3259421.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1814402.2500 - val_loss: 3258918.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1811316.6250 - val_loss: 3258390.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1808237.1250 - val_loss: 3257858.7500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1805163.0000 - val_loss: 3257340.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1802095.6250 - val_loss: 3256796.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1799034.1250 - val_loss: 3256247.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1795978.1250 - val_loss: 3255672.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1792925.3750 - val_loss: 3255123.5000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1789876.8750 - val_loss: 3254573.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1786836.0000 - val_loss: 3254002.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1783797.2500 - val_loss: 3253416.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1780761.7500 - val_loss: 3252831.2500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1777731.2500 - val_loss: 3252259.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1774706.5000 - val_loss: 3251691.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1771685.5000 - val_loss: 3251062.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1768667.8750 - val_loss: 3250484.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1765650.6250 - val_loss: 3249854.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1762639.6250 - val_loss: 3249287.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1759629.7500 - val_loss: 3248662.0000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1756622.2500 - val_loss: 3248058.0000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1753620.0000 - val_loss: 3247435.2500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1750620.3750 - val_loss: 3246813.7500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1747624.0000 - val_loss: 3246242.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1744633.1250 - val_loss: 3245598.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1741646.2500 - val_loss: 3244943.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1738660.1250 - val_loss: 3244274.0000\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 12ms/step - loss: 1908642.1250 - val_loss: 3265896.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1905186.7500 - val_loss: 3265345.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1895776.1250 - val_loss: 3268519.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1885839.1250 - val_loss: 3268015.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1880472.6250 - val_loss: 3267448.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1876205.1250 - val_loss: 3266901.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1872319.5000 - val_loss: 3266360.0000\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 12ms/step - loss: 1907745.1250 - val_loss: 3267785.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1902945.1250 - val_loss: 3269568.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1892969.1250 - val_loss: 3270586.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1885090.5000 - val_loss: 3270054.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1880314.6250 - val_loss: 3269699.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1876284.3750 - val_loss: 3269362.7500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 12ms/step - loss: 1907881.0000 - val_loss: 3268349.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1903726.8750 - val_loss: 3267836.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1894344.0000 - val_loss: 3267090.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1886037.1250 - val_loss: 3266414.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1881207.6250 - val_loss: 3265910.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1877136.1250 - val_loss: 3265368.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1873361.0000 - val_loss: 3264822.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1869753.7500 - val_loss: 3264259.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1866255.0000 - val_loss: 3263686.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1862837.0000 - val_loss: 3263107.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1859476.0000 - val_loss: 3262523.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1856160.0000 - val_loss: 3261942.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1852881.7500 - val_loss: 3261367.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1849630.8750 - val_loss: 3260773.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1846408.7500 - val_loss: 3260186.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1843207.3750 - val_loss: 3259610.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1840023.7500 - val_loss: 3259044.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1836854.3750 - val_loss: 3258452.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1833699.6250 - val_loss: 3257897.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1830557.0000 - val_loss: 3257303.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1827427.2500 - val_loss: 3256734.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1824306.3750 - val_loss: 3256165.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1821194.8750 - val_loss: 3255587.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1818091.6250 - val_loss: 3254996.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1814998.2500 - val_loss: 3254420.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1811908.6250 - val_loss: 3253852.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1808828.3750 - val_loss: 3253277.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1805754.5000 - val_loss: 3252696.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1802688.5000 - val_loss: 3252130.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1799625.1250 - val_loss: 3251565.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1796569.2500 - val_loss: 3251002.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1793517.1250 - val_loss: 3250405.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1790471.6250 - val_loss: 3249863.0000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1787428.7500 - val_loss: 3249267.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1784389.6250 - val_loss: 3248696.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1781356.5000 - val_loss: 3248119.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1778327.0000 - val_loss: 3247590.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1775299.0000 - val_loss: 3246984.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1772277.2500 - val_loss: 3246432.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1769258.0000 - val_loss: 3245855.0000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1766243.0000 - val_loss: 3245328.2500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1763231.1250 - val_loss: 3244739.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1760222.1250 - val_loss: 3244191.2500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1757216.2500 - val_loss: 3243668.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1754214.0000 - val_loss: 3243118.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1751214.8750 - val_loss: 3242552.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1748219.8750 - val_loss: 3242011.5000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1745227.0000 - val_loss: 3241453.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1742237.7500 - val_loss: 3240892.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1739251.2500 - val_loss: 3240384.5000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 12ms/step - loss: 1907528.3750 - val_loss: 3269092.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1902121.3750 - val_loss: 3268571.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1892648.7500 - val_loss: 3267730.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1886468.7500 - val_loss: 3267224.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1882279.7500 - val_loss: 3266678.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1877721.0000 - val_loss: 3266104.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1873667.8750 - val_loss: 3265587.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1869949.5000 - val_loss: 3265103.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1866390.6250 - val_loss: 3264642.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1862931.0000 - val_loss: 3264196.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1859542.6250 - val_loss: 3263755.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1856206.5000 - val_loss: 3263326.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1852912.7500 - val_loss: 3262905.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1849651.0000 - val_loss: 3262496.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1846417.8750 - val_loss: 3262085.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1843206.7500 - val_loss: 3261690.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1840017.2500 - val_loss: 3261295.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1836845.5000 - val_loss: 3260895.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1833687.6250 - val_loss: 3260512.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1830541.7500 - val_loss: 3260108.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1827407.5000 - val_loss: 3259708.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1824285.1250 - val_loss: 3259309.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1821172.3750 - val_loss: 3258901.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1818067.1250 - val_loss: 3258491.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1814970.0000 - val_loss: 3258080.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1811882.8750 - val_loss: 3257663.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1808802.6250 - val_loss: 3257236.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1805728.2500 - val_loss: 3256801.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1802658.5000 - val_loss: 3256370.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1799596.0000 - val_loss: 3255922.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1796539.7500 - val_loss: 3255475.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1793485.3750 - val_loss: 3255034.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1790436.6250 - val_loss: 3254588.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1787394.1250 - val_loss: 3254111.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1784357.5000 - val_loss: 3253660.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1781324.3750 - val_loss: 3253183.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1778294.6250 - val_loss: 3252706.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1775267.6250 - val_loss: 3252237.7500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1772243.6250 - val_loss: 3251758.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1769224.3750 - val_loss: 3251261.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1766208.2500 - val_loss: 3250776.2500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1763197.0000 - val_loss: 3250274.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1760188.3750 - val_loss: 3249769.0000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1757181.2500 - val_loss: 3249266.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1754179.3750 - val_loss: 3248757.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1751180.8750 - val_loss: 3248242.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1748184.5000 - val_loss: 3247730.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1745191.5000 - val_loss: 3247198.2500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1742202.3750 - val_loss: 3246674.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1739216.3750 - val_loss: 3246147.2500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 12ms/step - loss: 1907208.8750 - val_loss: 3268683.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1902542.2500 - val_loss: 3269252.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1893522.5000 - val_loss: 3269966.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1886869.0000 - val_loss: 3269473.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1882453.0000 - val_loss: 3269111.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1878546.5000 - val_loss: 3268757.5000\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 12ms/step - loss: 1907825.6250 - val_loss: 3269796.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1903379.0000 - val_loss: 3269524.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1893482.8750 - val_loss: 3269106.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1885950.6250 - val_loss: 3268744.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1881310.1250 - val_loss: 3268357.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1877297.7500 - val_loss: 3267987.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1873552.3750 - val_loss: 3267611.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1869965.3750 - val_loss: 3267221.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1866482.3750 - val_loss: 3266827.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1863074.6250 - val_loss: 3266425.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1859722.8750 - val_loss: 3266021.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1856414.3750 - val_loss: 3265602.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1853140.2500 - val_loss: 3265184.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1849896.7500 - val_loss: 3264762.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1846677.7500 - val_loss: 3264319.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1843480.0000 - val_loss: 3263884.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1840299.1250 - val_loss: 3263426.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1837133.6250 - val_loss: 3262977.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1833981.5000 - val_loss: 3262505.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1830840.3750 - val_loss: 3262049.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1827712.0000 - val_loss: 3261569.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1824593.0000 - val_loss: 3261104.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1821483.5000 - val_loss: 3260618.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1818380.7500 - val_loss: 3260110.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1815289.6250 - val_loss: 3259628.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1812201.6250 - val_loss: 3259097.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1809122.2500 - val_loss: 3258585.7500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1806049.3750 - val_loss: 3258036.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1802984.6250 - val_loss: 3257516.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1799922.6250 - val_loss: 3256978.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1796868.1250 - val_loss: 3256429.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1793816.2500 - val_loss: 3255869.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1790769.8750 - val_loss: 3255302.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1787727.7500 - val_loss: 3254722.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1784690.5000 - val_loss: 3254144.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1781656.6250 - val_loss: 3253530.2500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1778628.0000 - val_loss: 3252964.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1775598.5000 - val_loss: 3252371.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1772575.8750 - val_loss: 3251787.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1769556.8750 - val_loss: 3251167.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1766541.3750 - val_loss: 3250558.2500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1763530.0000 - val_loss: 3249930.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1760522.0000 - val_loss: 3249319.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1757516.2500 - val_loss: 3248677.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1754513.1250 - val_loss: 3248013.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1751514.1250 - val_loss: 3247399.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1748519.5000 - val_loss: 3246738.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1745527.0000 - val_loss: 3246086.0000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1742536.7500 - val_loss: 3245468.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1739550.5000 - val_loss: 3244811.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 9s 21ms/step - loss: 1909015.8750 - val_loss: 3268097.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1907686.2500 - val_loss: 3268025.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1905758.0000 - val_loss: 3267928.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1902586.7500 - val_loss: 3267753.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1897656.6250 - val_loss: 3267469.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1891874.0000 - val_loss: 3267005.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1887684.0000 - val_loss: 3266473.7500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1884886.3750 - val_loss: 3266064.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1882535.6250 - val_loss: 3265695.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1880379.1250 - val_loss: 3265353.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1878334.5000 - val_loss: 3265016.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1876372.3750 - val_loss: 3264686.0000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1874469.5000 - val_loss: 3264366.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1872612.8750 - val_loss: 3264035.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1870792.1250 - val_loss: 3263721.7500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1869002.8750 - val_loss: 3263405.0000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1867239.7500 - val_loss: 3263090.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1865495.1250 - val_loss: 3262774.2500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1863769.7500 - val_loss: 3262455.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1862062.2500 - val_loss: 3262142.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1860368.3750 - val_loss: 3261828.5000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1858683.7500 - val_loss: 3261519.5000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1857011.1250 - val_loss: 3261201.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1855345.8750 - val_loss: 3260885.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1853690.0000 - val_loss: 3260570.0000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1852044.1250 - val_loss: 3260252.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1850403.2500 - val_loss: 3259936.7500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1848767.8750 - val_loss: 3259627.7500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1847140.1250 - val_loss: 3259313.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1845518.2500 - val_loss: 3259013.5000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1843901.1250 - val_loss: 3258689.7500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1842288.1250 - val_loss: 3258384.2500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1840679.0000 - val_loss: 3258080.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1839075.3750 - val_loss: 3257770.0000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1837474.1250 - val_loss: 3257454.7500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1835880.0000 - val_loss: 3257134.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1834285.8750 - val_loss: 3256821.2500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1832695.7500 - val_loss: 3256524.2500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1831110.8750 - val_loss: 3256201.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1829526.0000 - val_loss: 3255892.2500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1827947.3750 - val_loss: 3255569.2500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1826368.5000 - val_loss: 3255268.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1824794.1250 - val_loss: 3254948.5000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1823221.2500 - val_loss: 3254634.7500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1821651.1250 - val_loss: 3254322.5000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1820080.5000 - val_loss: 3254021.7500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1818514.8750 - val_loss: 3253728.2500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1816949.6250 - val_loss: 3253426.5000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1815388.6250 - val_loss: 3253119.5000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1813828.5000 - val_loss: 3252817.5000\n",
            "7/7 [==============================] - 1s 3ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 17ms/step - loss: 1907767.3750 - val_loss: 3272584.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1905477.8750 - val_loss: 3272026.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1901361.7500 - val_loss: 3271504.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1895700.5000 - val_loss: 3271135.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1890579.0000 - val_loss: 3270563.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1887164.6250 - val_loss: 3270220.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1884646.8750 - val_loss: 3269961.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1882441.5000 - val_loss: 3269742.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1880392.0000 - val_loss: 3269538.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1878438.3750 - val_loss: 3269333.5000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1876549.3750 - val_loss: 3269136.0000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1874709.1250 - val_loss: 3268938.0000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1872907.3750 - val_loss: 3268741.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1871136.7500 - val_loss: 3268542.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1869391.6250 - val_loss: 3268347.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1867662.3750 - val_loss: 3268150.2500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1865952.2500 - val_loss: 3267954.7500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1864252.6250 - val_loss: 3267758.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1862570.7500 - val_loss: 3267564.0000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1860897.2500 - val_loss: 3267368.0000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1859233.6250 - val_loss: 3267173.0000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1857582.3750 - val_loss: 3266975.2500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1855934.8750 - val_loss: 3266782.2500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1854295.7500 - val_loss: 3266585.0000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1852663.8750 - val_loss: 3266384.5000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1851038.5000 - val_loss: 3266188.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1849419.0000 - val_loss: 3265989.7500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1847802.3750 - val_loss: 3265792.0000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1846191.5000 - val_loss: 3265592.7500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1844584.2500 - val_loss: 3265393.5000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1842982.6250 - val_loss: 3265192.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1841383.7500 - val_loss: 3264991.2500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1839785.5000 - val_loss: 3264791.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1838193.8750 - val_loss: 3264584.5000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1836605.3750 - val_loss: 3264377.0000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1835020.3750 - val_loss: 3264173.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1833438.5000 - val_loss: 3263962.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1831860.5000 - val_loss: 3263759.5000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1830283.1250 - val_loss: 3263547.5000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1828707.8750 - val_loss: 3263339.5000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1827134.6250 - val_loss: 3263137.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1825565.8750 - val_loss: 3262926.0000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1823996.7500 - val_loss: 3262713.2500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1822431.5000 - val_loss: 3262503.2500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1820865.2500 - val_loss: 3262292.5000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1819302.8750 - val_loss: 3262076.0000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1817742.7500 - val_loss: 3261859.2500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1816182.3750 - val_loss: 3261646.5000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1814625.6250 - val_loss: 3261427.7500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1813069.5000 - val_loss: 3261209.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 18ms/step - loss: 1907631.6250 - val_loss: 3272300.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1905312.2500 - val_loss: 3272041.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1900904.6250 - val_loss: 3271447.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1895425.1250 - val_loss: 3270959.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1891161.1250 - val_loss: 3270589.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1888181.6250 - val_loss: 3270233.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1885787.0000 - val_loss: 3269942.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1883652.8750 - val_loss: 3269716.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1881646.8750 - val_loss: 3269487.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1879725.5000 - val_loss: 3269276.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1877862.7500 - val_loss: 3269064.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1876044.5000 - val_loss: 3268854.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1874263.6250 - val_loss: 3268645.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1872508.0000 - val_loss: 3268436.7500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1870774.0000 - val_loss: 3268228.2500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1869060.0000 - val_loss: 3268021.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1867358.7500 - val_loss: 3267811.7500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1865671.2500 - val_loss: 3267605.2500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1863994.5000 - val_loss: 3267395.0000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1862330.5000 - val_loss: 3267186.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1860675.0000 - val_loss: 3266975.5000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1859028.6250 - val_loss: 3266765.5000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1857386.2500 - val_loss: 3266555.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1855751.0000 - val_loss: 3266343.7500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1854122.1250 - val_loss: 3266132.5000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1852499.8750 - val_loss: 3265918.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1850881.6250 - val_loss: 3265706.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1849268.3750 - val_loss: 3265491.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1847664.1250 - val_loss: 3265277.2500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1846059.5000 - val_loss: 3265059.5000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1844460.1250 - val_loss: 3264843.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1842863.0000 - val_loss: 3264626.5000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1841267.5000 - val_loss: 3264408.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1839677.0000 - val_loss: 3264190.2500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1838092.5000 - val_loss: 3263971.0000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1836510.8750 - val_loss: 3263751.2500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1834929.5000 - val_loss: 3263531.2500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1833351.3750 - val_loss: 3263311.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1831775.2500 - val_loss: 3263088.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1830202.0000 - val_loss: 3262865.5000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1828631.6250 - val_loss: 3262642.0000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1827061.3750 - val_loss: 3262419.0000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1825492.5000 - val_loss: 3262194.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1823927.3750 - val_loss: 3261968.7500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1822363.0000 - val_loss: 3261742.2500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1820798.3750 - val_loss: 3261517.2500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1819237.0000 - val_loss: 3261290.5000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1817676.3750 - val_loss: 3261063.2500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1816119.0000 - val_loss: 3260834.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1814563.5000 - val_loss: 3260604.0000\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 19ms/step - loss: 1908240.8750 - val_loss: 3271890.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1906325.6250 - val_loss: 3271865.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1902871.6250 - val_loss: 3271454.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1897051.1250 - val_loss: 3270864.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1890986.6250 - val_loss: 3270083.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1886715.8750 - val_loss: 3269305.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1883816.0000 - val_loss: 3268798.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1881440.0000 - val_loss: 3268376.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1879288.5000 - val_loss: 3268016.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1877263.2500 - val_loss: 3267664.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1875321.7500 - val_loss: 3267333.0000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1873436.5000 - val_loss: 3267013.2500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1871601.1250 - val_loss: 3266691.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1869800.3750 - val_loss: 3266384.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1868026.1250 - val_loss: 3266075.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1866278.2500 - val_loss: 3265760.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1864548.8750 - val_loss: 3265453.0000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1862836.8750 - val_loss: 3265146.2500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1861141.0000 - val_loss: 3264839.2500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1859456.6250 - val_loss: 3264532.0000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1857781.1250 - val_loss: 3264245.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1856115.7500 - val_loss: 3263948.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1854463.2500 - val_loss: 3263648.7500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1852818.1250 - val_loss: 3263350.2500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1851180.0000 - val_loss: 3263061.2500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1849547.1250 - val_loss: 3262765.0000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1847919.7500 - val_loss: 3262468.0000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1846298.7500 - val_loss: 3262175.5000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1844683.6250 - val_loss: 3261876.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1843073.2500 - val_loss: 3261586.2500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1841468.1250 - val_loss: 3261295.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1839865.6250 - val_loss: 3261005.2500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1838266.0000 - val_loss: 3260700.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1836671.7500 - val_loss: 3260412.0000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1835080.7500 - val_loss: 3260116.7500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1833491.2500 - val_loss: 3259826.7500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1831906.7500 - val_loss: 3259540.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1830323.8750 - val_loss: 3259241.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1828744.7500 - val_loss: 3258958.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1827167.7500 - val_loss: 3258683.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1825590.5000 - val_loss: 3258397.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1824019.1250 - val_loss: 3258111.0000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1822451.2500 - val_loss: 3257839.7500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1820884.8750 - val_loss: 3257556.0000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1819320.5000 - val_loss: 3257248.5000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1817755.8750 - val_loss: 3256984.5000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1816192.7500 - val_loss: 3256705.0000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1814634.7500 - val_loss: 3256405.7500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1813074.5000 - val_loss: 3256155.5000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1811517.3750 - val_loss: 3255894.2500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 19ms/step - loss: 1907997.5000 - val_loss: 3269534.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1906478.3750 - val_loss: 3269447.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1904009.7500 - val_loss: 3269380.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1900356.1250 - val_loss: 3269196.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1895997.2500 - val_loss: 3269026.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1891720.0000 - val_loss: 3268958.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1888655.0000 - val_loss: 3268835.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1886270.3750 - val_loss: 3268684.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1884129.8750 - val_loss: 3268519.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1882116.7500 - val_loss: 3268351.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1880179.0000 - val_loss: 3268175.5000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1878304.8750 - val_loss: 3267996.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1876471.8750 - val_loss: 3267817.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1874672.8750 - val_loss: 3267633.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1872900.2500 - val_loss: 3267448.7500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1871152.3750 - val_loss: 3267263.0000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1869419.5000 - val_loss: 3267074.7500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1867705.1250 - val_loss: 3266884.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1866007.2500 - val_loss: 3266691.2500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1864323.6250 - val_loss: 3266498.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1862649.2500 - val_loss: 3266301.0000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1860984.2500 - val_loss: 3266103.5000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1859326.8750 - val_loss: 3265903.7500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1857680.5000 - val_loss: 3265702.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1856039.3750 - val_loss: 3265504.2500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1854405.0000 - val_loss: 3265299.5000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1852778.7500 - val_loss: 3265096.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1851156.3750 - val_loss: 3264892.7500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1849537.6250 - val_loss: 3264680.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1847923.2500 - val_loss: 3264476.2500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1846315.6250 - val_loss: 3264264.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1844709.8750 - val_loss: 3264052.0000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1843110.1250 - val_loss: 3263838.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1841513.3750 - val_loss: 3263624.2500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1839918.2500 - val_loss: 3263410.0000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1838330.1250 - val_loss: 3263188.7500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1836743.0000 - val_loss: 3262973.5000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1835159.3750 - val_loss: 3262750.5000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1833578.6250 - val_loss: 3262529.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1831999.8750 - val_loss: 3262305.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1830423.2500 - val_loss: 3262077.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1828849.5000 - val_loss: 3261857.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1827276.8750 - val_loss: 3261624.2500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1825706.0000 - val_loss: 3261401.5000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1824137.0000 - val_loss: 3261166.2500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1822572.3750 - val_loss: 3260937.7500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1821008.8750 - val_loss: 3260707.0000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1819447.3750 - val_loss: 3260470.0000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1817886.6250 - val_loss: 3260231.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1816328.1250 - val_loss: 3259994.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 19ms/step - loss: 1908240.3750 - val_loss: 3269563.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1906385.6250 - val_loss: 3269686.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1902871.1250 - val_loss: 3269742.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1897592.3750 - val_loss: 3269372.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1892408.7500 - val_loss: 3268821.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1888612.1250 - val_loss: 3268397.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1886036.2500 - val_loss: 3268053.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1883818.6250 - val_loss: 3267747.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1881760.8750 - val_loss: 3267453.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1879805.7500 - val_loss: 3267169.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1877913.2500 - val_loss: 3266887.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1876071.3750 - val_loss: 3266615.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1874267.3750 - val_loss: 3266346.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1872491.5000 - val_loss: 3266071.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1870744.6250 - val_loss: 3265804.7500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1869015.1250 - val_loss: 3265536.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1867304.3750 - val_loss: 3265277.0000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1865606.3750 - val_loss: 3265012.7500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1863921.0000 - val_loss: 3264747.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1862250.8750 - val_loss: 3264481.0000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1860588.1250 - val_loss: 3264222.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1858930.6250 - val_loss: 3263951.5000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1857283.3750 - val_loss: 3263695.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1855644.1250 - val_loss: 3263433.0000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1854013.7500 - val_loss: 3263168.0000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1852388.0000 - val_loss: 3262905.5000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1850765.7500 - val_loss: 3262641.5000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1849152.6250 - val_loss: 3262374.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1847542.0000 - val_loss: 3262111.2500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1845933.0000 - val_loss: 3261851.2500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1844329.0000 - val_loss: 3261586.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1842728.8750 - val_loss: 3261326.0000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1841132.1250 - val_loss: 3261066.7500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1839536.8750 - val_loss: 3260801.2500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1837948.7500 - val_loss: 3260540.0000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1836363.6250 - val_loss: 3260267.5000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1834780.0000 - val_loss: 3260005.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1833202.5000 - val_loss: 3259751.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1831624.1250 - val_loss: 3259482.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1830048.0000 - val_loss: 3259216.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1828476.3750 - val_loss: 3258963.2500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1826906.3750 - val_loss: 3258695.2500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1825337.1250 - val_loss: 3258429.7500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1823771.2500 - val_loss: 3258169.5000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1822205.7500 - val_loss: 3257898.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1820643.3750 - val_loss: 3257638.2500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1819082.8750 - val_loss: 3257364.5000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1817523.6250 - val_loss: 3257101.5000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1815965.2500 - val_loss: 3256840.5000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1814408.2500 - val_loss: 3256576.0000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 19ms/step - loss: 1908176.8750 - val_loss: 3269528.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1906576.1250 - val_loss: 3269318.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1903849.0000 - val_loss: 3269921.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1899278.8750 - val_loss: 3270566.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1893565.7500 - val_loss: 3270684.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1889428.5000 - val_loss: 3270478.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1886679.7500 - val_loss: 3270333.0000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 25ms/step - loss: 1908289.2500 - val_loss: 3270877.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1906840.3750 - val_loss: 3270826.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1904175.6250 - val_loss: 3270782.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1899470.2500 - val_loss: 3270573.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1894209.2500 - val_loss: 3270189.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1890405.6250 - val_loss: 3269807.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1887713.8750 - val_loss: 3269505.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1885421.7500 - val_loss: 3269246.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1883314.5000 - val_loss: 3269005.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1881316.6250 - val_loss: 3268778.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1879396.8750 - val_loss: 3268556.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1877529.0000 - val_loss: 3268344.2500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1875703.6250 - val_loss: 3268129.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1873912.3750 - val_loss: 3267921.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1872146.8750 - val_loss: 3267712.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1870402.8750 - val_loss: 3267502.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1868675.8750 - val_loss: 3267294.5000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1866965.2500 - val_loss: 3267088.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1865268.6250 - val_loss: 3266880.0000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1863586.1250 - val_loss: 3266672.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1861914.3750 - val_loss: 3266467.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1860250.7500 - val_loss: 3266260.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1858598.6250 - val_loss: 3266052.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1856954.5000 - val_loss: 3265846.0000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1855313.5000 - val_loss: 3265639.0000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1853681.6250 - val_loss: 3265435.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1852055.2500 - val_loss: 3265225.0000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1850435.6250 - val_loss: 3265018.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1848821.2500 - val_loss: 3264810.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1847210.7500 - val_loss: 3264600.7500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1845606.6250 - val_loss: 3264392.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1844004.7500 - val_loss: 3264183.0000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1842405.0000 - val_loss: 3263974.0000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1840808.0000 - val_loss: 3263766.0000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1839214.2500 - val_loss: 3263553.7500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1837625.0000 - val_loss: 3263343.7500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1836039.2500 - val_loss: 3263133.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1834456.5000 - val_loss: 3262921.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1832877.8750 - val_loss: 3262710.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1831299.3750 - val_loss: 3262494.5000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1829724.7500 - val_loss: 3262282.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1828149.7500 - val_loss: 3262064.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1826577.6250 - val_loss: 3261850.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1825007.6250 - val_loss: 3261635.0000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1823438.1250 - val_loss: 3261422.7500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1821869.6250 - val_loss: 3261205.2500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1820305.5000 - val_loss: 3260988.2500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1818742.6250 - val_loss: 3260767.5000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1817183.7500 - val_loss: 3260545.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1815626.2500 - val_loss: 3260326.2500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 18ms/step - loss: 1908128.1250 - val_loss: 3269855.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1906653.1250 - val_loss: 3269811.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1904231.6250 - val_loss: 3269601.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1900524.7500 - val_loss: 3269342.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1896148.6250 - val_loss: 3269118.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1892682.6250 - val_loss: 3268892.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1890064.8750 - val_loss: 3268696.7500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1887821.1250 - val_loss: 3268520.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1885751.8750 - val_loss: 3268333.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1883781.8750 - val_loss: 3268144.5000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1881886.0000 - val_loss: 3267949.0000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1880038.8750 - val_loss: 3267754.2500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1878230.8750 - val_loss: 3267555.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1876453.5000 - val_loss: 3267357.7500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1874700.0000 - val_loss: 3267153.7500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1872967.0000 - val_loss: 3266953.0000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1871249.5000 - val_loss: 3266749.0000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1869550.1250 - val_loss: 3266542.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1867861.0000 - val_loss: 3266334.5000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1866185.0000 - val_loss: 3266127.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1864517.8750 - val_loss: 3265917.7500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1862860.3750 - val_loss: 3265710.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1861210.0000 - val_loss: 3265498.0000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1859569.1250 - val_loss: 3265288.0000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1857932.0000 - val_loss: 3265074.5000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1856302.3750 - val_loss: 3264860.2500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1854678.8750 - val_loss: 3264646.0000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1853060.1250 - val_loss: 3264430.7500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1851446.5000 - val_loss: 3264212.5000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1849839.0000 - val_loss: 3263995.0000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1848234.6250 - val_loss: 3263776.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1846632.6250 - val_loss: 3263557.7500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1845033.5000 - val_loss: 3263338.0000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1843439.0000 - val_loss: 3263116.5000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1841849.2500 - val_loss: 3262894.2500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1840264.8750 - val_loss: 3262670.7500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1838679.2500 - val_loss: 3262447.2500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1837098.1250 - val_loss: 3262221.7500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1835519.8750 - val_loss: 3261996.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1833941.2500 - val_loss: 3261768.5000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1832367.0000 - val_loss: 3261542.5000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1830792.1250 - val_loss: 3261315.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1829219.2500 - val_loss: 3261089.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1827644.5000 - val_loss: 3260860.7500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1826077.2500 - val_loss: 3260630.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1824511.2500 - val_loss: 3260398.7500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1822950.0000 - val_loss: 3260166.7500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1821390.3750 - val_loss: 3259934.0000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1819829.3750 - val_loss: 3259702.2500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1818270.6250 - val_loss: 3259467.7500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 20ms/step - loss: 1908465.0000 - val_loss: 3270807.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1906744.7500 - val_loss: 3270861.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1903372.5000 - val_loss: 3270508.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1897648.2500 - val_loss: 3270186.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1891906.1250 - val_loss: 3269885.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1888249.0000 - val_loss: 3269654.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1885590.8750 - val_loss: 3269442.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1883313.7500 - val_loss: 3269224.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1881220.2500 - val_loss: 3269016.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1879236.6250 - val_loss: 3268812.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1877323.5000 - val_loss: 3268607.0000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1875461.8750 - val_loss: 3268400.0000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1873645.3750 - val_loss: 3268194.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1871859.6250 - val_loss: 3267983.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1870100.2500 - val_loss: 3267776.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1868361.1250 - val_loss: 3267570.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1866641.5000 - val_loss: 3267365.0000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1864937.0000 - val_loss: 3267160.2500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1863249.5000 - val_loss: 3266955.0000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1861573.2500 - val_loss: 3266749.0000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1859907.3750 - val_loss: 3266545.5000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1858250.7500 - val_loss: 3266342.5000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1856599.2500 - val_loss: 3266137.7500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1854958.7500 - val_loss: 3265935.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1853323.1250 - val_loss: 3265734.7500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1851693.8750 - val_loss: 3265532.0000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1850069.3750 - val_loss: 3265329.5000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1848451.3750 - val_loss: 3265127.7500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1846838.8750 - val_loss: 3264924.7500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1845233.1250 - val_loss: 3264722.0000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1843629.5000 - val_loss: 3264517.7500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1842030.5000 - val_loss: 3264316.2500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1840435.2500 - val_loss: 3264110.7500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1838841.8750 - val_loss: 3263905.0000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1837252.5000 - val_loss: 3263698.7500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1835663.7500 - val_loss: 3263494.7500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1834082.5000 - val_loss: 3263286.5000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1832498.5000 - val_loss: 3263079.2500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1830920.2500 - val_loss: 3262870.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1829344.7500 - val_loss: 3262661.5000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1827768.7500 - val_loss: 3262448.0000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1826196.6250 - val_loss: 3262233.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1824629.6250 - val_loss: 3262019.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1823061.7500 - val_loss: 3261800.7500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1821499.7500 - val_loss: 3261583.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1819937.3750 - val_loss: 3261365.0000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1818376.8750 - val_loss: 3261147.0000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1816817.2500 - val_loss: 3260925.2500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1815258.3750 - val_loss: 3260705.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1813702.6250 - val_loss: 3260479.5000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Best_hyper_parameters: \n",
            " {'model': [10], 'optimizer': 'Adam', 'learning_rate': 0.1, 'batch_size': 4, 'best_avg_rmse': 1457.4247689598385}\n",
            "all_avg_rmse: \n",
            " [[[1457.42476896 1516.34778265 1540.91793819]\n",
            "  [1559.37159179 1593.71709369 1623.90901636]\n",
            "  [1647.28439758 1666.63274352 1682.15445055]]\n",
            "\n",
            " [[1691.1711407  1699.77819111 1707.72388432]\n",
            "  [1715.19828388 1721.72969785 1727.43400023]\n",
            "  [1732.45430105 1736.90859706 1740.87489885]]\n",
            "\n",
            " [[1727.63128056 1716.44813828 1713.02483791]\n",
            "  [1708.23988585 1709.27385217 1712.03817387]\n",
            "  [1715.11633683 1718.49496674 1721.7167455 ]]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'model': [10],\n",
              " 'optimizer': 'Adam',\n",
              " 'learning_rate': 0.1,\n",
              " 'batch_size': 4,\n",
              " 'best_avg_rmse': 1457.4247689598385}"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layers = [10]\n",
        "time_step = 5\n",
        "optimizers_names = ['Adam', 'Adagrad', 'Nadam']\n",
        "learning_rates =  [0.1, 0.01, 0.001]\n",
        "batch_sizes =  [4, 8, 16]\n",
        "epochs = 50\n",
        "num_replicates = 10\n",
        "\n",
        "\n",
        "N10_best_hyper_parameters = hyper_parameter_tuning(layers,  optimizers_names, learning_rates, batch_sizes, epochs = epochs, num_replicates = num_replicates)\n",
        "N10_best_hyper_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW2NwvjjqmH5"
      },
      "source": [
        "### Case II: Tuning parameters of 30 neuron single layer LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPamURZaqloU",
        "outputId": "b877be74-ec04-44e4-fb52-8a96bf4255a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 410613.5938 - val_loss: 3175682.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 297586.7500 - val_loss: 3176362.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 215245.8906 - val_loss: 3174372.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 156020.5000 - val_loss: 3173525.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 115122.4297 - val_loss: 3180685.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 87535.1641 - val_loss: 3189088.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 69334.3359 - val_loss: 3193681.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 57715.8555 - val_loss: 3206923.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 50585.6680 - val_loss: 3212237.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 19ms/step - loss: 1711751.0000 - val_loss: 3118628.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1334391.2500 - val_loss: 2947073.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1025008.0000 - val_loss: 2829316.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 778145.3750 - val_loss: 2767033.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 582866.5000 - val_loss: 2734550.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 431925.4062 - val_loss: 2724269.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 316944.1875 - val_loss: 2702985.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 231732.5938 - val_loss: 2686160.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 169329.6875 - val_loss: 2674764.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 125437.8594 - val_loss: 2670397.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 95154.7266 - val_loss: 2668733.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 74738.3906 - val_loss: 2670868.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 61414.6406 - val_loss: 2678898.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 52941.5664 - val_loss: 2698562.5000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 46205.6172 - val_loss: 2689561.7500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 39625.2266 - val_loss: 2724611.2500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 20ms/step - loss: 1719374.8750 - val_loss: 3257287.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1353855.7500 - val_loss: 3238911.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1052343.5000 - val_loss: 3226511.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 808067.0625 - val_loss: 3213821.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 613012.6875 - val_loss: 3205444.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 459821.5625 - val_loss: 3198589.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 341916.7500 - val_loss: 3193779.7500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 252496.3594 - val_loss: 3190767.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 186286.7031 - val_loss: 3188888.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 138472.0312 - val_loss: 3188035.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 104981.2344 - val_loss: 3187974.5000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 81716.2500 - val_loss: 3188244.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 66321.0078 - val_loss: 3188496.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 56273.7500 - val_loss: 3188676.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 49995.8516 - val_loss: 3187056.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 53533.3398 - val_loss: 2922318.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 34400.9648 - val_loss: 2380152.0000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 22884.4473 - val_loss: 2451107.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 16633.4434 - val_loss: 2292684.0000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 12997.0215 - val_loss: 2175996.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 10534.6260 - val_loss: 2169003.0000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 8714.8633 - val_loss: 2154712.7500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 7579.6069 - val_loss: 2356484.7500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 6807.8315 - val_loss: 2307325.7500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 5624.3027 - val_loss: 2365042.2500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 5100.4414 - val_loss: 2324090.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 4438.1211 - val_loss: 2256557.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 24ms/step - loss: 1719611.3750 - val_loss: 3255478.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1343093.8750 - val_loss: 3238145.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1033634.0625 - val_loss: 3219849.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 785409.0000 - val_loss: 3206682.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 588876.8125 - val_loss: 3198476.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 436399.4688 - val_loss: 3191391.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 320460.3438 - val_loss: 3187134.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 234118.7188 - val_loss: 3184100.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 171155.6719 - val_loss: 3182508.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 126668.5391 - val_loss: 3182177.5000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 95983.1094 - val_loss: 3182372.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 75458.6172 - val_loss: 3182993.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 61916.9766 - val_loss: 3184138.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 53131.3203 - val_loss: 3253082.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 52047.7656 - val_loss: 2323578.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 36069.0195 - val_loss: 2393632.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 30101.5645 - val_loss: 2386028.7500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 25713.5977 - val_loss: 2414661.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 21391.3574 - val_loss: 2406106.2500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 18173.0547 - val_loss: 2425626.7500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 21ms/step - loss: 1710467.0000 - val_loss: 3266996.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1326220.1250 - val_loss: 3260259.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1005476.6875 - val_loss: 3215070.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 754018.1250 - val_loss: 3191415.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 557747.5000 - val_loss: 3166653.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 407962.0625 - val_loss: 3154441.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 295273.9375 - val_loss: 3145480.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 213273.2188 - val_loss: 3139288.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 154590.6719 - val_loss: 3134870.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 114206.6406 - val_loss: 3131634.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 86889.0938 - val_loss: 3129721.5000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 68818.3516 - val_loss: 3128100.2500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 57211.0000 - val_loss: 3138198.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 50254.6094 - val_loss: 3138896.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 45906.1250 - val_loss: 3182726.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 51818.6680 - val_loss: 2211242.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 29285.2012 - val_loss: 2203316.0000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 24655.2578 - val_loss: 2223466.7500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 20793.2324 - val_loss: 2233031.2500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 17501.4922 - val_loss: 2216400.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 15020.0498 - val_loss: 2235794.7500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 12908.3359 - val_loss: 2219372.5000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 26ms/step - loss: 1704898.6250 - val_loss: 3280415.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1317717.6250 - val_loss: 3269757.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1002889.5625 - val_loss: 3249176.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 752764.6250 - val_loss: 3234691.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 557658.0625 - val_loss: 3225946.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 408522.7812 - val_loss: 3219919.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 296253.5000 - val_loss: 3215616.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 214023.0000 - val_loss: 3213221.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 155128.5156 - val_loss: 3210971.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 114303.4297 - val_loss: 3208994.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 86978.7188 - val_loss: 3207192.5000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 68993.4375 - val_loss: 3204948.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 57503.0469 - val_loss: 3201740.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 50409.3477 - val_loss: 3195016.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 76195.3672 - val_loss: 3057123.2500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 36515.0469 - val_loss: 2990792.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 30079.7480 - val_loss: 2916828.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 24848.5039 - val_loss: 2898072.2500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 20843.3750 - val_loss: 2882672.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 17573.6875 - val_loss: 2901286.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 14852.4766 - val_loss: 2891723.0000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 12811.6816 - val_loss: 2905069.2500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 11335.3975 - val_loss: 2920104.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 9969.1035 - val_loss: 2945109.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 22ms/step - loss: 1714353.5000 - val_loss: 3155400.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1333844.2500 - val_loss: 3137715.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1023334.3750 - val_loss: 3121930.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 775234.9375 - val_loss: 3138414.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 580831.7500 - val_loss: 3136436.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 429637.3125 - val_loss: 3138266.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 314653.4062 - val_loss: 3130897.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 229707.7500 - val_loss: 3125899.7500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 19ms/step - loss: 1706682.0000 - val_loss: 3218079.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1318593.2500 - val_loss: 3171675.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1002963.0625 - val_loss: 3175802.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 753297.3750 - val_loss: 3155215.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 557630.7500 - val_loss: 3137212.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 407959.7188 - val_loss: 3127733.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 296061.5938 - val_loss: 3122573.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 213889.7969 - val_loss: 3116567.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 155244.2031 - val_loss: 3117936.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 114663.8750 - val_loss: 3118387.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 87223.0625 - val_loss: 3119412.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 68998.2031 - val_loss: 3117635.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 57491.3789 - val_loss: 3107833.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 50354.2500 - val_loss: 3100230.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 43449.8359 - val_loss: 2652694.2500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 33521.6289 - val_loss: 2537916.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 27843.4531 - val_loss: 2603504.5000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 23314.1348 - val_loss: 2586533.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 19824.3262 - val_loss: 2608688.5000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 17094.1738 - val_loss: 2723125.5000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 14775.9219 - val_loss: 2633341.2500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 12ms/step - loss: 1802732.1250 - val_loss: 3251676.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1629160.6250 - val_loss: 3234236.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1474420.2500 - val_loss: 3216698.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1332048.3750 - val_loss: 3199041.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1200504.3750 - val_loss: 3180497.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1078877.3750 - val_loss: 3161133.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 966560.7500 - val_loss: 3145503.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 863077.1250 - val_loss: 3128819.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 767903.6875 - val_loss: 3113346.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 680526.8750 - val_loss: 3098641.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 600575.7500 - val_loss: 3082803.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 527763.2500 - val_loss: 3070119.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 461628.1250 - val_loss: 3058230.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 401810.6875 - val_loss: 3048019.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 348023.1875 - val_loss: 3036403.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 299951.3438 - val_loss: 3022348.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 257265.1875 - val_loss: 3011517.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 219680.7344 - val_loss: 2991366.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 186849.7969 - val_loss: 2981114.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 158422.2031 - val_loss: 2969622.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 134117.1719 - val_loss: 2966243.2500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 113655.3516 - val_loss: 2965652.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 96653.5859 - val_loss: 2964542.2500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 82725.4922 - val_loss: 2977322.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 71535.9844 - val_loss: 2998575.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 62761.9844 - val_loss: 3016424.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 56065.1523 - val_loss: 3030224.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 51054.8047 - val_loss: 3072623.2500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 1802122.8750 - val_loss: 3270856.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1628150.2500 - val_loss: 3267113.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1473371.7500 - val_loss: 3261547.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1330977.6250 - val_loss: 3251736.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1199436.5000 - val_loss: 3242867.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1077896.7500 - val_loss: 3234603.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 965732.8750 - val_loss: 3227207.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 862384.2500 - val_loss: 3220601.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 767297.0625 - val_loss: 3214738.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 680025.6250 - val_loss: 3210315.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 600182.2500 - val_loss: 3205202.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 527395.1875 - val_loss: 3197197.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 461290.0312 - val_loss: 3194277.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 401522.6875 - val_loss: 3189693.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 347781.5938 - val_loss: 3180726.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 299718.3125 - val_loss: 3178821.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 257083.6562 - val_loss: 3177992.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 219497.7344 - val_loss: 3177430.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 186671.3750 - val_loss: 3177465.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 158323.7500 - val_loss: 3177946.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 134093.3750 - val_loss: 3178893.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 113582.2812 - val_loss: 3187559.5000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 96539.5703 - val_loss: 3191427.0000\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 9ms/step - loss: 1801424.5000 - val_loss: 3249479.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1627509.2500 - val_loss: 3231931.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1472669.8750 - val_loss: 3219496.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1330237.0000 - val_loss: 3211761.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1198686.2500 - val_loss: 3201402.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1077149.5000 - val_loss: 3188245.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 965019.1875 - val_loss: 3174262.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 861635.0000 - val_loss: 3163340.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 766524.9375 - val_loss: 3153296.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 679259.8750 - val_loss: 3142559.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 599455.1875 - val_loss: 3133111.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 526728.9375 - val_loss: 3124317.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 460644.5312 - val_loss: 3116426.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 400953.8750 - val_loss: 3109308.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 347296.4062 - val_loss: 3102967.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 299352.9062 - val_loss: 3097245.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 256767.6250 - val_loss: 3092310.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 219213.1094 - val_loss: 3087965.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 186452.2812 - val_loss: 3084133.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 158133.9062 - val_loss: 3081013.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 133942.3125 - val_loss: 3078962.2500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 113499.9844 - val_loss: 3083907.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 96484.6797 - val_loss: 3081983.5000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 82562.2578 - val_loss: 3088906.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 71395.8672 - val_loss: 3088160.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 62653.6328 - val_loss: 3096652.0000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 11ms/step - loss: 1800334.7500 - val_loss: 3265045.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1625627.1250 - val_loss: 3255764.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1470791.6250 - val_loss: 3244222.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1328495.5000 - val_loss: 3230363.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1197129.6250 - val_loss: 3216397.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1075736.3750 - val_loss: 3202785.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 963754.1875 - val_loss: 3189807.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 860534.2500 - val_loss: 3177896.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 765615.6875 - val_loss: 3166861.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 678532.3125 - val_loss: 3156277.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 598770.3125 - val_loss: 3143884.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 526070.1875 - val_loss: 3133198.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 460064.3125 - val_loss: 3123128.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 400401.8125 - val_loss: 3115385.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 346765.7188 - val_loss: 3108539.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 298799.1562 - val_loss: 3101529.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 256210.6406 - val_loss: 3095656.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 218688.8438 - val_loss: 3084383.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 185956.2031 - val_loss: 3079092.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 157679.2188 - val_loss: 3076392.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 133513.9062 - val_loss: 3078542.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 113118.5859 - val_loss: 3075458.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 96198.2500 - val_loss: 3072813.2500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 82377.6172 - val_loss: 3071094.2500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 71280.2344 - val_loss: 3071809.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 62538.8594 - val_loss: 3088155.5000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 55877.5469 - val_loss: 3086556.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 50927.2617 - val_loss: 3087042.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 47000.2773 - val_loss: 3131427.0000\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 13ms/step - loss: 1802544.8750 - val_loss: 3253612.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1627931.2500 - val_loss: 3234457.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1473049.1250 - val_loss: 3214755.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1330657.2500 - val_loss: 3197705.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1199145.1250 - val_loss: 3179742.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1077652.5000 - val_loss: 3161961.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 965490.0625 - val_loss: 3145304.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 862076.3125 - val_loss: 3126037.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 766966.1875 - val_loss: 3108294.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 679679.7500 - val_loss: 3090979.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 599767.6250 - val_loss: 3076402.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 527010.3125 - val_loss: 3062503.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 460894.5000 - val_loss: 3032009.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 401130.4062 - val_loss: 3015304.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 347420.1250 - val_loss: 3003020.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 299363.6875 - val_loss: 2991493.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 256707.1562 - val_loss: 2980070.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 219123.5156 - val_loss: 2966401.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 186326.6094 - val_loss: 2956565.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 157981.7656 - val_loss: 2940434.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 133777.6406 - val_loss: 2935493.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 113335.9922 - val_loss: 2933367.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 96342.5000 - val_loss: 2934922.7500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 82508.2188 - val_loss: 2943971.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 71416.7109 - val_loss: 2964783.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 62667.4180 - val_loss: 2983348.2500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 55951.9180 - val_loss: 2997596.2500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 1805018.0000 - val_loss: 3267999.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1630576.7500 - val_loss: 3258893.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1475638.3750 - val_loss: 3244825.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1333198.1250 - val_loss: 3230872.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1201571.1250 - val_loss: 3216532.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1079897.0000 - val_loss: 3203272.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 967534.8750 - val_loss: 3191412.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 863939.0625 - val_loss: 3177972.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 768636.1250 - val_loss: 3163063.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 681247.0625 - val_loss: 3140946.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 601294.0625 - val_loss: 3127838.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 528350.0625 - val_loss: 3117960.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 462161.3125 - val_loss: 3107097.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 402347.6875 - val_loss: 3093911.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 348562.0625 - val_loss: 3084435.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 300385.8438 - val_loss: 3076675.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 257626.9219 - val_loss: 3070199.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 220009.5000 - val_loss: 3064400.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 187119.7969 - val_loss: 3059381.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 158699.7344 - val_loss: 3054801.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 134420.9844 - val_loss: 3050781.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 113889.4531 - val_loss: 3048367.2500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 96836.6250 - val_loss: 3052012.5000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 82864.0391 - val_loss: 3049841.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 71617.8438 - val_loss: 3055905.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 62815.4492 - val_loss: 3054799.2500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 56109.3750 - val_loss: 3078209.7500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 11ms/step - loss: 1799992.5000 - val_loss: 3260267.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1626936.2500 - val_loss: 3242797.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1472587.6250 - val_loss: 3225028.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1330395.1250 - val_loss: 3206443.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1199005.8750 - val_loss: 3190739.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1077576.6250 - val_loss: 3177224.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 965439.6250 - val_loss: 3163704.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 862073.6250 - val_loss: 3151145.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 767010.0000 - val_loss: 3139328.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 679764.0000 - val_loss: 3125687.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 600055.4375 - val_loss: 3116494.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 527367.5000 - val_loss: 3106889.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 461225.4062 - val_loss: 3096852.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 401432.7188 - val_loss: 3086907.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 347652.7812 - val_loss: 3077500.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 299569.2500 - val_loss: 3071152.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 256904.9062 - val_loss: 3067148.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 219345.6250 - val_loss: 3059804.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 186536.5000 - val_loss: 3057055.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 158174.7031 - val_loss: 3055228.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 133917.8281 - val_loss: 3054715.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 113452.0703 - val_loss: 3053880.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 96469.4375 - val_loss: 3057503.7500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 82570.9922 - val_loss: 3056334.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 71427.2266 - val_loss: 3062289.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 62665.2734 - val_loss: 3060920.7500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 55958.3438 - val_loss: 3068066.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 10ms/step - loss: 1802753.3750 - val_loss: 3268579.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1628611.3750 - val_loss: 3260083.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1473876.0000 - val_loss: 3244799.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1331496.7500 - val_loss: 3229170.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1199943.2500 - val_loss: 3214102.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1078391.7500 - val_loss: 3198916.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 966176.6250 - val_loss: 3179220.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 862742.1250 - val_loss: 3163178.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 767558.8125 - val_loss: 3151091.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 680163.4375 - val_loss: 3140156.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 600268.6875 - val_loss: 3130510.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 527470.2500 - val_loss: 3121691.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 461380.8125 - val_loss: 3112698.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 401624.2188 - val_loss: 3103938.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 347902.4062 - val_loss: 3097165.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 299848.2812 - val_loss: 3088362.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 257165.5469 - val_loss: 3084110.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 219585.3594 - val_loss: 3081353.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 186743.9375 - val_loss: 3080357.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 158326.0938 - val_loss: 3077844.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 134015.2656 - val_loss: 3074933.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 113533.9297 - val_loss: 3072646.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 96521.2031 - val_loss: 3075697.5000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 82641.0156 - val_loss: 3077205.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 71469.7500 - val_loss: 3084290.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 62706.8672 - val_loss: 3084162.5000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 56021.4336 - val_loss: 3093601.0000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 11ms/step - loss: 1805298.5000 - val_loss: 3262453.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1631367.6250 - val_loss: 3245232.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1476385.1250 - val_loss: 3230460.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1333883.7500 - val_loss: 3211799.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1202219.2500 - val_loss: 3193626.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1080543.8750 - val_loss: 3174795.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 968226.0000 - val_loss: 3156169.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 864722.7500 - val_loss: 3138313.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 769488.9375 - val_loss: 3121031.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 682019.6875 - val_loss: 3107584.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 602022.7500 - val_loss: 3092366.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 529129.1875 - val_loss: 3077404.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 462901.6562 - val_loss: 3066513.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 402996.0625 - val_loss: 3056797.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 349101.0625 - val_loss: 3047991.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 300933.1562 - val_loss: 3039929.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 258162.4844 - val_loss: 3032370.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 220496.1094 - val_loss: 3020123.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 187570.4844 - val_loss: 3008258.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 159095.7656 - val_loss: 2999900.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 134778.3750 - val_loss: 2994368.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 114215.4844 - val_loss: 2989889.2500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 97083.2734 - val_loss: 2988256.5000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 83101.8984 - val_loss: 2987417.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 71864.2344 - val_loss: 2987129.2500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 63045.8164 - val_loss: 2997708.2500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 56293.0820 - val_loss: 3018693.2500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 51221.1875 - val_loss: 3032130.5000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 48096.5938 - val_loss: 2579431.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 38198.0156 - val_loss: 2518975.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 31927.5820 - val_loss: 2521111.5000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 27235.7207 - val_loss: 2521530.7500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 23228.4336 - val_loss: 2533927.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 19858.7793 - val_loss: 2606114.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 16746.4219 - val_loss: 2622551.5000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 10ms/step - loss: 1802297.8750 - val_loss: 3261865.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1627988.0000 - val_loss: 3251092.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1473057.1250 - val_loss: 3239036.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1330491.2500 - val_loss: 3224672.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1198857.1250 - val_loss: 3210698.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1077405.0000 - val_loss: 3196620.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 965308.6250 - val_loss: 3183793.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 861993.6250 - val_loss: 3172414.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 766909.6875 - val_loss: 3154455.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 679678.1875 - val_loss: 3143420.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 599891.3125 - val_loss: 3133565.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 527113.7500 - val_loss: 3122407.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 461003.4375 - val_loss: 3114922.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 401232.3125 - val_loss: 3107467.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 347495.3438 - val_loss: 3098727.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 299500.2188 - val_loss: 3088109.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 256892.2500 - val_loss: 3081547.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 219345.5312 - val_loss: 3077202.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 186561.7656 - val_loss: 3075697.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 158204.2812 - val_loss: 3072270.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 133951.8594 - val_loss: 3069610.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 113520.2109 - val_loss: 3067074.5000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 96508.3828 - val_loss: 3068767.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 82627.3984 - val_loss: 3075691.2500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 71500.8047 - val_loss: 3087957.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 62747.5547 - val_loss: 3089155.7500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 56050.2266 - val_loss: 3098371.7500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 14ms/step - loss: 1848801.3750 - val_loss: 3272306.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1753544.1250 - val_loss: 3272047.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1668437.0000 - val_loss: 3269114.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1587596.3750 - val_loss: 3264240.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1510178.1250 - val_loss: 3259226.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1435831.1250 - val_loss: 3253845.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1364391.0000 - val_loss: 3248161.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1295743.5000 - val_loss: 3242493.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1229744.5000 - val_loss: 3236707.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1166313.6250 - val_loss: 3231065.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1105340.3750 - val_loss: 3223793.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1046694.5000 - val_loss: 3216211.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 990390.6875 - val_loss: 3210539.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 936339.6250 - val_loss: 3205295.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 884438.3750 - val_loss: 3200276.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 834654.6250 - val_loss: 3192926.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 786883.3125 - val_loss: 3185703.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 741164.6875 - val_loss: 3180376.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 697385.9375 - val_loss: 3175883.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 655517.6250 - val_loss: 3171432.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 615503.3750 - val_loss: 3167233.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 577262.8750 - val_loss: 3163507.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 540752.7500 - val_loss: 3159609.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 505963.3750 - val_loss: 3156224.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 472863.4688 - val_loss: 3152113.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 441412.5938 - val_loss: 3143440.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 411562.4062 - val_loss: 3139797.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 383204.4375 - val_loss: 3132315.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 356324.8750 - val_loss: 3126761.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 330912.5000 - val_loss: 3123820.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 306940.1562 - val_loss: 3120419.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 284343.3750 - val_loss: 3116649.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 263103.3125 - val_loss: 3114104.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 243145.3281 - val_loss: 3111369.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 224422.7344 - val_loss: 3108932.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 206907.2500 - val_loss: 3106573.2500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 190643.5938 - val_loss: 3104391.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 175500.7656 - val_loss: 3102343.7500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 161441.6250 - val_loss: 3102823.2500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 148460.6250 - val_loss: 3101686.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 136509.4375 - val_loss: 3100379.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 125501.6172 - val_loss: 3102736.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 115424.1328 - val_loss: 3101336.0000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 106186.0078 - val_loss: 3099420.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 97820.0781 - val_loss: 3098004.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 90299.0781 - val_loss: 3096734.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 83513.1953 - val_loss: 3095637.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 77438.3359 - val_loss: 3095150.0000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 72014.9141 - val_loss: 3102537.2500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 67220.2188 - val_loss: 3100668.0000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 13ms/step - loss: 1849177.0000 - val_loss: 3270936.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1752569.8750 - val_loss: 3267297.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1667146.0000 - val_loss: 3261562.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1585991.0000 - val_loss: 3255948.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1508491.6250 - val_loss: 3249196.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1434108.0000 - val_loss: 3243251.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1362618.0000 - val_loss: 3236246.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1293954.8750 - val_loss: 3230757.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1227917.6250 - val_loss: 3223966.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1164470.5000 - val_loss: 3218047.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1103484.2500 - val_loss: 3211674.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1044885.7500 - val_loss: 3205777.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 988600.1250 - val_loss: 3199866.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 934630.7500 - val_loss: 3194342.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 882781.1875 - val_loss: 3188900.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 833063.8125 - val_loss: 3183753.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 785375.3125 - val_loss: 3178676.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 739700.1250 - val_loss: 3173721.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 695943.5625 - val_loss: 3169063.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 654115.0625 - val_loss: 3164536.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 614103.7500 - val_loss: 3160445.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 575930.8750 - val_loss: 3156971.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 539515.6875 - val_loss: 3146078.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 504831.7812 - val_loss: 3141032.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 471820.1250 - val_loss: 3136789.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 440416.8438 - val_loss: 3132798.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 410559.9375 - val_loss: 3126630.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 382256.9062 - val_loss: 3124155.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 355443.0625 - val_loss: 3117343.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 330058.6875 - val_loss: 3113460.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 306094.0625 - val_loss: 3109220.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 283548.3125 - val_loss: 3106573.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 262328.4062 - val_loss: 3103338.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 242418.9844 - val_loss: 3100902.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 223770.3750 - val_loss: 3098181.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 206319.8438 - val_loss: 3095765.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 190064.2031 - val_loss: 3093432.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 174950.2344 - val_loss: 3091158.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 160929.7188 - val_loss: 3088977.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 147958.0938 - val_loss: 3086896.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 136010.4219 - val_loss: 3084963.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 125040.5938 - val_loss: 3083273.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 115009.7422 - val_loss: 3081710.2500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 105832.8516 - val_loss: 3080539.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 97499.7031 - val_loss: 3084333.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 89975.8203 - val_loss: 3085895.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 83202.6328 - val_loss: 3084312.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 77157.1875 - val_loss: 3083110.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 71764.9453 - val_loss: 3082269.7500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 18ms/step - loss: 1850246.8750 - val_loss: 3263652.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1754142.6250 - val_loss: 3258081.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1668747.3750 - val_loss: 3251923.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1587686.0000 - val_loss: 3245213.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1510120.1250 - val_loss: 3237609.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1435683.2500 - val_loss: 3230094.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1364217.7500 - val_loss: 3222897.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1295496.1250 - val_loss: 3216789.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1229452.5000 - val_loss: 3209624.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1165984.1250 - val_loss: 3201901.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1104954.5000 - val_loss: 3193587.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1046339.6875 - val_loss: 3185664.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 990049.9375 - val_loss: 3178115.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 935981.7500 - val_loss: 3170868.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 884099.4375 - val_loss: 3163003.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 834289.5000 - val_loss: 3156015.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 786537.5000 - val_loss: 3149114.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 740853.6875 - val_loss: 3142859.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 697093.3750 - val_loss: 3136968.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 655215.9375 - val_loss: 3131246.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 615210.4375 - val_loss: 3125659.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 576980.3750 - val_loss: 3120359.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 540557.5625 - val_loss: 3115149.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 505795.6875 - val_loss: 3110001.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 472729.5625 - val_loss: 3103290.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 441238.5312 - val_loss: 3097304.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 411362.0625 - val_loss: 3093162.7500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 383016.3438 - val_loss: 3088053.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 356177.5000 - val_loss: 3083950.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 330779.0625 - val_loss: 3079666.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 306809.2500 - val_loss: 3076761.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 284227.5625 - val_loss: 3072136.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 262968.0938 - val_loss: 3065385.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 243022.2969 - val_loss: 3060330.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 224304.1719 - val_loss: 3055851.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 206787.0312 - val_loss: 3052524.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 190475.5781 - val_loss: 3049040.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 175345.1719 - val_loss: 3047005.7500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 161283.9375 - val_loss: 3045573.2500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 148280.5469 - val_loss: 3043225.0000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 136326.4375 - val_loss: 3042339.2500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 125316.8516 - val_loss: 3042698.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 115251.3984 - val_loss: 3043306.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 106068.6484 - val_loss: 3045603.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 97735.3125 - val_loss: 3051277.2500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 90216.5469 - val_loss: 3060144.0000\n",
            "7/7 [==============================] - 1s 3ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 16ms/step - loss: 1848331.5000 - val_loss: 3263449.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1750887.6250 - val_loss: 3257632.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1665218.7500 - val_loss: 3252938.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1584059.7500 - val_loss: 3248273.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1506389.2500 - val_loss: 3242372.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1431975.6250 - val_loss: 3237815.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1360564.0000 - val_loss: 3232037.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1291957.6250 - val_loss: 3226968.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1225984.7500 - val_loss: 3220824.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1162535.7500 - val_loss: 3214412.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1101601.3750 - val_loss: 3208273.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1043042.5000 - val_loss: 3202456.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 986772.5000 - val_loss: 3196857.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 932770.4375 - val_loss: 3191253.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 880975.3750 - val_loss: 3185940.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 831311.3750 - val_loss: 3180739.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 783671.3750 - val_loss: 3175739.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 738029.3125 - val_loss: 3171473.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 694373.0000 - val_loss: 3166469.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 652580.7500 - val_loss: 3161768.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 612694.0000 - val_loss: 3157655.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 574552.0625 - val_loss: 3150211.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 538171.5000 - val_loss: 3142357.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 503510.9375 - val_loss: 3137609.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 470522.0938 - val_loss: 3133537.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 439150.6250 - val_loss: 3129588.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 409355.6250 - val_loss: 3125994.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 381131.1875 - val_loss: 3122523.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 354388.5625 - val_loss: 3119324.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 329090.5625 - val_loss: 3116162.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 305185.3438 - val_loss: 3113146.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 282695.5938 - val_loss: 3110361.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 261519.3906 - val_loss: 3107548.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 241654.9531 - val_loss: 3104936.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 223061.8594 - val_loss: 3102366.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 205659.9844 - val_loss: 3099999.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 189449.3594 - val_loss: 3097665.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 174347.7500 - val_loss: 3095505.7500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 160376.0625 - val_loss: 3093316.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 147433.4844 - val_loss: 3091378.0000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 135527.9062 - val_loss: 3089440.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 124571.2031 - val_loss: 3087631.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 114582.9297 - val_loss: 3085917.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 105444.8672 - val_loss: 3084293.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 97182.1328 - val_loss: 3082761.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 89687.4922 - val_loss: 3081463.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 82937.3594 - val_loss: 3087959.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 76916.9844 - val_loss: 3087226.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 71537.2812 - val_loss: 3086064.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 66785.3359 - val_loss: 3084834.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 13ms/step - loss: 1850868.5000 - val_loss: 3263896.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1754620.1250 - val_loss: 3259638.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1669234.2500 - val_loss: 3253401.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1588160.0000 - val_loss: 3246928.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1510557.5000 - val_loss: 3241376.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1436171.6250 - val_loss: 3236200.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1364663.8750 - val_loss: 3229595.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1295972.0000 - val_loss: 3224545.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1229880.2500 - val_loss: 3217030.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1166329.8750 - val_loss: 3211137.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1105335.7500 - val_loss: 3204816.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1046654.5000 - val_loss: 3198842.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 990364.8125 - val_loss: 3192242.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 936291.3125 - val_loss: 3186968.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 884364.9375 - val_loss: 3181220.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 834580.5000 - val_loss: 3172486.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 786865.0000 - val_loss: 3164827.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 741137.3750 - val_loss: 3158883.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 697377.1250 - val_loss: 3151280.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 655487.0625 - val_loss: 3144857.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 615462.5625 - val_loss: 3140446.2500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 577242.8750 - val_loss: 3135580.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 540789.0625 - val_loss: 3124395.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 506021.4375 - val_loss: 3118144.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 472947.1875 - val_loss: 3113548.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 441488.5000 - val_loss: 3109332.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 411600.0000 - val_loss: 3105316.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 383239.5000 - val_loss: 3101443.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 356407.0938 - val_loss: 3097841.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 330979.0000 - val_loss: 3094399.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 306966.9375 - val_loss: 3091062.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 284362.4688 - val_loss: 3087995.5000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 263087.0312 - val_loss: 3084914.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 243141.4531 - val_loss: 3082177.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 224444.1562 - val_loss: 3079410.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 206942.6562 - val_loss: 3076895.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 190637.1406 - val_loss: 3074497.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 175462.9062 - val_loss: 3072216.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 161383.4219 - val_loss: 3070194.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 148403.4375 - val_loss: 3068483.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 136415.2500 - val_loss: 3069249.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 125406.4688 - val_loss: 3072072.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 115339.5625 - val_loss: 3070815.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 106141.3281 - val_loss: 3069307.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 97790.3672 - val_loss: 3069972.5000\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 14ms/step - loss: 1847838.6250 - val_loss: 3272904.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1753322.3750 - val_loss: 3272002.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1668304.3750 - val_loss: 3268852.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1587462.1250 - val_loss: 3264671.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1510056.7500 - val_loss: 3258806.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1435817.0000 - val_loss: 3252445.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1364376.3750 - val_loss: 3246212.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1295720.3750 - val_loss: 3239400.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1229749.7500 - val_loss: 3231900.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1166319.8750 - val_loss: 3220497.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1105347.8750 - val_loss: 3212673.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1046703.7500 - val_loss: 3203963.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 990364.2500 - val_loss: 3195591.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 936269.0000 - val_loss: 3188448.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 884426.1875 - val_loss: 3180905.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 834666.0000 - val_loss: 3173859.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 786959.4375 - val_loss: 3167656.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 741228.5625 - val_loss: 3160864.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 697478.5625 - val_loss: 3154347.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 655590.0625 - val_loss: 3148414.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 615558.0000 - val_loss: 3136357.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 577361.7500 - val_loss: 3130646.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 540934.4375 - val_loss: 3125821.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 506115.0000 - val_loss: 3121176.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 473016.0625 - val_loss: 3116748.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 441560.2812 - val_loss: 3112460.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 411675.7188 - val_loss: 3108356.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 383316.6562 - val_loss: 3104352.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 356493.4688 - val_loss: 3100809.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 331085.1250 - val_loss: 3097326.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 307121.2188 - val_loss: 3094507.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 284500.7500 - val_loss: 3084964.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 263225.5312 - val_loss: 3079064.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 243279.0938 - val_loss: 3075554.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 224581.8750 - val_loss: 3072772.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 207069.9375 - val_loss: 3069676.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 190741.5625 - val_loss: 3067859.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 175549.8438 - val_loss: 3065364.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 161500.4844 - val_loss: 3063368.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 148522.6562 - val_loss: 3062074.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 136556.3281 - val_loss: 3060814.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 125531.5469 - val_loss: 3060432.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 115472.0312 - val_loss: 3061622.2500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 106277.2188 - val_loss: 3062161.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 97891.2344 - val_loss: 3061360.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 90344.5703 - val_loss: 3060231.7500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 83533.9453 - val_loss: 3060111.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 77445.8594 - val_loss: 3066872.0000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 72019.0938 - val_loss: 3073575.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 67246.5312 - val_loss: 3072636.0000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 14ms/step - loss: 1850333.8750 - val_loss: 3264223.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1754193.7500 - val_loss: 3256117.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1668748.0000 - val_loss: 3248549.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1587691.3750 - val_loss: 3240271.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1510099.8750 - val_loss: 3233096.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1435718.3750 - val_loss: 3227553.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1364237.5000 - val_loss: 3222316.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1295520.7500 - val_loss: 3217225.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1229480.1250 - val_loss: 3212015.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1165957.8750 - val_loss: 3206267.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1104935.7500 - val_loss: 3200307.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1046332.9375 - val_loss: 3197038.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 990031.1875 - val_loss: 3193501.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 935946.8125 - val_loss: 3183311.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 884033.4375 - val_loss: 3176565.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 834274.4375 - val_loss: 3174320.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 786555.1250 - val_loss: 3167038.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 740818.4375 - val_loss: 3158007.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 697052.6875 - val_loss: 3153265.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 655144.1875 - val_loss: 3149748.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 615130.3125 - val_loss: 3149336.2500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 576935.8750 - val_loss: 3138670.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 540495.5625 - val_loss: 3133910.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 505739.9688 - val_loss: 3128720.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 472660.0625 - val_loss: 3125897.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 441215.5938 - val_loss: 3122139.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 411341.0938 - val_loss: 3116442.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 382987.1875 - val_loss: 3113046.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 356180.7188 - val_loss: 3111053.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 330803.0312 - val_loss: 3107914.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 306833.7188 - val_loss: 3105412.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 284240.1250 - val_loss: 3101915.5000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 262998.2812 - val_loss: 3095917.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 243037.7969 - val_loss: 3090031.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 224353.4219 - val_loss: 3089219.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 206860.6562 - val_loss: 3087066.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 190583.1719 - val_loss: 3085519.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 175416.4531 - val_loss: 3084378.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 161361.5000 - val_loss: 3083604.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 148364.0938 - val_loss: 3085260.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 136370.1875 - val_loss: 3084899.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 125371.5703 - val_loss: 3085667.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 115265.7422 - val_loss: 3084284.0000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 106092.7578 - val_loss: 3082837.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 97740.9531 - val_loss: 3081725.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 90204.5234 - val_loss: 3080824.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 83455.3359 - val_loss: 3080162.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 77376.1172 - val_loss: 3083110.0000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 71981.1016 - val_loss: 3087538.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 67156.8984 - val_loss: 3086784.0000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 14ms/step - loss: 1848562.2500 - val_loss: 3267462.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1752308.8750 - val_loss: 3263277.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1666896.8750 - val_loss: 3258043.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1585798.3750 - val_loss: 3252869.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1508260.0000 - val_loss: 3247706.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1433936.2500 - val_loss: 3242402.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1362581.0000 - val_loss: 3236383.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1293979.0000 - val_loss: 3231643.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1227997.0000 - val_loss: 3232263.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1164564.3750 - val_loss: 3224497.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1103651.8750 - val_loss: 3219190.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1045050.5000 - val_loss: 3212928.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 988812.8125 - val_loss: 3207394.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 934749.9375 - val_loss: 3202206.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 882903.0625 - val_loss: 3197201.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 833177.1250 - val_loss: 3192494.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 785531.4375 - val_loss: 3188004.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 739853.9375 - val_loss: 3183697.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 696151.9375 - val_loss: 3179566.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 654319.6875 - val_loss: 3175647.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 614349.4375 - val_loss: 3171830.2500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 576175.3125 - val_loss: 3168167.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 539721.4375 - val_loss: 3164672.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 504982.5938 - val_loss: 3161339.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 471973.5938 - val_loss: 3158087.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 440538.6562 - val_loss: 3155021.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 410698.4062 - val_loss: 3152115.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 382366.5938 - val_loss: 3149335.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 355531.7812 - val_loss: 3146581.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 330185.5625 - val_loss: 3144272.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 306278.7188 - val_loss: 3142490.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 283730.1250 - val_loss: 3140131.5000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 262543.0938 - val_loss: 3137855.0000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 242627.3281 - val_loss: 3133259.7500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 223923.4688 - val_loss: 3128352.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 206467.3438 - val_loss: 3123548.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 190213.0156 - val_loss: 3123260.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 175065.9062 - val_loss: 3121948.7500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 161066.7969 - val_loss: 3119494.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 148078.6719 - val_loss: 3121372.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 136130.2500 - val_loss: 3123816.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 125121.0938 - val_loss: 3122654.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 115094.0312 - val_loss: 3120755.2500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 105942.0312 - val_loss: 3119430.0000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 97624.8984 - val_loss: 3118240.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 90101.3984 - val_loss: 3117392.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 83343.1797 - val_loss: 3116669.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 77271.3281 - val_loss: 3115830.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 71887.2500 - val_loss: 3115009.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 67097.9766 - val_loss: 3122652.2500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 15ms/step - loss: 1846343.5000 - val_loss: 3266323.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1749980.0000 - val_loss: 3263536.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1664598.5000 - val_loss: 3261739.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1583688.8750 - val_loss: 3256013.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1506335.2500 - val_loss: 3249924.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1432053.8750 - val_loss: 3243330.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1360706.6250 - val_loss: 3236299.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1292125.3750 - val_loss: 3229584.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1226208.8750 - val_loss: 3222346.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1162816.8750 - val_loss: 3215661.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1101858.8750 - val_loss: 3208874.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1043343.4375 - val_loss: 3201994.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 987139.8125 - val_loss: 3195448.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 933199.6875 - val_loss: 3189171.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 881395.8125 - val_loss: 3183146.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 831749.5625 - val_loss: 3177377.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 784121.7500 - val_loss: 3171728.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 738481.6875 - val_loss: 3166408.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 694815.3750 - val_loss: 3161425.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 653020.8750 - val_loss: 3156618.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 613093.7500 - val_loss: 3144685.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 574977.9375 - val_loss: 3139571.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 538605.7500 - val_loss: 3134790.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 503902.6875 - val_loss: 3130751.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 470872.4688 - val_loss: 3125701.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 439469.1250 - val_loss: 3121820.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 409678.6562 - val_loss: 3118164.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 381421.2500 - val_loss: 3114377.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 354690.3438 - val_loss: 3107865.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 329407.3750 - val_loss: 3106206.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 305496.1875 - val_loss: 3102535.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 282956.5000 - val_loss: 3099166.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 261773.1406 - val_loss: 3096583.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 241868.4375 - val_loss: 3095444.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 223229.4531 - val_loss: 3091770.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 205825.1094 - val_loss: 3090801.2500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 189575.0000 - val_loss: 3088925.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 174477.7031 - val_loss: 3087969.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 160495.6406 - val_loss: 3086749.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 147560.2969 - val_loss: 3084291.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 135646.0938 - val_loss: 3080653.2500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 124701.4062 - val_loss: 3078075.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 114700.1719 - val_loss: 3077268.2500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 105562.2969 - val_loss: 3071452.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 97290.2109 - val_loss: 3074448.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 89797.7812 - val_loss: 3073741.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 83059.0781 - val_loss: 3080669.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 77010.7578 - val_loss: 3081632.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 71642.8047 - val_loss: 3082432.5000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 13ms/step - loss: 1845768.7500 - val_loss: 3267180.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1749427.8750 - val_loss: 3262808.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1664364.1250 - val_loss: 3257228.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1583515.0000 - val_loss: 3251973.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1506138.0000 - val_loss: 3245696.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1431819.7500 - val_loss: 3241638.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1360446.3750 - val_loss: 3239393.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1291903.3750 - val_loss: 3236568.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1225963.5000 - val_loss: 3232348.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1162618.6250 - val_loss: 3229500.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1101705.2500 - val_loss: 3224083.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1043216.9375 - val_loss: 3218940.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 987025.6875 - val_loss: 3213753.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 933070.6875 - val_loss: 3206715.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 881272.3750 - val_loss: 3201341.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 831578.0000 - val_loss: 3196600.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 783930.5625 - val_loss: 3192178.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 738343.1875 - val_loss: 3188084.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 694676.6875 - val_loss: 3184117.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 652954.5000 - val_loss: 3180361.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 613029.6875 - val_loss: 3176747.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 574948.1875 - val_loss: 3173412.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 538557.6250 - val_loss: 3170034.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 503893.9062 - val_loss: 3166808.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 470882.8438 - val_loss: 3163826.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 439483.7500 - val_loss: 3161371.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 409699.2500 - val_loss: 3157625.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 381481.0000 - val_loss: 3147698.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 354761.1250 - val_loss: 3144884.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 329447.6875 - val_loss: 3142350.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 305591.0938 - val_loss: 3139937.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 283059.8750 - val_loss: 3137799.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 261856.5156 - val_loss: 3135760.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 241966.0938 - val_loss: 3133944.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 223337.4531 - val_loss: 3132171.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 205948.5312 - val_loss: 3130501.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 189737.8906 - val_loss: 3128928.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 174641.5625 - val_loss: 3127488.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 160648.2656 - val_loss: 3126141.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 147662.4375 - val_loss: 3124788.0000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 135752.5938 - val_loss: 3123742.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 124820.0469 - val_loss: 3122580.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 114792.6641 - val_loss: 3121531.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 105667.2344 - val_loss: 3120577.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 97373.9141 - val_loss: 3119614.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 89850.3750 - val_loss: 3118776.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 83090.6797 - val_loss: 3117973.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 77038.5078 - val_loss: 3117261.2500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 71666.1953 - val_loss: 3123329.2500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 66912.2812 - val_loss: 3124811.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 20ms/step - loss: 1876607.2500 - val_loss: 3268648.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1821178.0000 - val_loss: 3266945.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1774704.5000 - val_loss: 3265017.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1730384.2500 - val_loss: 3262596.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1687466.3750 - val_loss: 3261037.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1645623.7500 - val_loss: 3258688.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1604812.5000 - val_loss: 3256200.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1564943.7500 - val_loss: 3252083.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1525863.0000 - val_loss: 3249721.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1487556.5000 - val_loss: 3247092.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1450160.3750 - val_loss: 3244119.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1413417.6250 - val_loss: 3240553.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1377475.5000 - val_loss: 3238400.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1342147.2500 - val_loss: 3236570.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1307526.7500 - val_loss: 3234889.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1273607.7500 - val_loss: 3233117.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1240291.2500 - val_loss: 3231375.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1207692.5000 - val_loss: 3228683.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1175767.6250 - val_loss: 3225058.2500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1144521.2500 - val_loss: 3222155.0000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1113829.6250 - val_loss: 3221157.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1083724.3750 - val_loss: 3217563.2500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1054314.2500 - val_loss: 3213183.7500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1025338.6250 - val_loss: 3208588.0000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 997020.0000 - val_loss: 3207981.7500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 969328.0000 - val_loss: 3204437.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 942162.1250 - val_loss: 3200696.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 915559.3750 - val_loss: 3198002.7500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 889490.2500 - val_loss: 3195902.7500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 863996.6250 - val_loss: 3192860.5000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 838976.9375 - val_loss: 3190676.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 814551.5625 - val_loss: 3188853.5000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 790568.1875 - val_loss: 3187705.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 767046.3750 - val_loss: 3184869.7500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 744128.4375 - val_loss: 3182220.0000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 721635.6875 - val_loss: 3180108.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 699731.1875 - val_loss: 3177368.0000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 678318.3125 - val_loss: 3170877.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 657279.5625 - val_loss: 3166498.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 636752.4375 - val_loss: 3163646.2500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 616687.4375 - val_loss: 3162061.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 597130.5000 - val_loss: 3158010.0000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 578021.1250 - val_loss: 3156254.2500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 559384.7500 - val_loss: 3152528.7500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 541156.5625 - val_loss: 3150879.5000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 523376.3125 - val_loss: 3148643.0000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 506024.8750 - val_loss: 3146872.2500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 489151.5312 - val_loss: 3143798.2500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 472702.5312 - val_loss: 3141547.7500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 456625.1250 - val_loss: 3139301.2500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 20ms/step - loss: 1875068.0000 - val_loss: 3270429.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1820759.1250 - val_loss: 3269470.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1774509.6250 - val_loss: 3268136.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1730378.0000 - val_loss: 3266221.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1687540.3750 - val_loss: 3264129.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1645803.3750 - val_loss: 3262068.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1605082.7500 - val_loss: 3260048.7500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1565224.6250 - val_loss: 3257828.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1526163.7500 - val_loss: 3255588.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1487958.0000 - val_loss: 3253267.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1450543.8750 - val_loss: 3251258.0000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1413762.2500 - val_loss: 3249209.2500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1377808.7500 - val_loss: 3247040.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1342510.7500 - val_loss: 3246047.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1307957.7500 - val_loss: 3243917.2500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1274038.0000 - val_loss: 3241313.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1240787.2500 - val_loss: 3239390.5000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1208198.2500 - val_loss: 3236951.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1176187.6250 - val_loss: 3234995.2500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1144930.0000 - val_loss: 3232277.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1114232.7500 - val_loss: 3229869.7500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1084188.3750 - val_loss: 3227214.7500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1054724.7500 - val_loss: 3224556.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1025870.8750 - val_loss: 3221940.7500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 997589.5625 - val_loss: 3219393.5000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 969794.2500 - val_loss: 3216882.2500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 942593.1250 - val_loss: 3214375.5000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 915985.6875 - val_loss: 3212018.5000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 889957.5000 - val_loss: 3209608.5000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 864452.8125 - val_loss: 3207352.7500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 839547.1875 - val_loss: 3205030.5000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 815092.0625 - val_loss: 3202776.2500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 791163.5625 - val_loss: 3200617.2500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 767772.2500 - val_loss: 3198423.5000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 744803.7500 - val_loss: 3196291.2500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 722379.5000 - val_loss: 3194146.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 700397.2500 - val_loss: 3192100.5000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 678991.9375 - val_loss: 3190082.7500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 658010.5625 - val_loss: 3188127.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 637500.5625 - val_loss: 3186219.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 617492.3750 - val_loss: 3184324.0000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 597935.6250 - val_loss: 3182437.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 578765.0000 - val_loss: 3180630.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 560102.6250 - val_loss: 3178751.7500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 541916.3750 - val_loss: 3176950.2500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 524054.7812 - val_loss: 3175244.0000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 506644.7500 - val_loss: 3173518.7500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 489759.1875 - val_loss: 3171818.7500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 473206.8438 - val_loss: 3170189.2500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 457112.0000 - val_loss: 3168552.0000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 19ms/step - loss: 1874479.6250 - val_loss: 3270502.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1818366.5000 - val_loss: 3270498.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1771739.2500 - val_loss: 3270281.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1727433.1250 - val_loss: 3269549.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1684574.1250 - val_loss: 3268355.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1642781.3750 - val_loss: 3266751.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1602080.8750 - val_loss: 3264791.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1562201.1250 - val_loss: 3262839.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1523159.3750 - val_loss: 3260470.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1484887.8750 - val_loss: 3258207.5000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1447453.1250 - val_loss: 3255766.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1410721.8750 - val_loss: 3253176.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1374748.0000 - val_loss: 3250525.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1339448.7500 - val_loss: 3247875.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1304867.8750 - val_loss: 3245280.2500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1270997.3750 - val_loss: 3242596.2500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1237767.6250 - val_loss: 3239917.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1205171.2500 - val_loss: 3237267.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1173240.6250 - val_loss: 3234632.5000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1142008.1250 - val_loss: 3231990.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1111456.8750 - val_loss: 3229482.7500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1081361.7500 - val_loss: 3226982.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1051860.2500 - val_loss: 3224509.0000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1023025.6250 - val_loss: 3222056.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 994767.0000 - val_loss: 3219664.2500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 967031.7500 - val_loss: 3217312.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 939908.8125 - val_loss: 3215001.0000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 913354.3125 - val_loss: 3212745.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 887350.4375 - val_loss: 3210485.5000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 861848.4375 - val_loss: 3208337.7500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 836880.4375 - val_loss: 3205470.5000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 812430.6875 - val_loss: 3201819.2500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 788525.5625 - val_loss: 3197528.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 765153.7500 - val_loss: 3197492.2500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 742181.5625 - val_loss: 3193457.5000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 719823.3125 - val_loss: 3190860.7500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 697941.8125 - val_loss: 3188102.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 676547.1250 - val_loss: 3185964.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 655652.0000 - val_loss: 3183887.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 635143.5625 - val_loss: 3181877.2500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 615196.5000 - val_loss: 3180012.5000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 595656.8125 - val_loss: 3178075.2500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 576594.5000 - val_loss: 3176283.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 557918.5625 - val_loss: 3173866.7500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 539702.8125 - val_loss: 3172125.7500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 522020.4375 - val_loss: 3169876.0000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 504708.6250 - val_loss: 3164816.2500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 487788.5625 - val_loss: 3159409.5000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 471320.5625 - val_loss: 3156310.2500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 455295.5312 - val_loss: 3154062.0000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 25ms/step - loss: 1876848.3750 - val_loss: 3271335.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1822869.2500 - val_loss: 3271109.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1776609.3750 - val_loss: 3270316.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1732370.5000 - val_loss: 3268940.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1689583.6250 - val_loss: 3267091.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1647756.1250 - val_loss: 3265057.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1606976.8750 - val_loss: 3262631.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1567145.1250 - val_loss: 3260380.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1528059.1250 - val_loss: 3257830.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1489782.8750 - val_loss: 3254968.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1452294.6250 - val_loss: 3252310.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1415539.7500 - val_loss: 3249715.2500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1379571.7500 - val_loss: 3246805.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1344302.3750 - val_loss: 3243919.5000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1309699.5000 - val_loss: 3240985.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1275772.1250 - val_loss: 3238045.0000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1242424.2500 - val_loss: 3235163.5000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1209847.0000 - val_loss: 3232313.2500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1177838.5000 - val_loss: 3229455.2500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1146554.1250 - val_loss: 3226694.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1115796.0000 - val_loss: 3223948.0000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1085632.1250 - val_loss: 3221242.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1056122.8750 - val_loss: 3218571.7500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1027187.3125 - val_loss: 3215962.2500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 998914.7500 - val_loss: 3213491.7500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 971236.5000 - val_loss: 3211012.5000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 944085.8125 - val_loss: 3208524.0000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 917381.0000 - val_loss: 3206139.0000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 891278.5000 - val_loss: 3203812.7500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 865715.0625 - val_loss: 3201510.0000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 840713.8125 - val_loss: 3199217.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 816220.0000 - val_loss: 3197017.5000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 792287.5625 - val_loss: 3194857.2500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 768832.5625 - val_loss: 3192724.5000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 745856.8125 - val_loss: 3190593.5000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 723379.3750 - val_loss: 3188505.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 701457.0000 - val_loss: 3186494.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 680011.5625 - val_loss: 3184507.7500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 659034.0000 - val_loss: 3182541.5000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 638493.9375 - val_loss: 3180625.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 618362.8125 - val_loss: 3178762.0000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 598835.8750 - val_loss: 3176892.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 579692.7500 - val_loss: 3175061.2500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 561039.3125 - val_loss: 3173270.0000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 542776.0625 - val_loss: 3171498.5000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 524879.1875 - val_loss: 3169778.2500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 507485.0625 - val_loss: 3168087.5000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 490511.1250 - val_loss: 3166432.5000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 474011.4375 - val_loss: 3164788.7500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 457914.0938 - val_loss: 3163185.2500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 18ms/step - loss: 1875970.6250 - val_loss: 3271136.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1821895.7500 - val_loss: 3270673.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1775686.1250 - val_loss: 3269650.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1731584.7500 - val_loss: 3268158.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1688741.3750 - val_loss: 3266327.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1647020.8750 - val_loss: 3264246.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1606292.2500 - val_loss: 3262006.7500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1566397.1250 - val_loss: 3259619.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1527347.6250 - val_loss: 3257091.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1489069.3750 - val_loss: 3254444.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1451632.8750 - val_loss: 3251671.5000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1414851.0000 - val_loss: 3248817.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1378900.8750 - val_loss: 3245901.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1343568.5000 - val_loss: 3242914.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1308958.7500 - val_loss: 3239918.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1275011.1250 - val_loss: 3236919.0000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1241800.0000 - val_loss: 3233932.7500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1209246.3750 - val_loss: 3230961.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1177253.0000 - val_loss: 3228025.5000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1145866.5000 - val_loss: 3225122.5000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1115162.5000 - val_loss: 3222236.7500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1085140.7500 - val_loss: 3219420.7500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1055667.2500 - val_loss: 3216673.7500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1026765.6875 - val_loss: 3213939.7500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 998498.3750 - val_loss: 3211259.7500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 970772.3125 - val_loss: 3208629.0000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 943603.4375 - val_loss: 3206123.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 916949.7500 - val_loss: 3203546.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 890854.9375 - val_loss: 3201061.2500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 865302.8750 - val_loss: 3198615.2500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 840301.8750 - val_loss: 3196216.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 815788.3750 - val_loss: 3193842.7500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 791829.4375 - val_loss: 3191499.0000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 768369.0000 - val_loss: 3189183.7500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 745453.7500 - val_loss: 3186980.2500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 723008.5625 - val_loss: 3184757.2500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 701039.6250 - val_loss: 3182582.5000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 679578.5000 - val_loss: 3180444.5000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 658557.0000 - val_loss: 3178412.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 638060.3125 - val_loss: 3176224.5000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 617973.8125 - val_loss: 3174226.2500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 598395.1250 - val_loss: 3172195.0000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 579223.9375 - val_loss: 3170193.7500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 560540.1875 - val_loss: 3168194.2500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 542304.9375 - val_loss: 3166272.5000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 524483.5000 - val_loss: 3164300.5000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 507097.4062 - val_loss: 3162408.7500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 490123.4688 - val_loss: 3160526.0000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 473576.1875 - val_loss: 3158638.2500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 457424.5625 - val_loss: 3156874.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 25ms/step - loss: 1877174.5000 - val_loss: 3270487.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1823416.3750 - val_loss: 3270862.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1777100.2500 - val_loss: 3270459.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1732871.6250 - val_loss: 3269379.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1690020.5000 - val_loss: 3267673.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1648313.8750 - val_loss: 3265531.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1607544.7500 - val_loss: 3262823.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1567678.6250 - val_loss: 3260352.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1528600.3750 - val_loss: 3257206.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1490304.8750 - val_loss: 3254463.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1452768.5000 - val_loss: 3251646.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1416022.8750 - val_loss: 3248469.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1380017.6250 - val_loss: 3245079.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1344645.2500 - val_loss: 3241961.7500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1309931.3750 - val_loss: 3238912.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1275966.7500 - val_loss: 3235672.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1242648.7500 - val_loss: 3232618.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1210050.6250 - val_loss: 3229406.2500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1178124.0000 - val_loss: 3226369.0000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1146799.1250 - val_loss: 3223315.5000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1116063.3750 - val_loss: 3220369.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1085986.5000 - val_loss: 3217523.5000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1056466.7500 - val_loss: 3214667.2500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1027523.8750 - val_loss: 3211945.2500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 999229.5625 - val_loss: 3209208.7500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 971424.0000 - val_loss: 3206550.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 944225.1250 - val_loss: 3203966.5000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 917522.0625 - val_loss: 3201340.7500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 891417.2500 - val_loss: 3198757.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 865837.2500 - val_loss: 3196346.2500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 840845.8750 - val_loss: 3193937.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 816342.1875 - val_loss: 3191534.2500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 792343.8750 - val_loss: 3189163.2500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 768928.8125 - val_loss: 3186857.0000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 745962.9375 - val_loss: 3184639.7500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 723497.9375 - val_loss: 3182443.5000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 701551.3750 - val_loss: 3180343.0000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 680107.5625 - val_loss: 3178221.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 659022.5000 - val_loss: 3176158.2500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 638478.0625 - val_loss: 3174093.5000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 618412.3125 - val_loss: 3171726.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 598839.5625 - val_loss: 3168452.0000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 579639.6250 - val_loss: 3164510.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 560897.0625 - val_loss: 3160383.5000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 542680.4375 - val_loss: 3158228.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 524842.0625 - val_loss: 3155505.0000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 507504.3125 - val_loss: 3153586.2500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 490480.0625 - val_loss: 3151525.0000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 473947.7812 - val_loss: 3149682.5000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 457824.4062 - val_loss: 3147834.7500\n",
            "7/7 [==============================] - 1s 3ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 25ms/step - loss: 1872777.1250 - val_loss: 3271123.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1818058.3750 - val_loss: 3271738.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1771840.5000 - val_loss: 3271367.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1727703.6250 - val_loss: 3270233.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1685017.3750 - val_loss: 3268503.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1643333.6250 - val_loss: 3266158.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1602591.3750 - val_loss: 3263956.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1562777.1250 - val_loss: 3261264.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1523804.3750 - val_loss: 3258428.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1485703.7500 - val_loss: 3255957.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1448314.1250 - val_loss: 3252935.0000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1411702.0000 - val_loss: 3250001.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1375746.6250 - val_loss: 3246608.2500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1340474.3750 - val_loss: 3242983.5000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1305942.0000 - val_loss: 3239583.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1272076.1250 - val_loss: 3236513.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1238827.0000 - val_loss: 3233698.5000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1206258.2500 - val_loss: 3230378.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1174349.6250 - val_loss: 3227185.0000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1143110.1250 - val_loss: 3224191.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1112367.8750 - val_loss: 3221026.5000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1082314.3750 - val_loss: 3217996.2500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1052896.0000 - val_loss: 3215100.2500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1023981.7500 - val_loss: 3212157.2500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 995724.3750 - val_loss: 3209118.5000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 968013.6250 - val_loss: 3205910.0000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 940826.1875 - val_loss: 3199832.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 914153.2500 - val_loss: 3196579.7500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 888114.0625 - val_loss: 3193492.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 862643.6250 - val_loss: 3190520.0000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 837752.6250 - val_loss: 3187650.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 813305.1250 - val_loss: 3184994.5000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 789408.3750 - val_loss: 3182477.7500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 765905.7500 - val_loss: 3179909.7500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 742947.4375 - val_loss: 3177474.2500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 720572.5625 - val_loss: 3175018.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 698678.8750 - val_loss: 3172631.5000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 677268.3125 - val_loss: 3170338.5000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 656329.1250 - val_loss: 3168045.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 635871.7500 - val_loss: 3165869.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 615819.2500 - val_loss: 3163673.5000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 596272.2500 - val_loss: 3161501.0000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 577225.1875 - val_loss: 3159383.2500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 558613.1875 - val_loss: 3157327.0000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 540462.8750 - val_loss: 3155318.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 522668.9375 - val_loss: 3153371.7500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 505352.1250 - val_loss: 3151413.5000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 488402.7812 - val_loss: 3149514.7500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 471916.5625 - val_loss: 3147743.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 455849.3750 - val_loss: 3145923.7500\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 21ms/step - loss: 1876265.3750 - val_loss: 3271011.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1822285.0000 - val_loss: 3270685.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1775971.2500 - val_loss: 3269578.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1731794.1250 - val_loss: 3267893.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1688966.8750 - val_loss: 3265817.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1647258.1250 - val_loss: 3263564.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1606557.5000 - val_loss: 3261080.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1566666.3750 - val_loss: 3258485.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1527635.7500 - val_loss: 3255723.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1489391.0000 - val_loss: 3252931.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1451961.0000 - val_loss: 3250042.0000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1415201.6250 - val_loss: 3247136.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1379179.7500 - val_loss: 3244203.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1343947.3750 - val_loss: 3241283.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1309357.5000 - val_loss: 3238363.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1275461.0000 - val_loss: 3235482.2500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1242213.2500 - val_loss: 3232596.5000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1209580.5000 - val_loss: 3229739.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1177561.5000 - val_loss: 3226915.2500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1146215.2500 - val_loss: 3224108.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1115482.6250 - val_loss: 3221334.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1085360.2500 - val_loss: 3218614.2500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1055848.7500 - val_loss: 3215948.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1026912.9375 - val_loss: 3213298.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 998582.5000 - val_loss: 3210715.5000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 970869.1250 - val_loss: 3208151.0000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 943697.2500 - val_loss: 3205657.7500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 917083.5625 - val_loss: 3203150.5000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 891043.5000 - val_loss: 3200740.7500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 865448.5625 - val_loss: 3198335.7500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 840373.5625 - val_loss: 3195962.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 815901.8750 - val_loss: 3193669.7500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 791995.4375 - val_loss: 3191380.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 768515.8750 - val_loss: 3189165.7500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 745616.8125 - val_loss: 3186928.0000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 723135.0000 - val_loss: 3184787.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 701141.5000 - val_loss: 3182658.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 679720.5625 - val_loss: 3180546.5000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 658678.8125 - val_loss: 3178452.2500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 638169.3750 - val_loss: 3176416.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 618117.0000 - val_loss: 3174436.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 598508.5625 - val_loss: 3172489.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 579344.6250 - val_loss: 3170530.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 560684.5625 - val_loss: 3168659.0000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 542398.5625 - val_loss: 3166759.7500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 524562.0000 - val_loss: 3164920.7500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 507187.5625 - val_loss: 3163102.0000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 490228.4375 - val_loss: 3161346.5000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 473711.4688 - val_loss: 3159624.5000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 457620.9375 - val_loss: 3157928.7500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 18ms/step - loss: 1873531.2500 - val_loss: 3271663.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1818145.8750 - val_loss: 3272052.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1771837.1250 - val_loss: 3271793.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1727650.1250 - val_loss: 3270905.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1684816.3750 - val_loss: 3269710.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1643057.6250 - val_loss: 3268186.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1602248.8750 - val_loss: 3266432.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1562423.6250 - val_loss: 3264454.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1523358.0000 - val_loss: 3262185.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1485165.1250 - val_loss: 3259751.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1447709.0000 - val_loss: 3257157.5000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1411061.7500 - val_loss: 3254446.2500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1375167.1250 - val_loss: 3251685.2500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1339894.0000 - val_loss: 3248960.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1305343.2500 - val_loss: 3246156.2500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1271478.7500 - val_loss: 3243381.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1238291.3750 - val_loss: 3240658.7500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1205735.3750 - val_loss: 3237933.7500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1173817.1250 - val_loss: 3235268.2500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1142571.0000 - val_loss: 3232673.5000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1111923.8750 - val_loss: 3230048.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1081921.1250 - val_loss: 3227536.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1052466.1250 - val_loss: 3225075.2500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1023556.8750 - val_loss: 3222632.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 995280.3750 - val_loss: 3220264.7500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 967451.5000 - val_loss: 3217955.0000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 940370.0625 - val_loss: 3215631.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 913787.1875 - val_loss: 3213098.7500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 887755.3125 - val_loss: 3209466.2500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 862243.5000 - val_loss: 3205718.0000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 837275.1250 - val_loss: 3203828.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 812852.5000 - val_loss: 3200207.0000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 788946.9375 - val_loss: 3197398.7500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 765598.9375 - val_loss: 3194990.7500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 742734.3750 - val_loss: 3192618.0000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 720305.4375 - val_loss: 3190520.7500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 698379.8750 - val_loss: 3188476.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 676934.0625 - val_loss: 3186469.2500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 656021.8750 - val_loss: 3184542.5000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 635511.8750 - val_loss: 3182645.0000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 615481.3750 - val_loss: 3180803.2500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 595969.0625 - val_loss: 3178767.2500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 576845.0000 - val_loss: 3176563.7500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 558201.7500 - val_loss: 3172097.0000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 539976.3750 - val_loss: 3167999.7500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 522144.9062 - val_loss: 3165473.0000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 504800.0312 - val_loss: 3163122.5000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 487827.7812 - val_loss: 3161150.2500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 471292.8750 - val_loss: 3159425.5000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 455257.1250 - val_loss: 3157672.5000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 18ms/step - loss: 1876269.0000 - val_loss: 3271420.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1821307.2500 - val_loss: 3271636.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1774873.2500 - val_loss: 3271261.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1730628.1250 - val_loss: 3270277.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1687769.0000 - val_loss: 3268803.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1645983.3750 - val_loss: 3266927.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1605236.2500 - val_loss: 3264595.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1565339.3750 - val_loss: 3262056.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1526303.8750 - val_loss: 3259367.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1488059.8750 - val_loss: 3256538.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1450600.3750 - val_loss: 3253721.5000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1413801.1250 - val_loss: 3250845.0000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1377807.5000 - val_loss: 3247913.2500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1342432.8750 - val_loss: 3244950.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1307849.6250 - val_loss: 3242025.2500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1273982.8750 - val_loss: 3239061.2500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1240682.7500 - val_loss: 3236150.0000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1208080.7500 - val_loss: 3233299.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1176161.1250 - val_loss: 3230438.0000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1144882.2500 - val_loss: 3227609.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1114234.2500 - val_loss: 3224842.7500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1084152.0000 - val_loss: 3222119.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1054676.0000 - val_loss: 3219395.0000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1025816.6250 - val_loss: 3216741.0000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 997439.0625 - val_loss: 3214109.5000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 969728.6875 - val_loss: 3211524.5000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 942532.3125 - val_loss: 3208982.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 915954.9375 - val_loss: 3206495.0000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 889873.6250 - val_loss: 3204026.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 864364.9375 - val_loss: 3201623.0000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 839347.1875 - val_loss: 3199280.5000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 814874.9375 - val_loss: 3196917.5000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 790928.0000 - val_loss: 3194631.0000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 767484.5625 - val_loss: 3192381.2500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 744595.5000 - val_loss: 3190179.2500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 722183.1875 - val_loss: 3188008.7500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 700244.1875 - val_loss: 3185878.0000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 678769.2500 - val_loss: 3183802.2500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 657814.5625 - val_loss: 3181692.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 637257.2500 - val_loss: 3179728.2500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 617216.5625 - val_loss: 3177704.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 597602.2500 - val_loss: 3175766.0000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 578457.7500 - val_loss: 3173842.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 559756.3750 - val_loss: 3171951.2500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 541503.1250 - val_loss: 3170045.7500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 523708.7188 - val_loss: 3168188.0000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 506261.4062 - val_loss: 3166415.2500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 489335.8750 - val_loss: 3164616.0000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 472822.1562 - val_loss: 3162853.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 456753.1875 - val_loss: 3161155.2500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 8ms/step - loss: 1890907.5000 - val_loss: 3272082.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1857990.6250 - val_loss: 3271922.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1838010.6250 - val_loss: 3271823.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1819450.1250 - val_loss: 3271564.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1801527.3750 - val_loss: 3271128.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1783991.1250 - val_loss: 3270563.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1766720.6250 - val_loss: 3269927.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1749670.1250 - val_loss: 3269140.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1732810.0000 - val_loss: 3268135.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1716106.3750 - val_loss: 3266876.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1699548.3750 - val_loss: 3265328.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1683113.7500 - val_loss: 3263719.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1666794.7500 - val_loss: 3261855.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1650595.2500 - val_loss: 3259340.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1634510.3750 - val_loss: 3256991.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1618518.6250 - val_loss: 3254383.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1602634.6250 - val_loss: 3251978.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1586837.6250 - val_loss: 3249592.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1571133.1250 - val_loss: 3247252.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1555519.3750 - val_loss: 3244801.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1540001.5000 - val_loss: 3242376.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1524580.1250 - val_loss: 3239934.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1509245.8750 - val_loss: 3237585.5000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1493996.3750 - val_loss: 3235054.0000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1478837.8750 - val_loss: 3232742.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1463758.3750 - val_loss: 3230165.7500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1448758.8750 - val_loss: 3227844.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1433835.5000 - val_loss: 3225444.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1418998.8750 - val_loss: 3222914.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1404245.2500 - val_loss: 3220315.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1389579.5000 - val_loss: 3217781.2500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1374997.6250 - val_loss: 3215233.0000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1360495.8750 - val_loss: 3212651.5000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1346082.1250 - val_loss: 3210082.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1331752.0000 - val_loss: 3207403.5000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1317506.5000 - val_loss: 3204686.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1303334.6250 - val_loss: 3201488.0000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1289243.3750 - val_loss: 3198505.7500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1275234.8750 - val_loss: 3195539.0000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1261305.1250 - val_loss: 3193026.5000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1247458.1250 - val_loss: 3190614.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1233697.7500 - val_loss: 3187107.5000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1220021.1250 - val_loss: 3182321.2500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1206425.3750 - val_loss: 3179674.0000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1192911.1250 - val_loss: 3177143.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1179482.7500 - val_loss: 3174744.0000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1166130.8750 - val_loss: 3172341.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1152859.5000 - val_loss: 3170005.7500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1139669.0000 - val_loss: 3167606.2500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1126564.6250 - val_loss: 3164913.0000\n",
            "7/7 [==============================] - 1s 3ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 11ms/step - loss: 1891134.8750 - val_loss: 3268570.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1856904.2500 - val_loss: 3267939.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1836709.0000 - val_loss: 3267142.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1818070.2500 - val_loss: 3265977.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1800089.3750 - val_loss: 3264565.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1782512.8750 - val_loss: 3262944.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1765224.3750 - val_loss: 3261177.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1748170.2500 - val_loss: 3259303.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1731298.7500 - val_loss: 3257411.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1714578.8750 - val_loss: 3255476.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1698006.8750 - val_loss: 3253445.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1681571.6250 - val_loss: 3251333.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1665262.2500 - val_loss: 3249271.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1649068.8750 - val_loss: 3247168.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1632985.1250 - val_loss: 3244994.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1616999.5000 - val_loss: 3242866.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1601109.8750 - val_loss: 3240855.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1585320.1250 - val_loss: 3238786.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1569629.7500 - val_loss: 3236582.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1554034.3750 - val_loss: 3234398.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1538523.5000 - val_loss: 3232111.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1523104.0000 - val_loss: 3229937.5000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1507773.0000 - val_loss: 3227633.5000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1492527.2500 - val_loss: 3225274.2500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1477366.6250 - val_loss: 3222887.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1462292.2500 - val_loss: 3220527.7500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1447301.0000 - val_loss: 3218179.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1432394.0000 - val_loss: 3215727.5000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1417572.6250 - val_loss: 3213272.7500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1402836.8750 - val_loss: 3210855.2500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1388175.5000 - val_loss: 3208397.5000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1373600.8750 - val_loss: 3205949.7500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1359106.7500 - val_loss: 3203483.5000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1344699.5000 - val_loss: 3201048.2500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1330371.6250 - val_loss: 3198601.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1316128.6250 - val_loss: 3196166.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1301968.1250 - val_loss: 3193770.0000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1287892.0000 - val_loss: 3191378.2500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1273894.0000 - val_loss: 3188999.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1259977.1250 - val_loss: 3186691.0000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1246145.7500 - val_loss: 3184360.5000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1232394.1250 - val_loss: 3181959.7500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1218727.5000 - val_loss: 3179358.2500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1205137.2500 - val_loss: 3175648.5000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1191629.5000 - val_loss: 3172287.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1178205.3750 - val_loss: 3169297.7500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1164862.3750 - val_loss: 3166775.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1151602.0000 - val_loss: 3164188.5000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1138421.0000 - val_loss: 3161700.2500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1125319.0000 - val_loss: 3158811.7500\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 11ms/step - loss: 1894743.0000 - val_loss: 3268725.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1861864.2500 - val_loss: 3267779.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1841463.7500 - val_loss: 3267063.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1822728.2500 - val_loss: 3266252.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1804673.2500 - val_loss: 3265345.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1787043.8750 - val_loss: 3264314.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1769717.8750 - val_loss: 3263217.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1752621.0000 - val_loss: 3261970.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1735710.3750 - val_loss: 3260525.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1718972.0000 - val_loss: 3258824.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1702379.6250 - val_loss: 3256897.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1685911.0000 - val_loss: 3254583.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1669566.7500 - val_loss: 3252098.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1653341.7500 - val_loss: 3249547.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1637234.2500 - val_loss: 3246707.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1621230.3750 - val_loss: 3244237.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1605322.3750 - val_loss: 3241756.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1589514.1250 - val_loss: 3239300.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1573799.3750 - val_loss: 3237189.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1558177.3750 - val_loss: 3234937.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1542641.1250 - val_loss: 3232716.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1527196.3750 - val_loss: 3230319.5000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1511838.6250 - val_loss: 3227852.2500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1496569.3750 - val_loss: 3225402.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1481390.8750 - val_loss: 3223045.2500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1466293.8750 - val_loss: 3220498.7500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1451287.1250 - val_loss: 3218211.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1436357.2500 - val_loss: 3215805.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1421509.0000 - val_loss: 3213366.0000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1406749.8750 - val_loss: 3211345.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1392074.2500 - val_loss: 3208781.7500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1377482.0000 - val_loss: 3206672.2500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1362971.0000 - val_loss: 3204357.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1348543.2500 - val_loss: 3202055.7500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1334195.2500 - val_loss: 3199525.0000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1319933.1250 - val_loss: 3197285.7500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1305747.0000 - val_loss: 3194778.7500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1291645.1250 - val_loss: 3192248.0000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1277629.1250 - val_loss: 3189520.2500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1263691.3750 - val_loss: 3186709.2500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1249835.7500 - val_loss: 3183967.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1236061.2500 - val_loss: 3181095.7500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1222365.0000 - val_loss: 3178551.5000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1208750.1250 - val_loss: 3176007.2500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1195215.8750 - val_loss: 3173659.2500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1181766.1250 - val_loss: 3171396.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1168400.5000 - val_loss: 3169230.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1155118.8750 - val_loss: 3166625.7500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1141920.8750 - val_loss: 3161602.5000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1128800.7500 - val_loss: 3158563.2500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 11ms/step - loss: 1893422.2500 - val_loss: 3270066.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1859593.7500 - val_loss: 3269852.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1839273.3750 - val_loss: 3269539.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1820574.6250 - val_loss: 3269089.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1802549.0000 - val_loss: 3268473.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1784937.7500 - val_loss: 3267743.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1767624.8750 - val_loss: 3266837.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1750542.5000 - val_loss: 3265910.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1733648.3750 - val_loss: 3264690.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1716921.8750 - val_loss: 3263497.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1700339.0000 - val_loss: 3262089.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1683889.0000 - val_loss: 3260503.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1667564.7500 - val_loss: 3258825.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1651352.5000 - val_loss: 3257023.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1635248.1250 - val_loss: 3255341.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1619245.5000 - val_loss: 3253366.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1603349.3750 - val_loss: 3251476.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1587553.3750 - val_loss: 3249445.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1571847.2500 - val_loss: 3247504.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1556237.7500 - val_loss: 3245490.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1540714.8750 - val_loss: 3243506.2500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1525281.3750 - val_loss: 3241512.5000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1509936.2500 - val_loss: 3239383.5000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1494679.2500 - val_loss: 3237241.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1479507.1250 - val_loss: 3235212.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1464417.5000 - val_loss: 3233149.7500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1449415.2500 - val_loss: 3230811.2500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1434495.5000 - val_loss: 3228456.5000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1419657.7500 - val_loss: 3226172.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1404902.1250 - val_loss: 3224027.2500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1390230.2500 - val_loss: 3220940.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1375646.1250 - val_loss: 3218883.0000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1361143.1250 - val_loss: 3215962.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1346721.8750 - val_loss: 3212847.2500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1332379.8750 - val_loss: 3210411.7500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1318128.5000 - val_loss: 3206837.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1303960.3750 - val_loss: 3203875.7500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1289870.1250 - val_loss: 3201535.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1275862.3750 - val_loss: 3198864.5000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1261941.1250 - val_loss: 3196573.5000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1248100.8750 - val_loss: 3194287.7500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1234338.2500 - val_loss: 3192122.2500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1220656.3750 - val_loss: 3189920.5000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1207059.6250 - val_loss: 3187808.7500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1193545.3750 - val_loss: 3185656.2500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1180112.7500 - val_loss: 3183524.2500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1166755.8750 - val_loss: 3181426.7500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1153479.8750 - val_loss: 3179067.0000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1140284.5000 - val_loss: 3175831.2500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1127174.6250 - val_loss: 3172762.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 11ms/step - loss: 1893889.6250 - val_loss: 3270029.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1860472.6250 - val_loss: 3267943.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1840189.3750 - val_loss: 3266117.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1821490.6250 - val_loss: 3264134.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1803465.1250 - val_loss: 3262040.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1785858.7500 - val_loss: 3259893.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1768549.8750 - val_loss: 3257625.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1751459.2500 - val_loss: 3255274.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1734564.5000 - val_loss: 3252932.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1717834.2500 - val_loss: 3250389.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1701244.5000 - val_loss: 3247841.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1684788.2500 - val_loss: 3245129.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1668458.3750 - val_loss: 3242584.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1652246.3750 - val_loss: 3240124.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1636139.5000 - val_loss: 3237642.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1620137.5000 - val_loss: 3235362.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1604234.0000 - val_loss: 3233403.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1588425.6250 - val_loss: 3230964.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1572716.2500 - val_loss: 3228891.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1557105.7500 - val_loss: 3227257.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1541576.7500 - val_loss: 3225363.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1526133.1250 - val_loss: 3223788.0000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1510784.8750 - val_loss: 3221879.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1495528.1250 - val_loss: 3219957.0000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1480353.2500 - val_loss: 3217790.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1465261.7500 - val_loss: 3215960.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1450250.0000 - val_loss: 3213861.2500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1435326.6250 - val_loss: 3211938.0000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1420494.2500 - val_loss: 3210008.0000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1405740.2500 - val_loss: 3207774.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1391061.3750 - val_loss: 3205731.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1376473.6250 - val_loss: 3203489.5000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1361965.0000 - val_loss: 3201212.7500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1347544.5000 - val_loss: 3198741.7500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1333202.3750 - val_loss: 3195905.7500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1318949.0000 - val_loss: 3193503.2500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1304780.0000 - val_loss: 3189800.7500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1290688.7500 - val_loss: 3186926.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1276674.5000 - val_loss: 3184078.0000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1262733.2500 - val_loss: 3181461.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1248883.3750 - val_loss: 3178601.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1235115.0000 - val_loss: 3176097.7500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1221429.7500 - val_loss: 3173424.7500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1207828.1250 - val_loss: 3170380.0000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1194309.3750 - val_loss: 3167269.0000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1180873.1250 - val_loss: 3164025.0000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1167520.0000 - val_loss: 3160965.7500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1154249.0000 - val_loss: 3157793.0000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1141059.5000 - val_loss: 3153870.7500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1127946.2500 - val_loss: 3148979.7500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 1891546.3750 - val_loss: 3269887.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1858409.1250 - val_loss: 3268514.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1838359.7500 - val_loss: 3267186.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1819787.7500 - val_loss: 3265646.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1801854.0000 - val_loss: 3264132.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1784305.2500 - val_loss: 3262380.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1767029.6250 - val_loss: 3260686.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1749968.1250 - val_loss: 3258823.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1733092.0000 - val_loss: 3256928.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1716383.3750 - val_loss: 3254849.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1699819.7500 - val_loss: 3252593.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1683387.2500 - val_loss: 3250533.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1667068.0000 - val_loss: 3248265.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1650867.1250 - val_loss: 3245999.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1634771.0000 - val_loss: 3243728.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1618784.6250 - val_loss: 3241615.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1602894.8750 - val_loss: 3239392.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1587097.2500 - val_loss: 3237255.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1571392.1250 - val_loss: 3235164.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1555782.7500 - val_loss: 3233018.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1540268.3750 - val_loss: 3230878.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1524837.3750 - val_loss: 3228608.0000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1509493.6250 - val_loss: 3226533.7500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1494241.1250 - val_loss: 3224417.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1479076.2500 - val_loss: 3222141.2500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1463992.7500 - val_loss: 3220004.2500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1448991.2500 - val_loss: 3217616.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1434071.2500 - val_loss: 3215699.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1419237.6250 - val_loss: 3212989.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1404488.2500 - val_loss: 3211255.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1389822.7500 - val_loss: 3208837.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1375246.7500 - val_loss: 3206158.0000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1360754.6250 - val_loss: 3203432.0000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1346341.2500 - val_loss: 3200310.7500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1332004.2500 - val_loss: 3197550.0000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1317748.2500 - val_loss: 3194764.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1303574.8750 - val_loss: 3191858.7500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1289489.0000 - val_loss: 3189238.0000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1275483.0000 - val_loss: 3186710.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1261551.3750 - val_loss: 3184190.5000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1247710.2500 - val_loss: 3181353.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1233951.6250 - val_loss: 3178759.0000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1220271.5000 - val_loss: 3176081.7500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1206675.8750 - val_loss: 3173477.2500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1193159.2500 - val_loss: 3170420.0000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1179726.1250 - val_loss: 3167289.0000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1166373.8750 - val_loss: 3164032.5000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1153103.8750 - val_loss: 3160576.5000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1139919.7500 - val_loss: 3156934.5000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1126808.7500 - val_loss: 3153038.5000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 1892877.0000 - val_loss: 3269505.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1859370.3750 - val_loss: 3268492.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1839116.8750 - val_loss: 3267355.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1820448.8750 - val_loss: 3266087.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1802446.2500 - val_loss: 3264643.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1784852.5000 - val_loss: 3263329.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1767570.2500 - val_loss: 3261804.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1750505.3750 - val_loss: 3260255.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1733620.0000 - val_loss: 3258580.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1716902.2500 - val_loss: 3256770.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1700327.3750 - val_loss: 3254803.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1683886.3750 - val_loss: 3252569.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1667560.2500 - val_loss: 3250603.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1651345.1250 - val_loss: 3248520.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1635246.8750 - val_loss: 3246348.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1619248.2500 - val_loss: 3244252.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1603352.6250 - val_loss: 3242194.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1587551.8750 - val_loss: 3240045.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1571847.3750 - val_loss: 3237888.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1556236.8750 - val_loss: 3235675.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1540715.6250 - val_loss: 3233434.2500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1525278.6250 - val_loss: 3231145.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1509924.6250 - val_loss: 3228887.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1494664.7500 - val_loss: 3226765.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1479488.6250 - val_loss: 3224393.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1464405.6250 - val_loss: 3222074.7500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1449407.5000 - val_loss: 3219601.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1434484.6250 - val_loss: 3217168.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1419649.3750 - val_loss: 3214617.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1404902.6250 - val_loss: 3212057.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1390237.2500 - val_loss: 3209639.7500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1375655.7500 - val_loss: 3207061.7500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1361158.3750 - val_loss: 3204421.5000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1346739.0000 - val_loss: 3201929.0000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1332396.0000 - val_loss: 3199417.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1318136.0000 - val_loss: 3196862.2500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1303956.6250 - val_loss: 3194333.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1289869.7500 - val_loss: 3191913.2500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1275865.1250 - val_loss: 3189443.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1261935.5000 - val_loss: 3187048.5000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1248094.3750 - val_loss: 3184672.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1234329.6250 - val_loss: 3182178.0000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1220645.0000 - val_loss: 3178710.7500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1207047.7500 - val_loss: 3174669.7500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1193528.6250 - val_loss: 3171765.0000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1180086.8750 - val_loss: 3169214.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1166734.7500 - val_loss: 3166706.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1153464.5000 - val_loss: 3164253.7500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1140277.0000 - val_loss: 3161660.7500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1127174.6250 - val_loss: 3159166.2500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 11ms/step - loss: 1891465.5000 - val_loss: 3270940.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1855937.5000 - val_loss: 3270532.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1835656.8750 - val_loss: 3270018.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1816976.8750 - val_loss: 3269320.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1798977.8750 - val_loss: 3268471.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1781390.7500 - val_loss: 3267510.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1764103.7500 - val_loss: 3266427.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1747042.8750 - val_loss: 3265204.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1730170.5000 - val_loss: 3263826.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1713461.1250 - val_loss: 3262420.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1696901.3750 - val_loss: 3260808.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1680475.8750 - val_loss: 3259113.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1664171.0000 - val_loss: 3257107.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1647981.8750 - val_loss: 3255176.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1631900.1250 - val_loss: 3252846.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1615922.6250 - val_loss: 3250387.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1600048.5000 - val_loss: 3248051.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1584272.8750 - val_loss: 3245457.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1568584.3750 - val_loss: 3243005.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1552985.3750 - val_loss: 3240676.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1537478.3750 - val_loss: 3238456.2500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1522068.5000 - val_loss: 3235749.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1506747.3750 - val_loss: 3233695.2500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1491503.7500 - val_loss: 3231486.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1476349.2500 - val_loss: 3229151.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1461279.3750 - val_loss: 3227060.7500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1446289.1250 - val_loss: 3224756.2500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1431389.5000 - val_loss: 3222365.0000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1416570.3750 - val_loss: 3220224.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1401833.0000 - val_loss: 3217650.7500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1387179.6250 - val_loss: 3215575.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1372610.7500 - val_loss: 3213053.2500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1358125.8750 - val_loss: 3210596.7500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1343718.2500 - val_loss: 3208026.2500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1329398.8750 - val_loss: 3205551.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1315162.0000 - val_loss: 3202907.5000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1301009.6250 - val_loss: 3200045.0000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1286936.5000 - val_loss: 3196978.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1272950.6250 - val_loss: 3194196.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1259040.3750 - val_loss: 3191452.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1245209.0000 - val_loss: 3188826.7500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1231460.0000 - val_loss: 3186155.2500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1217791.5000 - val_loss: 3183459.2500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1204206.1250 - val_loss: 3181099.2500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1190703.7500 - val_loss: 3178469.2500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1177282.3750 - val_loss: 3176205.2500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1163941.0000 - val_loss: 3173918.2500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1150690.8750 - val_loss: 3171608.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1137521.2500 - val_loss: 3168896.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1124432.2500 - val_loss: 3164644.7500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 10ms/step - loss: 1892693.3750 - val_loss: 3270540.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1860745.1250 - val_loss: 3269794.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1840742.2500 - val_loss: 3268877.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1822165.2500 - val_loss: 3267669.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1804210.2500 - val_loss: 3266288.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1786649.1250 - val_loss: 3264837.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1769374.5000 - val_loss: 3263215.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1752318.3750 - val_loss: 3261519.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1735444.2500 - val_loss: 3259836.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1718726.0000 - val_loss: 3258006.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1702147.3750 - val_loss: 3256161.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1685696.5000 - val_loss: 3254341.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1669366.6250 - val_loss: 3252317.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1653153.6250 - val_loss: 3250421.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1637045.1250 - val_loss: 3248225.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1621036.8750 - val_loss: 3246010.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1605130.0000 - val_loss: 3243721.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1589319.5000 - val_loss: 3241434.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1573605.6250 - val_loss: 3239061.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1557985.6250 - val_loss: 3236772.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1542452.0000 - val_loss: 3234554.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1527009.2500 - val_loss: 3232273.5000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1511652.2500 - val_loss: 3230087.2500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1496389.0000 - val_loss: 3227987.2500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1481209.3750 - val_loss: 3225816.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1466116.2500 - val_loss: 3223888.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1451101.2500 - val_loss: 3221665.5000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1436168.2500 - val_loss: 3219472.0000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1421316.5000 - val_loss: 3217267.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1406552.6250 - val_loss: 3215232.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1391874.0000 - val_loss: 3212452.5000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1377274.6250 - val_loss: 3209729.7500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1362764.8750 - val_loss: 3207558.5000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1348335.2500 - val_loss: 3204754.2500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1333992.7500 - val_loss: 3201940.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1319734.6250 - val_loss: 3199137.5000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1305557.1250 - val_loss: 3196641.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1291454.0000 - val_loss: 3194181.2500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1277434.6250 - val_loss: 3191702.2500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1263495.1250 - val_loss: 3188830.2500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1249638.8750 - val_loss: 3186461.7500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1235871.1250 - val_loss: 3183878.5000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1222183.7500 - val_loss: 3181273.5000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1208581.3750 - val_loss: 3178768.0000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1195057.8750 - val_loss: 3176447.7500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1181617.6250 - val_loss: 3174130.2500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1168265.8750 - val_loss: 3171336.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1154983.8750 - val_loss: 3167549.5000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1141782.8750 - val_loss: 3164095.7500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1128660.7500 - val_loss: 3161591.0000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 9ms/step - loss: 1894567.2500 - val_loss: 3271370.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1862871.0000 - val_loss: 3271402.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1842596.5000 - val_loss: 3271379.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1823907.0000 - val_loss: 3271214.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1805887.1250 - val_loss: 3270833.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1788268.7500 - val_loss: 3270209.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1770948.8750 - val_loss: 3269294.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1753863.7500 - val_loss: 3268161.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1736966.2500 - val_loss: 3266843.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1720220.6250 - val_loss: 3265404.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1703627.6250 - val_loss: 3263903.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1687171.3750 - val_loss: 3262145.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1670833.5000 - val_loss: 3260187.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1654609.0000 - val_loss: 3258327.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1638495.5000 - val_loss: 3256332.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1622483.6250 - val_loss: 3254338.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1606571.3750 - val_loss: 3252522.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1590752.0000 - val_loss: 3250858.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1575029.8750 - val_loss: 3248947.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1559403.5000 - val_loss: 3247160.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1543866.6250 - val_loss: 3245064.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1528415.3750 - val_loss: 3242986.2500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1513052.3750 - val_loss: 3240575.7500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1497777.2500 - val_loss: 3237999.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1482586.1250 - val_loss: 3235196.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1467485.0000 - val_loss: 3232641.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1452467.7500 - val_loss: 3230334.2500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1437535.2500 - val_loss: 3228082.0000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1422685.3750 - val_loss: 3225844.0000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1407917.7500 - val_loss: 3223378.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1393236.3750 - val_loss: 3221254.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1378632.7500 - val_loss: 3218981.0000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1364111.2500 - val_loss: 3216736.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1349676.5000 - val_loss: 3214387.7500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1335324.6250 - val_loss: 3210869.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1321052.6250 - val_loss: 3206650.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1306858.8750 - val_loss: 3203702.2500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1292747.6250 - val_loss: 3201064.7500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1278720.8750 - val_loss: 3198571.5000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1264780.5000 - val_loss: 3196336.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1250918.6250 - val_loss: 3193813.5000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1237144.8750 - val_loss: 3191189.7500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1223444.2500 - val_loss: 3186716.2500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1209828.5000 - val_loss: 3182482.2500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1196298.6250 - val_loss: 3179342.0000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1182844.2500 - val_loss: 3176604.2500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1169468.3750 - val_loss: 3174344.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1156178.3750 - val_loss: 3172007.0000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1142973.1250 - val_loss: 3167563.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1129846.3750 - val_loss: 3163973.0000\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 18ms/step - loss: 1902999.2500 - val_loss: 3272044.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1876989.5000 - val_loss: 3271176.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1863816.2500 - val_loss: 3271047.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1853341.1250 - val_loss: 3270929.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1843538.1250 - val_loss: 3270792.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1834076.6250 - val_loss: 3270629.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1824832.2500 - val_loss: 3270399.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1815745.6250 - val_loss: 3270189.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1806772.8750 - val_loss: 3269947.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1797900.7500 - val_loss: 3269651.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1789107.1250 - val_loss: 3269357.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1780377.6250 - val_loss: 3269062.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1771719.2500 - val_loss: 3268762.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1763111.5000 - val_loss: 3268333.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1754551.0000 - val_loss: 3268003.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1746035.5000 - val_loss: 3267694.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1737562.7500 - val_loss: 3267243.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1729130.2500 - val_loss: 3266777.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1720729.7500 - val_loss: 3266293.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1712366.3750 - val_loss: 3265759.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1704033.2500 - val_loss: 3265241.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1695741.3750 - val_loss: 3264797.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1687482.3750 - val_loss: 3264166.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1679255.2500 - val_loss: 3263559.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1671051.5000 - val_loss: 3262825.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1662880.8750 - val_loss: 3262149.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1654739.5000 - val_loss: 3261495.7500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1646619.7500 - val_loss: 3260827.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1638525.8750 - val_loss: 3260180.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1630457.3750 - val_loss: 3259410.2500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1622414.7500 - val_loss: 3258619.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1614399.2500 - val_loss: 3257999.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1606401.8750 - val_loss: 3257319.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1598432.8750 - val_loss: 3256466.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1590493.0000 - val_loss: 3255714.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1582574.1250 - val_loss: 3255145.2500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1574676.2500 - val_loss: 3254280.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1566803.8750 - val_loss: 3253490.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1558957.0000 - val_loss: 3252653.2500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1551131.5000 - val_loss: 3252040.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1543327.8750 - val_loss: 3251132.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1535545.3750 - val_loss: 3250230.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1527785.5000 - val_loss: 3249528.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1520043.5000 - val_loss: 3248703.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1512321.5000 - val_loss: 3247824.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1504626.2500 - val_loss: 3247142.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1496951.0000 - val_loss: 3246531.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1489303.1250 - val_loss: 3245673.0000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1481677.3750 - val_loss: 3245238.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1474070.5000 - val_loss: 3244474.5000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 14ms/step - loss: 1903608.5000 - val_loss: 3271549.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1877592.7500 - val_loss: 3270097.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1863181.3750 - val_loss: 3269530.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1852504.0000 - val_loss: 3269053.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1842581.8750 - val_loss: 3268474.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1833037.0000 - val_loss: 3267912.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1823737.1250 - val_loss: 3267295.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1814607.5000 - val_loss: 3266580.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1805613.8750 - val_loss: 3265912.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1796723.7500 - val_loss: 3265176.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1787919.0000 - val_loss: 3264417.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1779176.2500 - val_loss: 3263624.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1770502.2500 - val_loss: 3262898.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1761883.3750 - val_loss: 3262110.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1753318.3750 - val_loss: 3261327.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1744791.3750 - val_loss: 3260636.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1736313.7500 - val_loss: 3259784.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1727874.8750 - val_loss: 3258975.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1719474.8750 - val_loss: 3258265.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1711116.5000 - val_loss: 3257514.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1702789.3750 - val_loss: 3256673.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1694493.3750 - val_loss: 3255953.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1686227.7500 - val_loss: 3255233.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1678000.7500 - val_loss: 3254364.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1669802.2500 - val_loss: 3253502.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1661628.1250 - val_loss: 3252734.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1653480.3750 - val_loss: 3251929.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1645361.1250 - val_loss: 3251147.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1637266.1250 - val_loss: 3250329.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1629202.5000 - val_loss: 3249488.2500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1621163.1250 - val_loss: 3248646.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1613148.7500 - val_loss: 3247732.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1605158.7500 - val_loss: 3246861.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1597194.0000 - val_loss: 3246063.7500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1589249.6250 - val_loss: 3245151.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1581332.5000 - val_loss: 3244244.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1573440.0000 - val_loss: 3243326.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1565570.2500 - val_loss: 3242342.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1557723.2500 - val_loss: 3241343.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1549901.5000 - val_loss: 3240351.0000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1542097.6250 - val_loss: 3239323.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1534317.7500 - val_loss: 3238342.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1526559.3750 - val_loss: 3237341.0000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1518817.5000 - val_loss: 3236303.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1511096.2500 - val_loss: 3235333.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1503400.6250 - val_loss: 3234440.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1495729.6250 - val_loss: 3233472.5000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1488077.6250 - val_loss: 3232473.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1480454.1250 - val_loss: 3231795.2500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1472851.1250 - val_loss: 3231039.0000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 19ms/step - loss: 1905730.5000 - val_loss: 3270124.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1882523.0000 - val_loss: 3269915.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1867489.1250 - val_loss: 3269747.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1856595.5000 - val_loss: 3269591.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1846553.2500 - val_loss: 3269393.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1836932.7500 - val_loss: 3269181.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1827560.8750 - val_loss: 3268925.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1818380.2500 - val_loss: 3268669.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1809341.1250 - val_loss: 3268340.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1800412.7500 - val_loss: 3268039.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1791573.6250 - val_loss: 3267659.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1782807.8750 - val_loss: 3267266.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1774106.1250 - val_loss: 3266833.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1765465.1250 - val_loss: 3266399.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1756873.1250 - val_loss: 3265988.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1748329.3750 - val_loss: 3265483.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1739838.3750 - val_loss: 3264933.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1731386.1250 - val_loss: 3264388.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1722974.3750 - val_loss: 3263833.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1714594.7500 - val_loss: 3263194.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1706250.1250 - val_loss: 3262658.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1697941.8750 - val_loss: 3261887.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1689667.2500 - val_loss: 3261235.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1681419.6250 - val_loss: 3260577.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1673205.2500 - val_loss: 3259886.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1665018.0000 - val_loss: 3259112.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1656862.6250 - val_loss: 3258431.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1648731.1250 - val_loss: 3257680.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1640626.3750 - val_loss: 3256982.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1632554.0000 - val_loss: 3256212.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1624501.0000 - val_loss: 3255536.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1616472.3750 - val_loss: 3254806.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1608469.7500 - val_loss: 3254089.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1600494.7500 - val_loss: 3253456.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1592540.6250 - val_loss: 3252770.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1584612.1250 - val_loss: 3252178.2500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1576710.1250 - val_loss: 3251338.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1568831.3750 - val_loss: 3250764.7500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1560978.2500 - val_loss: 3250152.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1553147.3750 - val_loss: 3249422.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1545335.1250 - val_loss: 3248777.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1537545.5000 - val_loss: 3248064.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1529777.7500 - val_loss: 3247467.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1522032.7500 - val_loss: 3246736.0000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1514306.6250 - val_loss: 3245905.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1506607.0000 - val_loss: 3245154.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1498928.8750 - val_loss: 3244401.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1491274.2500 - val_loss: 3243589.2500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1483634.3750 - val_loss: 3242744.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1476021.7500 - val_loss: 3241910.2500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 20ms/step - loss: 1902463.8750 - val_loss: 3272336.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1874220.8750 - val_loss: 3271722.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1860861.3750 - val_loss: 3271756.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1850365.0000 - val_loss: 3271791.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1840549.5000 - val_loss: 3271805.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1831082.3750 - val_loss: 3271779.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1821841.7500 - val_loss: 3271720.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1812752.7500 - val_loss: 3271634.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1803789.7500 - val_loss: 3271514.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1794922.6250 - val_loss: 3271361.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1786133.3750 - val_loss: 3271190.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1777415.2500 - val_loss: 3270987.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1768761.6250 - val_loss: 3270760.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1760160.5000 - val_loss: 3270493.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1751613.0000 - val_loss: 3270198.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1743108.0000 - val_loss: 3269868.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1734642.3750 - val_loss: 3269505.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1726216.6250 - val_loss: 3269139.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1717822.1250 - val_loss: 3268718.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1709465.0000 - val_loss: 3268275.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1701145.8750 - val_loss: 3267765.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1692860.3750 - val_loss: 3267236.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1684599.1250 - val_loss: 3266729.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1676373.7500 - val_loss: 3266160.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1668180.2500 - val_loss: 3265477.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1660014.1250 - val_loss: 3264866.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1651878.1250 - val_loss: 3264122.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1643767.7500 - val_loss: 3263380.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1635686.6250 - val_loss: 3262715.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1627625.6250 - val_loss: 3261918.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1619589.2500 - val_loss: 3261044.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1611580.6250 - val_loss: 3260297.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1603598.2500 - val_loss: 3259409.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1595635.7500 - val_loss: 3258547.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1587701.1250 - val_loss: 3257763.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1579794.5000 - val_loss: 3256787.2500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1571908.1250 - val_loss: 3255941.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1564042.7500 - val_loss: 3254912.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1556199.5000 - val_loss: 3254062.2500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1548375.1250 - val_loss: 3253245.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1540576.1250 - val_loss: 3252342.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1532798.7500 - val_loss: 3251439.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1525049.1250 - val_loss: 3250606.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1517315.0000 - val_loss: 3249681.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1509599.2500 - val_loss: 3248838.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1501913.3750 - val_loss: 3247979.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1494248.6250 - val_loss: 3247049.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1486605.8750 - val_loss: 3246130.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1478987.5000 - val_loss: 3245206.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1471387.1250 - val_loss: 3244284.7500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 13ms/step - loss: 1903779.2500 - val_loss: 3270745.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1877186.6250 - val_loss: 3270156.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1862711.7500 - val_loss: 3270314.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1852025.0000 - val_loss: 3270314.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1842098.2500 - val_loss: 3270208.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1832561.5000 - val_loss: 3270040.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1823261.2500 - val_loss: 3269791.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1814131.0000 - val_loss: 3269500.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1805129.7500 - val_loss: 3269108.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1796235.5000 - val_loss: 3268615.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1787424.5000 - val_loss: 3268138.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1778684.0000 - val_loss: 3267604.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1770011.2500 - val_loss: 3267024.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1761389.6250 - val_loss: 3266463.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1752817.8750 - val_loss: 3265846.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1744300.3750 - val_loss: 3265215.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1735823.1250 - val_loss: 3264554.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1727385.3750 - val_loss: 3263882.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1718983.2500 - val_loss: 3263183.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1710622.1250 - val_loss: 3262526.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1702289.0000 - val_loss: 3261774.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1693990.3750 - val_loss: 3261053.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1685725.5000 - val_loss: 3260261.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1677492.6250 - val_loss: 3259526.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1669290.0000 - val_loss: 3258745.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1661117.7500 - val_loss: 3257937.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1652978.5000 - val_loss: 3257133.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1644866.6250 - val_loss: 3256317.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1636778.2500 - val_loss: 3255501.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1628719.0000 - val_loss: 3254603.2500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1620680.3750 - val_loss: 3253760.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1612669.0000 - val_loss: 3252925.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1604684.0000 - val_loss: 3252024.0000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1596717.7500 - val_loss: 3251075.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1588772.0000 - val_loss: 3250197.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1580851.6250 - val_loss: 3249411.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1572959.5000 - val_loss: 3248475.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1565094.7500 - val_loss: 3247571.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1557248.6250 - val_loss: 3246554.2500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1549422.8750 - val_loss: 3245628.0000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1541620.0000 - val_loss: 3244832.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1533840.1250 - val_loss: 3243839.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1526084.2500 - val_loss: 3242800.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1518342.7500 - val_loss: 3241843.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1510637.1250 - val_loss: 3240951.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1502943.8750 - val_loss: 3239901.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1495277.8750 - val_loss: 3238942.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1487628.3750 - val_loss: 3237723.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1480004.6250 - val_loss: 3236943.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1472400.3750 - val_loss: 3235854.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 18ms/step - loss: 1903484.0000 - val_loss: 3271275.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1878469.8750 - val_loss: 3271156.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1865232.3750 - val_loss: 3271338.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1854745.3750 - val_loss: 3271479.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1844928.7500 - val_loss: 3271565.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1835456.0000 - val_loss: 3271594.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1826201.6250 - val_loss: 3271575.5000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 15ms/step - loss: 1903741.8750 - val_loss: 3269480.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1876741.2500 - val_loss: 3269283.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1862899.8750 - val_loss: 3269273.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1852288.1250 - val_loss: 3269260.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1842391.8750 - val_loss: 3269239.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1832880.8750 - val_loss: 3269200.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1823600.1250 - val_loss: 3269130.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1814487.7500 - val_loss: 3269023.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1805496.0000 - val_loss: 3268887.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1796606.7500 - val_loss: 3268675.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1787806.5000 - val_loss: 3268449.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1779071.1250 - val_loss: 3268165.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1770399.7500 - val_loss: 3267837.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1761777.8750 - val_loss: 3267472.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1753214.7500 - val_loss: 3267084.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1744691.2500 - val_loss: 3266641.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1736218.7500 - val_loss: 3266164.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1727781.0000 - val_loss: 3265591.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1719386.3750 - val_loss: 3265113.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1711027.6250 - val_loss: 3264546.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1702697.3750 - val_loss: 3263958.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1694409.3750 - val_loss: 3263395.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1686151.5000 - val_loss: 3262796.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1677914.7500 - val_loss: 3262192.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1669713.6250 - val_loss: 3261579.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1661534.8750 - val_loss: 3260941.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1653389.7500 - val_loss: 3260330.7500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1645269.1250 - val_loss: 3259562.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1637181.0000 - val_loss: 3258915.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1629113.6250 - val_loss: 3258252.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1621075.0000 - val_loss: 3257494.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1613064.2500 - val_loss: 3256725.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1605074.5000 - val_loss: 3256069.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1597106.3750 - val_loss: 3255233.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1589169.8750 - val_loss: 3254473.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1581248.2500 - val_loss: 3253715.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1573353.3750 - val_loss: 3252971.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1565487.1250 - val_loss: 3252103.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1557638.0000 - val_loss: 3251595.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1549815.1250 - val_loss: 3250724.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1542008.3750 - val_loss: 3250019.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1534229.6250 - val_loss: 3249289.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1526469.2500 - val_loss: 3248647.2500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1518734.1250 - val_loss: 3248072.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1511023.5000 - val_loss: 3247284.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1503335.7500 - val_loss: 3246448.7500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1495664.2500 - val_loss: 3245874.5000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1488018.1250 - val_loss: 3245204.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1480389.3750 - val_loss: 3244448.2500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1472785.6250 - val_loss: 3243817.2500\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 14ms/step - loss: 1903217.8750 - val_loss: 3271965.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1874657.8750 - val_loss: 3270932.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1859809.3750 - val_loss: 3270789.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1849096.7500 - val_loss: 3270678.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1839159.2500 - val_loss: 3270544.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1829613.0000 - val_loss: 3270390.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1820310.2500 - val_loss: 3270180.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1811181.7500 - val_loss: 3269970.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1802188.1250 - val_loss: 3269630.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1793297.2500 - val_loss: 3269307.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1784484.8750 - val_loss: 3268956.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1775748.1250 - val_loss: 3268538.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1767073.3750 - val_loss: 3268068.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1758461.2500 - val_loss: 3267537.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1749895.7500 - val_loss: 3267024.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1741381.8750 - val_loss: 3266479.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1732907.5000 - val_loss: 3265843.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1724479.3750 - val_loss: 3265259.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1716087.7500 - val_loss: 3264617.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1707734.3750 - val_loss: 3263977.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1699411.2500 - val_loss: 3263129.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1691118.8750 - val_loss: 3262512.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1682860.3750 - val_loss: 3261824.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1674632.0000 - val_loss: 3261116.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1666438.8750 - val_loss: 3260359.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1658275.3750 - val_loss: 3259639.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1650135.2500 - val_loss: 3258931.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1642026.0000 - val_loss: 3258172.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1633940.2500 - val_loss: 3257393.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1625879.7500 - val_loss: 3256651.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1617850.5000 - val_loss: 3255876.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1609845.6250 - val_loss: 3255120.5000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1601867.1250 - val_loss: 3254402.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1593909.8750 - val_loss: 3253574.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1585976.0000 - val_loss: 3252820.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1578071.6250 - val_loss: 3252018.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1570190.3750 - val_loss: 3251161.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1562329.0000 - val_loss: 3250403.7500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1554489.0000 - val_loss: 3249590.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1546670.5000 - val_loss: 3248881.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1538878.5000 - val_loss: 3248132.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1531103.5000 - val_loss: 3247452.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1523355.1250 - val_loss: 3246634.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1515631.2500 - val_loss: 3245842.0000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1507929.1250 - val_loss: 3245128.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1500246.6250 - val_loss: 3244455.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1492583.6250 - val_loss: 3244002.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1484940.0000 - val_loss: 3243058.2500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1477319.5000 - val_loss: 3242781.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1469720.0000 - val_loss: 3242057.7500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 18ms/step - loss: 1903067.3750 - val_loss: 3272123.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1875024.5000 - val_loss: 3271939.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1860988.6250 - val_loss: 3271971.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1850374.6250 - val_loss: 3272000.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1840492.1250 - val_loss: 3272017.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1830979.8750 - val_loss: 3272022.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1821707.7500 - val_loss: 3271989.5000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 18ms/step - loss: 1906000.2500 - val_loss: 3268898.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1879618.1250 - val_loss: 3268475.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1862281.3750 - val_loss: 3267818.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1851132.5000 - val_loss: 3267242.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1840964.6250 - val_loss: 3266655.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1831264.2500 - val_loss: 3266022.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1821847.3750 - val_loss: 3265393.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1812634.7500 - val_loss: 3264831.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1803560.6250 - val_loss: 3264152.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1794609.7500 - val_loss: 3263557.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1785750.2500 - val_loss: 3262954.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1776972.8750 - val_loss: 3262407.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1768267.5000 - val_loss: 3261723.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1759619.2500 - val_loss: 3261125.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1751032.2500 - val_loss: 3260552.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1742490.5000 - val_loss: 3259964.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1733993.0000 - val_loss: 3259398.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1725546.1250 - val_loss: 3258738.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1717136.3750 - val_loss: 3258112.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1708762.6250 - val_loss: 3257463.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1700430.8750 - val_loss: 3256775.2500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1692128.5000 - val_loss: 3256223.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1683857.5000 - val_loss: 3255490.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1675625.6250 - val_loss: 3254779.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1667423.3750 - val_loss: 3254082.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1659250.8750 - val_loss: 3253356.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1651100.3750 - val_loss: 3252624.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1642985.5000 - val_loss: 3251875.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1634899.6250 - val_loss: 3251151.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1626839.1250 - val_loss: 3250380.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1618805.0000 - val_loss: 3249653.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1610797.7500 - val_loss: 3248912.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1602804.6250 - val_loss: 3248125.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1594843.2500 - val_loss: 3247462.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1586903.0000 - val_loss: 3246653.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1578991.8750 - val_loss: 3246037.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1571108.1250 - val_loss: 3245288.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1563243.3750 - val_loss: 3244529.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1555397.6250 - val_loss: 3243769.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1547577.2500 - val_loss: 3242969.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1539774.6250 - val_loss: 3242339.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1532002.0000 - val_loss: 3241566.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1524247.8750 - val_loss: 3240783.0000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1516517.3750 - val_loss: 3240051.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1508806.7500 - val_loss: 3239266.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1501125.0000 - val_loss: 3238581.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1493456.5000 - val_loss: 3237848.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1485811.7500 - val_loss: 3237008.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1478190.7500 - val_loss: 3236220.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1470586.0000 - val_loss: 3235352.0000\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 20ms/step - loss: 1907773.1250 - val_loss: 3271079.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1898888.2500 - val_loss: 3273078.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1881544.1250 - val_loss: 3272184.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1873049.3750 - val_loss: 3272159.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1866939.1250 - val_loss: 3272198.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1861396.0000 - val_loss: 3272246.2500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 21ms/step - loss: 1907274.0000 - val_loss: 3270465.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1898634.3750 - val_loss: 3271088.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1881893.3750 - val_loss: 3270813.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1873247.3750 - val_loss: 3270700.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1867105.6250 - val_loss: 3270644.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1861553.2500 - val_loss: 3270599.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 18ms/step - loss: 1908016.7500 - val_loss: 3270552.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1900772.6250 - val_loss: 3271350.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1884442.3750 - val_loss: 3270849.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1876051.7500 - val_loss: 3270736.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1869927.3750 - val_loss: 3270710.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1864367.7500 - val_loss: 3270706.7500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 18ms/step - loss: 1907422.1250 - val_loss: 3272349.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1897419.0000 - val_loss: 3273089.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1880926.5000 - val_loss: 3272447.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1872798.1250 - val_loss: 3272457.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1866757.3750 - val_loss: 3272521.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1861257.0000 - val_loss: 3272596.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 21ms/step - loss: 1906652.0000 - val_loss: 3272716.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1894573.7500 - val_loss: 3273348.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1879322.6250 - val_loss: 3272494.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1872098.6250 - val_loss: 3272443.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1866292.8750 - val_loss: 3272463.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1860932.6250 - val_loss: 3272480.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1855813.6250 - val_loss: 3272524.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1850850.5000 - val_loss: 3272574.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1845989.2500 - val_loss: 3272603.7500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 18ms/step - loss: 1907530.8750 - val_loss: 3269505.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1899612.6250 - val_loss: 3269548.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1882310.8750 - val_loss: 3270183.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1871819.6250 - val_loss: 3270352.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1865341.1250 - val_loss: 3270413.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1859633.8750 - val_loss: 3270443.5000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 18ms/step - loss: 1906660.5000 - val_loss: 3272423.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1895095.3750 - val_loss: 3272611.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1876802.1250 - val_loss: 3271700.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1868565.0000 - val_loss: 3271687.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1862541.5000 - val_loss: 3271749.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1857055.2500 - val_loss: 3271811.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1851845.6250 - val_loss: 3271866.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1846815.5000 - val_loss: 3271918.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1841912.2500 - val_loss: 3271962.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 25ms/step - loss: 1907657.5000 - val_loss: 3270036.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1899695.7500 - val_loss: 3271617.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1882510.8750 - val_loss: 3271262.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1873344.6250 - val_loss: 3271251.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1867026.1250 - val_loss: 3271283.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1861168.5000 - val_loss: 3271318.2500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 18ms/step - loss: 1907226.1250 - val_loss: 3270893.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 1896432.5000 - val_loss: 3272632.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1878961.7500 - val_loss: 3271835.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1870807.2500 - val_loss: 3271852.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1864763.5000 - val_loss: 3271893.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1859272.3750 - val_loss: 3271939.0000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 25ms/step - loss: 1907573.2500 - val_loss: 3270607.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1898943.3750 - val_loss: 3271696.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1881108.3750 - val_loss: 3271280.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1871591.0000 - val_loss: 3271053.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1865271.0000 - val_loss: 3271042.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1859636.5000 - val_loss: 3271064.2500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Best_hyper_parameters: \n",
            " {'model': [30], 'optimizer': 'Adam', 'learning_rate': 0.1, 'batch_size': 4, 'best_avg_rmse': 1388.8425931594415}\n",
            "all_avg_rmse: \n",
            " [[[1388.84259316 1485.8172615  1559.81380326]\n",
            "  [1599.50022963 1629.80402676 1654.64708582]\n",
            "  [1672.33780712 1688.3096877  1701.58479122]]\n",
            "\n",
            " [[1707.56076508 1714.16855772 1720.86428254]\n",
            "  [1727.27102087 1732.93966025 1737.96042478]\n",
            "  [1742.35306689 1746.24155744 1749.70076653]]\n",
            "\n",
            " [[1738.28106268 1728.87944911 1725.42944148]\n",
            "  [1726.2944783  1727.64976755 1729.67688368]\n",
            "  [1731.60257847 1734.29968646 1737.05681246]]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'model': [30],\n",
              " 'optimizer': 'Adam',\n",
              " 'learning_rate': 0.1,\n",
              " 'batch_size': 4,\n",
              " 'best_avg_rmse': 1388.8425931594415}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layers = [30]\n",
        "time_step = 5\n",
        "optimizers_names = ['Adam', 'Adagrad', 'Nadam']\n",
        "learning_rates =  [0.1, 0.01, 0.001]\n",
        "batch_sizes =  [4, 8, 16]\n",
        "epochs = 50\n",
        "num_replicates = 10\n",
        "\n",
        "\n",
        "N30_best_hyper_parameters = hyper_parameter_tuning(layers,  optimizers_names, learning_rates, batch_sizes, epochs = epochs, num_replicates = num_replicates)\n",
        "N30_best_hyper_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1TPs5z4rpgr"
      },
      "source": [
        "### Case III: Tuning parameters of 50 neuron single layer LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zd99IAVrqct",
        "outputId": "bc34ffbd-cc40-43eb-e71c-814999533c1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1679707.1250 - val_loss: 3260163.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1676144.2500 - val_loss: 3259853.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1672652.0000 - val_loss: 3259540.0000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1669225.0000 - val_loss: 3259224.7500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1665861.3750 - val_loss: 3258905.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1662556.7500 - val_loss: 3258582.0000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1659309.6250 - val_loss: 3258256.5000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1656114.8750 - val_loss: 3257929.0000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1652972.8750 - val_loss: 3257599.7500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1649881.1250 - val_loss: 3257271.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1646835.6250 - val_loss: 3256944.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1643835.5000 - val_loss: 3256618.7500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1640880.1250 - val_loss: 3256298.2500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1637966.5000 - val_loss: 3255980.0000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1635092.2500 - val_loss: 3255667.5000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1632258.0000 - val_loss: 3255358.7500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1629460.3750 - val_loss: 3255054.5000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1626699.3750 - val_loss: 3254753.0000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1623973.8750 - val_loss: 3254457.2500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1621280.1250 - val_loss: 3254163.0000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1618619.8750 - val_loss: 3253871.2500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1615992.0000 - val_loss: 3253581.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1613393.8750 - val_loss: 3253294.5000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 2ms/step - loss: 1610824.7500 - val_loss: 3253009.2500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1864096.7500 - val_loss: 3267862.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1837626.1250 - val_loss: 3266516.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1823016.8750 - val_loss: 3265347.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1811414.6250 - val_loss: 3264281.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1801499.3750 - val_loss: 3263304.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1792705.3750 - val_loss: 3262400.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1784727.1250 - val_loss: 3261561.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1777378.2500 - val_loss: 3260781.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1770533.2500 - val_loss: 3260046.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1764104.3750 - val_loss: 3259347.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1758027.6250 - val_loss: 3258680.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1752250.7500 - val_loss: 3258041.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1746734.7500 - val_loss: 3257420.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1741449.5000 - val_loss: 3256817.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1736369.5000 - val_loss: 3256230.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1731473.0000 - val_loss: 3255656.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1726742.5000 - val_loss: 3255092.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1722162.8750 - val_loss: 3254540.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1717722.3750 - val_loss: 3253998.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1713408.1250 - val_loss: 3253465.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1709210.7500 - val_loss: 3252942.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1705123.0000 - val_loss: 3252428.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1701136.5000 - val_loss: 3251923.2500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1697244.5000 - val_loss: 3251425.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1693440.8750 - val_loss: 3250936.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1689719.8750 - val_loss: 3250456.5000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1686077.1250 - val_loss: 3249983.5000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1682508.3750 - val_loss: 3249519.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1679010.6250 - val_loss: 3249062.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1675577.7500 - val_loss: 3248612.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1672207.0000 - val_loss: 3248171.7500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1668897.2500 - val_loss: 3247737.2500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1665644.2500 - val_loss: 3247309.7500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1662444.7500 - val_loss: 3246891.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1659296.8750 - val_loss: 3246479.0000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1656199.0000 - val_loss: 3246074.7500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1653148.7500 - val_loss: 3245676.0000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1650143.8750 - val_loss: 3245284.2500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1647181.8750 - val_loss: 3244900.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1644262.3750 - val_loss: 3244522.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1641384.0000 - val_loss: 3244152.0000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1638544.7500 - val_loss: 3243786.0000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1635742.3750 - val_loss: 3243427.7500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1632975.5000 - val_loss: 3243074.5000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1630243.8750 - val_loss: 3242728.7500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1627546.6250 - val_loss: 3242387.0000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1624881.1250 - val_loss: 3242052.2500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1622248.2500 - val_loss: 3241722.5000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1619645.3750 - val_loss: 3241398.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1617072.1250 - val_loss: 3241079.0000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 5ms/step - loss: 1860991.3750 - val_loss: 3269963.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1834096.2500 - val_loss: 3269663.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1819483.5000 - val_loss: 3269314.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1807882.2500 - val_loss: 3268918.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1797971.5000 - val_loss: 3268485.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1789182.5000 - val_loss: 3268022.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1781209.6250 - val_loss: 3267527.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1773863.7500 - val_loss: 3267005.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1767025.2500 - val_loss: 3266462.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1760601.8750 - val_loss: 3265908.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1754528.8750 - val_loss: 3265349.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1748755.6250 - val_loss: 3264792.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1743244.5000 - val_loss: 3264242.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1737963.1250 - val_loss: 3263699.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1732886.6250 - val_loss: 3263163.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1727994.5000 - val_loss: 3262640.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1723267.6250 - val_loss: 3262124.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1718691.3750 - val_loss: 3261620.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1714254.2500 - val_loss: 3261125.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1709942.6250 - val_loss: 3260639.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1705749.6250 - val_loss: 3260163.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1701665.5000 - val_loss: 3259696.5000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1697682.1250 - val_loss: 3259239.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1693793.2500 - val_loss: 3258792.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1689993.6250 - val_loss: 3258358.2500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1686275.8750 - val_loss: 3257935.2500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1682636.0000 - val_loss: 3257525.2500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1679070.0000 - val_loss: 3257125.0000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1675574.6250 - val_loss: 3256735.7500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1672145.1250 - val_loss: 3256355.2500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1668776.7500 - val_loss: 3255983.5000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1665471.1250 - val_loss: 3255619.7500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1662220.3750 - val_loss: 3255263.7500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1659024.2500 - val_loss: 3254915.7500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1655880.2500 - val_loss: 3254573.7500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1652784.8750 - val_loss: 3254237.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1649738.1250 - val_loss: 3253905.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1646735.6250 - val_loss: 3253579.0000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1643776.0000 - val_loss: 3253256.0000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1640860.6250 - val_loss: 3252939.0000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1637983.8750 - val_loss: 3252625.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1635147.0000 - val_loss: 3252313.7500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1632346.5000 - val_loss: 3252006.0000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1629583.5000 - val_loss: 3251701.2500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1626854.1250 - val_loss: 3251397.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1624159.2500 - val_loss: 3251098.0000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1621497.1250 - val_loss: 3250800.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1618866.2500 - val_loss: 3250503.7500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1616266.2500 - val_loss: 3250210.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1613695.7500 - val_loss: 3249917.2500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 6ms/step - loss: 1861953.6250 - val_loss: 3269994.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1835124.2500 - val_loss: 3269876.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1820515.8750 - val_loss: 3269692.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1808915.2500 - val_loss: 3269454.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1799001.8750 - val_loss: 3269182.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1790210.7500 - val_loss: 3268892.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1782237.1250 - val_loss: 3268592.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1774891.6250 - val_loss: 3268290.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1768053.0000 - val_loss: 3267990.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1761628.5000 - val_loss: 3267692.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1755554.0000 - val_loss: 3267404.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1749780.2500 - val_loss: 3267114.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1744266.8750 - val_loss: 3266830.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 2ms/step - loss: 1738984.3750 - val_loss: 3266548.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1733907.6250 - val_loss: 3266266.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1729015.2500 - val_loss: 3265987.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1724287.8750 - val_loss: 3265707.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 2ms/step - loss: 1719710.7500 - val_loss: 3265433.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1715272.7500 - val_loss: 3265161.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1710961.7500 - val_loss: 3264888.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1706768.3750 - val_loss: 3264620.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1702683.1250 - val_loss: 3264352.2500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1698698.8750 - val_loss: 3264086.7500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1694809.7500 - val_loss: 3263822.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1691008.1250 - val_loss: 3263560.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1687289.3750 - val_loss: 3263298.5000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1683649.1250 - val_loss: 3263039.5000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1680083.5000 - val_loss: 3262781.7500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1676586.8750 - val_loss: 3262528.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1673156.7500 - val_loss: 3262276.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1669788.3750 - val_loss: 3262026.5000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1666479.6250 - val_loss: 3261778.7500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1663228.6250 - val_loss: 3261534.0000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1660031.8750 - val_loss: 3261292.7500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1656887.2500 - val_loss: 3261052.7500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1653790.6250 - val_loss: 3260815.5000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1650743.0000 - val_loss: 3260582.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1647739.2500 - val_loss: 3260350.2500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1644780.7500 - val_loss: 3260120.0000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1641863.0000 - val_loss: 3259893.2500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1638986.6250 - val_loss: 3259668.0000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1636148.6250 - val_loss: 3259445.5000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1633348.5000 - val_loss: 3259224.0000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1630583.6250 - val_loss: 3259006.2500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1627854.3750 - val_loss: 3258790.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1625157.8750 - val_loss: 3258575.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1622495.7500 - val_loss: 3258363.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1619863.3750 - val_loss: 3258152.7500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1617261.8750 - val_loss: 3257943.2500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1614691.0000 - val_loss: 3257735.7500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1862972.6250 - val_loss: 3270734.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 2ms/step - loss: 1836255.5000 - val_loss: 3270523.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1821635.2500 - val_loss: 3270150.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1810032.7500 - val_loss: 3269697.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1800119.3750 - val_loss: 3269211.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 2ms/step - loss: 1791325.7500 - val_loss: 3268723.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1783349.1250 - val_loss: 3268245.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1776001.1250 - val_loss: 3267782.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1769159.5000 - val_loss: 3267329.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1762734.3750 - val_loss: 3266895.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1756657.6250 - val_loss: 3266477.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1750882.6250 - val_loss: 3266077.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1745368.2500 - val_loss: 3265685.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1740084.5000 - val_loss: 3265302.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1735005.8750 - val_loss: 3264925.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1730110.8750 - val_loss: 3264558.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1725382.3750 - val_loss: 3264194.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1720804.1250 - val_loss: 3263836.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1716364.7500 - val_loss: 3263484.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1712051.8750 - val_loss: 3263136.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1707857.6250 - val_loss: 3262792.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1703770.6250 - val_loss: 3262451.5000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1699785.1250 - val_loss: 3262113.7500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1695893.8750 - val_loss: 3261781.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1692091.2500 - val_loss: 3261452.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1688371.5000 - val_loss: 3261126.7500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1684731.0000 - val_loss: 3260804.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1681163.3750 - val_loss: 3260487.0000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1677665.5000 - val_loss: 3260173.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1674233.8750 - val_loss: 3259864.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1670865.1250 - val_loss: 3259557.7500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1667556.6250 - val_loss: 3259254.2500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1664304.1250 - val_loss: 3258953.5000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1661106.1250 - val_loss: 3258657.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1657960.1250 - val_loss: 3258364.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1654863.6250 - val_loss: 3258074.2500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1651813.3750 - val_loss: 3257786.7500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1648810.1250 - val_loss: 3257502.2500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1645849.7500 - val_loss: 3257221.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1642931.5000 - val_loss: 3256942.5000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1640053.2500 - val_loss: 3256668.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1637214.8750 - val_loss: 3256396.7500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1634413.7500 - val_loss: 3256126.5000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1631648.0000 - val_loss: 3255860.0000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1628917.6250 - val_loss: 3255594.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1626220.2500 - val_loss: 3255333.0000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1623556.8750 - val_loss: 3255074.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1620924.5000 - val_loss: 3254817.5000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1618322.8750 - val_loss: 3254564.7500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1615750.8750 - val_loss: 3254314.0000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1863902.1250 - val_loss: 3270930.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1837684.2500 - val_loss: 3270249.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1823101.7500 - val_loss: 3269544.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1811515.8750 - val_loss: 3268831.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1801609.0000 - val_loss: 3268130.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1792820.0000 - val_loss: 3267455.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1784849.2500 - val_loss: 3266817.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1777504.5000 - val_loss: 3266222.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1770664.6250 - val_loss: 3265674.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1764238.5000 - val_loss: 3265160.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1758163.5000 - val_loss: 3264671.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1752388.6250 - val_loss: 3264203.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1746874.3750 - val_loss: 3263750.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1741589.8750 - val_loss: 3263312.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1736510.1250 - val_loss: 3262880.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1731614.5000 - val_loss: 3262455.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1726885.0000 - val_loss: 3262036.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1722306.0000 - val_loss: 3261622.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1717866.7500 - val_loss: 3261211.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1713551.7500 - val_loss: 3260809.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1709356.7500 - val_loss: 3260410.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1705268.3750 - val_loss: 3260016.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1701281.3750 - val_loss: 3259628.5000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1697389.1250 - val_loss: 3259244.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1693586.1250 - val_loss: 3258864.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1689865.7500 - val_loss: 3258489.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1686223.1250 - val_loss: 3258117.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1682654.7500 - val_loss: 3257747.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1679156.2500 - val_loss: 3257380.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1675723.1250 - val_loss: 3257014.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1672352.7500 - val_loss: 3256650.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1669042.2500 - val_loss: 3256289.7500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1665789.2500 - val_loss: 3255929.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1662589.5000 - val_loss: 3255569.7500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1659441.8750 - val_loss: 3255209.7500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1656343.7500 - val_loss: 3254851.7500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1653293.5000 - val_loss: 3254495.0000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1650288.5000 - val_loss: 3254141.7500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1647326.7500 - val_loss: 3253789.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1644408.2500 - val_loss: 3253438.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1641529.1250 - val_loss: 3253092.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1638688.6250 - val_loss: 3252749.7500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1635885.5000 - val_loss: 3252411.5000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1633119.3750 - val_loss: 3252077.7500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 2ms/step - loss: 1630388.2500 - val_loss: 3251750.2500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1627690.7500 - val_loss: 3251427.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1625025.5000 - val_loss: 3251110.2500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1622391.8750 - val_loss: 3250799.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1619789.0000 - val_loss: 3250491.7500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1617215.3750 - val_loss: 3250191.0000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 8ms/step - loss: 1871582.6250 - val_loss: 3272119.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1849574.8750 - val_loss: 3272155.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1838877.3750 - val_loss: 3272111.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1830451.7500 - val_loss: 3272012.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1823275.3750 - val_loss: 3271858.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1816920.6250 - val_loss: 3271685.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1811159.0000 - val_loss: 3271494.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1805854.7500 - val_loss: 3271308.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1800911.7500 - val_loss: 3271119.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1796267.0000 - val_loss: 3270925.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1791876.6250 - val_loss: 3270734.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1787704.3750 - val_loss: 3270544.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1783717.5000 - val_loss: 3270357.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1779895.3750 - val_loss: 3270175.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1776221.0000 - val_loss: 3269999.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1772675.3750 - val_loss: 3269829.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1769252.0000 - val_loss: 3269657.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1765934.3750 - val_loss: 3269482.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1762717.0000 - val_loss: 3269306.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1759590.1250 - val_loss: 3269135.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1756547.5000 - val_loss: 3268970.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1753581.3750 - val_loss: 3268809.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1750688.2500 - val_loss: 3268646.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1747863.8750 - val_loss: 3268491.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1745099.5000 - val_loss: 3268329.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1742398.3750 - val_loss: 3268171.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1739751.6250 - val_loss: 3268020.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1737155.8750 - val_loss: 3267863.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1734611.1250 - val_loss: 3267703.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1732112.1250 - val_loss: 3267548.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1729659.2500 - val_loss: 3267397.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1727249.0000 - val_loss: 3267245.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1724878.1250 - val_loss: 3267094.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1722547.6250 - val_loss: 3266943.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1720253.2500 - val_loss: 3266794.7500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1717993.5000 - val_loss: 3266645.2500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1715769.2500 - val_loss: 3266495.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1713575.5000 - val_loss: 3266348.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1711414.6250 - val_loss: 3266205.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1709283.6250 - val_loss: 3266072.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1707179.7500 - val_loss: 3265934.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1705105.6250 - val_loss: 3265798.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1703057.7500 - val_loss: 3265665.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1701036.1250 - val_loss: 3265540.0000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1699037.1250 - val_loss: 3265412.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1697063.5000 - val_loss: 3265286.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1695112.6250 - val_loss: 3265165.5000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1693184.1250 - val_loss: 3265045.2500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1691276.7500 - val_loss: 3264923.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1689392.3750 - val_loss: 3264807.0000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 6ms/step - loss: 1870345.1250 - val_loss: 3270338.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1848099.2500 - val_loss: 3270134.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1837407.2500 - val_loss: 3269951.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1828986.1250 - val_loss: 3269775.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1821807.7500 - val_loss: 3269593.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1815449.0000 - val_loss: 3269419.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1809686.0000 - val_loss: 3269236.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1804384.2500 - val_loss: 3269046.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1799444.3750 - val_loss: 3268850.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1794806.5000 - val_loss: 3268651.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1790418.5000 - val_loss: 3268458.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1786243.3750 - val_loss: 3268273.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1782257.0000 - val_loss: 3268094.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1778434.6250 - val_loss: 3267901.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1774761.5000 - val_loss: 3267723.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1771218.5000 - val_loss: 3267542.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1767797.0000 - val_loss: 3267372.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1764480.2500 - val_loss: 3267181.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1761263.5000 - val_loss: 3267008.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1758137.8750 - val_loss: 3266837.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1755098.3750 - val_loss: 3266672.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1752133.8750 - val_loss: 3266508.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1749242.3750 - val_loss: 3266346.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1746418.6250 - val_loss: 3266186.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1743657.7500 - val_loss: 3266027.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1740955.8750 - val_loss: 3265871.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1738309.6250 - val_loss: 3265717.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1735716.2500 - val_loss: 3265566.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1733172.8750 - val_loss: 3265413.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1730676.8750 - val_loss: 3265268.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1728224.7500 - val_loss: 3265121.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1725815.3750 - val_loss: 3264971.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1723446.8750 - val_loss: 3264826.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1721116.6250 - val_loss: 3264691.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1718821.2500 - val_loss: 3264552.7500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1716561.6250 - val_loss: 3264416.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1714336.0000 - val_loss: 3264272.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1712144.5000 - val_loss: 3264133.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1709983.5000 - val_loss: 3263995.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1707852.2500 - val_loss: 3263862.0000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1705750.2500 - val_loss: 3263726.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1703675.3750 - val_loss: 3263589.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1701628.6250 - val_loss: 3263454.2500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1699605.8750 - val_loss: 3263321.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1697607.6250 - val_loss: 3263191.2500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1695634.1250 - val_loss: 3263059.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1693685.0000 - val_loss: 3262927.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1691757.3750 - val_loss: 3262795.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1689850.3750 - val_loss: 3262667.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1687966.6250 - val_loss: 3262534.7500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 6ms/step - loss: 1872407.2500 - val_loss: 3269384.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1849009.0000 - val_loss: 3268854.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1838168.0000 - val_loss: 3268421.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1829680.8750 - val_loss: 3268012.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1822473.1250 - val_loss: 3267623.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1816089.2500 - val_loss: 3267250.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1810309.0000 - val_loss: 3266905.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1804989.8750 - val_loss: 3266560.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1800039.3750 - val_loss: 3266245.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1795386.7500 - val_loss: 3265936.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1790987.6250 - val_loss: 3265647.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1786807.7500 - val_loss: 3265379.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1782815.7500 - val_loss: 3265129.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1778988.1250 - val_loss: 3264888.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1775307.7500 - val_loss: 3264662.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1771761.0000 - val_loss: 3264445.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1768335.0000 - val_loss: 3264250.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1765016.3750 - val_loss: 3264055.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1761795.2500 - val_loss: 3263879.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1758665.6250 - val_loss: 3263709.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1755619.8750 - val_loss: 3263539.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1752653.8750 - val_loss: 3263368.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1749760.2500 - val_loss: 3263205.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1746934.5000 - val_loss: 3263068.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1744168.6250 - val_loss: 3262919.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1741463.6250 - val_loss: 3262772.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1738815.3750 - val_loss: 3262644.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1736218.3750 - val_loss: 3262491.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1733673.0000 - val_loss: 3262354.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1731175.0000 - val_loss: 3262217.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1728722.1250 - val_loss: 3262090.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1726310.1250 - val_loss: 3261957.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1723939.8750 - val_loss: 3261841.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1721607.0000 - val_loss: 3261721.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1719312.3750 - val_loss: 3261593.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1717053.5000 - val_loss: 3261472.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1714828.0000 - val_loss: 3261350.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1712634.5000 - val_loss: 3261225.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1710473.0000 - val_loss: 3261108.2500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1708341.2500 - val_loss: 3260985.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1706238.0000 - val_loss: 3260867.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1704161.8750 - val_loss: 3260756.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1702113.1250 - val_loss: 3260632.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1700091.7500 - val_loss: 3260508.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1698094.5000 - val_loss: 3260387.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1696119.7500 - val_loss: 3260265.7500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1694170.0000 - val_loss: 3260152.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1692241.5000 - val_loss: 3260044.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1690334.7500 - val_loss: 3259929.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1688449.1250 - val_loss: 3259812.5000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 8ms/step - loss: 1869103.5000 - val_loss: 3273756.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1847270.6250 - val_loss: 3273896.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1836598.6250 - val_loss: 3274013.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1828191.3750 - val_loss: 3274089.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1821021.7500 - val_loss: 3274139.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1814670.8750 - val_loss: 3274168.2500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 6ms/step - loss: 1870698.1250 - val_loss: 3269498.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1847314.6250 - val_loss: 3269411.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1836523.0000 - val_loss: 3269331.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1828058.0000 - val_loss: 3269227.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1820854.2500 - val_loss: 3269098.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1814485.2500 - val_loss: 3268946.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1808713.7500 - val_loss: 3268796.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1803398.2500 - val_loss: 3268639.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1798452.2500 - val_loss: 3268470.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1793805.1250 - val_loss: 3268314.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1789410.2500 - val_loss: 3268157.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1785232.2500 - val_loss: 3267990.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1781241.1250 - val_loss: 3267843.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1777415.2500 - val_loss: 3267689.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1773737.7500 - val_loss: 3267529.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1770192.2500 - val_loss: 3267390.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1766766.3750 - val_loss: 3267243.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1763449.2500 - val_loss: 3267092.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1760233.1250 - val_loss: 3266943.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1757107.2500 - val_loss: 3266801.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1754063.8750 - val_loss: 3266660.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1751100.0000 - val_loss: 3266517.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1748206.5000 - val_loss: 3266381.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1745380.8750 - val_loss: 3266242.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1742620.1250 - val_loss: 3266108.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1739914.6250 - val_loss: 3265972.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1737267.0000 - val_loss: 3265832.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1734674.1250 - val_loss: 3265694.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1732130.5000 - val_loss: 3265559.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1729631.2500 - val_loss: 3265422.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1727179.3750 - val_loss: 3265283.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1724770.5000 - val_loss: 3265140.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1722402.2500 - val_loss: 3265006.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1720071.5000 - val_loss: 3264871.7500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1717778.6250 - val_loss: 3264739.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1715520.7500 - val_loss: 3264603.2500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1713295.8750 - val_loss: 3264471.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1711104.0000 - val_loss: 3264344.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1708942.3750 - val_loss: 3264214.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1706812.0000 - val_loss: 3264077.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1704710.8750 - val_loss: 3263952.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1702635.3750 - val_loss: 3263822.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1700589.1250 - val_loss: 3263692.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1698566.3750 - val_loss: 3263558.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1696571.0000 - val_loss: 3263432.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1694598.2500 - val_loss: 3263305.7500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1692650.2500 - val_loss: 3263183.5000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1690721.1250 - val_loss: 3263056.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1688816.2500 - val_loss: 3262930.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1686933.7500 - val_loss: 3262807.2500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 3s 9ms/step - loss: 1871556.2500 - val_loss: 3272251.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1849220.0000 - val_loss: 3272230.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1838496.8750 - val_loss: 3272182.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1830056.3750 - val_loss: 3272099.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1822871.2500 - val_loss: 3271992.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1816511.5000 - val_loss: 3271867.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1810743.7500 - val_loss: 3271731.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1805436.7500 - val_loss: 3271583.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1800492.3750 - val_loss: 3271423.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1795848.8750 - val_loss: 3271249.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1791455.7500 - val_loss: 3271077.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1787280.8750 - val_loss: 3270898.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1783291.7500 - val_loss: 3270717.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1779469.5000 - val_loss: 3270537.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1775792.3750 - val_loss: 3270347.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1772249.1250 - val_loss: 3270161.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1768824.2500 - val_loss: 3269971.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1765506.7500 - val_loss: 3269786.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1762287.5000 - val_loss: 3269591.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1759162.0000 - val_loss: 3269396.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1756120.5000 - val_loss: 3269208.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1753153.1250 - val_loss: 3269019.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1750260.0000 - val_loss: 3268825.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1747434.6250 - val_loss: 3268631.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1744673.6250 - val_loss: 3268441.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1741970.1250 - val_loss: 3268248.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1739323.0000 - val_loss: 3268058.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1736728.0000 - val_loss: 3267866.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1734183.5000 - val_loss: 3267685.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1731684.7500 - val_loss: 3267501.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1729229.7500 - val_loss: 3267319.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1726817.5000 - val_loss: 3267130.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1724448.7500 - val_loss: 3266950.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1722116.6250 - val_loss: 3266771.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1719822.5000 - val_loss: 3266587.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1717562.3750 - val_loss: 3266401.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1715338.1250 - val_loss: 3266215.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1713146.1250 - val_loss: 3266032.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1710985.0000 - val_loss: 3265853.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1708853.0000 - val_loss: 3265674.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1706750.7500 - val_loss: 3265494.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1704675.5000 - val_loss: 3265318.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1702626.6250 - val_loss: 3265143.0000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1700603.3750 - val_loss: 3264964.0000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1698605.6250 - val_loss: 3264786.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1696633.0000 - val_loss: 3264615.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1694682.0000 - val_loss: 3264440.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1692754.5000 - val_loss: 3264265.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1690847.8750 - val_loss: 3264099.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1688961.6250 - val_loss: 3263927.5000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 6ms/step - loss: 1873363.2500 - val_loss: 3270333.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1850907.5000 - val_loss: 3270424.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1840133.2500 - val_loss: 3270367.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1831676.6250 - val_loss: 3270248.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1824477.3750 - val_loss: 3270081.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1818105.6250 - val_loss: 3269891.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1812328.6250 - val_loss: 3269665.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1807010.1250 - val_loss: 3269448.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1802057.3750 - val_loss: 3269214.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1797406.6250 - val_loss: 3268972.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1793009.8750 - val_loss: 3268732.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1788832.7500 - val_loss: 3268495.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1784842.3750 - val_loss: 3268264.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1781015.6250 - val_loss: 3268033.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1777336.7500 - val_loss: 3267823.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1773787.1250 - val_loss: 3267607.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1770359.6250 - val_loss: 3267396.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1767040.6250 - val_loss: 3267186.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1763820.1250 - val_loss: 3266983.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1760689.1250 - val_loss: 3266777.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1757644.1250 - val_loss: 3266582.2500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1754674.8750 - val_loss: 3266391.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1751777.6250 - val_loss: 3266211.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1748947.7500 - val_loss: 3266023.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1746183.7500 - val_loss: 3265837.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1743478.2500 - val_loss: 3265655.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1740829.0000 - val_loss: 3265477.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1738231.1250 - val_loss: 3265301.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1735685.3750 - val_loss: 3265126.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1733185.3750 - val_loss: 3264948.2500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1730732.8750 - val_loss: 3264774.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1728321.8750 - val_loss: 3264605.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1725950.8750 - val_loss: 3264434.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1723618.1250 - val_loss: 3264268.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1721323.0000 - val_loss: 3264101.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1719063.3750 - val_loss: 3263936.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1716836.8750 - val_loss: 3263770.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1714642.8750 - val_loss: 3263609.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1712479.3750 - val_loss: 3263455.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1710345.6250 - val_loss: 3263293.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1708240.8750 - val_loss: 3263138.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1706165.8750 - val_loss: 3262978.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1704116.6250 - val_loss: 3262830.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1702092.3750 - val_loss: 3262677.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1700093.2500 - val_loss: 3262519.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1698119.7500 - val_loss: 3262363.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1696169.3750 - val_loss: 3262210.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1694240.5000 - val_loss: 3262057.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1692333.6250 - val_loss: 3261911.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1690448.2500 - val_loss: 3261765.0000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 7ms/step - loss: 1875831.0000 - val_loss: 3270356.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1853470.3750 - val_loss: 3270046.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1842686.1250 - val_loss: 3269717.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1834216.6250 - val_loss: 3269326.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1827008.8750 - val_loss: 3268918.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1820631.0000 - val_loss: 3268513.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1814845.8750 - val_loss: 3268095.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1809525.0000 - val_loss: 3267685.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1804570.6250 - val_loss: 3267273.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1799918.8750 - val_loss: 3266882.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1795520.6250 - val_loss: 3266519.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1791333.3750 - val_loss: 3266160.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1787335.5000 - val_loss: 3265819.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1783507.0000 - val_loss: 3265489.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1779827.0000 - val_loss: 3265171.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1776278.6250 - val_loss: 3264862.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1772848.7500 - val_loss: 3264585.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1769523.6250 - val_loss: 3264316.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1766298.5000 - val_loss: 3264041.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1763167.3750 - val_loss: 3263788.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1760117.8750 - val_loss: 3263526.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1757147.7500 - val_loss: 3263274.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1754251.3750 - val_loss: 3263037.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1751422.0000 - val_loss: 3262809.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1748655.8750 - val_loss: 3262576.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1745949.7500 - val_loss: 3262352.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1743298.5000 - val_loss: 3262135.7500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1740699.2500 - val_loss: 3261930.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1738150.8750 - val_loss: 3261723.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1735649.5000 - val_loss: 3261516.2500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1733192.2500 - val_loss: 3261313.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1730779.0000 - val_loss: 3261114.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1728404.6250 - val_loss: 3260914.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1726070.0000 - val_loss: 3260736.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1723772.1250 - val_loss: 3260553.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1721509.0000 - val_loss: 3260362.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1719280.3750 - val_loss: 3260183.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1717084.0000 - val_loss: 3260010.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1714918.1250 - val_loss: 3259828.2500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1712784.5000 - val_loss: 3259651.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1710679.2500 - val_loss: 3259472.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1708601.8750 - val_loss: 3259306.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1706550.5000 - val_loss: 3259137.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1704524.3750 - val_loss: 3258967.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1702523.1250 - val_loss: 3258806.2500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1700546.2500 - val_loss: 3258639.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1698594.2500 - val_loss: 3258478.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1696664.3750 - val_loss: 3258321.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1694755.0000 - val_loss: 3258165.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1692866.6250 - val_loss: 3258003.0000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 3s 9ms/step - loss: 1873225.0000 - val_loss: 3270481.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1850058.2500 - val_loss: 3270285.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1839139.8750 - val_loss: 3270143.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1830627.0000 - val_loss: 3269994.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1823391.7500 - val_loss: 3269831.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1816998.6250 - val_loss: 3269665.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1811212.8750 - val_loss: 3269508.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1805885.5000 - val_loss: 3269348.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1800925.0000 - val_loss: 3269179.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1796268.3750 - val_loss: 3269009.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1791867.0000 - val_loss: 3268845.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1787682.6250 - val_loss: 3268677.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1783689.3750 - val_loss: 3268507.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1779861.0000 - val_loss: 3268358.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1776178.3750 - val_loss: 3268204.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1772630.5000 - val_loss: 3268051.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1769201.5000 - val_loss: 3267908.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1765879.0000 - val_loss: 3267763.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1762656.6250 - val_loss: 3267621.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1759525.0000 - val_loss: 3267477.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1756480.6250 - val_loss: 3267336.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1753513.6250 - val_loss: 3267201.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1750616.6250 - val_loss: 3267061.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1747788.7500 - val_loss: 3266929.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1745023.7500 - val_loss: 3266796.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1742317.3750 - val_loss: 3266662.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1739665.8750 - val_loss: 3266531.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1737070.1250 - val_loss: 3266401.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1734524.3750 - val_loss: 3266274.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1732024.6250 - val_loss: 3266153.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1729568.6250 - val_loss: 3266036.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1727154.5000 - val_loss: 3265913.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1724783.1250 - val_loss: 3265786.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1722451.6250 - val_loss: 3265663.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1720155.7500 - val_loss: 3265541.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1717895.0000 - val_loss: 3265413.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1715669.7500 - val_loss: 3265291.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1713476.2500 - val_loss: 3265167.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1711314.5000 - val_loss: 3265047.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1709180.5000 - val_loss: 3264928.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1707077.0000 - val_loss: 3264806.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1705000.8750 - val_loss: 3264686.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1702952.2500 - val_loss: 3264566.2500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1700927.5000 - val_loss: 3264447.0000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1698928.5000 - val_loss: 3264333.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1696953.2500 - val_loss: 3264217.7500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1695001.6250 - val_loss: 3264099.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1693072.3750 - val_loss: 3263978.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1691165.2500 - val_loss: 3263865.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1689279.1250 - val_loss: 3263752.2500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 6ms/step - loss: 1869888.8750 - val_loss: 3271696.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1847518.3750 - val_loss: 3271639.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1836822.6250 - val_loss: 3271576.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1828400.8750 - val_loss: 3271465.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1821224.1250 - val_loss: 3271332.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1814873.7500 - val_loss: 3271185.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1809114.6250 - val_loss: 3271029.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1803809.2500 - val_loss: 3270871.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1798869.6250 - val_loss: 3270694.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1794229.3750 - val_loss: 3270538.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1789840.2500 - val_loss: 3270389.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1785667.3750 - val_loss: 3270247.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1781682.6250 - val_loss: 3270104.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1777864.2500 - val_loss: 3269960.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1774192.3750 - val_loss: 3269828.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1770651.7500 - val_loss: 3269685.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1767229.7500 - val_loss: 3269549.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1763917.7500 - val_loss: 3269419.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1760702.8750 - val_loss: 3269295.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1757578.2500 - val_loss: 3269161.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1754539.0000 - val_loss: 3269039.2500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1751576.0000 - val_loss: 3268913.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1748683.3750 - val_loss: 3268796.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1745860.6250 - val_loss: 3268674.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1743100.1250 - val_loss: 3268560.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1740396.7500 - val_loss: 3268441.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1737749.3750 - val_loss: 3268324.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1735157.1250 - val_loss: 3268207.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1732613.3750 - val_loss: 3268085.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1730118.2500 - val_loss: 3267969.2500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1727667.0000 - val_loss: 3267850.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1725258.6250 - val_loss: 3267729.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1722891.3750 - val_loss: 3267612.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1720561.6250 - val_loss: 3267497.7500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1718268.5000 - val_loss: 3267374.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1716010.8750 - val_loss: 3267252.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1713788.0000 - val_loss: 3267132.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1711598.3750 - val_loss: 3267012.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1709439.2500 - val_loss: 3266903.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1707306.0000 - val_loss: 3266787.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1705203.7500 - val_loss: 3266671.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1703130.3750 - val_loss: 3266554.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1701083.7500 - val_loss: 3266434.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1699061.8750 - val_loss: 3266320.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1697064.2500 - val_loss: 3266204.2500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1695091.7500 - val_loss: 3266086.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1693143.8750 - val_loss: 3265970.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1691217.8750 - val_loss: 3265854.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1689312.6250 - val_loss: 3265742.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1687428.6250 - val_loss: 3265629.5000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1880038.7500 - val_loss: 3273065.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1859134.5000 - val_loss: 3273108.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1851064.6250 - val_loss: 3273194.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1844846.3750 - val_loss: 3273261.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1839590.0000 - val_loss: 3273319.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1834954.7500 - val_loss: 3273356.0000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1879463.0000 - val_loss: 3273060.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1859565.8750 - val_loss: 3273087.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1851555.8750 - val_loss: 3273164.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1845369.3750 - val_loss: 3273221.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1840137.5000 - val_loss: 3273277.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1835526.2500 - val_loss: 3273314.0000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1880330.3750 - val_loss: 3273449.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1860062.8750 - val_loss: 3273556.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1852059.8750 - val_loss: 3273654.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1845876.3750 - val_loss: 3273721.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1840650.3750 - val_loss: 3273769.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1836022.6250 - val_loss: 3273803.0000\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1879751.3750 - val_loss: 3271749.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 1859240.8750 - val_loss: 3271959.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1851200.6250 - val_loss: 3272211.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1844999.5000 - val_loss: 3272412.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1839757.0000 - val_loss: 3272572.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1835131.7500 - val_loss: 3272696.2500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1876759.1250 - val_loss: 3272966.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1855985.6250 - val_loss: 3272931.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1847967.2500 - val_loss: 3272993.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1841775.5000 - val_loss: 3273057.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1836543.5000 - val_loss: 3273118.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1831914.7500 - val_loss: 3273165.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1827733.8750 - val_loss: 3273208.2500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 9ms/step - loss: 1879779.6250 - val_loss: 3273529.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1859360.7500 - val_loss: 3273663.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1851344.2500 - val_loss: 3273709.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1845154.6250 - val_loss: 3273733.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 1839916.7500 - val_loss: 3273741.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1835296.8750 - val_loss: 3273728.0000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 9ms/step - loss: 1881374.3750 - val_loss: 3272718.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1860477.3750 - val_loss: 3272875.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1852390.1250 - val_loss: 3273026.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1846171.8750 - val_loss: 3273159.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1840901.3750 - val_loss: 3273270.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1836260.2500 - val_loss: 3273345.2500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1878521.7500 - val_loss: 3273592.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1859158.3750 - val_loss: 3273750.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1851219.2500 - val_loss: 3273907.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1845070.5000 - val_loss: 3274038.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1839853.0000 - val_loss: 3274145.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1835246.7500 - val_loss: 3274237.7500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 9ms/step - loss: 1881666.7500 - val_loss: 3272615.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1861306.0000 - val_loss: 3272634.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1853248.5000 - val_loss: 3272676.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1847037.2500 - val_loss: 3272692.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1841794.1250 - val_loss: 3272688.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1837151.3750 - val_loss: 3272662.2500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 9ms/step - loss: 1879467.7500 - val_loss: 3272439.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1858776.3750 - val_loss: 3272501.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1850700.5000 - val_loss: 3272602.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1844488.1250 - val_loss: 3272683.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1839234.5000 - val_loss: 3272741.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1834609.0000 - val_loss: 3272782.0000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1907848.6250 - val_loss: 3269651.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1906027.6250 - val_loss: 3270037.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1903833.0000 - val_loss: 3270355.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1900798.0000 - val_loss: 3270653.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1896797.5000 - val_loss: 3270932.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1892123.2500 - val_loss: 3271147.5000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 5ms/step - loss: 1907747.2500 - val_loss: 3270342.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1905901.3750 - val_loss: 3270728.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1903567.0000 - val_loss: 3271076.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1900117.1250 - val_loss: 3271425.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1895424.6250 - val_loss: 3271746.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1890208.7500 - val_loss: 3271982.5000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1907191.2500 - val_loss: 3272021.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1904854.8750 - val_loss: 3272748.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1901819.8750 - val_loss: 3273253.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1897514.0000 - val_loss: 3273649.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1892126.5000 - val_loss: 3273937.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1886583.3750 - val_loss: 3274100.2500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1907492.2500 - val_loss: 3270911.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1905571.6250 - val_loss: 3271272.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1903105.8750 - val_loss: 3271513.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1899649.1250 - val_loss: 3271700.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1895290.0000 - val_loss: 3271841.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1890723.3750 - val_loss: 3271930.0000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1907801.6250 - val_loss: 3269438.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1905856.5000 - val_loss: 3270129.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 2ms/step - loss: 1903439.6250 - val_loss: 3270630.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1899933.7500 - val_loss: 3270961.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1895249.5000 - val_loss: 3271134.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1889987.6250 - val_loss: 3271178.5000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1907589.5000 - val_loss: 3269574.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1905764.1250 - val_loss: 3269899.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1903610.5000 - val_loss: 3270055.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1900678.2500 - val_loss: 3270139.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1896754.5000 - val_loss: 3270203.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1891998.3750 - val_loss: 3270245.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1907544.6250 - val_loss: 3270392.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1905556.0000 - val_loss: 3271032.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1903048.0000 - val_loss: 3271616.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1899556.1250 - val_loss: 3272152.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1895095.2500 - val_loss: 3272595.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1890252.3750 - val_loss: 3272887.0000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1906975.2500 - val_loss: 3270524.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1904698.0000 - val_loss: 3270954.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1901784.2500 - val_loss: 3271360.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1897782.5000 - val_loss: 3271714.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1892952.2500 - val_loss: 3271956.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1888125.0000 - val_loss: 3272069.0000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1907679.3750 - val_loss: 3270269.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1905792.1250 - val_loss: 3270952.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1903540.5000 - val_loss: 3271450.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1900534.6250 - val_loss: 3271819.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1896768.8750 - val_loss: 3272076.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1892489.1250 - val_loss: 3272253.0000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1907568.7500 - val_loss: 3270169.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 2ms/step - loss: 1905698.0000 - val_loss: 3270681.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1903327.8750 - val_loss: 3271161.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1899833.3750 - val_loss: 3271668.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1894995.7500 - val_loss: 3272109.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1889546.3750 - val_loss: 3272394.7500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 7ms/step - loss: 1907330.1250 - val_loss: 3272559.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1905667.0000 - val_loss: 3273160.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1903866.1250 - val_loss: 3273592.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1901613.0000 - val_loss: 3273933.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1898790.2500 - val_loss: 3274203.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1895457.3750 - val_loss: 3274414.2500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 7ms/step - loss: 1908123.8750 - val_loss: 3270029.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1906902.5000 - val_loss: 3270440.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1905780.8750 - val_loss: 3270793.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1904509.8750 - val_loss: 3271126.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1902980.8750 - val_loss: 3271454.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1901099.6250 - val_loss: 3271767.2500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 6ms/step - loss: 1907965.7500 - val_loss: 3270298.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1906762.6250 - val_loss: 3270766.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1905437.7500 - val_loss: 3271175.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1903734.3750 - val_loss: 3271577.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1901512.6250 - val_loss: 3271970.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1898771.6250 - val_loss: 3272333.5000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 6ms/step - loss: 1907968.0000 - val_loss: 3270057.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1906767.8750 - val_loss: 3270347.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1905522.2500 - val_loss: 3270607.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1904004.0000 - val_loss: 3270870.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1902102.6250 - val_loss: 3271158.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1899755.0000 - val_loss: 3271469.2500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 7ms/step - loss: 1907766.6250 - val_loss: 3270079.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1906236.3750 - val_loss: 3270542.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1904744.7500 - val_loss: 3270890.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1903025.8750 - val_loss: 3271204.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1900974.2500 - val_loss: 3271522.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1898535.7500 - val_loss: 3271864.0000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 6ms/step - loss: 1908306.8750 - val_loss: 3269787.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1907124.5000 - val_loss: 3270254.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1905981.8750 - val_loss: 3270612.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1904640.1250 - val_loss: 3270916.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1902983.6250 - val_loss: 3271193.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1900947.1250 - val_loss: 3271452.7500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 6ms/step - loss: 1907805.2500 - val_loss: 3269215.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1906413.8750 - val_loss: 3269604.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1905023.7500 - val_loss: 3269923.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1903386.6250 - val_loss: 3270209.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1901418.8750 - val_loss: 3270486.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1899099.8750 - val_loss: 3270758.5000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 6ms/step - loss: 1907833.2500 - val_loss: 3270608.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1906453.1250 - val_loss: 3270996.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1905003.5000 - val_loss: 3271265.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1903230.5000 - val_loss: 3271475.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1901064.2500 - val_loss: 3271650.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1898537.6250 - val_loss: 3271803.0000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 3s 9ms/step - loss: 1908387.8750 - val_loss: 3269627.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1907334.0000 - val_loss: 3270075.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1906330.3750 - val_loss: 3270469.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1905149.8750 - val_loss: 3270828.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1903690.3750 - val_loss: 3271155.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1901871.5000 - val_loss: 3271452.7500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 6ms/step - loss: 1907992.0000 - val_loss: 3269802.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1906821.2500 - val_loss: 3270223.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1905687.3750 - val_loss: 3270555.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1904346.6250 - val_loss: 3270843.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1902708.0000 - val_loss: 3271112.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1900718.3750 - val_loss: 3271358.5000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 12ms/step - loss: 1908277.2500 - val_loss: 3269913.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1907543.2500 - val_loss: 3270276.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1906908.3750 - val_loss: 3270565.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1906242.8750 - val_loss: 3270821.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1905507.2500 - val_loss: 3271048.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1904684.0000 - val_loss: 3271258.7500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1907753.7500 - val_loss: 3271026.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1906789.0000 - val_loss: 3271485.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1905939.6250 - val_loss: 3271866.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1905035.3750 - val_loss: 3272193.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1904018.3750 - val_loss: 3272485.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1902860.0000 - val_loss: 3272751.2500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1908371.0000 - val_loss: 3269579.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1907504.1250 - val_loss: 3269942.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1906750.6250 - val_loss: 3270226.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1905952.5000 - val_loss: 3270469.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1905070.8750 - val_loss: 3270683.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1904072.7500 - val_loss: 3270877.7500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1908127.7500 - val_loss: 3270713.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 1907216.7500 - val_loss: 3271329.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1906413.7500 - val_loss: 3271840.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1905549.0000 - val_loss: 3272301.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1904555.0000 - val_loss: 3272709.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1903413.2500 - val_loss: 3273066.7500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1907902.8750 - val_loss: 3270965.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1906951.2500 - val_loss: 3271364.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1906120.2500 - val_loss: 3271701.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1905237.2500 - val_loss: 3272004.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1904253.1250 - val_loss: 3272277.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1903142.2500 - val_loss: 3272536.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 9ms/step - loss: 1908450.8750 - val_loss: 3270164.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1907603.8750 - val_loss: 3270711.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1906878.7500 - val_loss: 3271153.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1906108.5000 - val_loss: 3271526.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1905245.7500 - val_loss: 3271844.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1904273.0000 - val_loss: 3272131.2500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1908648.0000 - val_loss: 3269563.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1907805.3750 - val_loss: 3269947.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1907088.2500 - val_loss: 3270221.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1906342.7500 - val_loss: 3270424.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1905532.0000 - val_loss: 3270584.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1904623.2500 - val_loss: 3270710.7500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1907874.7500 - val_loss: 3271124.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1906920.0000 - val_loss: 3271455.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1906082.2500 - val_loss: 3271698.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1905192.1250 - val_loss: 3271899.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 1904198.0000 - val_loss: 3272079.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1903071.2500 - val_loss: 3272252.0000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1908326.1250 - val_loss: 3269396.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1907456.6250 - val_loss: 3269914.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1906726.6250 - val_loss: 3270303.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1905971.6250 - val_loss: 3270623.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1905141.1250 - val_loss: 3270891.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1904216.3750 - val_loss: 3271130.7500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1908516.5000 - val_loss: 3268441.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1907800.6250 - val_loss: 3268624.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1907223.7500 - val_loss: 3268755.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1906642.6250 - val_loss: 3268837.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1906023.5000 - val_loss: 3268912.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1905347.5000 - val_loss: 3268972.0000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 5ms/step - loss: 988386.8125 - val_loss: 3191821.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 172384.0312 - val_loss: 3153942.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 52615.0586 - val_loss: 2039027.8750\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 18441.4062 - val_loss: 1465231.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 9212.6836 - val_loss: 1118262.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 4782.3130 - val_loss: 921396.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 3710.7725 - val_loss: 971359.0625\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 2881.0581 - val_loss: 1283150.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1897.2554 - val_loss: 1443887.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1934.0647 - val_loss: 1489141.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1706.6096 - val_loss: 1567069.5000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 5ms/step - loss: 917227.6250 - val_loss: 2877295.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 130640.6406 - val_loss: 2901225.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 46538.0352 - val_loss: 870791.4375\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 17737.9922 - val_loss: 1349161.6250\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 8049.9175 - val_loss: 856038.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 4709.4648 - val_loss: 770577.3125\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 3464.1396 - val_loss: 688258.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 3679.7131 - val_loss: 902575.0625\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 3334.7671 - val_loss: 1338696.1250\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 2463.9204 - val_loss: 1543490.8750\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 2680.2178 - val_loss: 1264976.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1953.1604 - val_loss: 1138682.3750\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 4ms/step - loss: 927869.1875 - val_loss: 2707229.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 137490.4844 - val_loss: 2607266.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 46132.8516 - val_loss: 3093802.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 20873.8848 - val_loss: 2635411.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 7532.6162 - val_loss: 2637546.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 4275.5977 - val_loss: 2678156.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 3108.2727 - val_loss: 2984451.7500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 912277.0625 - val_loss: 2884905.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 130272.9688 - val_loss: 2952211.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 44562.9141 - val_loss: 2846797.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 23542.2871 - val_loss: 2561581.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 9323.6182 - val_loss: 2383098.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 4388.5879 - val_loss: 2088597.1250\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 2742.3269 - val_loss: 2083691.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 2197.2290 - val_loss: 1607038.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 2553.1255 - val_loss: 2074045.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 3588.8975 - val_loss: 1366309.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 2408.1936 - val_loss: 1440442.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 3059.6782 - val_loss: 854686.1875\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 2446.9316 - val_loss: 1144932.6250\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 2212.5178 - val_loss: 1115210.6250\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 2056.8564 - val_loss: 1648881.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1801.0846 - val_loss: 1680471.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1286.1826 - val_loss: 1989421.8750\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 952459.3125 - val_loss: 2784134.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 142592.6719 - val_loss: 2683479.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 47454.5039 - val_loss: 2165802.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 19101.5605 - val_loss: 1867501.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 9420.7998 - val_loss: 1836951.1250\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 7197.4229 - val_loss: 1834578.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 4286.0151 - val_loss: 1880671.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 3504.9680 - val_loss: 1908690.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 2835.4497 - val_loss: 2105060.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 2334.4304 - val_loss: 2108610.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 2058.7395 - val_loss: 2194912.5000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 5ms/step - loss: 952602.0000 - val_loss: 2749870.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 150616.1875 - val_loss: 2760107.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 60803.1094 - val_loss: 2945518.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 22567.8828 - val_loss: 1111666.6250\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 7361.4912 - val_loss: 962169.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 3999.5828 - val_loss: 830040.0625\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 2729.6375 - val_loss: 778628.5625\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 2322.2380 - val_loss: 911199.4375\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1999.9283 - val_loss: 964240.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1857.4202 - val_loss: 1042655.9375\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1445.8304 - val_loss: 965788.1250\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1359.8564 - val_loss: 1028759.4375\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 904753.1250 - val_loss: 3008096.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 125539.0781 - val_loss: 3004747.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 48949.8125 - val_loss: 536502.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 21184.2559 - val_loss: 439573.5938\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 9863.8379 - val_loss: 510597.5625\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 6212.4717 - val_loss: 1141608.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 4356.7563 - val_loss: 1263244.6250\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 2873.8308 - val_loss: 1149841.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 2315.4146 - val_loss: 1281443.5000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 5ms/step - loss: 957756.1250 - val_loss: 3014321.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 152657.7969 - val_loss: 3014979.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 47811.3828 - val_loss: 1518361.8750\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 20365.0137 - val_loss: 2809268.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 11611.3086 - val_loss: 2448827.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 6252.2119 - val_loss: 2045656.3750\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 5486.8511 - val_loss: 1872609.1250\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 4112.8398 - val_loss: 1942215.6250\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 927764.0625 - val_loss: 2745051.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 134632.5625 - val_loss: 2704632.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 44210.5742 - val_loss: 2864357.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 19904.7871 - val_loss: 3147766.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 9918.9561 - val_loss: 3064511.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 7988.1489 - val_loss: 2451876.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 6857.0469 - val_loss: 2539751.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 4114.6069 - val_loss: 2552013.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 3026.4702 - val_loss: 2502214.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 2617.4363 - val_loss: 2450262.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1969.2086 - val_loss: 2242531.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1782.8080 - val_loss: 2075127.3750\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1587.0984 - val_loss: 2088947.6250\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1613.4067 - val_loss: 2547168.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1607.0281 - val_loss: 2153432.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1886.2681 - val_loss: 2246467.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1709.1072 - val_loss: 2455974.7500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 4ms/step - loss: 916072.0625 - val_loss: 1894572.1250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 126451.9453 - val_loss: 1584219.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 44439.9844 - val_loss: 1394422.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 36306.1992 - val_loss: 1580649.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 12841.1123 - val_loss: 2063795.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 6661.6772 - val_loss: 1882122.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 5292.5366 - val_loss: 2366567.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 4250.5391 - val_loss: 2416126.5000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 6ms/step - loss: 1336493.3750 - val_loss: 3096517.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 551048.5625 - val_loss: 3101844.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 206090.5469 - val_loss: 3199078.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 83550.9922 - val_loss: 3254567.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 50066.7891 - val_loss: 3351513.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 47044.0586 - val_loss: 712538.4375\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 34981.6680 - val_loss: 1410070.6250\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 13506.4893 - val_loss: 1402975.1250\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 10038.1416 - val_loss: 1282824.6250\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 8545.3604 - val_loss: 1469384.8750\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 5414.4980 - val_loss: 1693499.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 7ms/step - loss: 1381530.5000 - val_loss: 2430050.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 589832.5625 - val_loss: 1966459.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 229798.7031 - val_loss: 1794415.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 93942.0859 - val_loss: 1699085.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 50447.1094 - val_loss: 2002789.8750\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 37621.6367 - val_loss: 2370996.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 19915.0566 - val_loss: 2482578.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 12491.9199 - val_loss: 2629385.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 8277.6895 - val_loss: 2583773.5000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 6ms/step - loss: 1335772.5000 - val_loss: 2059495.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 549868.1875 - val_loss: 1595165.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 206709.3594 - val_loss: 2108792.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 83820.1250 - val_loss: 2413503.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 49521.0508 - val_loss: 2514254.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 46165.9648 - val_loss: 3053104.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 35685.4844 - val_loss: 2559075.0000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 7ms/step - loss: 1324178.3750 - val_loss: 1892049.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 501801.6875 - val_loss: 1267372.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 166626.0938 - val_loss: 1010317.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 66964.0078 - val_loss: 1002054.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 45198.9570 - val_loss: 1152481.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 39966.3125 - val_loss: 1336814.1250\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 20094.1406 - val_loss: 1952681.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 11747.1689 - val_loss: 2212812.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 7747.5986 - val_loss: 2192975.2500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 7ms/step - loss: 1321912.6250 - val_loss: 2966544.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 513157.4062 - val_loss: 3046717.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 179687.0938 - val_loss: 3144423.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 72872.8516 - val_loss: 3169060.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 51979.4883 - val_loss: 2399061.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 47324.6133 - val_loss: 2042827.1250\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 18126.0371 - val_loss: 1947710.3750\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 11783.0801 - val_loss: 1891386.1250\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 8444.4590 - val_loss: 1703830.6250\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 6447.3882 - val_loss: 1701044.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 5341.4912 - val_loss: 1689912.6250\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4481.8345 - val_loss: 1767051.1250\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 3693.3115 - val_loss: 1626441.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 3145.2957 - val_loss: 1498798.8750\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 3285.4551 - val_loss: 1453534.6250\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 2651.7090 - val_loss: 1402710.6250\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 2227.9949 - val_loss: 1347779.3750\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1958.2196 - val_loss: 1309017.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1843.6278 - val_loss: 1364375.3750\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1700.4669 - val_loss: 1550904.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1514.7698 - val_loss: 1501749.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1289.2911 - val_loss: 1446999.6250\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1215.9945 - val_loss: 1470963.8750\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 7ms/step - loss: 1328349.3750 - val_loss: 3317434.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 526181.4375 - val_loss: 3340012.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 188223.3906 - val_loss: 3371111.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 75470.3359 - val_loss: 3406628.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 54574.2539 - val_loss: 2156501.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 46418.6875 - val_loss: 584076.6875\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 23671.3281 - val_loss: 644549.4375\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 14805.9775 - val_loss: 683589.8750\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 11280.6660 - val_loss: 1614824.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 8409.7373 - val_loss: 1323873.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 10951.0254 - val_loss: 1287208.1250\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 7ms/step - loss: 1328507.5000 - val_loss: 3069807.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 540217.1875 - val_loss: 3237471.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 199564.5625 - val_loss: 3344501.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 81288.1641 - val_loss: 3399255.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 48818.5273 - val_loss: 3377987.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 44429.3359 - val_loss: 1061850.8750\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 17535.3457 - val_loss: 992307.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 11058.9033 - val_loss: 876874.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 7669.2749 - val_loss: 1413070.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 5717.6353 - val_loss: 1388200.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4275.8584 - val_loss: 1349124.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 3152.2539 - val_loss: 1170557.8750\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 2603.7625 - val_loss: 1124129.5000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 7ms/step - loss: 1343465.6250 - val_loss: 3085362.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 552784.5000 - val_loss: 3041409.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 207266.0156 - val_loss: 3036150.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 83739.3359 - val_loss: 3060947.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 49615.6406 - val_loss: 3110109.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 45647.8789 - val_loss: 801126.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 15228.5059 - val_loss: 940808.4375\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 8976.2324 - val_loss: 737693.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 6438.9468 - val_loss: 680331.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 4818.4302 - val_loss: 597295.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 4465.4526 - val_loss: 564881.6875\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 3702.7979 - val_loss: 568635.4375\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 3146.9014 - val_loss: 537697.3750\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 2725.4922 - val_loss: 524521.1250\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 2220.9565 - val_loss: 548699.3750\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 2171.6096 - val_loss: 469049.3438\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1901.5020 - val_loss: 509707.9375\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1858.2300 - val_loss: 465652.3125\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1587.3684 - val_loss: 464140.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1561.2242 - val_loss: 420454.3125\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1625.5807 - val_loss: 428419.4375\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1263.0989 - val_loss: 471341.7812\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1138.8914 - val_loss: 468833.3750\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1396.2081 - val_loss: 362227.5938\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1830.1562 - val_loss: 422401.1875\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1466.5789 - val_loss: 403657.5312\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1235.9200 - val_loss: 474935.7812\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1240.7563 - val_loss: 518956.5312\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1268.5500 - val_loss: 583803.3125\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 7ms/step - loss: 1349290.1250 - val_loss: 2969382.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 560267.0000 - val_loss: 2885618.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 199962.9688 - val_loss: 2920657.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 78995.2188 - val_loss: 2926918.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 48080.8320 - val_loss: 3022408.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 38234.8906 - val_loss: 847932.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 17660.2559 - val_loss: 2189551.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 11048.7891 - val_loss: 2504331.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 8332.9932 - val_loss: 2243542.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 6031.6162 - val_loss: 2229649.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 5886.6655 - val_loss: 1975310.2500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 7ms/step - loss: 1366348.3750 - val_loss: 3130399.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 602313.2500 - val_loss: 3097769.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 242712.1406 - val_loss: 3055392.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 100558.2031 - val_loss: 3043680.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 54825.4922 - val_loss: 3077617.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 42820.9102 - val_loss: 1128695.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 22396.5996 - val_loss: 1315697.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 13472.5469 - val_loss: 2436875.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 9099.4980 - val_loss: 2545781.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 6583.5063 - val_loss: 2763188.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4676.4053 - val_loss: 2758481.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1623506.1250 - val_loss: 3209285.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1093999.8750 - val_loss: 3288515.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 710719.0000 - val_loss: 3283725.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 447845.3438 - val_loss: 3295434.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 277025.2188 - val_loss: 3302066.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 170545.7031 - val_loss: 3311227.5000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 13ms/step - loss: 1602881.6250 - val_loss: 3263908.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1043433.1875 - val_loss: 3258945.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 650228.3750 - val_loss: 3275687.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 392252.5938 - val_loss: 3282569.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 232555.5781 - val_loss: 3292971.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 138909.9219 - val_loss: 3305514.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 87636.9062 - val_loss: 3317422.7500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1610905.2500 - val_loss: 3300151.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1070168.5000 - val_loss: 3292728.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 683215.0625 - val_loss: 3289545.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 422780.2812 - val_loss: 3287225.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 256003.2656 - val_loss: 3290559.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 155486.8750 - val_loss: 3294834.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 98510.6484 - val_loss: 3299112.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 67947.6094 - val_loss: 3303542.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 52685.5469 - val_loss: 3306414.2500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1591053.1250 - val_loss: 3174324.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1020865.2500 - val_loss: 3123064.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 627041.8750 - val_loss: 3053371.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 372353.5312 - val_loss: 2994535.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 217237.8438 - val_loss: 2958244.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 128533.3672 - val_loss: 2947046.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 81594.4688 - val_loss: 2936086.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 58431.8086 - val_loss: 2947303.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 47820.7812 - val_loss: 2984731.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 43423.9961 - val_loss: 2999215.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 47467.6523 - val_loss: 966065.6250\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 26598.4980 - val_loss: 970746.3125\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 20161.5664 - val_loss: 856273.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 15496.1211 - val_loss: 809288.1250\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 12283.3672 - val_loss: 794173.8750\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 10032.0859 - val_loss: 802341.3750\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 8616.0371 - val_loss: 738321.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7438.9951 - val_loss: 735167.8750\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6218.7803 - val_loss: 766370.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 5431.1758 - val_loss: 731458.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 4793.1709 - val_loss: 808365.5625\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 4212.3281 - val_loss: 806310.8750\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 3911.6768 - val_loss: 879501.8750\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 3575.7996 - val_loss: 938424.9375\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 3574.6050 - val_loss: 881868.3750\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1633840.5000 - val_loss: 3255692.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1123211.3750 - val_loss: 3283818.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 747800.5000 - val_loss: 3284795.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 484902.8125 - val_loss: 3294683.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 307395.1875 - val_loss: 3308913.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 193701.2656 - val_loss: 3320487.2500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1619459.6250 - val_loss: 3277522.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1096045.7500 - val_loss: 3237086.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 714768.0000 - val_loss: 3212107.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 452718.5000 - val_loss: 3197253.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 281042.0312 - val_loss: 3189992.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 173489.7656 - val_loss: 3185685.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 110197.4922 - val_loss: 3184029.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 75179.8594 - val_loss: 3183871.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 56914.8242 - val_loss: 3184716.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 47887.6133 - val_loss: 3206879.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 46010.4688 - val_loss: 1794922.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 23825.5703 - val_loss: 1622322.3750\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 17187.4082 - val_loss: 1343816.3750\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 13123.6582 - val_loss: 1289849.8750\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 10083.2754 - val_loss: 1234334.1250\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8762.9990 - val_loss: 1016580.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6386.4116 - val_loss: 976422.4375\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5248.0947 - val_loss: 1032848.3125\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 4144.6948 - val_loss: 975634.8125\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 3605.7468 - val_loss: 899796.5000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 3043.1746 - val_loss: 750798.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 2478.0747 - val_loss: 726555.6875\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 2196.6482 - val_loss: 759583.1875\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1788.5068 - val_loss: 744614.1250\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1717.5612 - val_loss: 774305.6875\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1620.5114 - val_loss: 744015.9375\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1486.4373 - val_loss: 767798.6875\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1614734.2500 - val_loss: 3034770.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1078948.0000 - val_loss: 3111228.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 694637.2500 - val_loss: 3110435.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 434175.0938 - val_loss: 3067045.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 265812.4688 - val_loss: 3059989.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 162541.3438 - val_loss: 3049144.7500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1612898.7500 - val_loss: 3247989.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1081460.0000 - val_loss: 3256179.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 698266.8750 - val_loss: 3248522.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 438081.4062 - val_loss: 3243067.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 261508.4844 - val_loss: 3242562.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 153834.1406 - val_loss: 3245907.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 95726.3750 - val_loss: 3248640.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 65815.1484 - val_loss: 3249182.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 51522.0859 - val_loss: 3248853.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 123486.6016 - val_loss: 1551458.1250\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 25047.5859 - val_loss: 1404015.1250\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 17199.5371 - val_loss: 1175774.0000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 12630.5107 - val_loss: 1434396.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9601.0088 - val_loss: 1419601.7500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7464.5029 - val_loss: 1430805.8750\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5852.3359 - val_loss: 1471039.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5102.7891 - val_loss: 1456261.2500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1618929.2500 - val_loss: 3254180.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1092716.8750 - val_loss: 3256348.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 711763.5000 - val_loss: 3261649.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 450677.2812 - val_loss: 3258318.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 279339.4375 - val_loss: 3261477.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 172566.8281 - val_loss: 3269857.7500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 9ms/step - loss: 1598182.0000 - val_loss: 3263136.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1039773.9375 - val_loss: 3255817.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 646971.6250 - val_loss: 3227894.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 389994.4375 - val_loss: 3217933.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 230887.2188 - val_loss: 3214310.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 137817.7344 - val_loss: 3213748.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 87178.4375 - val_loss: 3217519.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 61403.7695 - val_loss: 3220846.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 49317.4648 - val_loss: 3223964.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 45586.0938 - val_loss: 1596585.6250\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 29775.0098 - val_loss: 1459728.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 22300.0508 - val_loss: 1444582.8750\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 17121.8848 - val_loss: 1405646.2500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 13247.4961 - val_loss: 1360819.7500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 10548.1953 - val_loss: 1368951.3750\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8755.4219 - val_loss: 1486753.6250\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7081.8335 - val_loss: 1384707.8750\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5926.4336 - val_loss: 1350986.6250\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5139.5591 - val_loss: 1312600.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 4338.9551 - val_loss: 1282673.5000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 4229.5308 - val_loss: 1301904.7500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 4173.3281 - val_loss: 1483233.2500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 3114.0371 - val_loss: 1539001.3750\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 2825.7456 - val_loss: 1506308.6250\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 2528.1965 - val_loss: 1567948.0000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1737147.5000 - val_loss: 3258117.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1470218.0000 - val_loss: 3240714.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1241570.2500 - val_loss: 3229673.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1041698.3125 - val_loss: 3224626.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 867843.3750 - val_loss: 3214175.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 717466.5625 - val_loss: 3200432.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 588036.6875 - val_loss: 3188392.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 477696.6875 - val_loss: 3178310.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 384608.7500 - val_loss: 3170301.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 306955.0312 - val_loss: 3164160.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 242984.1406 - val_loss: 3159491.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 191137.2031 - val_loss: 3156121.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 149937.0781 - val_loss: 3153928.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 117916.7969 - val_loss: 3152729.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 93606.1406 - val_loss: 3152876.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 75714.4609 - val_loss: 3163259.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 63047.6680 - val_loss: 3166743.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 54394.1680 - val_loss: 3183565.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 48729.7227 - val_loss: 3196566.2500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 5ms/step - loss: 1743441.5000 - val_loss: 3259870.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1476488.1250 - val_loss: 3233138.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1247227.3750 - val_loss: 3209216.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1047117.5625 - val_loss: 3198272.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 872795.6875 - val_loss: 3181570.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 721706.3125 - val_loss: 3166498.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 591847.5000 - val_loss: 3154502.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 480989.7188 - val_loss: 3142220.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 387359.7812 - val_loss: 3134592.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 309144.3750 - val_loss: 3127034.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 244801.6250 - val_loss: 3121818.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 192660.1875 - val_loss: 3117812.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 151215.7344 - val_loss: 3115091.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 118999.2812 - val_loss: 3118759.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 94523.0156 - val_loss: 3121012.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 76432.4297 - val_loss: 3129299.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 63561.1328 - val_loss: 3150915.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 54709.6211 - val_loss: 3183127.0000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 5ms/step - loss: 1745511.5000 - val_loss: 3246500.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1475597.3750 - val_loss: 3220784.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1246205.1250 - val_loss: 3208079.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1046062.3125 - val_loss: 3197363.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 871858.0000 - val_loss: 3177342.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 720998.3750 - val_loss: 3164556.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 591111.8750 - val_loss: 3149474.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 480233.9375 - val_loss: 3141222.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 386680.0312 - val_loss: 3138062.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 308666.3125 - val_loss: 3128485.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 244458.8594 - val_loss: 3119785.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 192444.9062 - val_loss: 3116062.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 151080.8594 - val_loss: 3116263.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 118823.7422 - val_loss: 3124100.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 94346.3359 - val_loss: 3127921.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 76319.3281 - val_loss: 3135422.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 63439.1641 - val_loss: 3144483.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 5ms/step - loss: 1743705.3750 - val_loss: 3244590.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1474832.3750 - val_loss: 3233821.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1245489.1250 - val_loss: 3221137.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1045475.6250 - val_loss: 3203475.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 871370.0000 - val_loss: 3195643.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 720461.5625 - val_loss: 3184513.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 590663.1875 - val_loss: 3172028.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 480053.3125 - val_loss: 3161588.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 386683.7812 - val_loss: 3153518.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 308662.2812 - val_loss: 3147984.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 244401.7656 - val_loss: 3148082.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 192292.7344 - val_loss: 3146677.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 150880.5938 - val_loss: 3143548.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 118657.2891 - val_loss: 3142226.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 94195.4844 - val_loss: 3149274.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 76246.7188 - val_loss: 3158414.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 63443.2930 - val_loss: 3169066.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 54605.4609 - val_loss: 3192953.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 48783.5352 - val_loss: 3230821.7500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 6ms/step - loss: 1740433.1250 - val_loss: 3258173.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1471920.3750 - val_loss: 3230894.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1243122.2500 - val_loss: 3208721.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1043535.9375 - val_loss: 3193706.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 869751.5625 - val_loss: 3175869.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 719134.3750 - val_loss: 3158676.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 589445.8125 - val_loss: 3143137.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 478756.4688 - val_loss: 3128291.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 385415.5938 - val_loss: 3116093.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 307571.9375 - val_loss: 3107311.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 243524.9375 - val_loss: 3092219.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 191600.1719 - val_loss: 3092250.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 150362.7500 - val_loss: 3090706.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 118250.7188 - val_loss: 3089250.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 93886.1797 - val_loss: 3093249.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 75981.1016 - val_loss: 3126499.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 63208.6172 - val_loss: 3164922.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 54479.8086 - val_loss: 3183886.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 48749.3164 - val_loss: 3205133.7500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 5ms/step - loss: 1739831.8750 - val_loss: 3175432.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1471322.0000 - val_loss: 3125367.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1242801.6250 - val_loss: 3102146.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1043255.5000 - val_loss: 3091013.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 869479.0625 - val_loss: 3075006.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 718916.5625 - val_loss: 3043741.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 589386.8750 - val_loss: 3015514.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 478901.1562 - val_loss: 2994793.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 385548.9062 - val_loss: 2969010.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 307598.6562 - val_loss: 2953578.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 243434.8125 - val_loss: 2943046.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 191517.6250 - val_loss: 2935263.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 150288.3125 - val_loss: 2937501.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 118190.7656 - val_loss: 2936819.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 93898.0703 - val_loss: 2936840.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 75976.7188 - val_loss: 2945989.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 63232.4883 - val_loss: 2956362.7500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 5ms/step - loss: 1746495.5000 - val_loss: 3241989.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1478299.5000 - val_loss: 3215359.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1248795.2500 - val_loss: 3211958.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1048409.4375 - val_loss: 3199431.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 873838.6250 - val_loss: 3188318.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 722597.7500 - val_loss: 3175704.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 592482.6250 - val_loss: 3162464.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 481553.1562 - val_loss: 3149706.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 387815.5312 - val_loss: 3135226.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 309564.1875 - val_loss: 3128136.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 245161.0781 - val_loss: 3127488.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 192903.6875 - val_loss: 3122899.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 151429.5312 - val_loss: 3119948.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 119091.6172 - val_loss: 3125707.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 94530.1875 - val_loss: 3143840.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 76446.2578 - val_loss: 3142336.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 63570.9141 - val_loss: 3152280.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 54731.0156 - val_loss: 3165117.5000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 6ms/step - loss: 1746218.0000 - val_loss: 3259419.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1477846.6250 - val_loss: 3245709.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1248271.7500 - val_loss: 3233824.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1047943.7500 - val_loss: 3217669.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 873479.8750 - val_loss: 3205377.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 722352.2500 - val_loss: 3188824.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 592262.1250 - val_loss: 3172453.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 481379.0938 - val_loss: 3160532.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 387716.1875 - val_loss: 3152311.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 309481.6562 - val_loss: 3150397.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 245091.6250 - val_loss: 3145407.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 192887.0625 - val_loss: 3141564.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 151413.0156 - val_loss: 3139127.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 119111.3984 - val_loss: 3145251.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 94545.5469 - val_loss: 3144139.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 76453.3047 - val_loss: 3152629.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 63526.6406 - val_loss: 3153591.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 54673.6875 - val_loss: 3171063.0000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 5ms/step - loss: 1740509.5000 - val_loss: 3255174.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1472526.8750 - val_loss: 3241086.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1243385.1250 - val_loss: 3231356.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1043524.0625 - val_loss: 3219817.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 869635.6875 - val_loss: 3212199.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 718999.5000 - val_loss: 3207102.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 589446.1250 - val_loss: 3192109.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 478874.0312 - val_loss: 3196614.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 385435.2500 - val_loss: 3196755.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 307434.2812 - val_loss: 3193320.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 243336.9219 - val_loss: 3191208.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 191431.8438 - val_loss: 3190207.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 150199.3750 - val_loss: 3190007.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 118169.9141 - val_loss: 3197124.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 93846.0938 - val_loss: 3200700.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 75864.9844 - val_loss: 3202829.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 63098.8867 - val_loss: 3216699.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 54409.5391 - val_loss: 3234506.0000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1744645.8750 - val_loss: 3244499.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1476776.1250 - val_loss: 3229616.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1247524.2500 - val_loss: 3212700.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1047662.2500 - val_loss: 3198983.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 873543.0625 - val_loss: 3180601.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 722518.5000 - val_loss: 3167428.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 592492.5000 - val_loss: 3166601.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 481658.5938 - val_loss: 3158670.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 388001.8438 - val_loss: 3150426.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 309771.4688 - val_loss: 3143829.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 245348.7812 - val_loss: 3138618.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 193097.1250 - val_loss: 3142368.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 151598.6094 - val_loss: 3140224.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 119267.5781 - val_loss: 3138595.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 94681.8359 - val_loss: 3137816.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 76586.6250 - val_loss: 3138075.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 63674.1445 - val_loss: 3139956.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 54809.4297 - val_loss: 3144668.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 48979.7812 - val_loss: 3146244.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 45150.7852 - val_loss: 3171986.2500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 8ms/step - loss: 1815149.8750 - val_loss: 3258097.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1665677.8750 - val_loss: 3245415.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1533371.3750 - val_loss: 3229624.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1410401.6250 - val_loss: 3214294.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1295508.3750 - val_loss: 3205971.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1188135.3750 - val_loss: 3199632.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1087872.5000 - val_loss: 3196289.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 994379.4375 - val_loss: 3195256.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 907080.2500 - val_loss: 3194951.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 825778.0625 - val_loss: 3194179.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 750290.8125 - val_loss: 3192219.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 680234.5625 - val_loss: 3186071.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 615364.6875 - val_loss: 3179897.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 555465.6875 - val_loss: 3174303.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 500249.5938 - val_loss: 3169213.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 449450.9062 - val_loss: 3164123.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 402902.8438 - val_loss: 3160430.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 360305.8438 - val_loss: 3157633.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 321491.0938 - val_loss: 3157934.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 286194.3438 - val_loss: 3155760.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 254245.6250 - val_loss: 3153409.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 225513.6250 - val_loss: 3151248.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 199837.3281 - val_loss: 3149357.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 176923.7500 - val_loss: 3147958.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 156538.4531 - val_loss: 3146758.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 138498.7500 - val_loss: 3145947.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 122693.3594 - val_loss: 3145733.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 108935.5234 - val_loss: 3153521.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 97004.0000 - val_loss: 3160318.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 86768.8594 - val_loss: 3161563.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 78039.8594 - val_loss: 3171016.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 70652.1172 - val_loss: 3171783.7500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 7ms/step - loss: 1815943.6250 - val_loss: 3271912.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1668019.0000 - val_loss: 3267986.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1535977.0000 - val_loss: 3258138.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1413236.2500 - val_loss: 3251059.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1298565.3750 - val_loss: 3244379.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1191249.1250 - val_loss: 3237541.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1091000.0000 - val_loss: 3230362.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 997317.8750 - val_loss: 3224822.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 909985.6250 - val_loss: 3221331.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 828697.7500 - val_loss: 3213633.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 753093.3750 - val_loss: 3204109.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 682919.5000 - val_loss: 3200688.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 617845.7500 - val_loss: 3194283.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 557825.6250 - val_loss: 3188945.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 502437.2500 - val_loss: 3184265.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 451478.5000 - val_loss: 3180087.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 404746.5938 - val_loss: 3176393.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 362032.6562 - val_loss: 3173205.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 323081.3438 - val_loss: 3170480.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 287700.1250 - val_loss: 3168129.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 255701.8594 - val_loss: 3166223.2500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 226896.5000 - val_loss: 3164746.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 201053.4688 - val_loss: 3163424.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 177966.2188 - val_loss: 3162600.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 157457.2500 - val_loss: 3162228.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 139345.0469 - val_loss: 3163303.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 123418.1562 - val_loss: 3170489.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 109539.0625 - val_loss: 3178942.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 97516.6953 - val_loss: 3179585.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 87160.3828 - val_loss: 3189935.5000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 7ms/step - loss: 1814475.1250 - val_loss: 3263160.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1666650.0000 - val_loss: 3261836.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1534542.2500 - val_loss: 3257619.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1411617.3750 - val_loss: 3251829.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1296810.1250 - val_loss: 3249684.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1189567.3750 - val_loss: 3248015.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1089328.1250 - val_loss: 3246875.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 995801.3125 - val_loss: 3243636.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 908563.4375 - val_loss: 3243160.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 827351.2500 - val_loss: 3245941.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 751808.0000 - val_loss: 3244909.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 681775.0625 - val_loss: 3241015.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 616851.5000 - val_loss: 3237999.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 556814.6875 - val_loss: 3234827.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 501462.5000 - val_loss: 3232333.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 450562.4062 - val_loss: 3223537.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 403828.9062 - val_loss: 3220583.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 361148.0938 - val_loss: 3217555.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 322269.6250 - val_loss: 3215990.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 286975.0938 - val_loss: 3214076.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 255077.3281 - val_loss: 3212186.2500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 226344.8750 - val_loss: 3211334.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 200508.4062 - val_loss: 3210712.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 177475.5469 - val_loss: 3210540.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 157023.1719 - val_loss: 3210840.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 138956.4219 - val_loss: 3219862.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 123087.2891 - val_loss: 3227982.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 109286.4219 - val_loss: 3227724.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 97338.6875 - val_loss: 3228612.0000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 3s 7ms/step - loss: 1813291.5000 - val_loss: 3265045.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1663728.2500 - val_loss: 3263025.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1531426.5000 - val_loss: 3254744.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1408605.5000 - val_loss: 3244078.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1293944.6250 - val_loss: 3234553.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1186779.3750 - val_loss: 3225150.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1086666.6250 - val_loss: 3217075.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 993251.6875 - val_loss: 3213084.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 906099.6875 - val_loss: 3204308.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 824980.0000 - val_loss: 3195978.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 749529.2500 - val_loss: 3184773.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 679521.6250 - val_loss: 3176298.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 614677.5625 - val_loss: 3170102.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 554783.5625 - val_loss: 3163332.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 499560.4688 - val_loss: 3157306.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 448837.1250 - val_loss: 3152337.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 402261.0000 - val_loss: 3146736.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 359634.4375 - val_loss: 3144013.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 320804.2188 - val_loss: 3139015.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 285614.3125 - val_loss: 3136662.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 253759.1562 - val_loss: 3135015.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 225108.0938 - val_loss: 3131895.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 199443.3906 - val_loss: 3131629.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 176541.7812 - val_loss: 3131627.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 156172.5156 - val_loss: 3130396.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 138172.7812 - val_loss: 3129919.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 122430.0312 - val_loss: 3129085.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 108657.8594 - val_loss: 3128444.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 96724.3672 - val_loss: 3129356.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 86477.6094 - val_loss: 3143867.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 77794.8906 - val_loss: 3149375.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 70485.5859 - val_loss: 3156110.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 64346.7148 - val_loss: 3166183.7500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 3s 9ms/step - loss: 1818383.8750 - val_loss: 3268918.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1668643.3750 - val_loss: 3266700.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1536028.6250 - val_loss: 3258972.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1412877.8750 - val_loss: 3252740.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1298002.2500 - val_loss: 3246985.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1190613.3750 - val_loss: 3238680.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1090281.7500 - val_loss: 3234595.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 996567.8750 - val_loss: 3230500.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 909173.1875 - val_loss: 3224913.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 827713.6875 - val_loss: 3218374.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 752069.3750 - val_loss: 3212768.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 681933.6875 - val_loss: 3207498.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 616972.1875 - val_loss: 3198032.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 556949.7500 - val_loss: 3191983.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 501593.8125 - val_loss: 3185562.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 450715.5625 - val_loss: 3181329.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 403987.1875 - val_loss: 3177558.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 361270.8438 - val_loss: 3173806.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 322349.6562 - val_loss: 3170497.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 287024.0625 - val_loss: 3167665.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 255065.7031 - val_loss: 3164876.2500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 226286.2969 - val_loss: 3162633.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 200455.3438 - val_loss: 3160113.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 177428.3281 - val_loss: 3158235.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 156967.3438 - val_loss: 3156945.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 138888.2500 - val_loss: 3163236.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 123050.0469 - val_loss: 3164277.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 109254.7188 - val_loss: 3162545.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 97299.2266 - val_loss: 3161786.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 86997.0312 - val_loss: 3161236.0000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 6ms/step - loss: 1813159.2500 - val_loss: 3267386.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1663682.2500 - val_loss: 3263379.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1531215.1250 - val_loss: 3255380.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1408290.7500 - val_loss: 3248117.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1293568.7500 - val_loss: 3240824.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1186396.7500 - val_loss: 3237474.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1086334.7500 - val_loss: 3231278.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 992934.3750 - val_loss: 3226905.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 905852.1250 - val_loss: 3221467.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 824754.8125 - val_loss: 3217509.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 749280.7500 - val_loss: 3211260.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 679308.5625 - val_loss: 3205269.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 614554.6250 - val_loss: 3199685.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 554730.1250 - val_loss: 3194730.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 499503.4375 - val_loss: 3190376.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 448699.8750 - val_loss: 3186756.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 402143.5312 - val_loss: 3184404.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 359614.8125 - val_loss: 3185230.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 320800.9062 - val_loss: 3183224.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 285654.2812 - val_loss: 3181401.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 253864.8750 - val_loss: 3179425.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 225209.8594 - val_loss: 3178000.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 199551.7969 - val_loss: 3176928.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 176603.3125 - val_loss: 3176234.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 156215.4219 - val_loss: 3176218.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 138270.4844 - val_loss: 3182464.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 122495.9922 - val_loss: 3184203.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 108712.7734 - val_loss: 3192106.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 96819.6328 - val_loss: 3193585.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 86598.0469 - val_loss: 3203353.5000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 6ms/step - loss: 1815069.5000 - val_loss: 3270099.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1664952.7500 - val_loss: 3273618.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1532275.5000 - val_loss: 3274211.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1409211.1250 - val_loss: 3272653.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1294427.0000 - val_loss: 3270020.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1187167.5000 - val_loss: 3265931.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1086958.7500 - val_loss: 3261816.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 993344.3750 - val_loss: 3259383.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 906172.0000 - val_loss: 3255636.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 825003.3125 - val_loss: 3249624.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 749586.7500 - val_loss: 3248949.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 679584.1250 - val_loss: 3241243.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 614792.8750 - val_loss: 3237822.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 554886.5000 - val_loss: 3234439.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 499691.0000 - val_loss: 3232062.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 448891.5625 - val_loss: 3229807.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 402344.1250 - val_loss: 3228124.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 359763.9375 - val_loss: 3226571.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 320927.9688 - val_loss: 3225402.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 285714.1875 - val_loss: 3224836.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 253864.7969 - val_loss: 3224065.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 225206.5312 - val_loss: 3223847.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 199474.2344 - val_loss: 3224455.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 176526.1250 - val_loss: 3231867.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 156150.6719 - val_loss: 3233693.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 138208.7344 - val_loss: 3234307.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 122425.6719 - val_loss: 3235321.2500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 3s 6ms/step - loss: 1818484.2500 - val_loss: 3267046.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1669460.5000 - val_loss: 3265324.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1536826.7500 - val_loss: 3260673.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1413644.2500 - val_loss: 3256089.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1298688.1250 - val_loss: 3256053.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1191301.8750 - val_loss: 3253923.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1090876.0000 - val_loss: 3248140.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 997290.1250 - val_loss: 3242260.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 909934.3750 - val_loss: 3240506.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 828673.1250 - val_loss: 3233320.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 753116.5625 - val_loss: 3224393.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 682903.1250 - val_loss: 3227735.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 617862.1250 - val_loss: 3224809.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 557795.4375 - val_loss: 3217034.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 502383.2500 - val_loss: 3211672.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 451398.1250 - val_loss: 3207298.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 404606.4688 - val_loss: 3204409.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 361831.0000 - val_loss: 3201000.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 322901.4375 - val_loss: 3198170.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 287491.1250 - val_loss: 3195946.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 255490.1094 - val_loss: 3194636.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 226692.1719 - val_loss: 3192855.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 200868.1562 - val_loss: 3191298.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 177771.6250 - val_loss: 3192149.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 157265.3750 - val_loss: 3199103.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 139201.1719 - val_loss: 3197997.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 123305.7578 - val_loss: 3197205.7500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 109434.3516 - val_loss: 3197292.0000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 9ms/step - loss: 1813333.7500 - val_loss: 3268528.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1665158.6250 - val_loss: 3266082.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1533037.8750 - val_loss: 3261834.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1410152.2500 - val_loss: 3256830.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1295562.0000 - val_loss: 3251146.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1188379.6250 - val_loss: 3246611.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1088150.5000 - val_loss: 3240883.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 994658.4375 - val_loss: 3236763.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 907404.3125 - val_loss: 3232933.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 826201.8750 - val_loss: 3229192.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 750695.8750 - val_loss: 3228930.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 680607.0625 - val_loss: 3228246.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 615740.8750 - val_loss: 3224347.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 555755.8750 - val_loss: 3220920.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 500499.9375 - val_loss: 3215395.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 449635.8125 - val_loss: 3215238.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 403001.8125 - val_loss: 3209149.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 360385.5000 - val_loss: 3203715.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 321513.3750 - val_loss: 3202135.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 286240.5625 - val_loss: 3198860.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 254352.0156 - val_loss: 3205316.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 225693.3594 - val_loss: 3204158.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 199981.2188 - val_loss: 3207795.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 176972.8281 - val_loss: 3211017.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 156613.0625 - val_loss: 3209747.5000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 2s 7ms/step - loss: 1818399.1250 - val_loss: 3269757.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1669134.5000 - val_loss: 3267178.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1536363.3750 - val_loss: 3262489.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1413130.0000 - val_loss: 3257767.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1298187.5000 - val_loss: 3252309.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1190824.0000 - val_loss: 3247245.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 1090478.1250 - val_loss: 3248217.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 996841.1250 - val_loss: 3241237.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 909525.3125 - val_loss: 3234774.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 828214.7500 - val_loss: 3228632.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 752607.6875 - val_loss: 3223058.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 682359.1250 - val_loss: 3217897.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 617445.5000 - val_loss: 3213515.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 557416.8125 - val_loss: 3209145.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 502090.5625 - val_loss: 3204979.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 451158.0000 - val_loss: 3194301.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 404435.5312 - val_loss: 3190745.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 361723.8125 - val_loss: 3187274.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 322807.0312 - val_loss: 3186801.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 287480.5312 - val_loss: 3183019.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 255486.4375 - val_loss: 3180897.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 226607.5469 - val_loss: 3182273.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 200770.7969 - val_loss: 3187699.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 177702.7500 - val_loss: 3191283.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 157217.0938 - val_loss: 3190398.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 139126.0000 - val_loss: 3188228.5000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1856957.7500 - val_loss: 3270649.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1773890.6250 - val_loss: 3270054.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1700772.7500 - val_loss: 3269175.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1631507.1250 - val_loss: 3268213.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1564892.0000 - val_loss: 3267170.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1500712.7500 - val_loss: 3266337.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1438740.0000 - val_loss: 3265647.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1378885.3750 - val_loss: 3263510.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1321157.8750 - val_loss: 3261038.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1265292.0000 - val_loss: 3258550.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 1211311.6250 - val_loss: 3256878.5000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 1159100.0000 - val_loss: 3255954.2500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1108684.6250 - val_loss: 3253349.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1059944.3750 - val_loss: 3250665.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1012736.3750 - val_loss: 3247999.7500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 967288.3750 - val_loss: 3245291.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 923420.8125 - val_loss: 3242704.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 881134.3750 - val_loss: 3240249.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 840331.5625 - val_loss: 3237835.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 800967.8750 - val_loss: 3235429.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 763039.8750 - val_loss: 3233189.0000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 726515.3125 - val_loss: 3231043.7500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 691447.2500 - val_loss: 3229015.2500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 657538.1250 - val_loss: 3227018.0000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 625073.3125 - val_loss: 3225187.7500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 593829.0625 - val_loss: 3223368.5000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 563829.5000 - val_loss: 3221641.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 534820.8750 - val_loss: 3220064.7500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 507170.4062 - val_loss: 3218454.7500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 480670.3438 - val_loss: 3216941.2500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 455270.2812 - val_loss: 3215544.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 430955.7188 - val_loss: 3214151.0000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 407699.8125 - val_loss: 3212899.7500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 385497.5000 - val_loss: 3211684.7500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 364241.2188 - val_loss: 3210470.5000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 343950.5938 - val_loss: 3209377.7500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 324650.7500 - val_loss: 3208514.2500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 306311.2500 - val_loss: 3207561.5000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 288795.5312 - val_loss: 3206650.5000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 272152.9688 - val_loss: 3205807.2500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 256354.3594 - val_loss: 3205030.0000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 241321.4688 - val_loss: 3204215.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 227109.3906 - val_loss: 3203554.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 213683.4688 - val_loss: 3202976.2500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 200977.0469 - val_loss: 3202326.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 188948.3750 - val_loss: 3201673.5000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 177606.3594 - val_loss: 3201002.0000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 166939.3906 - val_loss: 3200512.5000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 156935.4531 - val_loss: 3199949.7500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 147485.1406 - val_loss: 3199457.7500\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1856572.0000 - val_loss: 3272156.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1772795.1250 - val_loss: 3273713.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 1699512.5000 - val_loss: 3274937.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1630044.5000 - val_loss: 3274526.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1563393.1250 - val_loss: 3273161.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 1499209.7500 - val_loss: 3271440.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 1437322.1250 - val_loss: 3269343.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1377558.6250 - val_loss: 3266945.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1319761.5000 - val_loss: 3264298.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1263903.5000 - val_loss: 3261460.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1209850.6250 - val_loss: 3258356.0000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1157715.6250 - val_loss: 3255117.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1107385.1250 - val_loss: 3251726.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1058746.1250 - val_loss: 3248514.7500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1011689.0625 - val_loss: 3245208.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 966309.3750 - val_loss: 3241948.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 922471.2500 - val_loss: 3238774.7500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 880196.3750 - val_loss: 3235676.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 839429.4375 - val_loss: 3232738.5000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 800035.3750 - val_loss: 3229935.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 762196.0625 - val_loss: 3227130.7500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 725598.9375 - val_loss: 3224497.5000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 690475.1875 - val_loss: 3221975.2500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 656758.2500 - val_loss: 3219476.7500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 624266.3750 - val_loss: 3217069.2500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 593071.6250 - val_loss: 3214792.0000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 563053.7500 - val_loss: 3212588.0000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 534253.5000 - val_loss: 3210416.7500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 506699.5938 - val_loss: 3208433.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 480215.3125 - val_loss: 3206487.5000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 454855.3438 - val_loss: 3204625.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 430552.3125 - val_loss: 3202841.0000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 407275.6250 - val_loss: 3201126.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 385003.9688 - val_loss: 3199471.7500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 363711.4688 - val_loss: 3197939.7500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 343539.5938 - val_loss: 3196451.5000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 324301.2812 - val_loss: 3195023.5000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 305945.5938 - val_loss: 3193684.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 288469.0000 - val_loss: 3192403.2500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 271848.6562 - val_loss: 3191112.0000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 256014.7812 - val_loss: 3189954.2500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 241071.7500 - val_loss: 3188799.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 226842.4844 - val_loss: 3187760.5000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 213370.4531 - val_loss: 3186711.2500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 200683.3281 - val_loss: 3185775.2500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 188708.6562 - val_loss: 3184795.2500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 177381.2812 - val_loss: 3183954.2500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 166697.5469 - val_loss: 3183131.2500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 156658.6562 - val_loss: 3182330.2500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 147223.5781 - val_loss: 3181630.5000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 13ms/step - loss: 1859239.7500 - val_loss: 3269899.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1777249.2500 - val_loss: 3270118.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1704169.3750 - val_loss: 3270055.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1634834.2500 - val_loss: 3266830.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1568287.1250 - val_loss: 3262710.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 1504090.7500 - val_loss: 3260550.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1442043.7500 - val_loss: 3257258.7500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 1382100.2500 - val_loss: 3253903.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1324246.2500 - val_loss: 3250943.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1268265.3750 - val_loss: 3248229.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1214183.3750 - val_loss: 3247840.5000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1161968.2500 - val_loss: 3245748.0000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1111452.6250 - val_loss: 3242210.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1062749.7500 - val_loss: 3238819.5000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1015568.6875 - val_loss: 3236469.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 970152.8750 - val_loss: 3233063.2500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 926331.9375 - val_loss: 3231720.5000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 883924.3750 - val_loss: 3226103.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 843085.6875 - val_loss: 3224414.5000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 803619.3750 - val_loss: 3221800.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 765614.3125 - val_loss: 3218584.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 729075.8125 - val_loss: 3211174.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 693867.1250 - val_loss: 3206863.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 659908.8125 - val_loss: 3203935.0000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 627316.8750 - val_loss: 3200838.0000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 595997.8750 - val_loss: 3198441.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 565890.3750 - val_loss: 3192712.5000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 537011.7500 - val_loss: 3193876.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 509268.2500 - val_loss: 3191730.2500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 482667.9375 - val_loss: 3183997.7500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 457220.1875 - val_loss: 3180987.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 432883.4062 - val_loss: 3178424.0000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 409582.8438 - val_loss: 3176415.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 387347.2188 - val_loss: 3174692.5000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 366085.5938 - val_loss: 3173140.5000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 345763.0000 - val_loss: 3171655.2500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 326301.0000 - val_loss: 3170258.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 307775.8750 - val_loss: 3168889.5000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 290211.1875 - val_loss: 3167919.2500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 273515.2500 - val_loss: 3166849.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 257691.0938 - val_loss: 3165874.2500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 242564.2344 - val_loss: 3165735.0000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 228294.4531 - val_loss: 3165644.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 214761.9688 - val_loss: 3167700.0000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 202014.8750 - val_loss: 3168012.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 190027.9375 - val_loss: 3168480.7500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 178603.7656 - val_loss: 3168032.7500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 167915.5625 - val_loss: 3167585.0000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1858761.0000 - val_loss: 3272536.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1776139.5000 - val_loss: 3273930.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1703126.0000 - val_loss: 3273976.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1633845.8750 - val_loss: 3273197.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1567260.0000 - val_loss: 3271177.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1503129.7500 - val_loss: 3268010.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1441259.7500 - val_loss: 3263828.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1381220.8750 - val_loss: 3263386.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1323452.3750 - val_loss: 3260246.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1267580.6250 - val_loss: 3259487.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1213529.1250 - val_loss: 3257901.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1161254.6250 - val_loss: 3257986.2500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1110739.3750 - val_loss: 3254784.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1061980.1250 - val_loss: 3251563.7500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1014888.1250 - val_loss: 3248375.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 969398.1875 - val_loss: 3245220.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 925592.4375 - val_loss: 3242126.5000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 883150.5625 - val_loss: 3239187.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 842235.8750 - val_loss: 3236390.5000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 802720.6875 - val_loss: 3233725.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 764842.8750 - val_loss: 3230980.5000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 728264.1875 - val_loss: 3228263.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 693167.4375 - val_loss: 3225839.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 659245.6875 - val_loss: 3223572.2500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 626634.2500 - val_loss: 3221274.0000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 595264.3750 - val_loss: 3219114.5000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 565244.6875 - val_loss: 3217035.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 536429.0625 - val_loss: 3214995.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 508691.5312 - val_loss: 3213072.2500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 482082.7188 - val_loss: 3211262.7500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 456645.4062 - val_loss: 3209507.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 432377.2188 - val_loss: 3207896.2500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 409118.8125 - val_loss: 3206351.0000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 386896.3125 - val_loss: 3204978.7500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 365565.4062 - val_loss: 3203536.7500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 345192.9062 - val_loss: 3202270.5000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 325843.9062 - val_loss: 3201030.0000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 307361.9375 - val_loss: 3199871.5000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 289835.3438 - val_loss: 3198662.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 273195.3125 - val_loss: 3197572.0000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 257376.7031 - val_loss: 3196599.0000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 242397.0781 - val_loss: 3195757.0000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 228143.2500 - val_loss: 3194798.2500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 214646.4688 - val_loss: 3193985.7500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 201826.9219 - val_loss: 3193249.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 189730.1250 - val_loss: 3192603.5000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 178320.5312 - val_loss: 3191936.5000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 167605.7969 - val_loss: 3191403.2500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 157549.2031 - val_loss: 3190860.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 148098.0000 - val_loss: 3190402.5000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 11ms/step - loss: 1853915.5000 - val_loss: 3273412.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1771890.2500 - val_loss: 3275363.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 1699299.0000 - val_loss: 3276205.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1630195.8750 - val_loss: 3276205.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1563823.0000 - val_loss: 3275846.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1499769.6250 - val_loss: 3275038.5000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1855443.6250 - val_loss: 3265944.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1771930.3750 - val_loss: 3263256.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1698922.6250 - val_loss: 3260927.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1629640.3750 - val_loss: 3258649.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1563126.3750 - val_loss: 3257563.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1499102.0000 - val_loss: 3254758.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1437169.2500 - val_loss: 3252211.7500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1377384.7500 - val_loss: 3249217.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1319631.1250 - val_loss: 3245821.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1263800.2500 - val_loss: 3243441.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1209858.8750 - val_loss: 3240566.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1157708.1250 - val_loss: 3237654.2500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1107273.1250 - val_loss: 3233651.2500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1058602.8750 - val_loss: 3235680.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1011566.7500 - val_loss: 3236045.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 966150.5625 - val_loss: 3237613.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 922292.0625 - val_loss: 3234249.5000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 880045.6250 - val_loss: 3231049.7500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 839370.6250 - val_loss: 3228037.0000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 800029.6875 - val_loss: 3225085.5000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 762208.1250 - val_loss: 3222428.7500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 725723.3125 - val_loss: 3219811.2500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 690646.3750 - val_loss: 3217144.0000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 656882.9375 - val_loss: 3214922.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 624313.6875 - val_loss: 3212489.7500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 593113.4375 - val_loss: 3210241.5000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 563034.0000 - val_loss: 3208200.0000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 534197.2500 - val_loss: 3206206.7500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 506591.3125 - val_loss: 3204318.5000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 480035.8125 - val_loss: 3202513.5000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 454705.3125 - val_loss: 3200678.5000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 430498.1875 - val_loss: 3199263.5000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 407246.8750 - val_loss: 3197941.2500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 385062.4375 - val_loss: 3196095.5000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 363885.1562 - val_loss: 3194592.2500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 343682.8438 - val_loss: 3193313.5000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 324279.5000 - val_loss: 3192128.5000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 305796.1562 - val_loss: 3190631.5000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 288380.5312 - val_loss: 3189707.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 271775.7188 - val_loss: 3189276.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 255998.0938 - val_loss: 3189010.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 241067.7500 - val_loss: 3190774.2500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 226882.5000 - val_loss: 3188998.7500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 213408.1719 - val_loss: 3191423.0000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 200716.1719 - val_loss: 3191023.7500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 188753.2656 - val_loss: 3190177.0000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 177401.3594 - val_loss: 3189408.7500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 166783.0781 - val_loss: 3188673.7500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 156762.7344 - val_loss: 3188086.7500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 147383.7969 - val_loss: 3187526.5000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 12ms/step - loss: 1857687.8750 - val_loss: 3271552.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1775258.7500 - val_loss: 3273461.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1702381.1250 - val_loss: 3272386.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1633135.2500 - val_loss: 3269780.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1566560.1250 - val_loss: 3267152.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1502498.7500 - val_loss: 3265039.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1440545.6250 - val_loss: 3261816.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1380764.6250 - val_loss: 3260056.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1322936.0000 - val_loss: 3257262.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1267030.2500 - val_loss: 3254760.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1212930.2500 - val_loss: 3252825.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1160693.7500 - val_loss: 3250618.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1110147.8750 - val_loss: 3249100.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1061435.6250 - val_loss: 3248176.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1014209.2500 - val_loss: 3247320.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 968839.1875 - val_loss: 3244986.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 924985.6250 - val_loss: 3242387.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 882736.3125 - val_loss: 3239818.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 841901.3750 - val_loss: 3236881.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 802489.6250 - val_loss: 3234034.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 764562.3125 - val_loss: 3231244.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 727973.3750 - val_loss: 3228711.7500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 692775.9375 - val_loss: 3226201.7500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 658954.1250 - val_loss: 3223851.7500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 626411.6875 - val_loss: 3221643.0000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 595095.6875 - val_loss: 3219411.5000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 565064.0000 - val_loss: 3217370.7500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 536169.6875 - val_loss: 3215577.5000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 508445.1562 - val_loss: 3213883.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 481774.0000 - val_loss: 3212235.0000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 456315.0312 - val_loss: 3210767.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 431872.0000 - val_loss: 3209056.2500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 408602.0312 - val_loss: 3207728.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 386411.4375 - val_loss: 3206424.2500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 365181.3125 - val_loss: 3205193.7500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 344917.2812 - val_loss: 3204152.2500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 325563.4375 - val_loss: 3202912.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 307119.4688 - val_loss: 3203923.5000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 289583.1250 - val_loss: 3203199.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 272855.2812 - val_loss: 3205126.0000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 257028.0312 - val_loss: 3205590.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 241995.7969 - val_loss: 3205139.0000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1854662.8750 - val_loss: 3272625.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1772499.6250 - val_loss: 3274038.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1699813.2500 - val_loss: 3274440.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1630739.8750 - val_loss: 3273967.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1564283.7500 - val_loss: 3272751.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1500266.0000 - val_loss: 3271032.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 1438461.3750 - val_loss: 3268763.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 1378720.1250 - val_loss: 3266232.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 1320860.1250 - val_loss: 3263265.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1265132.0000 - val_loss: 3260230.5000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 1211184.7500 - val_loss: 3257020.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1158956.3750 - val_loss: 3253755.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1108492.0000 - val_loss: 3250345.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1059847.6250 - val_loss: 3247005.7500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1012808.1250 - val_loss: 3243623.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 967468.5625 - val_loss: 3240292.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 923652.3125 - val_loss: 3237062.0000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 881338.5625 - val_loss: 3233946.7500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 840576.6875 - val_loss: 3230777.5000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 801286.8750 - val_loss: 3227858.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 763392.3750 - val_loss: 3224999.7500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 726892.5000 - val_loss: 3222227.2500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 691772.3125 - val_loss: 3219642.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 657964.3750 - val_loss: 3217101.7500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 625441.1250 - val_loss: 3214624.7500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 594118.2500 - val_loss: 3212272.0000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 564056.0625 - val_loss: 3210091.7500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 535286.0000 - val_loss: 3207894.7500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 507549.2500 - val_loss: 3205760.2500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 481020.0312 - val_loss: 3203781.7500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 455557.7188 - val_loss: 3201859.7500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 431278.8125 - val_loss: 3200054.2500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 408063.3438 - val_loss: 3198281.2500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 385890.4375 - val_loss: 3196728.2500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 364693.9062 - val_loss: 3195047.5000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 344432.6250 - val_loss: 3193566.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 325010.8750 - val_loss: 3192083.5000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 306581.9375 - val_loss: 3190609.7500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 289058.1875 - val_loss: 3189323.2500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 272385.2188 - val_loss: 3187989.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 256561.1094 - val_loss: 3186706.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 241554.4062 - val_loss: 3185555.5000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 227282.4844 - val_loss: 3184337.7500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 213742.9531 - val_loss: 3183247.5000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 200981.7656 - val_loss: 3182156.5000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 188968.0781 - val_loss: 3181208.0000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 177680.4844 - val_loss: 3180191.5000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 167009.3438 - val_loss: 3179250.7500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 156983.4062 - val_loss: 3178296.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 147547.3750 - val_loss: 3177405.0000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 2s 10ms/step - loss: 1854689.1250 - val_loss: 3270910.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1770882.7500 - val_loss: 3272233.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1697722.3750 - val_loss: 3272606.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1628389.2500 - val_loss: 3271903.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1561728.1250 - val_loss: 3270930.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1497508.1250 - val_loss: 3269106.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1435699.0000 - val_loss: 3267322.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1375998.1250 - val_loss: 3266884.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1318166.6250 - val_loss: 3266885.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1262298.6250 - val_loss: 3264744.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1208268.5000 - val_loss: 3262157.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 1156068.2500 - val_loss: 3259502.0000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1105660.6250 - val_loss: 3256758.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1056898.0000 - val_loss: 3253940.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1009931.3125 - val_loss: 3251069.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 964637.2500 - val_loss: 3248240.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 920808.1250 - val_loss: 3245461.7500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 878429.1875 - val_loss: 3242807.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 837763.5000 - val_loss: 3240160.5000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 798564.1250 - val_loss: 3237642.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 760841.0625 - val_loss: 3235238.5000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 724373.1250 - val_loss: 3232881.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 689330.6875 - val_loss: 3230714.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 655592.1875 - val_loss: 3228477.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 623162.4375 - val_loss: 3226486.5000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 591922.8125 - val_loss: 3224567.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 562021.2500 - val_loss: 3222701.7500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 533268.0000 - val_loss: 3221034.7500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 505774.7812 - val_loss: 3219304.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 479396.6250 - val_loss: 3217744.7500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 454103.0312 - val_loss: 3216317.5000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 429904.6250 - val_loss: 3214817.0000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 406634.2500 - val_loss: 3213417.2500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 384428.6250 - val_loss: 3212153.2500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 363232.5000 - val_loss: 3210994.5000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 343077.2500 - val_loss: 3209830.5000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 323767.4375 - val_loss: 3208630.5000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 305325.1562 - val_loss: 3207575.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 287811.2812 - val_loss: 3206540.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 271214.4375 - val_loss: 3205625.0000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 255460.3125 - val_loss: 3204704.5000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 240424.6250 - val_loss: 3203822.2500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 226237.8438 - val_loss: 3203013.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 212870.5312 - val_loss: 3202217.0000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 200204.5312 - val_loss: 3201487.5000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 188245.2188 - val_loss: 3200792.7500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 176945.7031 - val_loss: 3200151.5000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 166303.6562 - val_loss: 3199492.0000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 156309.5312 - val_loss: 3198900.2500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 146908.8750 - val_loss: 3198277.0000\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 10ms/step - loss: 1856047.0000 - val_loss: 3272221.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1773303.6250 - val_loss: 3273938.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1700431.6250 - val_loss: 3274518.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1631148.7500 - val_loss: 3274166.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1564631.8750 - val_loss: 3273179.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1500535.0000 - val_loss: 3271547.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1438622.3750 - val_loss: 3269926.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1378805.1250 - val_loss: 3267512.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1320928.1250 - val_loss: 3264965.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1265096.7500 - val_loss: 3262130.5000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1211032.5000 - val_loss: 3258830.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1158966.1250 - val_loss: 3255407.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1108578.1250 - val_loss: 3251900.2500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1059836.6250 - val_loss: 3248358.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1012766.5625 - val_loss: 3244907.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 967389.6875 - val_loss: 3241567.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 923636.7500 - val_loss: 3238286.7500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 881260.5625 - val_loss: 3235149.2500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 840454.0625 - val_loss: 3232204.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 801194.5000 - val_loss: 3229272.5000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 763187.3125 - val_loss: 3226518.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 726826.9375 - val_loss: 3223933.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 691683.5000 - val_loss: 3221345.0000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 657920.0625 - val_loss: 3218936.7500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 625389.6875 - val_loss: 3216637.2500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 594096.6250 - val_loss: 3214422.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 564062.9375 - val_loss: 3212300.5000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 535303.0625 - val_loss: 3210280.0000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 507653.9062 - val_loss: 3208272.2500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 481077.4375 - val_loss: 3206435.7500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 455610.0000 - val_loss: 3204687.5000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 431209.1875 - val_loss: 3203004.2500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 407929.7500 - val_loss: 3201426.7500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 385773.3438 - val_loss: 3199878.0000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 364547.0312 - val_loss: 3198425.5000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 344265.8125 - val_loss: 3197017.5000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 324930.7188 - val_loss: 3195739.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 306468.1250 - val_loss: 3194412.5000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 288894.8438 - val_loss: 3193257.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 272248.4062 - val_loss: 3192105.0000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 256458.9531 - val_loss: 3191061.2500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 241402.6719 - val_loss: 3189970.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 227126.1250 - val_loss: 3188934.5000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 213663.5781 - val_loss: 3187949.7500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 200956.4844 - val_loss: 3187190.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 188945.1875 - val_loss: 3186279.7500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 177674.6562 - val_loss: 3185447.7500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 166906.7344 - val_loss: 3184674.2500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 156853.0156 - val_loss: 3183913.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 147380.3750 - val_loss: 3183207.5000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1877238.3750 - val_loss: 3272844.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1832206.8750 - val_loss: 3272754.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1801222.7500 - val_loss: 3272221.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1771899.2500 - val_loss: 3271207.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1743468.1250 - val_loss: 3270049.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1715622.6250 - val_loss: 3268599.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1688254.0000 - val_loss: 3266779.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1661294.8750 - val_loss: 3264624.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1634681.0000 - val_loss: 3261909.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1608417.3750 - val_loss: 3259181.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1582464.1250 - val_loss: 3256434.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1556806.6250 - val_loss: 3253893.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1531431.2500 - val_loss: 3251082.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1506334.1250 - val_loss: 3248202.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1481501.8750 - val_loss: 3245078.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1456916.0000 - val_loss: 3242057.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1432576.6250 - val_loss: 3239067.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1408490.1250 - val_loss: 3236032.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1384633.1250 - val_loss: 3232535.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1361009.6250 - val_loss: 3229535.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1337620.8750 - val_loss: 3226554.2500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1314469.3750 - val_loss: 3223454.2500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1291553.6250 - val_loss: 3220406.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1268863.2500 - val_loss: 3217392.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1246402.5000 - val_loss: 3214259.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1224152.8750 - val_loss: 3211018.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1202124.3750 - val_loss: 3207177.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1180324.6250 - val_loss: 3203444.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1158742.1250 - val_loss: 3200097.0000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 1137380.5000 - val_loss: 3195406.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1116237.7500 - val_loss: 3191576.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1095320.3750 - val_loss: 3187845.5000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1074630.8750 - val_loss: 3184356.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1054159.8750 - val_loss: 3180924.7500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1033886.2500 - val_loss: 3177535.5000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1013839.4375 - val_loss: 3174257.5000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 994006.5625 - val_loss: 3170975.2500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 974380.2500 - val_loss: 3167832.2500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 954965.0625 - val_loss: 3164720.5000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 935765.5625 - val_loss: 3161647.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 916791.1250 - val_loss: 3158588.0000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 898039.4375 - val_loss: 3155562.5000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 879503.4375 - val_loss: 3152586.0000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 861170.9375 - val_loss: 3149632.2500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 843059.6875 - val_loss: 3146552.7500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 825166.0625 - val_loss: 3143075.0000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 807484.5000 - val_loss: 3137798.5000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 790007.1250 - val_loss: 3129546.5000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 772748.3750 - val_loss: 3123155.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 755704.0625 - val_loss: 3113011.7500\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 2s 4ms/step - loss: 1881620.3750 - val_loss: 3271808.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1834441.0000 - val_loss: 3271591.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1802869.6250 - val_loss: 3270506.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 3ms/step - loss: 1773230.5000 - val_loss: 3268834.2500\n",
            "Epoch 5/50\n",
            " 88/209 [===========>..................] - ETA: 0s - loss: 1715536.0000"
          ]
        }
      ],
      "source": [
        "layers = [50]\n",
        "time_step = 5\n",
        "optimizers_names = ['Adam', 'Adagrad', 'Nadam']\n",
        "learning_rates =  [0.1, 0.01, 0.001]\n",
        "batch_sizes =  [4, 8, 16]\n",
        "epochs = 50\n",
        "num_replicates = 10\n",
        "\n",
        "\n",
        "N50_best_hyper_parameters = hyper_parameter_tuning(layers,  optimizers_names, learning_rates, batch_sizes, epochs = epochs, num_replicates = num_replicates)\n",
        "N50_best_hyper_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case IV: Tuning parameters of 100 neuron single layer LSTM"
      ],
      "metadata": {
        "id": "cEV4tinQgwbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [100]\n",
        "time_step = 5\n",
        "optimizers_names = ['Adam', 'Adagrad', 'Nadam']\n",
        "learning_rates =  [0.1, 0.01, 0.001]\n",
        "batch_sizes =  [4, 8, 16]\n",
        "epochs = 50\n",
        "num_replicates = 10\n",
        "\n",
        "\n",
        "N100_best_hyper_parameters = hyper_parameter_tuning(layers,  optimizers_names, learning_rates, batch_sizes, epochs = epochs, num_replicates = num_replicates)\n",
        "N100_best_hyper_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP4EGsd-g308",
        "outputId": "610715b2-0db7-4a45-f2f7-c278f8605542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1414215.3750 - val_loss: 3256478.5000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1409367.6250 - val_loss: 3256181.5000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1404587.3750 - val_loss: 3255889.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1399870.7500 - val_loss: 3255602.0000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1395217.7500 - val_loss: 3255317.7500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1390624.6250 - val_loss: 3255038.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1386090.8750 - val_loss: 3254760.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1381613.3750 - val_loss: 3254487.5000\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 10ms/step - loss: 1826493.2500 - val_loss: 3268707.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1778441.1250 - val_loss: 3265999.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1750534.1250 - val_loss: 3263674.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1728384.6250 - val_loss: 3261774.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1709495.1250 - val_loss: 3260158.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1692786.3750 - val_loss: 3258712.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1677664.8750 - val_loss: 3257378.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1663768.2500 - val_loss: 3256117.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1650857.5000 - val_loss: 3254905.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1638759.2500 - val_loss: 3253747.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1627346.1250 - val_loss: 3252622.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1616521.5000 - val_loss: 3251534.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1606208.2500 - val_loss: 3250474.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1596347.8750 - val_loss: 3249438.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1586888.7500 - val_loss: 3248423.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1577791.2500 - val_loss: 3247425.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1569017.7500 - val_loss: 3246450.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1560540.1250 - val_loss: 3245490.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1552335.1250 - val_loss: 3244554.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1544378.0000 - val_loss: 3243642.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1536652.2500 - val_loss: 3242752.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1529138.3750 - val_loss: 3241885.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1521824.5000 - val_loss: 3241047.5000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1514695.0000 - val_loss: 3240235.2500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1507739.1250 - val_loss: 3239451.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1500946.2500 - val_loss: 3238691.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1494306.7500 - val_loss: 3237953.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1487812.2500 - val_loss: 3237245.5000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1481453.8750 - val_loss: 3236562.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1475226.3750 - val_loss: 3235904.2500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1469121.8750 - val_loss: 3235268.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1463133.2500 - val_loss: 3234658.0000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1457256.3750 - val_loss: 3234073.0000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1451486.5000 - val_loss: 3233512.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1445817.1250 - val_loss: 3232977.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1440244.6250 - val_loss: 3232464.5000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1434765.3750 - val_loss: 3231980.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1429376.1250 - val_loss: 3231522.2500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1424072.8750 - val_loss: 3231090.5000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1418851.2500 - val_loss: 3230686.5000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1413708.2500 - val_loss: 3230309.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1408641.6250 - val_loss: 3229964.2500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1403648.8750 - val_loss: 3229648.7500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1398727.3750 - val_loss: 3229368.0000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1393873.7500 - val_loss: 3229119.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1389085.3750 - val_loss: 3228904.7500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1384362.0000 - val_loss: 3228721.2500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1379699.5000 - val_loss: 3228572.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1375097.3750 - val_loss: 3228454.5000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1370553.3750 - val_loss: 3228366.0000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 1821028.1250 - val_loss: 3269834.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1773825.5000 - val_loss: 3267977.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1746093.8750 - val_loss: 3266223.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1724048.5000 - val_loss: 3264700.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1705229.0000 - val_loss: 3263390.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1688574.5000 - val_loss: 3262247.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1673496.0000 - val_loss: 3261229.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1659637.8750 - val_loss: 3260305.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1646759.5000 - val_loss: 3259436.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1634689.8750 - val_loss: 3258616.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1623301.0000 - val_loss: 3257833.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1612499.5000 - val_loss: 3257063.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1602205.8750 - val_loss: 3256317.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1592364.2500 - val_loss: 3255570.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1582921.1250 - val_loss: 3254824.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1573839.2500 - val_loss: 3254084.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1565083.1250 - val_loss: 3253350.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1556621.1250 - val_loss: 3252631.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1548430.7500 - val_loss: 3251921.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1540488.6250 - val_loss: 3251238.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1532776.2500 - val_loss: 3250579.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1525277.2500 - val_loss: 3249949.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1517975.0000 - val_loss: 3249348.2500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1510859.1250 - val_loss: 3248777.0000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1503915.6250 - val_loss: 3248233.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1497135.1250 - val_loss: 3247719.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1490507.6250 - val_loss: 3247232.2500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1484024.3750 - val_loss: 3246768.7500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1477677.1250 - val_loss: 3246327.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1471459.8750 - val_loss: 3245908.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1465365.8750 - val_loss: 3245510.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1459387.5000 - val_loss: 3245130.5000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1453520.8750 - val_loss: 3244767.5000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1447760.5000 - val_loss: 3244419.7500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1442100.8750 - val_loss: 3244087.0000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1436538.1250 - val_loss: 3243765.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1431068.7500 - val_loss: 3243456.0000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1425688.5000 - val_loss: 3243155.0000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1420392.6250 - val_loss: 3242861.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1415179.7500 - val_loss: 3242575.0000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1410045.1250 - val_loss: 3242293.0000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1404986.3750 - val_loss: 3242018.5000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1400001.8750 - val_loss: 3241748.0000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1395087.8750 - val_loss: 3241481.0000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1390241.6250 - val_loss: 3241219.2500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1385461.8750 - val_loss: 3240963.2500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1380745.5000 - val_loss: 3240713.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1376091.3750 - val_loss: 3240470.7500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1371496.1250 - val_loss: 3240235.5000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1366959.7500 - val_loss: 3240010.7500\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 12ms/step - loss: 1827771.3750 - val_loss: 3274131.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1780996.1250 - val_loss: 3273296.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1753219.5000 - val_loss: 3271974.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1731119.2500 - val_loss: 3270551.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1712265.5000 - val_loss: 3269027.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1695576.0000 - val_loss: 3267436.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1680467.8750 - val_loss: 3265775.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1666580.8750 - val_loss: 3264167.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1653676.1250 - val_loss: 3262668.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1641582.2500 - val_loss: 3261317.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1630170.7500 - val_loss: 3260124.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1619348.3750 - val_loss: 3259018.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1609035.5000 - val_loss: 3257932.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1599173.5000 - val_loss: 3256833.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1589712.8750 - val_loss: 3255735.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1580611.8750 - val_loss: 3254644.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1571837.0000 - val_loss: 3253600.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1563357.0000 - val_loss: 3252633.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1555148.8750 - val_loss: 3251738.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1547189.0000 - val_loss: 3250902.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1539461.0000 - val_loss: 3250106.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1531944.7500 - val_loss: 3249337.2500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1524626.8750 - val_loss: 3248584.5000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1517494.3750 - val_loss: 3247835.2500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1510535.0000 - val_loss: 3247089.2500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1503738.7500 - val_loss: 3246348.2500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1497096.0000 - val_loss: 3245617.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1490597.8750 - val_loss: 3244902.0000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1484237.3750 - val_loss: 3244210.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1478005.0000 - val_loss: 3243542.2500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1471895.8750 - val_loss: 3242901.2500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1465904.8750 - val_loss: 3242283.7500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1460024.0000 - val_loss: 3241688.7500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1454250.6250 - val_loss: 3241115.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1448576.7500 - val_loss: 3240561.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1443001.7500 - val_loss: 3240024.2500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1437519.1250 - val_loss: 3239502.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1432125.5000 - val_loss: 3238993.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1426817.2500 - val_loss: 3238497.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1421592.5000 - val_loss: 3238011.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1416445.2500 - val_loss: 3237536.7500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1411375.2500 - val_loss: 3237070.0000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1406378.2500 - val_loss: 3236612.5000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1401451.6250 - val_loss: 3236162.7500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1396593.6250 - val_loss: 3235719.7500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1391802.1250 - val_loss: 3235284.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1387074.6250 - val_loss: 3234854.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1382408.6250 - val_loss: 3234430.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1377802.7500 - val_loss: 3234012.5000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1373254.3750 - val_loss: 3233599.7500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 14ms/step - loss: 1842192.8750 - val_loss: 3275533.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1806792.2500 - val_loss: 3276083.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1786688.6250 - val_loss: 3276306.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1770682.6250 - val_loss: 3276359.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1757002.1250 - val_loss: 3276269.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1744886.6250 - val_loss: 3276106.7500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 19ms/step - loss: 1838630.6250 - val_loss: 3274985.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1802315.7500 - val_loss: 3275285.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1782160.5000 - val_loss: 3275415.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1766143.7500 - val_loss: 3275444.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1752473.1250 - val_loss: 3275430.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1740367.2500 - val_loss: 3275386.0000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 15ms/step - loss: 1841673.1250 - val_loss: 3271734.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1805725.2500 - val_loss: 3271026.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1785563.0000 - val_loss: 3270342.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1769535.3750 - val_loss: 3269575.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1755854.3750 - val_loss: 3268797.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1743737.3750 - val_loss: 3268043.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1732758.8750 - val_loss: 3267324.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1722649.0000 - val_loss: 3266684.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1713239.8750 - val_loss: 3266104.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1704413.1250 - val_loss: 3265571.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1696073.0000 - val_loss: 3265083.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1688145.6250 - val_loss: 3264641.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1680590.5000 - val_loss: 3264164.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1673354.7500 - val_loss: 3263748.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1666403.0000 - val_loss: 3263340.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1659711.3750 - val_loss: 3262951.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1653250.7500 - val_loss: 3262569.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1646997.7500 - val_loss: 3262205.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1640941.6250 - val_loss: 3261849.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1635061.0000 - val_loss: 3261502.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1629344.1250 - val_loss: 3261174.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1623783.2500 - val_loss: 3260837.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1618359.2500 - val_loss: 3260503.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1613068.0000 - val_loss: 3260183.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1607901.2500 - val_loss: 3259853.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1602856.2500 - val_loss: 3259525.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1597915.1250 - val_loss: 3259215.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1593078.5000 - val_loss: 3258885.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1588339.0000 - val_loss: 3258594.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1583689.0000 - val_loss: 3258290.2500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1579129.6250 - val_loss: 3257977.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1574655.5000 - val_loss: 3257666.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1570259.0000 - val_loss: 3257359.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1565937.0000 - val_loss: 3257043.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1561688.6250 - val_loss: 3256720.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1557510.8750 - val_loss: 3256381.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1553401.3750 - val_loss: 3256029.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1549352.8750 - val_loss: 3255694.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1545362.3750 - val_loss: 3255327.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1541433.3750 - val_loss: 3254947.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1537560.6250 - val_loss: 3254555.2500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1533743.0000 - val_loss: 3254136.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1529979.2500 - val_loss: 3253732.2500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1526264.5000 - val_loss: 3253302.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1522601.7500 - val_loss: 3252876.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1518981.3750 - val_loss: 3252477.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1515409.0000 - val_loss: 3252108.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1511880.7500 - val_loss: 3251750.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1508395.0000 - val_loss: 3251392.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1504950.3750 - val_loss: 3251065.0000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 15ms/step - loss: 1845273.0000 - val_loss: 3274505.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1809443.0000 - val_loss: 3274981.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1789303.7500 - val_loss: 3275161.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1773290.6250 - val_loss: 3275139.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1759615.3750 - val_loss: 3275060.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1747498.0000 - val_loss: 3274945.7500\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 17ms/step - loss: 1842054.6250 - val_loss: 3274639.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1805964.5000 - val_loss: 3274996.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1785787.0000 - val_loss: 3275004.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1769764.6250 - val_loss: 3274900.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1756071.0000 - val_loss: 3274738.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1743949.3750 - val_loss: 3274531.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1732961.6250 - val_loss: 3274233.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1722852.0000 - val_loss: 3273815.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1713445.0000 - val_loss: 3273409.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1704615.5000 - val_loss: 3273065.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1696276.3750 - val_loss: 3272796.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1688360.2500 - val_loss: 3272551.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1680801.2500 - val_loss: 3272258.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1673567.1250 - val_loss: 3271900.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1666618.3750 - val_loss: 3271460.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1659925.6250 - val_loss: 3270980.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1653472.0000 - val_loss: 3270528.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1647221.0000 - val_loss: 3270100.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1641168.8750 - val_loss: 3269697.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1635294.5000 - val_loss: 3269304.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1629579.0000 - val_loss: 3268887.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1624013.7500 - val_loss: 3268447.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1618592.8750 - val_loss: 3267988.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1613301.3750 - val_loss: 3267540.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1608134.0000 - val_loss: 3267045.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1603088.2500 - val_loss: 3266540.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1598147.6250 - val_loss: 3266017.7500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1593309.1250 - val_loss: 3265443.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1588571.1250 - val_loss: 3264858.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1583922.6250 - val_loss: 3264312.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1579362.1250 - val_loss: 3263727.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1574887.3750 - val_loss: 3263122.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1570491.5000 - val_loss: 3262481.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1566172.1250 - val_loss: 3261799.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1561922.7500 - val_loss: 3261119.7500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1557744.8750 - val_loss: 3260454.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1553631.2500 - val_loss: 3259828.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1549583.1250 - val_loss: 3259254.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1545595.3750 - val_loss: 3258727.2500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1541664.7500 - val_loss: 3258246.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1537791.7500 - val_loss: 3257789.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1533971.6250 - val_loss: 3257343.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1530206.3750 - val_loss: 3256919.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1526492.5000 - val_loss: 3256524.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1522824.7500 - val_loss: 3256135.2500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1519206.6250 - val_loss: 3255769.7500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1515632.3750 - val_loss: 3255406.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1512104.8750 - val_loss: 3255057.2500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1508616.6250 - val_loss: 3254707.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1505172.2500 - val_loss: 3254364.5000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 16ms/step - loss: 1841778.3750 - val_loss: 3273696.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1805506.0000 - val_loss: 3273745.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1785328.3750 - val_loss: 3273505.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1769314.2500 - val_loss: 3273115.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1755630.2500 - val_loss: 3272676.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1743500.5000 - val_loss: 3272189.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1732510.8750 - val_loss: 3271673.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1722397.0000 - val_loss: 3271157.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1712990.6250 - val_loss: 3270679.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1704162.8750 - val_loss: 3270216.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1695820.2500 - val_loss: 3269771.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1687903.1250 - val_loss: 3269370.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1680348.0000 - val_loss: 3268998.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1673110.3750 - val_loss: 3268622.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1666158.3750 - val_loss: 3268283.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1659462.8750 - val_loss: 3267922.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1653002.3750 - val_loss: 3267558.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1646758.1250 - val_loss: 3267214.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1640702.3750 - val_loss: 3266877.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1634822.3750 - val_loss: 3266546.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1629109.3750 - val_loss: 3266208.2500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1623547.3750 - val_loss: 3265880.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1618129.0000 - val_loss: 3265569.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1612839.6250 - val_loss: 3265256.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1607675.3750 - val_loss: 3264931.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1602625.2500 - val_loss: 3264638.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1597687.6250 - val_loss: 3264361.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1592851.8750 - val_loss: 3264096.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1588110.8750 - val_loss: 3263829.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1583464.3750 - val_loss: 3263569.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1578905.8750 - val_loss: 3263317.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1574430.3750 - val_loss: 3263072.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1570036.0000 - val_loss: 3262832.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1565716.5000 - val_loss: 3262597.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1561469.8750 - val_loss: 3262369.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1557292.8750 - val_loss: 3262147.2500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1553178.6250 - val_loss: 3261927.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1549133.6250 - val_loss: 3261713.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1545146.5000 - val_loss: 3261505.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1541216.0000 - val_loss: 3261301.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1537341.7500 - val_loss: 3261098.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1533525.3750 - val_loss: 3260899.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1529760.8750 - val_loss: 3260703.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1526046.8750 - val_loss: 3260512.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1522381.6250 - val_loss: 3260325.2500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1518762.6250 - val_loss: 3260141.7500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1515188.2500 - val_loss: 3259961.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1511657.7500 - val_loss: 3259782.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1508170.1250 - val_loss: 3259610.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1504722.6250 - val_loss: 3259439.2500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 19ms/step - loss: 1839797.3750 - val_loss: 3274487.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1803883.3750 - val_loss: 3274938.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1783910.6250 - val_loss: 3275087.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1767628.1250 - val_loss: 3274983.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1753798.2500 - val_loss: 3274691.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1741603.2500 - val_loss: 3274298.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1730575.5000 - val_loss: 3273890.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1720435.5000 - val_loss: 3273425.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1711010.1250 - val_loss: 3272987.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1702164.6250 - val_loss: 3272551.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1693810.8750 - val_loss: 3272102.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1685879.2500 - val_loss: 3271681.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1678314.6250 - val_loss: 3271254.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1671074.1250 - val_loss: 3270827.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1664122.6250 - val_loss: 3270413.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1657428.3750 - val_loss: 3270003.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1650969.2500 - val_loss: 3269604.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1644719.8750 - val_loss: 3269234.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1638658.1250 - val_loss: 3268865.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1632777.6250 - val_loss: 3268504.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1627065.3750 - val_loss: 3268162.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1621505.5000 - val_loss: 3267856.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1616081.5000 - val_loss: 3267562.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1610792.8750 - val_loss: 3267284.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1605623.6250 - val_loss: 3267018.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1600569.6250 - val_loss: 3266753.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1595630.5000 - val_loss: 3266495.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1590793.0000 - val_loss: 3266227.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1586052.6250 - val_loss: 3265966.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1581410.0000 - val_loss: 3265698.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1576849.6250 - val_loss: 3265444.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1572372.2500 - val_loss: 3265181.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1567976.8750 - val_loss: 3264920.0000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1563658.2500 - val_loss: 3264654.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1559413.3750 - val_loss: 3264393.7500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1555234.0000 - val_loss: 3264142.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1551119.2500 - val_loss: 3263873.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1547071.5000 - val_loss: 3263591.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1543083.6250 - val_loss: 3263315.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1539155.5000 - val_loss: 3263034.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1535283.2500 - val_loss: 3262766.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1531466.0000 - val_loss: 3262478.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1527701.8750 - val_loss: 3262215.0000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1523985.5000 - val_loss: 3261934.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1520320.6250 - val_loss: 3261661.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1516702.3750 - val_loss: 3261372.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1513131.1250 - val_loss: 3261097.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1509604.0000 - val_loss: 3260834.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1506117.2500 - val_loss: 3260575.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1502671.8750 - val_loss: 3260311.2500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 14ms/step - loss: 1840346.3750 - val_loss: 3272801.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1803745.8750 - val_loss: 3272331.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1783556.0000 - val_loss: 3271648.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1767515.8750 - val_loss: 3270830.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1753832.7500 - val_loss: 3270058.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1741715.0000 - val_loss: 3269376.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1730731.1250 - val_loss: 3268810.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1720617.0000 - val_loss: 3268304.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1711210.1250 - val_loss: 3267850.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1702379.3750 - val_loss: 3267418.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1694042.1250 - val_loss: 3267014.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1686121.7500 - val_loss: 3266640.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1678565.0000 - val_loss: 3266285.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1671330.2500 - val_loss: 3265934.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1664381.8750 - val_loss: 3265588.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1657690.3750 - val_loss: 3265252.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1651229.7500 - val_loss: 3264893.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1644981.8750 - val_loss: 3264543.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1638927.5000 - val_loss: 3264171.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1633053.8750 - val_loss: 3263789.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1627342.3750 - val_loss: 3263383.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1621785.2500 - val_loss: 3262985.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1616364.8750 - val_loss: 3262586.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1611074.5000 - val_loss: 3262186.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1605907.5000 - val_loss: 3261763.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1600861.0000 - val_loss: 3261366.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1595924.5000 - val_loss: 3260991.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1591091.1250 - val_loss: 3260645.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1586354.2500 - val_loss: 3260310.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1581707.7500 - val_loss: 3259995.2500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1577150.6250 - val_loss: 3259687.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1572677.0000 - val_loss: 3259383.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1568283.7500 - val_loss: 3259086.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1563965.5000 - val_loss: 3258784.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1559721.6250 - val_loss: 3258496.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1555546.7500 - val_loss: 3258196.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1551439.1250 - val_loss: 3257915.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1547391.7500 - val_loss: 3257635.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1543405.5000 - val_loss: 3257347.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1539477.7500 - val_loss: 3257063.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1535608.3750 - val_loss: 3256784.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1531794.1250 - val_loss: 3256509.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1528028.6250 - val_loss: 3256223.0000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1524315.1250 - val_loss: 3255941.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1520648.3750 - val_loss: 3255665.2500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1517030.1250 - val_loss: 3255381.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1513459.5000 - val_loss: 3255090.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1509931.7500 - val_loss: 3254795.2500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1506447.7500 - val_loss: 3254510.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1503004.0000 - val_loss: 3254219.2500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 3s 14ms/step - loss: 1841973.7500 - val_loss: 3271965.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1806560.1250 - val_loss: 3271686.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1786460.0000 - val_loss: 3271406.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1770475.3750 - val_loss: 3271202.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1756804.1250 - val_loss: 3271039.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 1744693.2500 - val_loss: 3270938.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1733708.8750 - val_loss: 3270833.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1723608.0000 - val_loss: 3270762.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1714199.8750 - val_loss: 3270681.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1705376.8750 - val_loss: 3270555.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1697045.8750 - val_loss: 3270460.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1689130.1250 - val_loss: 3270352.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1681575.2500 - val_loss: 3270227.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1674341.0000 - val_loss: 3270071.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1667396.5000 - val_loss: 3269909.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1660706.8750 - val_loss: 3269733.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1654249.3750 - val_loss: 3269535.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1648000.5000 - val_loss: 3269319.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1641945.2500 - val_loss: 3269102.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1636066.2500 - val_loss: 3268874.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1630352.2500 - val_loss: 3268647.2500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1624792.2500 - val_loss: 3268418.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1619369.3750 - val_loss: 3268175.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1614082.6250 - val_loss: 3267952.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1608916.2500 - val_loss: 3267734.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1603867.7500 - val_loss: 3267517.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1598928.3750 - val_loss: 3267301.7500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1594095.0000 - val_loss: 3267115.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1589355.5000 - val_loss: 3266927.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1584709.3750 - val_loss: 3266731.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1580149.8750 - val_loss: 3266569.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1575673.6250 - val_loss: 3266401.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1571279.5000 - val_loss: 3266264.0000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1566958.8750 - val_loss: 3266127.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1562711.6250 - val_loss: 3265991.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1558533.6250 - val_loss: 3265865.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1554422.5000 - val_loss: 3265744.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1550375.5000 - val_loss: 3265646.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1546386.6250 - val_loss: 3265550.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1542456.3750 - val_loss: 3265453.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1538584.3750 - val_loss: 3265348.2500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1534766.7500 - val_loss: 3265269.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1530996.6250 - val_loss: 3265185.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1527281.2500 - val_loss: 3265106.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1523612.7500 - val_loss: 3265046.2500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1519994.3750 - val_loss: 3264987.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1516419.3750 - val_loss: 3264916.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1512891.1250 - val_loss: 3264851.2500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1509402.3750 - val_loss: 3264797.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1505955.2500 - val_loss: 3264735.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 3s 14ms/step - loss: 1840096.2500 - val_loss: 3275150.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1803875.8750 - val_loss: 3275545.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1783716.5000 - val_loss: 3275560.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1767701.8750 - val_loss: 3275341.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1754014.0000 - val_loss: 3274987.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1741896.2500 - val_loss: 3274531.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1730919.2500 - val_loss: 3274062.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1720807.0000 - val_loss: 3273581.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1711402.8750 - val_loss: 3273084.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1702579.8750 - val_loss: 3272604.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1694246.2500 - val_loss: 3272107.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1686329.0000 - val_loss: 3271647.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1678775.1250 - val_loss: 3271225.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1671542.6250 - val_loss: 3270796.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1664596.3750 - val_loss: 3270367.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1657909.1250 - val_loss: 3269968.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1651455.5000 - val_loss: 3269598.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1645205.8750 - val_loss: 3269230.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1639152.8750 - val_loss: 3268891.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1633275.2500 - val_loss: 3268558.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1627567.0000 - val_loss: 3268268.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1622002.1250 - val_loss: 3267978.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1616582.1250 - val_loss: 3267694.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1611294.3750 - val_loss: 3267419.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1606131.2500 - val_loss: 3267154.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1601085.1250 - val_loss: 3266890.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1596150.5000 - val_loss: 3266634.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1591318.2500 - val_loss: 3266393.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1586577.1250 - val_loss: 3266150.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1581932.3750 - val_loss: 3265911.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1577378.0000 - val_loss: 3265676.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1572904.8750 - val_loss: 3265449.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1568509.5000 - val_loss: 3265228.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1564190.6250 - val_loss: 3265003.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1559945.1250 - val_loss: 3264782.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1555769.6250 - val_loss: 3264574.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1551658.3750 - val_loss: 3264358.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1547613.0000 - val_loss: 3264141.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1543626.7500 - val_loss: 3263933.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1539699.0000 - val_loss: 3263722.0000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1535827.5000 - val_loss: 3263500.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1532011.1250 - val_loss: 3263283.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1528248.6250 - val_loss: 3263069.0000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1524537.3750 - val_loss: 3262854.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1520873.0000 - val_loss: 3262637.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1517256.2500 - val_loss: 3262411.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1513686.5000 - val_loss: 3262183.5000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1510160.5000 - val_loss: 3261963.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1506675.5000 - val_loss: 3261740.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1503230.0000 - val_loss: 3261499.7500\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 20ms/step - loss: 1856684.7500 - val_loss: 3271633.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1825941.6250 - val_loss: 3271390.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1811056.7500 - val_loss: 3271161.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1799326.1250 - val_loss: 3270933.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1789327.8750 - val_loss: 3270579.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1780496.5000 - val_loss: 3270353.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1772480.2500 - val_loss: 3270086.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1765126.1250 - val_loss: 3269865.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1758263.0000 - val_loss: 3269629.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1751828.8750 - val_loss: 3269449.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1745734.6250 - val_loss: 3269210.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1739969.1250 - val_loss: 3269032.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1734451.8750 - val_loss: 3268833.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1729176.6250 - val_loss: 3268643.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1724102.6250 - val_loss: 3268479.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1719214.5000 - val_loss: 3268312.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1714492.7500 - val_loss: 3268171.0000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1709926.6250 - val_loss: 3268014.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1705491.5000 - val_loss: 3267882.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1701184.5000 - val_loss: 3267773.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1696989.7500 - val_loss: 3267624.5000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1692915.5000 - val_loss: 3267480.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1688944.2500 - val_loss: 3267350.7500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1685055.1250 - val_loss: 3267232.2500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1681264.3750 - val_loss: 3267131.5000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1677551.2500 - val_loss: 3267042.0000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1673914.7500 - val_loss: 3266931.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1670356.8750 - val_loss: 3266813.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1666867.5000 - val_loss: 3266706.7500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1663442.6250 - val_loss: 3266605.0000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1660081.1250 - val_loss: 3266469.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1656775.5000 - val_loss: 3266332.7500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1653528.6250 - val_loss: 3266211.2500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1650343.2500 - val_loss: 3266109.2500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1647203.2500 - val_loss: 3265992.0000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1644117.2500 - val_loss: 3265884.7500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1641072.2500 - val_loss: 3265717.2500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1638078.6250 - val_loss: 3265547.2500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1635130.6250 - val_loss: 3265476.5000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1632215.3750 - val_loss: 3265386.2500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1629347.3750 - val_loss: 3265277.5000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1626521.3750 - val_loss: 3265168.5000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1623730.6250 - val_loss: 3265088.5000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1620967.6250 - val_loss: 3264997.2500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1618240.2500 - val_loss: 3264901.2500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1615549.5000 - val_loss: 3264828.7500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1612888.0000 - val_loss: 3264710.7500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1610264.5000 - val_loss: 3264544.5000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1607669.3750 - val_loss: 3264440.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1605106.1250 - val_loss: 3264340.5000\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 26ms/step - loss: 1852259.2500 - val_loss: 3273247.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1821160.8750 - val_loss: 3273186.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1806360.0000 - val_loss: 3273105.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1794680.5000 - val_loss: 3273053.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1784730.7500 - val_loss: 3272978.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1775924.6250 - val_loss: 3272944.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1767942.2500 - val_loss: 3272893.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1760582.2500 - val_loss: 3272842.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1753738.6250 - val_loss: 3272777.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1747324.1250 - val_loss: 3272714.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1741255.2500 - val_loss: 3272669.5000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1735496.0000 - val_loss: 3272624.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1730003.1250 - val_loss: 3272599.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1724726.6250 - val_loss: 3272569.5000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1719655.2500 - val_loss: 3272555.2500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1714773.2500 - val_loss: 3272539.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1710051.3750 - val_loss: 3272529.7500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1705485.8750 - val_loss: 3272486.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1701062.2500 - val_loss: 3272494.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1696757.3750 - val_loss: 3272487.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1692572.3750 - val_loss: 3272467.5000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1688500.8750 - val_loss: 3272485.2500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1684531.2500 - val_loss: 3272463.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1680655.5000 - val_loss: 3272442.2500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1676870.3750 - val_loss: 3272481.7500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1673160.3750 - val_loss: 3272476.2500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1669534.0000 - val_loss: 3272492.7500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1665972.8750 - val_loss: 3272501.0000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1662489.3750 - val_loss: 3272516.5000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 21ms/step - loss: 1853040.7500 - val_loss: 3275125.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1822942.7500 - val_loss: 3275502.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1808170.2500 - val_loss: 3275695.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1796508.0000 - val_loss: 3275742.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1786565.5000 - val_loss: 3275775.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1777763.2500 - val_loss: 3275764.2500\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 25ms/step - loss: 1854855.2500 - val_loss: 3274013.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1824925.3750 - val_loss: 3274120.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1810200.2500 - val_loss: 3274117.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1798328.0000 - val_loss: 3274079.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1788315.1250 - val_loss: 3274004.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1779473.1250 - val_loss: 3273947.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1771467.7500 - val_loss: 3273873.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1764103.5000 - val_loss: 3273810.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1757235.5000 - val_loss: 3273783.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1750788.6250 - val_loss: 3273682.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1744710.7500 - val_loss: 3273648.5000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1738919.2500 - val_loss: 3273597.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1733402.5000 - val_loss: 3273583.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1728119.3750 - val_loss: 3273506.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1723053.6250 - val_loss: 3273469.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1718162.8750 - val_loss: 3273409.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1713439.1250 - val_loss: 3273392.5000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1708865.2500 - val_loss: 3273385.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1704431.1250 - val_loss: 3273351.2500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1700128.7500 - val_loss: 3273364.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1695935.2500 - val_loss: 3273311.5000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1691864.0000 - val_loss: 3273249.5000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1687891.6250 - val_loss: 3273209.0000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1684011.5000 - val_loss: 3273231.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1680206.3750 - val_loss: 3273172.7500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1676502.0000 - val_loss: 3273135.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1672870.8750 - val_loss: 3273093.5000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1669312.8750 - val_loss: 3273037.7500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1665820.5000 - val_loss: 3273021.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1662390.5000 - val_loss: 3272994.0000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1659031.8750 - val_loss: 3272939.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1655737.6250 - val_loss: 3272861.7500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1652492.2500 - val_loss: 3272826.2500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1649301.0000 - val_loss: 3272777.2500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1646162.3750 - val_loss: 3272735.5000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1643072.1250 - val_loss: 3272668.7500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1640032.8750 - val_loss: 3272586.5000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1637043.2500 - val_loss: 3272498.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1634093.3750 - val_loss: 3272438.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1631178.3750 - val_loss: 3272338.2500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1628311.3750 - val_loss: 3272257.2500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1625484.0000 - val_loss: 3272169.2500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1622690.2500 - val_loss: 3272059.5000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1619935.1250 - val_loss: 3271994.2500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1617212.7500 - val_loss: 3271919.5000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1614520.5000 - val_loss: 3271851.7500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1611863.6250 - val_loss: 3271794.0000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1609235.1250 - val_loss: 3271725.7500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1606634.7500 - val_loss: 3271625.5000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1604073.5000 - val_loss: 3271523.7500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 18ms/step - loss: 1855965.8750 - val_loss: 3275054.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1826255.5000 - val_loss: 3275637.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1811428.8750 - val_loss: 3276053.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1799731.8750 - val_loss: 3276331.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1789765.2500 - val_loss: 3276549.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1780951.7500 - val_loss: 3276719.5000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 20ms/step - loss: 1854178.1250 - val_loss: 3273349.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1824674.2500 - val_loss: 3273384.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1809703.7500 - val_loss: 3273365.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1797911.8750 - val_loss: 3273245.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1787938.2500 - val_loss: 3273116.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1779125.2500 - val_loss: 3273007.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1771127.6250 - val_loss: 3272915.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1763770.7500 - val_loss: 3272824.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1756917.7500 - val_loss: 3272733.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1750490.1250 - val_loss: 3272626.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1744419.8750 - val_loss: 3272535.0000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1738649.6250 - val_loss: 3272413.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1733140.0000 - val_loss: 3272281.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1727864.3750 - val_loss: 3272182.5000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1722785.3750 - val_loss: 3272071.2500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1717896.0000 - val_loss: 3271921.2500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1713176.7500 - val_loss: 3271801.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1708606.5000 - val_loss: 3271695.2500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1704179.2500 - val_loss: 3271576.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1699870.7500 - val_loss: 3271466.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1695686.2500 - val_loss: 3271397.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1691599.2500 - val_loss: 3271287.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1687623.7500 - val_loss: 3271168.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1683744.8750 - val_loss: 3271047.7500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1679954.5000 - val_loss: 3270952.5000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1676239.8750 - val_loss: 3270842.0000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1672608.8750 - val_loss: 3270730.0000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1669047.2500 - val_loss: 3270616.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1665559.6250 - val_loss: 3270505.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1662136.2500 - val_loss: 3270383.5000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1658774.6250 - val_loss: 3270208.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1655475.7500 - val_loss: 3270041.7500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1652235.3750 - val_loss: 3269904.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1649045.1250 - val_loss: 3269743.5000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1645911.6250 - val_loss: 3269598.2500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1642825.3750 - val_loss: 3269437.5000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1639787.3750 - val_loss: 3269275.2500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1636797.5000 - val_loss: 3269101.7500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1633851.8750 - val_loss: 3268911.5000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1630943.3750 - val_loss: 3268770.2500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1628072.8750 - val_loss: 3268629.2500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1625234.6250 - val_loss: 3268447.5000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1622448.1250 - val_loss: 3268292.5000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1619689.5000 - val_loss: 3268119.2500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1616967.0000 - val_loss: 3267959.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1614278.6250 - val_loss: 3267792.2500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1611620.2500 - val_loss: 3267661.2500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1608991.5000 - val_loss: 3267516.0000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1606391.2500 - val_loss: 3267346.2500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1603824.7500 - val_loss: 3267170.2500\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 27ms/step - loss: 1853651.2500 - val_loss: 3272935.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1823457.6250 - val_loss: 3273137.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1808672.2500 - val_loss: 3273210.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1797004.5000 - val_loss: 3273234.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1787068.5000 - val_loss: 3273198.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1778266.5000 - val_loss: 3273132.0000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 21ms/step - loss: 1856951.6250 - val_loss: 3274238.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1826532.8750 - val_loss: 3274632.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1811685.5000 - val_loss: 3274885.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1799957.7500 - val_loss: 3274959.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1790001.1250 - val_loss: 3275013.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1781193.0000 - val_loss: 3274995.5000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 19ms/step - loss: 1856647.7500 - val_loss: 3274713.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1826233.2500 - val_loss: 3275343.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1811521.8750 - val_loss: 3275713.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1799923.2500 - val_loss: 3275952.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1789916.5000 - val_loss: 3276225.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1780868.2500 - val_loss: 3276373.2500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 19ms/step - loss: 1854441.6250 - val_loss: 3275350.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1824540.7500 - val_loss: 3275962.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1809687.7500 - val_loss: 3276362.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1798010.5000 - val_loss: 3276662.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1788041.1250 - val_loss: 3276911.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 1779240.0000 - val_loss: 3277129.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 9ms/step - loss: 1905682.2500 - val_loss: 3272229.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1893612.1250 - val_loss: 3273881.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1875269.6250 - val_loss: 3274090.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1864906.2500 - val_loss: 3273744.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1859769.1250 - val_loss: 3273428.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1856472.0000 - val_loss: 3273227.2500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 1906120.1250 - val_loss: 3272143.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1895118.8750 - val_loss: 3273556.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1878910.7500 - val_loss: 3274036.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1868573.3750 - val_loss: 3273881.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1863143.7500 - val_loss: 3273576.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1859750.6250 - val_loss: 3273320.5000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 1906254.8750 - val_loss: 3271231.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1895868.7500 - val_loss: 3273131.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1878188.1250 - val_loss: 3273831.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1867248.3750 - val_loss: 3273675.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1861693.8750 - val_loss: 3273345.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1858181.8750 - val_loss: 3273081.0000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 11ms/step - loss: 1905718.8750 - val_loss: 3272178.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1894317.3750 - val_loss: 3274762.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1875377.8750 - val_loss: 3275476.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1863488.7500 - val_loss: 3275186.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1857705.6250 - val_loss: 3274738.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1854154.2500 - val_loss: 3274380.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 13ms/step - loss: 1906070.2500 - val_loss: 3272022.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1895315.1250 - val_loss: 3273361.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1877966.1250 - val_loss: 3273498.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1867178.7500 - val_loss: 3273139.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1861676.2500 - val_loss: 3272842.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1858272.8750 - val_loss: 3272664.5000\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 9ms/step - loss: 1905267.0000 - val_loss: 3272973.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1892165.3750 - val_loss: 3274257.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1874277.8750 - val_loss: 3274452.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1864723.0000 - val_loss: 3274158.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1859893.6250 - val_loss: 3273859.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1856711.2500 - val_loss: 3273639.7500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 1906150.1250 - val_loss: 3271731.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1895301.5000 - val_loss: 3273691.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1878486.2500 - val_loss: 3274237.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1868495.8750 - val_loss: 3274060.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1863402.8750 - val_loss: 3273741.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1860097.5000 - val_loss: 3273475.2500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 11ms/step - loss: 1905867.0000 - val_loss: 3272318.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1893324.5000 - val_loss: 3274070.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1874812.5000 - val_loss: 3274336.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1864937.6250 - val_loss: 3274145.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1860095.3750 - val_loss: 3273944.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1856930.8750 - val_loss: 3273807.0000\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 11s 48ms/step - loss: 1905276.1250 - val_loss: 3272414.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1892789.7500 - val_loss: 3273583.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1874800.1250 - val_loss: 3273658.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1864140.3750 - val_loss: 3273424.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1858906.7500 - val_loss: 3273249.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1855600.1250 - val_loss: 3273142.0000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 1905857.2500 - val_loss: 3272771.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1895000.2500 - val_loss: 3274364.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1878862.5000 - val_loss: 3274663.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1868956.3750 - val_loss: 3274421.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1863709.0000 - val_loss: 3274161.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1860315.8750 - val_loss: 3273983.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 20ms/step - loss: 1906778.6250 - val_loss: 3272199.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1901806.7500 - val_loss: 3273546.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1892148.0000 - val_loss: 3274345.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1880159.7500 - val_loss: 3274565.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1871092.6250 - val_loss: 3274482.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1865645.8750 - val_loss: 3274345.7500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 14ms/step - loss: 1906645.8750 - val_loss: 3272630.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1901193.0000 - val_loss: 3273907.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1890902.6250 - val_loss: 3274843.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1879319.3750 - val_loss: 3275322.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1870996.3750 - val_loss: 3275484.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1865720.5000 - val_loss: 3275454.2500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 15ms/step - loss: 1906770.6250 - val_loss: 3273227.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1901315.2500 - val_loss: 3274440.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1890414.2500 - val_loss: 3275179.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1878309.6250 - val_loss: 3275457.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1870092.3750 - val_loss: 3275427.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1865116.6250 - val_loss: 3275270.0000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 18ms/step - loss: 1906572.2500 - val_loss: 3272740.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1899925.0000 - val_loss: 3273638.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1888997.8750 - val_loss: 3274223.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1878973.1250 - val_loss: 3274639.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1871550.1250 - val_loss: 3274836.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1866482.1250 - val_loss: 3274857.7500\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 20ms/step - loss: 1906363.7500 - val_loss: 3272984.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1899809.5000 - val_loss: 3274267.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1887780.7500 - val_loss: 3275081.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1876369.6250 - val_loss: 3275399.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1869154.2500 - val_loss: 3275438.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1864728.2500 - val_loss: 3275342.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 14ms/step - loss: 1907385.6250 - val_loss: 3272132.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1903439.2500 - val_loss: 3273463.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1895345.7500 - val_loss: 3274368.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1884157.0000 - val_loss: 3274775.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1875029.2500 - val_loss: 3274822.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1869174.0000 - val_loss: 3274675.5000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 15ms/step - loss: 1907111.5000 - val_loss: 3272055.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1902514.6250 - val_loss: 3273453.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1893700.7500 - val_loss: 3274187.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1883504.3750 - val_loss: 3274395.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1876257.1250 - val_loss: 3274350.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1871759.5000 - val_loss: 3274203.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 20ms/step - loss: 1906795.1250 - val_loss: 3272449.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1901559.7500 - val_loss: 3274188.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1890983.7500 - val_loss: 3275385.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1878856.3750 - val_loss: 3275926.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1870426.6250 - val_loss: 3276046.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1865227.3750 - val_loss: 3275955.2500\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 3s 14ms/step - loss: 1907011.6250 - val_loss: 3272007.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1902145.6250 - val_loss: 3273374.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1892426.6250 - val_loss: 3274190.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1881041.0000 - val_loss: 3274505.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1873034.0000 - val_loss: 3274523.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1867996.5000 - val_loss: 3274405.2500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 16ms/step - loss: 1906929.5000 - val_loss: 3271685.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1902250.0000 - val_loss: 3272403.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1894144.7500 - val_loss: 3272927.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1883941.0000 - val_loss: 3273285.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1875121.5000 - val_loss: 3273406.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1868983.0000 - val_loss: 3273353.5000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 26ms/step - loss: 1907240.7500 - val_loss: 3273222.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1904620.3750 - val_loss: 3274515.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1900729.6250 - val_loss: 3275556.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1894674.8750 - val_loss: 3276318.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1887123.7500 - val_loss: 3276785.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1879858.1250 - val_loss: 3276986.5000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 21ms/step - loss: 1907768.7500 - val_loss: 3272042.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1905526.2500 - val_loss: 3273302.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1902145.5000 - val_loss: 3274347.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1896804.5000 - val_loss: 3275152.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1890056.6250 - val_loss: 3275682.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1883542.8750 - val_loss: 3275986.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 25ms/step - loss: 1907217.0000 - val_loss: 3273147.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1904345.1250 - val_loss: 3274195.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1899961.6250 - val_loss: 3274957.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1893619.8750 - val_loss: 3275473.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1886322.6250 - val_loss: 3275806.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1879653.0000 - val_loss: 3275989.2500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 20ms/step - loss: 1907692.8750 - val_loss: 3270756.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1905433.8750 - val_loss: 3271519.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1902197.6250 - val_loss: 3272061.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1897285.0000 - val_loss: 3272593.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1890596.5000 - val_loss: 3273119.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1883131.5000 - val_loss: 3273548.5000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 28ms/step - loss: 1907630.1250 - val_loss: 3271719.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1905170.2500 - val_loss: 3273058.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1901429.0000 - val_loss: 3274045.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1895617.8750 - val_loss: 3274711.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1888400.7500 - val_loss: 3275107.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1881485.7500 - val_loss: 3275293.0000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 21ms/step - loss: 1907772.3750 - val_loss: 3272133.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1905556.6250 - val_loss: 3273434.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1902028.7500 - val_loss: 3274404.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1896113.6250 - val_loss: 3275019.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1888636.0000 - val_loss: 3275402.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1881574.0000 - val_loss: 3275629.2500\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 19ms/step - loss: 1907831.3750 - val_loss: 3269985.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1905659.8750 - val_loss: 3271099.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1902822.8750 - val_loss: 3272100.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1898503.2500 - val_loss: 3273021.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1892274.3750 - val_loss: 3273787.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1884820.5000 - val_loss: 3274309.2500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 23ms/step - loss: 1907776.2500 - val_loss: 3271878.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1905639.3750 - val_loss: 3273015.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1902609.2500 - val_loss: 3273838.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1897791.8750 - val_loss: 3274501.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1891140.0000 - val_loss: 3274990.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1883989.1250 - val_loss: 3275276.5000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 19ms/step - loss: 1907891.8750 - val_loss: 3271073.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1905844.6250 - val_loss: 3272068.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1902897.8750 - val_loss: 3272849.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1898222.8750 - val_loss: 3273488.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1892027.5000 - val_loss: 3273996.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 1885653.6250 - val_loss: 3274334.0000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 26ms/step - loss: 1907638.5000 - val_loss: 3271310.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1905322.7500 - val_loss: 3272410.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1902221.0000 - val_loss: 3273185.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1897699.6250 - val_loss: 3273837.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1891697.6250 - val_loss: 3274392.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1885026.6250 - val_loss: 3274808.2500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 10ms/step - loss: 638194.8750 - val_loss: 625705.3125\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 45846.7578 - val_loss: 499267.4062\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 23840.4375 - val_loss: 511039.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 6273.5894 - val_loss: 443017.6562\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3381.5496 - val_loss: 319100.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3481.1465 - val_loss: 830254.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1885.2263 - val_loss: 1018655.6875\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2188.3574 - val_loss: 1001574.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2089.6348 - val_loss: 1371639.8750\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1798.1835 - val_loss: 1507065.1250\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 13ms/step - loss: 794530.2500 - val_loss: 772658.6250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 79155.5781 - val_loss: 377524.0625\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 33927.9844 - val_loss: 2042617.1250\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 6952.8481 - val_loss: 2344579.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3998.2324 - val_loss: 1859387.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2478.6606 - val_loss: 2125213.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2625.9321 - val_loss: 2311511.2500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 11ms/step - loss: 618390.1875 - val_loss: 1505414.1250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 45845.4102 - val_loss: 1033713.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 13603.3096 - val_loss: 1247289.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 5988.9648 - val_loss: 1096024.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 4021.1719 - val_loss: 1089258.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 5456.0610 - val_loss: 1299425.1250\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3112.3406 - val_loss: 1826723.6250\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 673303.4375 - val_loss: 2339324.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 50323.2422 - val_loss: 2446663.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 9201.8174 - val_loss: 2403990.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3994.0081 - val_loss: 2603495.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2492.1167 - val_loss: 2713759.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2056.1226 - val_loss: 2823131.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 12ms/step - loss: 609246.7500 - val_loss: 2696839.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 48696.1875 - val_loss: 2551973.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 16183.7764 - val_loss: 2598104.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 4804.7251 - val_loss: 2463933.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 4488.2153 - val_loss: 2066813.8750\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2904.4958 - val_loss: 2141592.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1914.8617 - val_loss: 2008049.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1661.4327 - val_loss: 1661862.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1332.0995 - val_loss: 1599417.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1199.9132 - val_loss: 1238575.1250\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 978.4829 - val_loss: 1190654.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1115.7662 - val_loss: 1328634.6250\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1055.5070 - val_loss: 1168613.8750\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1016.1428 - val_loss: 1143909.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 961.9459 - val_loss: 1259936.1250\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1013.4934 - val_loss: 1486103.8750\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1001.2466 - val_loss: 1551941.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 948.9858 - val_loss: 1921141.3750\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 880.7201 - val_loss: 1503346.5000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 10ms/step - loss: 550595.9375 - val_loss: 2619596.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 38630.6992 - val_loss: 2371946.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 9627.1885 - val_loss: 2400244.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 4426.4072 - val_loss: 1385029.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3063.5364 - val_loss: 1636985.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2383.5454 - val_loss: 2210802.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1814.7003 - val_loss: 2201710.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1708.9427 - val_loss: 1939790.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1548.0266 - val_loss: 1824651.3750\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 10ms/step - loss: 590619.5625 - val_loss: 1230909.8750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 66938.4766 - val_loss: 2917216.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 19153.8984 - val_loss: 394148.4688\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 4844.7466 - val_loss: 355778.6875\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2986.3120 - val_loss: 375035.6875\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2744.4961 - val_loss: 554114.3125\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3093.5354 - val_loss: 769381.4375\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3730.2009 - val_loss: 1057582.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3358.4895 - val_loss: 1088234.1250\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 11ms/step - loss: 597453.8125 - val_loss: 1209534.1250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 47078.0508 - val_loss: 1300587.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 22193.2832 - val_loss: 1235569.8750\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 15429.5195 - val_loss: 814580.6875\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3467.1760 - val_loss: 846554.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 4864.1895 - val_loss: 1543006.1250\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3185.8992 - val_loss: 1398835.8750\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2322.3965 - val_loss: 1224901.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1986.6337 - val_loss: 1289820.5000\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 13ms/step - loss: 659279.7500 - val_loss: 3319853.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 76614.8359 - val_loss: 2027766.3750\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 41657.8906 - val_loss: 1060428.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 4059.1653 - val_loss: 575692.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2985.4810 - val_loss: 538657.5625\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2674.5076 - val_loss: 455967.5312\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3390.0090 - val_loss: 624444.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2169.8662 - val_loss: 562125.3750\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2209.1106 - val_loss: 593014.3125\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3210.6094 - val_loss: 526581.5625\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2957.0793 - val_loss: 471416.4688\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 589423.5000 - val_loss: 2630163.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 48712.2695 - val_loss: 2187920.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 23663.5000 - val_loss: 1636611.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 5111.3135 - val_loss: 2086563.3750\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3503.6648 - val_loss: 2361024.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2774.5161 - val_loss: 2462211.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2938.9048 - val_loss: 2286074.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2856.9668 - val_loss: 1714649.6250\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 15ms/step - loss: 1105360.6250 - val_loss: 2861259.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 239696.7812 - val_loss: 2759062.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 62000.0508 - val_loss: 2761782.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 49372.6328 - val_loss: 2648569.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 10244.4189 - val_loss: 2503697.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 4633.3335 - val_loss: 2685266.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 3195.2551 - val_loss: 2678316.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 2416.1628 - val_loss: 2779237.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1985.0154 - val_loss: 2913223.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1923.8220 - val_loss: 2895399.7500\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 18ms/step - loss: 1111242.7500 - val_loss: 1327328.1250\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 240830.6094 - val_loss: 608987.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 61429.3594 - val_loss: 424775.4375\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 44600.2070 - val_loss: 1082390.8750\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 20264.0215 - val_loss: 1801946.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 8532.9639 - val_loss: 1303227.1250\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 5563.5830 - val_loss: 1715759.8750\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 3787.7317 - val_loss: 1884886.6250\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 20ms/step - loss: 1068621.2500 - val_loss: 3041296.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 218102.9844 - val_loss: 3061914.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 57087.4258 - val_loss: 3164186.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 46268.5273 - val_loss: 448783.0938\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 12140.9893 - val_loss: 457034.5625\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 6327.7612 - val_loss: 442914.0938\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 4127.1938 - val_loss: 447255.0312\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 3170.7827 - val_loss: 474835.2812\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 2541.9451 - val_loss: 512925.8125\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 2020.9226 - val_loss: 486243.3438\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 2137.7524 - val_loss: 558481.1250\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 15ms/step - loss: 1091208.2500 - val_loss: 3180876.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 231523.7969 - val_loss: 3294798.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 59275.5547 - val_loss: 3396353.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 30098.2148 - val_loss: 1047036.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 6119.2163 - val_loss: 1265035.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 2884.9233 - val_loss: 862848.5625\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 2577.2405 - val_loss: 771212.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1972.4658 - val_loss: 571921.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1570.1790 - val_loss: 533259.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1554.3784 - val_loss: 566637.3125\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1353.8877 - val_loss: 507519.9375\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1394.4523 - val_loss: 479102.6250\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1079.5021 - val_loss: 492674.5625\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1049.0583 - val_loss: 637341.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1255.4309 - val_loss: 481576.9688\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1052.7555 - val_loss: 478841.9062\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 962.6559 - val_loss: 646143.0625\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1230.6021 - val_loss: 900739.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1252.9106 - val_loss: 763872.4375\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1166.1395 - val_loss: 923241.8125\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 858.5214 - val_loss: 587215.5625\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 19ms/step - loss: 1219900.2500 - val_loss: 2322471.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 353381.7500 - val_loss: 2249808.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 94477.0234 - val_loss: 2053541.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 45242.2070 - val_loss: 1417714.8750\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 27327.8398 - val_loss: 2809887.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 5862.3184 - val_loss: 2413071.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 3245.2043 - val_loss: 2483428.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 3247.5256 - val_loss: 2530686.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 3137.6494 - val_loss: 2416989.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 17ms/step - loss: 1094353.2500 - val_loss: 2983228.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 237788.0625 - val_loss: 3095929.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 61657.0938 - val_loss: 3091460.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 42761.0156 - val_loss: 1505166.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 11391.0361 - val_loss: 1734793.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 4697.2056 - val_loss: 2192648.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 3133.5786 - val_loss: 2399906.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 2144.8271 - val_loss: 2374803.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1843.5596 - val_loss: 2502489.7500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 15ms/step - loss: 1131120.2500 - val_loss: 2849716.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 274883.7188 - val_loss: 2815385.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 69832.4375 - val_loss: 2876172.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 43079.7070 - val_loss: 2798661.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 16440.4551 - val_loss: 2131198.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 8471.9922 - val_loss: 1706319.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 4199.6885 - val_loss: 1902782.6250\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 3041.1665 - val_loss: 2144967.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 2239.1113 - val_loss: 2528327.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 2112.3826 - val_loss: 2476985.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1678.8785 - val_loss: 2447784.2500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 14ms/step - loss: 1099843.3750 - val_loss: 3032881.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 188451.3906 - val_loss: 3204922.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 55136.4258 - val_loss: 1975180.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 24029.2871 - val_loss: 460024.7188\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 7454.2632 - val_loss: 570339.5625\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 4507.9912 - val_loss: 701366.0625\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 3091.1494 - val_loss: 553527.4375\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 2301.7817 - val_loss: 435596.8125\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 2200.4155 - val_loss: 442258.9375\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1787.3923 - val_loss: 410006.8750\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1567.7250 - val_loss: 450137.4062\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1192.8588 - val_loss: 421986.5312\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 907.3922 - val_loss: 428024.1875\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1122.9270 - val_loss: 382439.6562\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1471.6372 - val_loss: 374351.8125\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1449.7485 - val_loss: 390925.9688\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1422.3669 - val_loss: 765576.9375\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1734.8916 - val_loss: 539168.9375\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1316.9836 - val_loss: 568353.0625\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1156.6747 - val_loss: 644005.5625\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 13s 100ms/step - loss: 1067655.3750 - val_loss: 3023678.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 208482.4375 - val_loss: 2989302.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 55462.9492 - val_loss: 3056838.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 40838.6094 - val_loss: 1924834.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 8865.2832 - val_loss: 3201605.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 4770.9819 - val_loss: 3222904.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 3104.6401 - val_loss: 3146482.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 2746.3059 - val_loss: 3012999.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1833.2194 - val_loss: 2946164.2500\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 16ms/step - loss: 1095550.7500 - val_loss: 2541986.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 228874.1875 - val_loss: 2629457.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 59316.7930 - val_loss: 2565158.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 85059.5469 - val_loss: 1424347.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 16325.1963 - val_loss: 1344431.8750\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 7717.8408 - val_loss: 1354962.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 4017.4072 - val_loss: 1277998.3750\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 3187.5190 - val_loss: 1388979.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 2597.3152 - val_loss: 1390719.3750\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 2175.6409 - val_loss: 1407354.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1854.0392 - val_loss: 1423111.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1766.5280 - val_loss: 1363392.5000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 23ms/step - loss: 1458585.3750 - val_loss: 3418223.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 727814.1875 - val_loss: 3519192.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 328162.0312 - val_loss: 3593557.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 144544.7344 - val_loss: 3645012.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 72657.4141 - val_loss: 3666930.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 48853.2109 - val_loss: 3658807.7500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 23ms/step - loss: 1468829.1250 - val_loss: 3004170.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 739557.5000 - val_loss: 2836441.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 330181.1250 - val_loss: 2807663.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 130893.4453 - val_loss: 2885360.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 64203.8945 - val_loss: 2963356.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 45856.8672 - val_loss: 3178539.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 37339.2539 - val_loss: 3363268.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 19415.2422 - val_loss: 3077064.2500\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 28ms/step - loss: 1472216.0000 - val_loss: 2688381.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 750343.8125 - val_loss: 2806486.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 349606.7812 - val_loss: 2984246.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 157481.4688 - val_loss: 3082145.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 79482.4375 - val_loss: 3205538.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 51705.3906 - val_loss: 3342143.5000\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 23ms/step - loss: 1510767.0000 - val_loss: 2973510.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 823853.0000 - val_loss: 2863270.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 407316.2500 - val_loss: 2992046.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 190614.2344 - val_loss: 2839011.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 89336.3516 - val_loss: 2780373.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 54487.7812 - val_loss: 2813597.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 46433.7578 - val_loss: 1093773.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 20571.7090 - val_loss: 967674.3125\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 8555.2119 - val_loss: 943088.4375\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 4827.2573 - val_loss: 813609.0625\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 3016.3203 - val_loss: 760434.6250\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2193.3684 - val_loss: 881127.4375\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1739.7927 - val_loss: 972118.1875\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1437.3224 - val_loss: 838699.9375\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1449.5011 - val_loss: 781934.7500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1120.0378 - val_loss: 602175.8750\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1026.4677 - val_loss: 557783.5000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 865.5850 - val_loss: 530811.8750\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 844.5790 - val_loss: 448191.1250\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 765.4910 - val_loss: 446935.3125\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 731.7585 - val_loss: 453164.7188\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 764.9052 - val_loss: 441197.9688\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 624.4118 - val_loss: 474836.1875\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 732.4352 - val_loss: 450428.1250\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 673.5950 - val_loss: 399881.7188\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 622.2689 - val_loss: 413417.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 538.9285 - val_loss: 380368.7500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 495.1842 - val_loss: 380951.8125\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 508.4080 - val_loss: 391512.1250\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 485.2467 - val_loss: 418679.1562\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 439.5851 - val_loss: 447656.3125\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 483.0182 - val_loss: 468877.5938\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 6s 31ms/step - loss: 1424099.2500 - val_loss: 3329745.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 652475.5000 - val_loss: 3377652.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 266350.8750 - val_loss: 3388003.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 110087.5391 - val_loss: 3423297.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 58255.6367 - val_loss: 3466209.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 46157.3477 - val_loss: 2412713.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 42031.9922 - val_loss: 1545702.6250\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 10035.1523 - val_loss: 1599856.1250\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 5724.7852 - val_loss: 1397936.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 3912.9197 - val_loss: 1433743.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 2859.2166 - val_loss: 1438215.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 2174.7043 - val_loss: 1384429.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1974.3862 - val_loss: 1262515.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1552.6809 - val_loss: 1208275.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1308.5693 - val_loss: 1207812.2500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1129.7100 - val_loss: 1203058.1250\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1046.9561 - val_loss: 1146972.1250\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 853.2178 - val_loss: 1147762.2500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 825.9686 - val_loss: 1035769.3125\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 812.5640 - val_loss: 1051530.0000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 851.2065 - val_loss: 1145693.8750\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 744.1327 - val_loss: 1237967.1250\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 732.6732 - val_loss: 1114298.3750\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 750.6490 - val_loss: 1114262.8750\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 24ms/step - loss: 1467915.0000 - val_loss: 3183110.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 747193.8750 - val_loss: 3198135.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 346801.5938 - val_loss: 3254697.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 155896.4844 - val_loss: 3351673.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 78130.7734 - val_loss: 3392710.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 51118.9844 - val_loss: 3428629.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 27ms/step - loss: 1448212.6250 - val_loss: 3398588.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 705326.5625 - val_loss: 3405933.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 311672.3438 - val_loss: 3422188.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 134919.7500 - val_loss: 3457979.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 68116.6250 - val_loss: 3487692.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 97252.3750 - val_loss: 2736618.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 75538.1797 - val_loss: 1731938.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 24916.8203 - val_loss: 1738532.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 14613.2510 - val_loss: 1744090.1250\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 10692.1953 - val_loss: 1698649.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 8618.7080 - val_loss: 1646117.8750\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 6375.2837 - val_loss: 1621809.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 4883.7803 - val_loss: 1624404.8750\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 3887.6702 - val_loss: 1625279.5000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 3467.7329 - val_loss: 1750272.7500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 2816.8806 - val_loss: 1768133.8750\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2469.1035 - val_loss: 1751839.5000\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 21ms/step - loss: 1451215.8750 - val_loss: 3289916.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 706445.7500 - val_loss: 3309131.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 311244.2188 - val_loss: 3321692.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 132413.0625 - val_loss: 3398237.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 51609.6133 - val_loss: 3484822.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 31281.7910 - val_loss: 1016088.9375\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 10306.1504 - val_loss: 1004121.5625\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 6465.9658 - val_loss: 1041882.1250\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 4712.3740 - val_loss: 970423.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3743.4114 - val_loss: 849622.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 3642.1211 - val_loss: 799008.4375\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2566.1147 - val_loss: 640001.6250\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2067.3293 - val_loss: 655593.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1867.5714 - val_loss: 647418.6250\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1609.4291 - val_loss: 640508.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1388.7681 - val_loss: 710830.6250\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1209.9281 - val_loss: 630690.0000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1143.1519 - val_loss: 596702.6250\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1074.5596 - val_loss: 657335.1250\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1034.3010 - val_loss: 672427.6875\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1352.1289 - val_loss: 744344.3750\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1386.0638 - val_loss: 756272.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1028.7914 - val_loss: 787771.3125\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 22ms/step - loss: 1445879.6250 - val_loss: 3212577.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 699032.3750 - val_loss: 3272079.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 305487.0312 - val_loss: 3286558.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 131417.8594 - val_loss: 3329187.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 67058.4062 - val_loss: 3343805.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 120476.2422 - val_loss: 1999460.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 245112.4062 - val_loss: 1457618.3750\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 24784.7266 - val_loss: 1430146.1250\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 17074.0039 - val_loss: 1447991.3750\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 10680.1670 - val_loss: 1446385.6250\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 7708.6880 - val_loss: 1442067.0000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 5632.8931 - val_loss: 1439440.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 4346.3452 - val_loss: 1425502.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 3519.2961 - val_loss: 1408650.8750\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 3132.9060 - val_loss: 1428804.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2656.3167 - val_loss: 1432349.0000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2717.3242 - val_loss: 1441283.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2197.2056 - val_loss: 1442155.3750\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1896.4966 - val_loss: 1446126.5000\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 23ms/step - loss: 1464385.1250 - val_loss: 3396961.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 743537.5000 - val_loss: 3434660.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 344563.7188 - val_loss: 3571138.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 154769.6406 - val_loss: 3636663.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 77924.6875 - val_loss: 3676029.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 51245.0938 - val_loss: 3671675.0000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 11ms/step - loss: 1609369.1250 - val_loss: 3229971.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1147408.6250 - val_loss: 3179142.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 801562.0000 - val_loss: 3165289.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 545444.5625 - val_loss: 3171251.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 361971.0000 - val_loss: 3164102.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 235874.1094 - val_loss: 3190804.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 152894.5000 - val_loss: 3200227.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 101142.0781 - val_loss: 3223759.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 71005.6875 - val_loss: 3248031.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 54709.1523 - val_loss: 3282004.7500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 11ms/step - loss: 1608623.7500 - val_loss: 3213012.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1143814.0000 - val_loss: 3198714.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 797243.5000 - val_loss: 3206507.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 541907.0000 - val_loss: 3231447.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 359382.9688 - val_loss: 3247757.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 233833.5938 - val_loss: 3246867.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 151393.7969 - val_loss: 3267347.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 13ms/step - loss: 1606506.2500 - val_loss: 3195742.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1143790.1250 - val_loss: 3136029.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 798482.0000 - val_loss: 3084917.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 543285.1875 - val_loss: 3040251.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 360399.2812 - val_loss: 3022318.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 234493.6875 - val_loss: 3007178.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 151777.5156 - val_loss: 3000254.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 100475.3281 - val_loss: 3000875.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 70717.0938 - val_loss: 3008995.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 54637.5156 - val_loss: 3028907.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 46595.0625 - val_loss: 2969280.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 49501.8438 - val_loss: 1259165.8750\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 30609.6836 - val_loss: 1169644.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 21332.6523 - val_loss: 1162866.6250\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 15589.7354 - val_loss: 1114538.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 11584.5352 - val_loss: 1106462.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 8751.2588 - val_loss: 1113514.1250\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 6717.2881 - val_loss: 1234692.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 5204.5234 - val_loss: 1304943.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 4163.9346 - val_loss: 1360514.6250\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3315.1843 - val_loss: 1382040.6250\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 11ms/step - loss: 1610384.2500 - val_loss: 3243930.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1153240.6250 - val_loss: 3226957.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 804957.6250 - val_loss: 3217729.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 548267.5625 - val_loss: 3201886.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 364641.1875 - val_loss: 3208907.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 237902.7969 - val_loss: 3211747.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 154363.4219 - val_loss: 3218439.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 102313.5000 - val_loss: 3246302.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 71906.2109 - val_loss: 3277349.2500\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 1603485.3750 - val_loss: 3233729.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1141527.7500 - val_loss: 3146340.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 796483.6250 - val_loss: 3064475.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 541932.5625 - val_loss: 3041073.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 359485.1250 - val_loss: 3056881.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 233815.2656 - val_loss: 3066204.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 151410.1250 - val_loss: 3122403.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 100203.5469 - val_loss: 3143417.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 70384.4297 - val_loss: 3186195.0000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 1615621.6250 - val_loss: 3259600.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1158485.5000 - val_loss: 3238162.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 815239.7500 - val_loss: 3233099.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 559579.6250 - val_loss: 3237167.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 371754.5000 - val_loss: 3234385.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 241268.1875 - val_loss: 3249607.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 156292.4844 - val_loss: 3260252.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 103274.8672 - val_loss: 3266547.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 12ms/step - loss: 1601983.7500 - val_loss: 3172902.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1138836.3750 - val_loss: 3094488.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 794445.2500 - val_loss: 3048423.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 540378.2500 - val_loss: 3018033.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 358223.5312 - val_loss: 3018552.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 232921.0938 - val_loss: 3027302.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 150837.7969 - val_loss: 3046844.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 100092.4141 - val_loss: 3073516.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 70431.4141 - val_loss: 3148617.7500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 11ms/step - loss: 1606464.5000 - val_loss: 3211522.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1146485.2500 - val_loss: 3158177.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 798810.4375 - val_loss: 3127745.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 541859.3125 - val_loss: 3083756.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 358839.0312 - val_loss: 3059330.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 233198.3281 - val_loss: 3049514.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 150648.3594 - val_loss: 3043677.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 99486.9766 - val_loss: 3035978.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 69972.2656 - val_loss: 3055386.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 54179.4766 - val_loss: 3054413.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 46387.2578 - val_loss: 2929332.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 57894.3164 - val_loss: 2685408.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 25602.5645 - val_loss: 2668457.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 18855.5195 - val_loss: 2621832.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 13997.9609 - val_loss: 2574537.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 10561.6562 - val_loss: 2551541.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 8165.5894 - val_loss: 2473636.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 6340.6919 - val_loss: 2539768.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 4942.8916 - val_loss: 2541715.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3945.0874 - val_loss: 2550241.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3219.3022 - val_loss: 2560209.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2614.1099 - val_loss: 2602890.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 10ms/step - loss: 1606379.3750 - val_loss: 3253756.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1144434.7500 - val_loss: 3233085.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 799086.1875 - val_loss: 3247605.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 544028.0000 - val_loss: 3242867.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 361120.9062 - val_loss: 3236814.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 234934.0312 - val_loss: 3236893.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 152075.6875 - val_loss: 3258689.2500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 1605758.8750 - val_loss: 3248528.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1143007.5000 - val_loss: 3243314.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 797376.3750 - val_loss: 3255459.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 542559.3750 - val_loss: 3252914.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 360026.0312 - val_loss: 3258061.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 234312.1875 - val_loss: 3265746.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 151848.2656 - val_loss: 3285926.0000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 14ms/step - loss: 1744464.5000 - val_loss: 3265176.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1472506.0000 - val_loss: 3235164.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1242549.0000 - val_loss: 3209239.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1042882.2500 - val_loss: 3193397.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 870078.1875 - val_loss: 3190565.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 721145.8750 - val_loss: 3185551.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 593821.3125 - val_loss: 3183547.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 485684.8125 - val_loss: 3195038.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 394792.1250 - val_loss: 3191668.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 319079.4688 - val_loss: 3188090.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 256576.2656 - val_loss: 3186823.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 205829.6406 - val_loss: 3202484.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 16ms/step - loss: 1740390.1250 - val_loss: 3277283.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1471727.7500 - val_loss: 3271877.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1242689.1250 - val_loss: 3265062.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1043536.7500 - val_loss: 3266798.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 870848.7500 - val_loss: 3266814.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 722083.3125 - val_loss: 3271490.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 594768.5625 - val_loss: 3276236.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 486543.4375 - val_loss: 3272950.2500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 17ms/step - loss: 1740670.3750 - val_loss: 3263538.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1471221.7500 - val_loss: 3259571.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1241755.1250 - val_loss: 3246928.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1042587.8750 - val_loss: 3240835.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 869840.6250 - val_loss: 3236106.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 720938.1250 - val_loss: 3236199.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 593466.5000 - val_loss: 3252876.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 485397.3125 - val_loss: 3252610.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 394600.3750 - val_loss: 3250004.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 318877.9688 - val_loss: 3247670.0000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 16ms/step - loss: 1740752.5000 - val_loss: 3225276.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1470584.0000 - val_loss: 3192728.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1241089.1250 - val_loss: 3165446.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1041823.2500 - val_loss: 3145211.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 869211.6250 - val_loss: 3134467.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 720598.5000 - val_loss: 3120309.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 593426.5000 - val_loss: 3118728.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 485488.5312 - val_loss: 3103287.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 394531.9062 - val_loss: 3102973.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 318834.7500 - val_loss: 3109276.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 256593.8125 - val_loss: 3122603.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 205947.7188 - val_loss: 3133568.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 165262.7969 - val_loss: 3138327.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 133149.7656 - val_loss: 3138117.7500\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 15ms/step - loss: 1743968.6250 - val_loss: 3269198.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1473564.5000 - val_loss: 3262225.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1244015.2500 - val_loss: 3251602.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1044684.3125 - val_loss: 3238700.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 871917.2500 - val_loss: 3233477.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 722889.3125 - val_loss: 3225817.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 595434.8750 - val_loss: 3228217.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 487089.6562 - val_loss: 3235999.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 395852.4688 - val_loss: 3240400.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 319934.5625 - val_loss: 3238749.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 257491.2656 - val_loss: 3244135.5000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 15ms/step - loss: 1742503.6250 - val_loss: 3277455.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1472362.3750 - val_loss: 3272340.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1242906.0000 - val_loss: 3267820.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1043453.6875 - val_loss: 3268337.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 870777.6250 - val_loss: 3269681.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 721974.9375 - val_loss: 3273281.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 594443.3125 - val_loss: 3269113.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 486192.5312 - val_loss: 3264612.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 395187.7812 - val_loss: 3262454.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 319454.5938 - val_loss: 3266681.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 257080.0625 - val_loss: 3265984.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 206342.6562 - val_loss: 3265467.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 165545.2969 - val_loss: 3265428.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 133327.5469 - val_loss: 3266084.7500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 15ms/step - loss: 1740111.0000 - val_loss: 3249708.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1470328.3750 - val_loss: 3248741.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1241100.5000 - val_loss: 3243432.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1041882.1875 - val_loss: 3238258.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 869304.1250 - val_loss: 3237483.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 720586.1875 - val_loss: 3231074.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 593270.3750 - val_loss: 3231000.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 485206.5000 - val_loss: 3241318.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 394317.7812 - val_loss: 3256806.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 318695.6250 - val_loss: 3259959.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 256429.6094 - val_loss: 3258858.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 205793.1875 - val_loss: 3257955.0000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 15ms/step - loss: 1742603.0000 - val_loss: 3276475.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1475310.1250 - val_loss: 3267461.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1247554.6250 - val_loss: 3255159.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1049743.8750 - val_loss: 3248473.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 877910.9375 - val_loss: 3244784.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 729380.0625 - val_loss: 3243408.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 602000.9375 - val_loss: 3250042.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 493507.9375 - val_loss: 3246143.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 402121.0625 - val_loss: 3250080.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 325964.9375 - val_loss: 3248271.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 262987.5938 - val_loss: 3247074.0000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 15ms/step - loss: 1742425.1250 - val_loss: 3274051.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1473418.3750 - val_loss: 3273196.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1243945.6250 - val_loss: 3275061.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1044658.8125 - val_loss: 3279926.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 871926.8125 - val_loss: 3278862.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 723019.1250 - val_loss: 3282907.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 595539.1250 - val_loss: 3286696.7500\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 15ms/step - loss: 1741169.6250 - val_loss: 3259433.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1472185.0000 - val_loss: 3253605.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1242851.6250 - val_loss: 3247222.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1043574.1250 - val_loss: 3245237.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 870889.5000 - val_loss: 3252202.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 722099.1250 - val_loss: 3246975.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 594614.8750 - val_loss: 3249744.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 486441.2500 - val_loss: 3242014.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 395400.3438 - val_loss: 3235668.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 319670.8438 - val_loss: 3230503.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 257335.2969 - val_loss: 3227474.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 206517.5000 - val_loss: 3241262.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 165699.5938 - val_loss: 3244208.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 133416.8125 - val_loss: 3245090.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 108324.5078 - val_loss: 3246720.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 89139.1562 - val_loss: 3258804.2500\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 22ms/step - loss: 1812659.1250 - val_loss: 3275256.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1663273.3750 - val_loss: 3278520.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1529825.1250 - val_loss: 3278545.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1406248.2500 - val_loss: 3275480.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1291113.5000 - val_loss: 3273490.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1183836.6250 - val_loss: 3271771.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1083900.2500 - val_loss: 3271627.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 990913.8125 - val_loss: 3272785.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 904423.2500 - val_loss: 3274846.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 824100.7500 - val_loss: 3277843.5000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 749485.8750 - val_loss: 3276926.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 680430.3750 - val_loss: 3280176.0000\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 20ms/step - loss: 1812342.3750 - val_loss: 3270489.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1662957.8750 - val_loss: 3270788.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1529173.3750 - val_loss: 3271074.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1405684.5000 - val_loss: 3268613.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1290365.5000 - val_loss: 3264561.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1183051.0000 - val_loss: 3261641.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1083109.7500 - val_loss: 3258512.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 989940.6875 - val_loss: 3258250.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 903423.5625 - val_loss: 3256173.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 822880.6250 - val_loss: 3252934.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 748507.6250 - val_loss: 3249723.5000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 679581.1875 - val_loss: 3249463.0000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 616004.1250 - val_loss: 3245146.2500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 557387.5625 - val_loss: 3241469.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 503455.2500 - val_loss: 3242137.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 454151.9375 - val_loss: 3239434.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 408941.0938 - val_loss: 3236098.7500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 367789.4375 - val_loss: 3233535.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 330095.8438 - val_loss: 3231252.2500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 296027.3125 - val_loss: 3232606.5000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 265008.3125 - val_loss: 3234730.5000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 237130.3125 - val_loss: 3233736.2500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 212145.7188 - val_loss: 3233991.0000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 189823.5156 - val_loss: 3239538.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 21ms/step - loss: 1816664.3750 - val_loss: 3275387.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1667071.3750 - val_loss: 3279270.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1533113.7500 - val_loss: 3281944.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1409147.1250 - val_loss: 3279271.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1293804.7500 - val_loss: 3275209.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1186314.8750 - val_loss: 3274989.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1086224.2500 - val_loss: 3274670.7500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 992791.2500 - val_loss: 3274370.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 906105.8125 - val_loss: 3274280.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 825549.2500 - val_loss: 3276178.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 751023.9375 - val_loss: 3278052.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 681837.0625 - val_loss: 3282821.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 617991.7500 - val_loss: 3284347.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 559144.9375 - val_loss: 3283363.0000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 22ms/step - loss: 1816906.7500 - val_loss: 3270092.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1667510.5000 - val_loss: 3269285.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1533502.5000 - val_loss: 3267686.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1409638.8750 - val_loss: 3265483.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1294317.5000 - val_loss: 3262982.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1187043.0000 - val_loss: 3259642.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1087063.7500 - val_loss: 3257857.7500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 993816.8125 - val_loss: 3257391.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 907030.5625 - val_loss: 3254657.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 826652.9375 - val_loss: 3254932.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 751790.9375 - val_loss: 3262133.0000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 682379.6875 - val_loss: 3271631.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 618524.1250 - val_loss: 3268688.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 559944.0625 - val_loss: 3266052.0000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 22ms/step - loss: 1816529.8750 - val_loss: 3276787.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1666400.8750 - val_loss: 3281966.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1532472.6250 - val_loss: 3283483.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1408443.1250 - val_loss: 3284541.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1293181.0000 - val_loss: 3285542.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1185641.6250 - val_loss: 3286433.5000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 22ms/step - loss: 1814022.2500 - val_loss: 3270493.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1665246.5000 - val_loss: 3267389.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1531802.1250 - val_loss: 3264522.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1408006.1250 - val_loss: 3259306.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1292900.7500 - val_loss: 3256328.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1185497.2500 - val_loss: 3254433.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1085267.2500 - val_loss: 3257622.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 992131.0000 - val_loss: 3257149.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 905430.4375 - val_loss: 3257350.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 824751.4375 - val_loss: 3263850.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 750238.8750 - val_loss: 3264446.5000\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 20ms/step - loss: 1816581.5000 - val_loss: 3274242.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1667136.5000 - val_loss: 3280912.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1533532.5000 - val_loss: 3284104.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1409801.0000 - val_loss: 3285039.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1294446.8750 - val_loss: 3285125.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1186998.8750 - val_loss: 3284169.7500\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 29ms/step - loss: 1813326.3750 - val_loss: 3277315.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1664515.6250 - val_loss: 3283166.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1531061.3750 - val_loss: 3286473.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1407646.3750 - val_loss: 3289006.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1292534.0000 - val_loss: 3287608.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1185172.5000 - val_loss: 3288362.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 23ms/step - loss: 1813730.2500 - val_loss: 3273353.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1663842.5000 - val_loss: 3280416.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1530144.5000 - val_loss: 3282575.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1406387.5000 - val_loss: 3281884.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1291103.8750 - val_loss: 3282458.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1183771.2500 - val_loss: 3281605.7500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 22ms/step - loss: 1815830.5000 - val_loss: 3276257.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1665558.5000 - val_loss: 3281435.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1531658.0000 - val_loss: 3284844.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1407769.2500 - val_loss: 3287656.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1292556.1250 - val_loss: 3282443.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1185090.6250 - val_loss: 3280896.2500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 15s 12ms/step - loss: 1850744.0000 - val_loss: 3273042.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1775948.2500 - val_loss: 3271484.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1718107.1250 - val_loss: 3268403.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1663156.5000 - val_loss: 3265208.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1610113.5000 - val_loss: 3260946.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1558623.1250 - val_loss: 3256766.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1508518.8750 - val_loss: 3251885.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1459677.1250 - val_loss: 3246790.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1412005.5000 - val_loss: 3242172.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1365442.0000 - val_loss: 3237617.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1319935.7500 - val_loss: 3233494.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1275439.8750 - val_loss: 3229416.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1231940.6250 - val_loss: 3226030.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1189399.0000 - val_loss: 3224167.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1147787.8750 - val_loss: 3222924.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1107090.0000 - val_loss: 3221592.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1067303.5000 - val_loss: 3218993.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1028404.3750 - val_loss: 3219496.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 990381.5000 - val_loss: 3217836.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 953204.5000 - val_loss: 3216851.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 916875.9375 - val_loss: 3214355.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 881369.9375 - val_loss: 3211383.5000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 846700.3125 - val_loss: 3210587.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 812865.6875 - val_loss: 3209483.2500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 779834.6250 - val_loss: 3205845.2500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 747611.8125 - val_loss: 3202592.5000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 716202.6875 - val_loss: 3199542.5000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 685609.1250 - val_loss: 3199523.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 655804.3125 - val_loss: 3198375.7500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 626788.1250 - val_loss: 3195302.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 598562.0000 - val_loss: 3192883.5000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 571136.6875 - val_loss: 3192093.5000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 544504.0000 - val_loss: 3191443.5000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 518625.9375 - val_loss: 3191538.0000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 493503.3750 - val_loss: 3190091.0000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 469155.0000 - val_loss: 3187843.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 445568.0000 - val_loss: 3185188.7500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 422711.5938 - val_loss: 3182589.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 400633.4688 - val_loss: 3180215.5000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 379323.1250 - val_loss: 3178189.5000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 358747.1875 - val_loss: 3172341.0000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 338897.3438 - val_loss: 3165003.7500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 319787.0938 - val_loss: 3162673.2500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 301390.8750 - val_loss: 3160454.7500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 283718.4062 - val_loss: 3158492.7500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 266774.7500 - val_loss: 3156589.7500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 250561.2812 - val_loss: 3154794.5000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 235048.2656 - val_loss: 3153086.5000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 220224.2031 - val_loss: 3151600.5000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 206105.6094 - val_loss: 3150177.0000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 14ms/step - loss: 1853078.6250 - val_loss: 3273501.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1777517.6250 - val_loss: 3272760.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1719500.1250 - val_loss: 3270049.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1664429.7500 - val_loss: 3267237.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1611294.5000 - val_loss: 3264121.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1559726.7500 - val_loss: 3259975.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1509550.7500 - val_loss: 3254268.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1460634.3750 - val_loss: 3248107.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1412909.7500 - val_loss: 3242624.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1366321.5000 - val_loss: 3236866.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1320801.6250 - val_loss: 3231684.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1276299.3750 - val_loss: 3227116.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1232767.8750 - val_loss: 3222900.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1190199.6250 - val_loss: 3219032.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1148577.8750 - val_loss: 3215330.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1107869.2500 - val_loss: 3212110.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1068088.2500 - val_loss: 3210765.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1029169.7500 - val_loss: 3214340.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 991087.3125 - val_loss: 3214363.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 953859.1250 - val_loss: 3212713.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 917513.7500 - val_loss: 3209028.2500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 882004.8125 - val_loss: 3205377.0000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 847333.1875 - val_loss: 3202390.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 813493.3750 - val_loss: 3203248.0000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 780465.3750 - val_loss: 3200296.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 748239.1875 - val_loss: 3196259.2500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 716812.8750 - val_loss: 3192620.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 686192.9375 - val_loss: 3188992.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 656372.0625 - val_loss: 3185317.7500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 627315.8125 - val_loss: 3181838.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 599048.3125 - val_loss: 3178474.5000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 571585.5000 - val_loss: 3175139.7500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 544895.1250 - val_loss: 3171896.0000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 518976.5000 - val_loss: 3168708.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 493827.1250 - val_loss: 3166871.0000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 469451.0625 - val_loss: 3161535.7500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 445833.5000 - val_loss: 3153301.2500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 422972.2188 - val_loss: 3148874.0000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 400885.9062 - val_loss: 3145746.0000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 379554.1875 - val_loss: 3142755.5000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 358975.0000 - val_loss: 3139935.0000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 339130.2812 - val_loss: 3137277.7500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 320015.2500 - val_loss: 3134878.5000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 301618.7500 - val_loss: 3132323.7500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 283930.6875 - val_loss: 3130479.2500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 266968.6875 - val_loss: 3128784.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 250731.9375 - val_loss: 3117460.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 235209.7656 - val_loss: 3115375.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 220412.4531 - val_loss: 3113128.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 206290.1094 - val_loss: 3111494.0000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 16ms/step - loss: 1852182.6250 - val_loss: 3274407.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1775176.2500 - val_loss: 3273497.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1716936.7500 - val_loss: 3270480.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1661794.0000 - val_loss: 3266661.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1608624.8750 - val_loss: 3263070.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1557084.3750 - val_loss: 3259608.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1506958.2500 - val_loss: 3255794.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1458106.0000 - val_loss: 3252065.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1410405.2500 - val_loss: 3247482.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1363810.5000 - val_loss: 3243187.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1318289.1250 - val_loss: 3239031.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1273806.6250 - val_loss: 3234815.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1230322.6250 - val_loss: 3231216.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1187786.3750 - val_loss: 3228302.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1146185.3750 - val_loss: 3225576.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1105511.7500 - val_loss: 3223097.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1065755.3750 - val_loss: 3220274.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1026895.8750 - val_loss: 3219264.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 988902.2500 - val_loss: 3216355.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 951745.1250 - val_loss: 3212711.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 915420.9375 - val_loss: 3209051.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 879941.4375 - val_loss: 3205401.0000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 845297.7500 - val_loss: 3202135.2500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 811491.5000 - val_loss: 3201389.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 778501.3125 - val_loss: 3201867.2500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 746316.5000 - val_loss: 3202006.2500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 714932.0000 - val_loss: 3198549.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 684342.8125 - val_loss: 3197729.5000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 654568.4375 - val_loss: 3196662.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 625591.6250 - val_loss: 3196721.2500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 597389.0625 - val_loss: 3193982.7500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 569961.9375 - val_loss: 3190410.5000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 543302.8750 - val_loss: 3186798.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 517430.4688 - val_loss: 3183631.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 492356.1250 - val_loss: 3180137.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 468060.8125 - val_loss: 3174781.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 444494.6562 - val_loss: 3166117.7500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 421676.4062 - val_loss: 3162595.7500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 399612.6562 - val_loss: 3159421.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 378300.9375 - val_loss: 3156292.5000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 357724.5625 - val_loss: 3153463.7500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 337894.9688 - val_loss: 3150760.5000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 318798.4688 - val_loss: 3148170.7500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 300445.0312 - val_loss: 3145639.0000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 282825.1562 - val_loss: 3143188.7500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 265951.4375 - val_loss: 3140899.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 249775.7656 - val_loss: 3138881.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 234302.2344 - val_loss: 3137048.0000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 219530.4062 - val_loss: 3131024.7500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 205451.1562 - val_loss: 3126097.2500\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 14ms/step - loss: 1854768.2500 - val_loss: 3271526.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1780039.3750 - val_loss: 3269123.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1722538.6250 - val_loss: 3265164.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1667965.3750 - val_loss: 3261240.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1615291.1250 - val_loss: 3257246.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1564182.0000 - val_loss: 3253386.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1514398.6250 - val_loss: 3248751.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1465876.5000 - val_loss: 3243865.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1418534.1250 - val_loss: 3236954.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1372270.1250 - val_loss: 3230281.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1327051.0000 - val_loss: 3225548.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1282817.5000 - val_loss: 3221031.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1239560.6250 - val_loss: 3217539.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1197238.8750 - val_loss: 3213660.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1155839.5000 - val_loss: 3213055.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1115351.7500 - val_loss: 3211101.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1075756.3750 - val_loss: 3209526.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1037027.6875 - val_loss: 3209439.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 999148.5000 - val_loss: 3207549.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 962117.4375 - val_loss: 3204826.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 925922.6875 - val_loss: 3201824.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 890534.5000 - val_loss: 3201520.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 855971.5000 - val_loss: 3198593.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 822218.6250 - val_loss: 3194523.2500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 789257.7500 - val_loss: 3190663.2500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 757102.2500 - val_loss: 3186848.5000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 725731.3750 - val_loss: 3184058.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 695143.5000 - val_loss: 3180713.7500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 665357.2500 - val_loss: 3175965.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 636353.8125 - val_loss: 3173322.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 608120.7500 - val_loss: 3167316.5000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 580646.8750 - val_loss: 3163313.5000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 553927.6250 - val_loss: 3159355.5000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 527981.5625 - val_loss: 3155732.7500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 502789.2812 - val_loss: 3152202.7500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 478344.5625 - val_loss: 3148858.2500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 454641.7500 - val_loss: 3145599.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 431687.6562 - val_loss: 3142474.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 409491.2500 - val_loss: 3139477.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 388027.2500 - val_loss: 3136860.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 367307.2500 - val_loss: 3128194.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 347325.7812 - val_loss: 3123313.0000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 328045.3125 - val_loss: 3120292.2500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 309266.7812 - val_loss: 3120202.5000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 290824.5312 - val_loss: 3117833.2500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 273365.1562 - val_loss: 3115596.2500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 256730.8594 - val_loss: 3113524.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 240868.8594 - val_loss: 3111613.5000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 225735.1562 - val_loss: 3109770.5000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 211324.3594 - val_loss: 3108587.2500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 13ms/step - loss: 1854049.8750 - val_loss: 3272038.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1778868.2500 - val_loss: 3269757.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1720913.6250 - val_loss: 3266043.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1665896.1250 - val_loss: 3262317.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1612789.2500 - val_loss: 3258843.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1561226.7500 - val_loss: 3255150.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1511072.1250 - val_loss: 3249856.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1462175.2500 - val_loss: 3244059.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1414443.0000 - val_loss: 3238875.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1367829.1250 - val_loss: 3233824.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1322264.3750 - val_loss: 3229990.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1277717.6250 - val_loss: 3226250.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1234166.6250 - val_loss: 3222563.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1191565.3750 - val_loss: 3218891.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1149902.8750 - val_loss: 3217445.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1109166.7500 - val_loss: 3214806.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1069349.2500 - val_loss: 3212552.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1030396.2500 - val_loss: 3213529.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 992295.0625 - val_loss: 3211042.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 955058.1250 - val_loss: 3207421.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 918688.3125 - val_loss: 3203915.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 883157.1250 - val_loss: 3202169.2500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 848440.4375 - val_loss: 3200833.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 814555.3125 - val_loss: 3197111.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 781477.3125 - val_loss: 3193706.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 749232.7500 - val_loss: 3193766.5000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 717797.3125 - val_loss: 3193157.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 687172.1250 - val_loss: 3193431.5000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 657329.6250 - val_loss: 3194891.0000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 628273.6250 - val_loss: 3192401.7500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 600006.6875 - val_loss: 3189077.2500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 572542.5625 - val_loss: 3185856.2500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 545841.8125 - val_loss: 3182717.0000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 519915.9375 - val_loss: 3179709.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 494722.5625 - val_loss: 3176962.5000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 470301.0000 - val_loss: 3174307.7500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 446656.5000 - val_loss: 3171796.2500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 423776.4062 - val_loss: 3168508.7500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 401643.2188 - val_loss: 3160274.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 380269.1250 - val_loss: 3155703.0000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 359634.6875 - val_loss: 3153136.0000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 339751.4375 - val_loss: 3150636.5000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 320609.1250 - val_loss: 3148300.7500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 302197.9688 - val_loss: 3146214.2500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 284503.2812 - val_loss: 3144209.2500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 267524.1875 - val_loss: 3142235.2500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 251258.1562 - val_loss: 3140430.5000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 235694.0938 - val_loss: 3138696.0000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 220842.1875 - val_loss: 3137073.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 206677.0781 - val_loss: 3135519.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 14ms/step - loss: 1855451.8750 - val_loss: 3272436.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1780480.0000 - val_loss: 3271129.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1722451.6250 - val_loss: 3267825.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1667392.1250 - val_loss: 3264046.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1614259.1250 - val_loss: 3260303.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1562690.8750 - val_loss: 3256523.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1512478.6250 - val_loss: 3252582.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1463528.3750 - val_loss: 3248564.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1415754.8750 - val_loss: 3244268.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1369090.8750 - val_loss: 3240347.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1323476.6250 - val_loss: 3236783.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1278898.6250 - val_loss: 3233312.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1235328.7500 - val_loss: 3229849.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1192719.5000 - val_loss: 3226305.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1151047.6250 - val_loss: 3222755.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1110288.5000 - val_loss: 3219232.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1070419.2500 - val_loss: 3216174.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1031443.3125 - val_loss: 3213653.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 993337.1875 - val_loss: 3211308.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 956084.1875 - val_loss: 3207898.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 919686.1250 - val_loss: 3205431.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 884115.1875 - val_loss: 3204255.2500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 849390.3750 - val_loss: 3200445.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 815499.0000 - val_loss: 3196508.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 782412.8750 - val_loss: 3192585.2500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 750142.8750 - val_loss: 3189011.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 718679.4375 - val_loss: 3186334.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 688013.6250 - val_loss: 3187495.0000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 658137.5625 - val_loss: 3186924.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 629056.4375 - val_loss: 3183588.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 600763.4375 - val_loss: 3179954.7500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 573250.1250 - val_loss: 3176369.2500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 546517.1875 - val_loss: 3172827.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 520553.5625 - val_loss: 3169469.0000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 495353.5000 - val_loss: 3166096.0000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 470917.1250 - val_loss: 3162954.7500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 447245.9688 - val_loss: 3159862.0000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 424333.5938 - val_loss: 3156830.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 402211.7812 - val_loss: 3153987.2500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 380823.8750 - val_loss: 3151221.5000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 360188.0625 - val_loss: 3148563.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 340296.2812 - val_loss: 3146048.2500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 321141.3438 - val_loss: 3143777.7500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 302711.5625 - val_loss: 3141916.7500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 284979.5938 - val_loss: 3133347.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 267979.1250 - val_loss: 3129035.7500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 251689.1875 - val_loss: 3126250.2500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 236112.2344 - val_loss: 3123930.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 221256.9062 - val_loss: 3121749.5000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 207100.9219 - val_loss: 3119974.5000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 14ms/step - loss: 1850785.6250 - val_loss: 3274500.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1775913.6250 - val_loss: 3274462.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1718129.2500 - val_loss: 3272326.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1663199.1250 - val_loss: 3269991.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1610199.8750 - val_loss: 3267740.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1558723.5000 - val_loss: 3265312.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1508605.2500 - val_loss: 3262995.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1459729.8750 - val_loss: 3258880.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1412042.7500 - val_loss: 3255287.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1365476.0000 - val_loss: 3252037.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1319942.6250 - val_loss: 3248847.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1275424.8750 - val_loss: 3245164.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1231926.8750 - val_loss: 3241478.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1189366.2500 - val_loss: 3238799.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1147751.7500 - val_loss: 3235630.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1107064.2500 - val_loss: 3233474.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1067264.3750 - val_loss: 3231163.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1028354.0000 - val_loss: 3231120.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 990321.8125 - val_loss: 3228127.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 953150.9375 - val_loss: 3225216.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 916825.9375 - val_loss: 3223416.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 881337.8750 - val_loss: 3223158.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 846678.1875 - val_loss: 3220514.2500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 812837.1250 - val_loss: 3218344.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 779828.8750 - val_loss: 3218641.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 747608.9375 - val_loss: 3219515.5000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 716190.1875 - val_loss: 3216753.5000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 685587.0625 - val_loss: 3213440.0000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 655777.0625 - val_loss: 3210116.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 626748.7500 - val_loss: 3206883.2500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 598524.0625 - val_loss: 3203571.7500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 571095.1875 - val_loss: 3200392.2500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 544432.1875 - val_loss: 3197189.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 518528.6875 - val_loss: 3194128.2500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 493385.8438 - val_loss: 3191174.7500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 469032.6875 - val_loss: 3188311.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 445451.1875 - val_loss: 3185556.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 422626.2188 - val_loss: 3182860.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 400540.2812 - val_loss: 3180362.5000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 379203.1250 - val_loss: 3177804.0000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 358612.6562 - val_loss: 3175457.0000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 338765.0000 - val_loss: 3173118.2500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 319647.1875 - val_loss: 3170694.7500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 301275.0625 - val_loss: 3168848.7500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 283605.9375 - val_loss: 3166051.7500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 266654.9375 - val_loss: 3155943.2500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 250426.7969 - val_loss: 3153948.2500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 234913.8594 - val_loss: 3152218.7500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 220103.6562 - val_loss: 3150672.2500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 205997.2188 - val_loss: 3149163.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 12ms/step - loss: 1851034.7500 - val_loss: 3274497.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1774315.5000 - val_loss: 3273913.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1716270.8750 - val_loss: 3271565.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1661247.8750 - val_loss: 3269355.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1608176.1250 - val_loss: 3267246.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1556729.1250 - val_loss: 3264400.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1506637.5000 - val_loss: 3261770.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1457795.5000 - val_loss: 3258084.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1410116.6250 - val_loss: 3252847.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1363562.2500 - val_loss: 3248905.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1318048.1250 - val_loss: 3245588.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1273575.6250 - val_loss: 3242488.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1230116.5000 - val_loss: 3239414.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1187606.6250 - val_loss: 3236357.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1146030.8750 - val_loss: 3233132.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1105380.8750 - val_loss: 3229839.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1065625.3750 - val_loss: 3226397.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1026751.1875 - val_loss: 3223020.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 988731.5625 - val_loss: 3219550.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 951583.7500 - val_loss: 3217078.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 915284.0625 - val_loss: 3215405.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 879825.6875 - val_loss: 3213108.0000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 845176.9375 - val_loss: 3210676.7500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 811355.8125 - val_loss: 3215620.0000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 778374.0000 - val_loss: 3217207.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 746196.1250 - val_loss: 3213016.7500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 714813.6875 - val_loss: 3209228.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 684234.4375 - val_loss: 3205661.7500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 654445.5625 - val_loss: 3202080.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 625453.6875 - val_loss: 3198611.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 597232.0000 - val_loss: 3195219.2500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 569775.1875 - val_loss: 3191863.0000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 543116.4375 - val_loss: 3188512.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 517248.4688 - val_loss: 3179803.7500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 492156.6562 - val_loss: 3174546.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 467846.8125 - val_loss: 3171396.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 444297.1875 - val_loss: 3168444.0000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 421511.7188 - val_loss: 3165654.2500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 399464.5312 - val_loss: 3163026.2500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 378173.0625 - val_loss: 3160564.2500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 357627.6250 - val_loss: 3158164.7500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 337815.4688 - val_loss: 3155980.7500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 318732.0000 - val_loss: 3153790.2500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 300394.9688 - val_loss: 3151741.0000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 282784.9688 - val_loss: 3149917.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 265884.5938 - val_loss: 3148139.7500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 249714.6719 - val_loss: 3146504.2500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 234241.2656 - val_loss: 3144776.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 219461.1094 - val_loss: 3143375.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 205368.5156 - val_loss: 3144606.2500\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 14ms/step - loss: 1854336.2500 - val_loss: 3268545.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1778435.2500 - val_loss: 3265274.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1720359.5000 - val_loss: 3260408.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1665281.5000 - val_loss: 3255633.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1612158.6250 - val_loss: 3252126.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1560589.1250 - val_loss: 3248212.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1510415.0000 - val_loss: 3243712.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1461504.7500 - val_loss: 3239830.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1413774.5000 - val_loss: 3235625.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1367149.0000 - val_loss: 3230538.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1321612.2500 - val_loss: 3226527.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1277093.7500 - val_loss: 3223542.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1233542.3750 - val_loss: 3222161.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1190963.1250 - val_loss: 3220590.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1149313.2500 - val_loss: 3221056.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1108578.0000 - val_loss: 3218799.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1068749.0000 - val_loss: 3218215.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1029796.3125 - val_loss: 3218522.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 991722.6875 - val_loss: 3221219.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 954502.9375 - val_loss: 3217636.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 918137.5000 - val_loss: 3213690.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 882612.3750 - val_loss: 3209748.2500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 847929.3125 - val_loss: 3205869.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 814059.3125 - val_loss: 3201969.2500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 780982.5000 - val_loss: 3202661.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 748717.9375 - val_loss: 3199613.7500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 717283.3750 - val_loss: 3197939.2500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 686636.9375 - val_loss: 3201398.5000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 656790.3750 - val_loss: 3198154.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 627752.0625 - val_loss: 3194599.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 599507.0000 - val_loss: 3191260.5000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 572017.9375 - val_loss: 3187945.7500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 545329.1250 - val_loss: 3184879.5000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 519409.5625 - val_loss: 3181912.0000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 494266.1875 - val_loss: 3178934.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 469882.0312 - val_loss: 3176088.2500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 446241.3125 - val_loss: 3173398.2500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 423362.0938 - val_loss: 3170816.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 401239.1562 - val_loss: 3168366.7500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 379883.5312 - val_loss: 3165745.0000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 359278.6250 - val_loss: 3163463.7500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 339413.7188 - val_loss: 3161197.7500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 320292.2188 - val_loss: 3159219.7500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 301895.0000 - val_loss: 3158333.7500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 284219.6250 - val_loss: 3146818.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 267262.9688 - val_loss: 3144531.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 251022.0938 - val_loss: 3142642.7500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 235484.7500 - val_loss: 3140976.5000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 220654.1250 - val_loss: 3139538.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 206527.1719 - val_loss: 3138143.5000\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 15ms/step - loss: 1851223.1250 - val_loss: 3274049.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1776518.7500 - val_loss: 3272350.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1718793.1250 - val_loss: 3268357.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1663907.5000 - val_loss: 3264309.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1610917.5000 - val_loss: 3260265.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1559483.3750 - val_loss: 3255541.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1509405.0000 - val_loss: 3249942.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1460566.0000 - val_loss: 3240845.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1412885.0000 - val_loss: 3232066.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1366290.5000 - val_loss: 3222655.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1320746.2500 - val_loss: 3214053.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1276230.0000 - val_loss: 3206694.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1232711.6250 - val_loss: 3199463.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1190135.0000 - val_loss: 3195184.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1148508.1250 - val_loss: 3190072.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1107828.3750 - val_loss: 3185573.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1068026.8750 - val_loss: 3182929.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1029111.2500 - val_loss: 3180882.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 991061.5625 - val_loss: 3176317.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 953845.0625 - val_loss: 3171737.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 917475.3750 - val_loss: 3170171.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 881955.4375 - val_loss: 3174732.5000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 847279.3125 - val_loss: 3172895.5000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 813414.2500 - val_loss: 3171051.2500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 780377.3125 - val_loss: 3167319.2500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 748171.5000 - val_loss: 3164154.5000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 716756.1250 - val_loss: 3164406.2500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 686119.3750 - val_loss: 3164672.5000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 656279.3750 - val_loss: 3163500.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 627225.0000 - val_loss: 3160403.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 598982.6875 - val_loss: 3159393.5000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 571510.9375 - val_loss: 3155612.2500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 544814.6875 - val_loss: 3151903.0000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 518911.6250 - val_loss: 3143042.7500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 493776.9688 - val_loss: 3137418.0000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 469382.8125 - val_loss: 3133351.2500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 445764.4688 - val_loss: 3129688.2500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 422931.6250 - val_loss: 3126187.7500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 400843.3438 - val_loss: 3122883.0000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 379496.5000 - val_loss: 3119791.5000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 358906.7188 - val_loss: 3116801.7500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 339060.5312 - val_loss: 3113902.5000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 319936.8125 - val_loss: 3110638.7500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 301545.6562 - val_loss: 3107521.5000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 283861.6562 - val_loss: 3105517.2500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 266906.8750 - val_loss: 3101828.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 250681.9375 - val_loss: 3097902.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 235158.5625 - val_loss: 3095591.5000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 220333.0156 - val_loss: 3089266.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 206206.1562 - val_loss: 3089594.0000\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 7s 21ms/step - loss: 1877641.0000 - val_loss: 3273361.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1826951.6250 - val_loss: 3274505.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1794962.5000 - val_loss: 3275011.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1765093.6250 - val_loss: 3275239.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1736272.2500 - val_loss: 3275092.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1708187.3750 - val_loss: 3274804.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 16ms/step - loss: 1879522.5000 - val_loss: 3273483.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1827635.7500 - val_loss: 3274873.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1795343.5000 - val_loss: 3275815.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 1765290.1250 - val_loss: 3276157.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1736372.5000 - val_loss: 3276200.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1708207.1250 - val_loss: 3275915.7500\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 16ms/step - loss: 1876082.1250 - val_loss: 3274443.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1823211.7500 - val_loss: 3275781.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1790979.0000 - val_loss: 3276699.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1761016.3750 - val_loss: 3277314.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1732154.5000 - val_loss: 3277667.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1704037.2500 - val_loss: 3277713.5000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 17ms/step - loss: 1874227.0000 - val_loss: 3274410.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1820480.7500 - val_loss: 3275871.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1788464.5000 - val_loss: 3276953.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1758596.8750 - val_loss: 3277770.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1729802.1250 - val_loss: 3278322.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1701747.7500 - val_loss: 3278627.7500\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 20ms/step - loss: 1877903.5000 - val_loss: 3274033.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1827158.3750 - val_loss: 3275160.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1795262.7500 - val_loss: 3275549.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1765438.6250 - val_loss: 3275197.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1736623.1250 - val_loss: 3274804.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1708542.0000 - val_loss: 3274236.0000\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 16ms/step - loss: 1878869.0000 - val_loss: 3273275.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1826084.0000 - val_loss: 3274281.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1793788.1250 - val_loss: 3274681.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1763744.2500 - val_loss: 3274650.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1734823.3750 - val_loss: 3274486.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1706647.8750 - val_loss: 3274187.7500\n",
            "7/7 [==============================] - 1s 4ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 16ms/step - loss: 1878226.3750 - val_loss: 3273108.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1823929.0000 - val_loss: 3274008.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1791527.2500 - val_loss: 3274476.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1761454.1250 - val_loss: 3274277.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1732517.8750 - val_loss: 3273755.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1704354.6250 - val_loss: 3273072.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1676777.3750 - val_loss: 3272042.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1649672.6250 - val_loss: 3270981.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1623017.6250 - val_loss: 3269915.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1596768.6250 - val_loss: 3268929.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1570896.8750 - val_loss: 3267457.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1545373.7500 - val_loss: 3266136.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1520191.1250 - val_loss: 3264377.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1495320.6250 - val_loss: 3263008.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1470779.0000 - val_loss: 3261723.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1446516.2500 - val_loss: 3260378.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1422556.3750 - val_loss: 3259133.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1398870.5000 - val_loss: 3257908.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1375454.3750 - val_loss: 3256632.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1352315.1250 - val_loss: 3255500.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1329457.2500 - val_loss: 3254310.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1306844.7500 - val_loss: 3253203.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1284486.8750 - val_loss: 3252024.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1262374.0000 - val_loss: 3250925.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1240489.6250 - val_loss: 3249770.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1218865.6250 - val_loss: 3248599.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1197480.3750 - val_loss: 3247425.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1176328.1250 - val_loss: 3246266.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1155408.7500 - val_loss: 3245127.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1134719.3750 - val_loss: 3243982.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1114275.7500 - val_loss: 3242861.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1094056.0000 - val_loss: 3241769.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1074072.3750 - val_loss: 3240774.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1054297.3750 - val_loss: 3240196.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1034753.2500 - val_loss: 3240611.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1015419.2500 - val_loss: 3240354.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 996301.0000 - val_loss: 3240061.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 977407.1875 - val_loss: 3243137.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 958724.6875 - val_loss: 3242049.2500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 940253.7500 - val_loss: 3242234.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 922014.7500 - val_loss: 3245084.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 903975.2500 - val_loss: 3247828.0000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 15ms/step - loss: 1877798.0000 - val_loss: 3273635.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1825812.5000 - val_loss: 3275144.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1793554.3750 - val_loss: 3275989.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1763566.8750 - val_loss: 3276145.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1734700.3750 - val_loss: 3275660.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1706572.2500 - val_loss: 3274862.0000\n",
            "7/7 [==============================] - 1s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 15ms/step - loss: 1877591.8750 - val_loss: 3273851.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1823921.0000 - val_loss: 3275299.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1791461.3750 - val_loss: 3276304.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1761265.7500 - val_loss: 3276847.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1732300.5000 - val_loss: 3277014.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1704122.1250 - val_loss: 3276931.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 16ms/step - loss: 1878357.0000 - val_loss: 3273561.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1827083.7500 - val_loss: 3274767.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1794955.0000 - val_loss: 3275594.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1765019.0000 - val_loss: 3275943.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1736176.2500 - val_loss: 3275573.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1708048.7500 - val_loss: 3274688.2500\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 28ms/step - loss: 1898210.1250 - val_loss: 3275549.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1855829.7500 - val_loss: 3274652.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1836243.7500 - val_loss: 3275484.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1819422.1250 - val_loss: 3276211.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1803537.5000 - val_loss: 3276835.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1788187.1250 - val_loss: 3277373.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1773243.2500 - val_loss: 3277848.0000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 20ms/step - loss: 1897187.0000 - val_loss: 3276429.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1853077.1250 - val_loss: 3274443.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1833156.5000 - val_loss: 3275240.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1816317.0000 - val_loss: 3275870.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1800462.3750 - val_loss: 3276319.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1785130.2500 - val_loss: 3276631.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1770170.0000 - val_loss: 3276791.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 30ms/step - loss: 1897201.1250 - val_loss: 3275649.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1852056.0000 - val_loss: 3274218.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1832078.3750 - val_loss: 3274736.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1815227.7500 - val_loss: 3275089.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1799364.8750 - val_loss: 3275215.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1784049.0000 - val_loss: 3275228.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1769068.8750 - val_loss: 3275195.0000\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 21ms/step - loss: 1898600.6250 - val_loss: 3275933.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1849365.3750 - val_loss: 3274565.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1828552.8750 - val_loss: 3275269.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1811504.2500 - val_loss: 3275899.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1795512.5000 - val_loss: 3276361.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1780093.2500 - val_loss: 3276797.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1765078.3750 - val_loss: 3277133.2500\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 21ms/step - loss: 1899868.5000 - val_loss: 3274482.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1856026.5000 - val_loss: 3274000.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1835703.8750 - val_loss: 3274931.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1818685.5000 - val_loss: 3275691.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1802722.0000 - val_loss: 3276315.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1787307.5000 - val_loss: 3276840.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1772311.6250 - val_loss: 3277262.5000\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 22ms/step - loss: 1899336.6250 - val_loss: 3275008.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1854261.3750 - val_loss: 3274683.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1833747.1250 - val_loss: 3275602.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1816708.7500 - val_loss: 3276371.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1800695.7500 - val_loss: 3277037.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1785299.6250 - val_loss: 3277629.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1770283.3750 - val_loss: 3278159.5000\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 20ms/step - loss: 1896947.2500 - val_loss: 3276604.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1850976.1250 - val_loss: 3274721.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1831039.7500 - val_loss: 3275505.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1814186.1250 - val_loss: 3276153.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1798319.1250 - val_loss: 3276724.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1782981.3750 - val_loss: 3277220.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1767995.7500 - val_loss: 3277659.5000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 22ms/step - loss: 1897904.7500 - val_loss: 3275984.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1853015.1250 - val_loss: 3274030.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1832933.5000 - val_loss: 3274507.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1816014.2500 - val_loss: 3274856.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1800100.5000 - val_loss: 3275155.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1784750.8750 - val_loss: 3275243.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1769788.1250 - val_loss: 3275285.7500\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 22ms/step - loss: 1901164.0000 - val_loss: 3274544.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1854363.5000 - val_loss: 3273658.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1832515.2500 - val_loss: 3274268.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1815052.8750 - val_loss: 3274880.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1798856.8750 - val_loss: 3275302.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1783289.7500 - val_loss: 3275605.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1768135.7500 - val_loss: 3275778.5000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 21ms/step - loss: 1899814.3750 - val_loss: 3273548.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1855571.0000 - val_loss: 3273492.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1834884.8750 - val_loss: 3274354.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1817834.2500 - val_loss: 3275051.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1801832.2500 - val_loss: 3275615.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1786375.0000 - val_loss: 3276075.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1771320.7500 - val_loss: 3276388.5000\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Best_hyper_parameters: \n",
            " {'model': [100], 'optimizer': 'Adam', 'learning_rate': 0.1, 'batch_size': 4, 'best_avg_rmse': 1418.7608647911215}\n",
            "all_avg_rmse: \n",
            " [[[1418.76086479 1438.88599925 1437.22264069]\n",
            "  [1530.38941748 1585.74938931 1622.90821426]\n",
            "  [1643.43416623 1664.1031188  1680.34282015]]\n",
            "\n",
            " [[1679.7175553  1687.86793653 1695.90718009]\n",
            "  [1703.92072089 1711.2430452  1717.76909698]\n",
            "  [1723.48815034 1728.55573229 1733.06684752]]\n",
            "\n",
            " [[1707.80864744 1687.29736992 1675.60200045]\n",
            "  [1677.63457668 1682.97979477 1688.26526987]\n",
            "  [1691.47143444 1695.99700268 1700.22598705]]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': [100],\n",
              " 'optimizer': 'Adam',\n",
              " 'learning_rate': 0.1,\n",
              " 'batch_size': 4,\n",
              " 'best_avg_rmse': 1418.7608647911215}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case V: Tuning parameters of 150 neuron single layer LSTM"
      ],
      "metadata": {
        "id": "eiMQEKgUhK9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [150]\n",
        "time_step = 5\n",
        "optimizers_names = ['Adam', 'Adagrad', 'Nadam']\n",
        "learning_rates =  [0.1, 0.01, 0.001]\n",
        "batch_sizes =  [4, 8, 16]\n",
        "epochs = 50\n",
        "num_replicates = 10\n",
        "\n",
        "\n",
        "N150_best_hyper_parameters = hyper_parameter_tuning(layers,  optimizers_names, learning_rates, batch_sizes, epochs = epochs, num_replicates = num_replicates)\n",
        "N150_best_hyper_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IGiKNtDhRMr",
        "outputId": "0ad521f5-5e0c-41db-94be-1daf9b79e795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1562454.3750 - val_loss: 3259092.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1544270.1250 - val_loss: 3257630.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1527272.0000 - val_loss: 3255945.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1511275.7500 - val_loss: 3253889.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1496139.6250 - val_loss: 3251793.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1481751.2500 - val_loss: 3249974.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1468022.5000 - val_loss: 3248346.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1454880.1250 - val_loss: 3246627.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1442265.8750 - val_loss: 3244680.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1430129.5000 - val_loss: 3242676.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1418424.2500 - val_loss: 3240858.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1407115.6250 - val_loss: 3239332.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1396170.1250 - val_loss: 3238063.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1385562.3750 - val_loss: 3236963.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1375266.0000 - val_loss: 3235980.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1365259.5000 - val_loss: 3235072.2500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1355524.1250 - val_loss: 3234215.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1346041.7500 - val_loss: 3233391.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1336797.5000 - val_loss: 3232580.5000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1327777.5000 - val_loss: 3231762.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1318969.2500 - val_loss: 3230921.0000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1310360.0000 - val_loss: 3230049.0000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1301939.8750 - val_loss: 3229138.7500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1293700.0000 - val_loss: 3228202.2500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1285630.8750 - val_loss: 3227253.2500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1277724.3750 - val_loss: 3226311.7500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1269972.2500 - val_loss: 3225398.2500\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1262367.7500 - val_loss: 3224513.7500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1254905.7500 - val_loss: 3223662.7500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1247578.7500 - val_loss: 3222844.2500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1240381.7500 - val_loss: 3222061.2500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1233309.2500 - val_loss: 3221307.0000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1226356.5000 - val_loss: 3220584.5000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1219519.1250 - val_loss: 3219891.7500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1212793.2500 - val_loss: 3219224.5000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1206173.0000 - val_loss: 3218587.7500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1199656.7500 - val_loss: 3217979.5000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1193239.5000 - val_loss: 3217399.0000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1186918.3750 - val_loss: 3216844.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1180690.8750 - val_loss: 3216317.2500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1174552.7500 - val_loss: 3215818.7500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1168502.7500 - val_loss: 3215346.5000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1162536.0000 - val_loss: 3214900.2500\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 15ms/step - loss: 1791368.3750 - val_loss: 3272679.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1724283.0000 - val_loss: 3269727.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1683896.3750 - val_loss: 3266793.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1652012.5000 - val_loss: 3263077.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1624914.1250 - val_loss: 3259291.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1601013.0000 - val_loss: 3255507.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1579456.7500 - val_loss: 3251900.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1559704.6250 - val_loss: 3248705.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1541402.0000 - val_loss: 3245895.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1524296.7500 - val_loss: 3243025.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1508201.3750 - val_loss: 3240106.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1492975.0000 - val_loss: 3237415.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1478503.3750 - val_loss: 3234877.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1464695.6250 - val_loss: 3232210.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1451479.2500 - val_loss: 3229230.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1438793.6250 - val_loss: 3225711.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1426587.5000 - val_loss: 3221662.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1414818.0000 - val_loss: 3217350.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1403446.6250 - val_loss: 3213167.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1392444.3750 - val_loss: 3209208.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1381781.0000 - val_loss: 3205392.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1371430.1250 - val_loss: 3201612.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1361373.3750 - val_loss: 3197788.2500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1351588.8750 - val_loss: 3193951.0000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1342058.3750 - val_loss: 3190143.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1332768.6250 - val_loss: 3186426.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1323703.8750 - val_loss: 3182903.7500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1314852.6250 - val_loss: 3179683.7500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1306202.1250 - val_loss: 3176790.7500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1297741.6250 - val_loss: 3174177.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1289462.2500 - val_loss: 3171777.7500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1281354.5000 - val_loss: 3169523.7500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1273410.6250 - val_loss: 3167341.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1265622.3750 - val_loss: 3165190.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1257983.2500 - val_loss: 3163077.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1250487.5000 - val_loss: 3161048.7500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1243127.3750 - val_loss: 3159135.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1235898.2500 - val_loss: 3157356.7500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1228794.1250 - val_loss: 3155696.5000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1221811.5000 - val_loss: 3154145.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1214943.8750 - val_loss: 3152684.5000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1208188.2500 - val_loss: 3151297.2500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1201540.8750 - val_loss: 3149973.7500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1194997.0000 - val_loss: 3148707.7500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1188553.3750 - val_loss: 3147487.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1182206.3750 - val_loss: 3146315.2500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1175952.5000 - val_loss: 3145184.7500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1169789.7500 - val_loss: 3144091.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1163714.1250 - val_loss: 3143030.2500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1157723.0000 - val_loss: 3142001.2500\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 13ms/step - loss: 1795415.2500 - val_loss: 3274369.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1729040.3750 - val_loss: 3271638.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1688890.7500 - val_loss: 3269120.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1657059.6250 - val_loss: 3267201.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1629969.6250 - val_loss: 3265295.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1606069.2500 - val_loss: 3263221.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1584126.0000 - val_loss: 3261124.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1563874.5000 - val_loss: 3258834.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1545292.8750 - val_loss: 3256837.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1527970.8750 - val_loss: 3255187.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1511689.3750 - val_loss: 3253756.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1496295.7500 - val_loss: 3252434.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1481673.3750 - val_loss: 3251081.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1467730.1250 - val_loss: 3249539.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1454390.2500 - val_loss: 3247647.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1441589.1250 - val_loss: 3245202.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1429273.6250 - val_loss: 3242061.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1417401.0000 - val_loss: 3238617.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1405932.1250 - val_loss: 3235550.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1394838.0000 - val_loss: 3233130.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1384084.8750 - val_loss: 3231312.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1373649.8750 - val_loss: 3229859.2500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1363510.2500 - val_loss: 3228577.5000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1353646.1250 - val_loss: 3227346.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1344039.7500 - val_loss: 3226060.5000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1334676.5000 - val_loss: 3224640.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1325540.7500 - val_loss: 3223046.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1316620.0000 - val_loss: 3221318.0000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1307902.6250 - val_loss: 3219521.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1299377.7500 - val_loss: 3217710.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1291035.0000 - val_loss: 3215901.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1282866.5000 - val_loss: 3214089.0000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1274862.8750 - val_loss: 3212297.7500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1267017.1250 - val_loss: 3210571.0000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1259321.1250 - val_loss: 3208957.0000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1251769.6250 - val_loss: 3207480.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1244355.6250 - val_loss: 3206124.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1237074.0000 - val_loss: 3204850.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1229918.8750 - val_loss: 3203613.5000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1222885.6250 - val_loss: 3202376.2500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1215969.2500 - val_loss: 3201109.7500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1209166.3750 - val_loss: 3199805.0000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1202471.6250 - val_loss: 3198466.2500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1195882.0000 - val_loss: 3197116.2500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1189392.5000 - val_loss: 3195778.7500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1183002.2500 - val_loss: 3194484.0000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1176705.1250 - val_loss: 3193251.7500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1170499.6250 - val_loss: 3192091.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1164382.1250 - val_loss: 3190999.2500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1158350.3750 - val_loss: 3189975.5000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 13ms/step - loss: 1792557.3750 - val_loss: 3273120.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1726114.0000 - val_loss: 3271488.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1685790.8750 - val_loss: 3267494.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1653806.8750 - val_loss: 3263837.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1626597.2500 - val_loss: 3261062.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1602580.3750 - val_loss: 3257798.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1580905.3750 - val_loss: 3253558.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1561045.6250 - val_loss: 3249207.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1542641.6250 - val_loss: 3245434.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1525436.5000 - val_loss: 3241173.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1509246.3750 - val_loss: 3236366.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1493925.5000 - val_loss: 3230945.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1479365.3750 - val_loss: 3226072.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1465474.1250 - val_loss: 3222338.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1452177.0000 - val_loss: 3218658.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1439416.2500 - val_loss: 3215079.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1427137.5000 - val_loss: 3210959.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1415298.5000 - val_loss: 3206415.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1403861.0000 - val_loss: 3202792.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1392792.3750 - val_loss: 3199868.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1382065.5000 - val_loss: 3197242.2500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1371654.1250 - val_loss: 3194896.0000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1361536.5000 - val_loss: 3192837.7500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1351694.1250 - val_loss: 3190995.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1342107.7500 - val_loss: 3189308.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1332763.1250 - val_loss: 3187732.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1323645.1250 - val_loss: 3186241.5000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1314741.7500 - val_loss: 3184820.0000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1306040.3750 - val_loss: 3183456.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1297530.6250 - val_loss: 3182139.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1289202.5000 - val_loss: 3180852.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1281048.0000 - val_loss: 3179565.2500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1273057.8750 - val_loss: 3178235.5000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1265224.7500 - val_loss: 3176808.0000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1257541.6250 - val_loss: 3175271.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1250002.6250 - val_loss: 3173682.2500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1242600.0000 - val_loss: 3172131.2500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1235329.2500 - val_loss: 3170683.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1228185.0000 - val_loss: 3169339.5000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1221162.3750 - val_loss: 3168086.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1214256.7500 - val_loss: 3166901.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1207463.1250 - val_loss: 3165767.0000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1200777.1250 - val_loss: 3164672.0000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1194196.3750 - val_loss: 3163608.7500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1187717.1250 - val_loss: 3162572.0000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1181334.3750 - val_loss: 3161556.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1175046.0000 - val_loss: 3160561.5000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1168848.5000 - val_loss: 3159585.0000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1162739.5000 - val_loss: 3158624.5000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1156716.3750 - val_loss: 3157678.5000\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 12ms/step - loss: 1794420.2500 - val_loss: 3272811.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1728172.8750 - val_loss: 3271456.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1688288.1250 - val_loss: 3270119.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1656670.6250 - val_loss: 3268498.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1629770.3750 - val_loss: 3266761.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1606031.5000 - val_loss: 3265187.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1584605.3750 - val_loss: 3263746.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1564968.1250 - val_loss: 3262371.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1546767.8750 - val_loss: 3261022.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1529756.1250 - val_loss: 3259760.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1513744.8750 - val_loss: 3258663.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1498593.3750 - val_loss: 3257699.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1484191.3750 - val_loss: 3256794.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1470452.5000 - val_loss: 3255850.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1457300.0000 - val_loss: 3254809.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1444675.0000 - val_loss: 3253696.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1432255.5000 - val_loss: 3253173.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1420041.1250 - val_loss: 3252269.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1408460.1250 - val_loss: 3251474.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1397308.5000 - val_loss: 3250767.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1386525.7500 - val_loss: 3250113.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1376076.8750 - val_loss: 3249494.0000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1365933.7500 - val_loss: 3248895.5000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1356074.3750 - val_loss: 3248304.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1346477.5000 - val_loss: 3247713.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1337127.3750 - val_loss: 3247113.5000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1328007.6250 - val_loss: 3246499.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1319104.5000 - val_loss: 3245863.7500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1310406.7500 - val_loss: 3245217.0000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1301902.2500 - val_loss: 3244554.5000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1293582.1250 - val_loss: 3243889.0000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1285436.0000 - val_loss: 3243226.7500\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1277456.0000 - val_loss: 3242579.0000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1269633.8750 - val_loss: 3241955.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1261961.8750 - val_loss: 3241356.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1254434.2500 - val_loss: 3240784.5000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1247045.0000 - val_loss: 3240242.2500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1239788.0000 - val_loss: 3239724.7500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1232656.1250 - val_loss: 3239228.2500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1225646.5000 - val_loss: 3238755.0000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1218754.5000 - val_loss: 3238299.5000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1211975.0000 - val_loss: 3237859.5000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1205303.3750 - val_loss: 3237434.2500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1198737.1250 - val_loss: 3237020.5000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1192270.8750 - val_loss: 3236617.7500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1185902.7500 - val_loss: 3236224.2500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1179628.1250 - val_loss: 3235838.7500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1173445.2500 - val_loss: 3235461.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1167350.7500 - val_loss: 3235091.2500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1161341.8750 - val_loss: 3234726.2500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 22ms/step - loss: 1818306.8750 - val_loss: 3273806.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1767082.0000 - val_loss: 3273453.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1737577.6250 - val_loss: 3272256.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1714177.2500 - val_loss: 3270342.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1694220.0000 - val_loss: 3268479.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1676593.1250 - val_loss: 3266917.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1660642.0000 - val_loss: 3265712.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1645990.7500 - val_loss: 3264829.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1632373.8750 - val_loss: 3264055.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1619625.6250 - val_loss: 3263380.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1607597.0000 - val_loss: 3262738.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1596197.3750 - val_loss: 3262104.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1585338.3750 - val_loss: 3261473.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1574962.5000 - val_loss: 3260833.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1565007.7500 - val_loss: 3260143.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1555437.6250 - val_loss: 3259428.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1546205.7500 - val_loss: 3258641.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1537287.5000 - val_loss: 3257819.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1528666.5000 - val_loss: 3256996.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1520306.3750 - val_loss: 3256111.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1512193.6250 - val_loss: 3255226.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1504304.1250 - val_loss: 3254351.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1496624.3750 - val_loss: 3253414.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1489140.2500 - val_loss: 3252567.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1481841.2500 - val_loss: 3251755.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1474712.0000 - val_loss: 3250970.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1467746.1250 - val_loss: 3250183.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1460937.0000 - val_loss: 3249416.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1454266.7500 - val_loss: 3248644.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1447735.1250 - val_loss: 3247827.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1441333.1250 - val_loss: 3247015.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1435063.0000 - val_loss: 3246216.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1428909.3750 - val_loss: 3245475.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1422866.2500 - val_loss: 3244768.7500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1416927.3750 - val_loss: 3244064.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1411096.5000 - val_loss: 3243400.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1405358.1250 - val_loss: 3242800.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1399716.2500 - val_loss: 3242241.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1394165.6250 - val_loss: 3241710.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1388700.6250 - val_loss: 3241197.0000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1383321.3750 - val_loss: 3240698.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1378021.0000 - val_loss: 3240234.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1372798.6250 - val_loss: 3239784.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1367653.5000 - val_loss: 3239342.0000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1362579.7500 - val_loss: 3238928.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1357575.3750 - val_loss: 3238522.7500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1352640.2500 - val_loss: 3238111.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1347768.3750 - val_loss: 3237730.2500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1342963.6250 - val_loss: 3237337.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1338216.3750 - val_loss: 3236985.2500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 17ms/step - loss: 1817854.1250 - val_loss: 3273574.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1766197.8750 - val_loss: 3271789.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1736773.5000 - val_loss: 3270267.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1713480.3750 - val_loss: 3269007.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1693646.1250 - val_loss: 3268071.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1676104.8750 - val_loss: 3267306.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1660236.7500 - val_loss: 3266672.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1645674.6250 - val_loss: 3266131.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1632138.0000 - val_loss: 3265938.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1619060.8750 - val_loss: 3265639.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1606843.8750 - val_loss: 3265264.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1595339.3750 - val_loss: 3264873.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1584403.8750 - val_loss: 3264394.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1573969.0000 - val_loss: 3263939.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1563970.8750 - val_loss: 3263491.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1554359.3750 - val_loss: 3262985.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1545099.7500 - val_loss: 3262443.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1536160.8750 - val_loss: 3261870.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1527519.3750 - val_loss: 3261300.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1519140.2500 - val_loss: 3260732.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1511007.3750 - val_loss: 3260153.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1503106.7500 - val_loss: 3259608.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1495410.2500 - val_loss: 3259068.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1487916.8750 - val_loss: 3258524.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1480606.6250 - val_loss: 3258021.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1473471.3750 - val_loss: 3257521.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1466498.0000 - val_loss: 3257060.7500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1459678.0000 - val_loss: 3256571.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1453003.6250 - val_loss: 3256092.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1446469.3750 - val_loss: 3255629.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1440063.1250 - val_loss: 3255141.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1433784.5000 - val_loss: 3254647.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1427621.5000 - val_loss: 3254234.0000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1421567.3750 - val_loss: 3253794.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1415628.2500 - val_loss: 3253368.7500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1409789.3750 - val_loss: 3252944.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1404050.6250 - val_loss: 3252516.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 1398409.5000 - val_loss: 3252133.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1392856.6250 - val_loss: 3251792.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 1387389.3750 - val_loss: 3251446.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1382006.2500 - val_loss: 3251123.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1376704.0000 - val_loss: 3250819.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1371479.0000 - val_loss: 3250501.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1366332.0000 - val_loss: 3250217.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1361257.3750 - val_loss: 3249990.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1356251.3750 - val_loss: 3249750.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1351314.6250 - val_loss: 3249568.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1346441.1250 - val_loss: 3249402.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1341630.5000 - val_loss: 3249235.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1336884.8750 - val_loss: 3249134.7500\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 16ms/step - loss: 1817569.6250 - val_loss: 3271452.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1767148.5000 - val_loss: 3270292.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1737769.0000 - val_loss: 3268910.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1714418.2500 - val_loss: 3267438.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1694506.7500 - val_loss: 3265915.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1676885.2500 - val_loss: 3264667.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1660951.2500 - val_loss: 3263684.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1646299.5000 - val_loss: 3262792.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1632696.2500 - val_loss: 3261925.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1619954.5000 - val_loss: 3261008.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1607931.5000 - val_loss: 3259863.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1596535.3750 - val_loss: 3258611.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1585673.5000 - val_loss: 3257502.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1575302.7500 - val_loss: 3256463.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1565345.8750 - val_loss: 3255198.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1555781.6250 - val_loss: 3253803.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1546551.6250 - val_loss: 3252368.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1537642.7500 - val_loss: 3251143.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1529020.7500 - val_loss: 3250167.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1520661.1250 - val_loss: 3249227.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1512546.6250 - val_loss: 3248317.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1504659.7500 - val_loss: 3247477.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1496982.3750 - val_loss: 3246665.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1489501.3750 - val_loss: 3245940.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1482203.3750 - val_loss: 3245239.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1475080.6250 - val_loss: 3244562.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1468115.5000 - val_loss: 3243867.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1461306.1250 - val_loss: 3243138.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1454637.8750 - val_loss: 3242307.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1448113.5000 - val_loss: 3241384.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 1441713.1250 - val_loss: 3240370.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1435440.1250 - val_loss: 3239417.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1429281.6250 - val_loss: 3238552.0000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1423237.8750 - val_loss: 3237787.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1417299.6250 - val_loss: 3237093.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1411462.8750 - val_loss: 3236451.2500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1405726.8750 - val_loss: 3235858.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1400087.8750 - val_loss: 3235296.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1394536.2500 - val_loss: 3234762.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1389073.1250 - val_loss: 3234250.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1383693.8750 - val_loss: 3233750.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1378392.3750 - val_loss: 3233273.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1373169.1250 - val_loss: 3232801.0000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1368020.8750 - val_loss: 3232345.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1362947.5000 - val_loss: 3231905.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1357944.2500 - val_loss: 3231469.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1353011.2500 - val_loss: 3231049.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1348141.6250 - val_loss: 3230636.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1343336.3750 - val_loss: 3230231.2500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1338585.8750 - val_loss: 3229833.5000\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 23ms/step - loss: 1812578.8750 - val_loss: 3276641.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1762083.0000 - val_loss: 3276784.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1732711.6250 - val_loss: 3276209.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1709371.3750 - val_loss: 3275308.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1689472.2500 - val_loss: 3274386.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1671885.3750 - val_loss: 3273590.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1655981.3750 - val_loss: 3272798.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1641362.5000 - val_loss: 3271985.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1627777.6250 - val_loss: 3271083.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1615059.0000 - val_loss: 3270315.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1603061.2500 - val_loss: 3269592.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1591680.7500 - val_loss: 3268859.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1580841.1250 - val_loss: 3268069.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1570484.2500 - val_loss: 3267269.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1560544.7500 - val_loss: 3266347.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1550989.6250 - val_loss: 3265334.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1541787.8750 - val_loss: 3264314.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1532891.2500 - val_loss: 3263445.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1524280.7500 - val_loss: 3262644.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1515935.7500 - val_loss: 3261986.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1507831.2500 - val_loss: 3261392.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1499957.7500 - val_loss: 3260855.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1492296.1250 - val_loss: 3260363.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1484823.8750 - val_loss: 3259894.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1477535.7500 - val_loss: 3259427.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1470423.6250 - val_loss: 3259001.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1463469.1250 - val_loss: 3258577.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1456675.0000 - val_loss: 3258169.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1450023.0000 - val_loss: 3257784.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1443506.2500 - val_loss: 3257390.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1437115.1250 - val_loss: 3257042.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1430846.6250 - val_loss: 3256668.5000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1424698.5000 - val_loss: 3256283.0000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1418665.0000 - val_loss: 3255917.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1412731.5000 - val_loss: 3255537.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 1406907.5000 - val_loss: 3255151.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1401180.7500 - val_loss: 3254740.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1395551.8750 - val_loss: 3254328.7500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1390010.5000 - val_loss: 3253912.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1384554.1250 - val_loss: 3253473.0000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1379183.7500 - val_loss: 3253019.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1373893.2500 - val_loss: 3252562.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1368682.0000 - val_loss: 3252146.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1363543.8750 - val_loss: 3251689.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1358480.7500 - val_loss: 3251288.2500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1353486.5000 - val_loss: 3250937.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1348557.8750 - val_loss: 3250552.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1343695.5000 - val_loss: 3250150.2500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1338897.8750 - val_loss: 3249846.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1334160.1250 - val_loss: 3249545.7500\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 17ms/step - loss: 1812973.3750 - val_loss: 3274030.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1762125.3750 - val_loss: 3271910.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1732708.6250 - val_loss: 3269696.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1709355.0000 - val_loss: 3267878.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1689438.3750 - val_loss: 3266286.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1671839.1250 - val_loss: 3264761.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1655925.6250 - val_loss: 3263344.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1641299.0000 - val_loss: 3262035.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1627710.8750 - val_loss: 3260746.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1614978.0000 - val_loss: 3259397.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1602980.1250 - val_loss: 3257954.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1591602.1250 - val_loss: 3256411.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1580767.3750 - val_loss: 3254865.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1570411.6250 - val_loss: 3253403.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1560475.5000 - val_loss: 3252111.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1550918.2500 - val_loss: 3250993.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1541710.8750 - val_loss: 3249993.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1532806.2500 - val_loss: 3249075.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1524198.6250 - val_loss: 3248210.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1515851.6250 - val_loss: 3247399.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1507749.8750 - val_loss: 3246622.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1499867.0000 - val_loss: 3245823.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1492200.6250 - val_loss: 3245060.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1484727.7500 - val_loss: 3244302.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 1477444.0000 - val_loss: 3243535.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1470327.7500 - val_loss: 3242776.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1463371.6250 - val_loss: 3242020.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1456572.0000 - val_loss: 3241234.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1449917.7500 - val_loss: 3240410.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1443400.0000 - val_loss: 3239510.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1437011.0000 - val_loss: 3238556.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1430745.7500 - val_loss: 3237536.5000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 1424595.2500 - val_loss: 3236418.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1418563.0000 - val_loss: 3235332.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1412635.1250 - val_loss: 3234191.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1406812.0000 - val_loss: 3233081.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1401084.1250 - val_loss: 3231983.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1395450.0000 - val_loss: 3230873.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1389912.6250 - val_loss: 3229795.2500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1384460.2500 - val_loss: 3228747.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1379087.1250 - val_loss: 3227734.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1373794.2500 - val_loss: 3226720.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1368581.2500 - val_loss: 3225806.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1363447.6250 - val_loss: 3224953.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1358381.6250 - val_loss: 3224154.2500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1353386.0000 - val_loss: 3223390.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1348462.7500 - val_loss: 3222675.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1343598.1250 - val_loss: 3222012.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1338796.2500 - val_loss: 3221359.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 1334061.7500 - val_loss: 3220719.7500\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 20ms/step - loss: 1813951.1250 - val_loss: 3275310.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 1763156.8750 - val_loss: 3274260.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1733772.0000 - val_loss: 3273398.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1710415.0000 - val_loss: 3272557.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1690522.5000 - val_loss: 3271709.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1672926.5000 - val_loss: 3270870.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1657004.1250 - val_loss: 3269986.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1642364.3750 - val_loss: 3269114.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1628781.8750 - val_loss: 3268250.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1616054.6250 - val_loss: 3267487.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1604051.2500 - val_loss: 3266822.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1592663.8750 - val_loss: 3266179.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1581824.7500 - val_loss: 3265579.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1571462.2500 - val_loss: 3265014.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1561525.3750 - val_loss: 3264472.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1551963.8750 - val_loss: 3263930.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1542747.1250 - val_loss: 3263376.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1533847.3750 - val_loss: 3262801.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1525233.7500 - val_loss: 3262169.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1516889.3750 - val_loss: 3261484.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1508779.1250 - val_loss: 3260755.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1500900.8750 - val_loss: 3260016.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1493233.8750 - val_loss: 3259284.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1485761.6250 - val_loss: 3258602.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1478470.7500 - val_loss: 3257962.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1471357.8750 - val_loss: 3257380.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1464400.8750 - val_loss: 3256814.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1457598.7500 - val_loss: 3256281.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1450940.1250 - val_loss: 3255761.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1444420.7500 - val_loss: 3255265.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1438028.5000 - val_loss: 3254794.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1431757.7500 - val_loss: 3254359.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1425606.0000 - val_loss: 3253924.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1419563.5000 - val_loss: 3253494.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1413638.2500 - val_loss: 3253087.7500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1407813.5000 - val_loss: 3252683.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1402087.5000 - val_loss: 3252292.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1396453.0000 - val_loss: 3251915.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1390909.2500 - val_loss: 3251525.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1385451.3750 - val_loss: 3251153.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1380076.5000 - val_loss: 3250765.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 1374787.0000 - val_loss: 3250375.0000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1369574.3750 - val_loss: 3250006.0000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1364435.0000 - val_loss: 3249631.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1359369.6250 - val_loss: 3249246.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1354373.6250 - val_loss: 3248890.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1349440.0000 - val_loss: 3248574.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1344572.1250 - val_loss: 3248186.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1339771.5000 - val_loss: 3247811.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1335036.1250 - val_loss: 3247422.5000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 21ms/step - loss: 1817678.7500 - val_loss: 3273703.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1766961.7500 - val_loss: 3272583.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1738021.3750 - val_loss: 3271073.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1715054.3750 - val_loss: 3269231.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1695486.6250 - val_loss: 3267341.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1678182.1250 - val_loss: 3265695.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1662527.1250 - val_loss: 3264329.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1648138.1250 - val_loss: 3263064.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1634781.7500 - val_loss: 3261885.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1622264.7500 - val_loss: 3260738.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1610458.0000 - val_loss: 3259575.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1599266.6250 - val_loss: 3258447.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1588598.0000 - val_loss: 3257353.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1578401.5000 - val_loss: 3256298.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1568631.8750 - val_loss: 3255349.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1559222.6250 - val_loss: 3254463.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1550161.6250 - val_loss: 3253642.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1541404.5000 - val_loss: 3252861.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1532927.7500 - val_loss: 3252126.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1524714.6250 - val_loss: 3251428.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1516734.7500 - val_loss: 3250758.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1508978.6250 - val_loss: 3250116.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1501422.2500 - val_loss: 3249486.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1494068.5000 - val_loss: 3248879.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1486892.8750 - val_loss: 3248290.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1479889.1250 - val_loss: 3247719.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1473043.7500 - val_loss: 3247162.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1466345.0000 - val_loss: 3246616.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1459788.0000 - val_loss: 3246085.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1453369.0000 - val_loss: 3245570.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1447076.2500 - val_loss: 3245057.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1440908.3750 - val_loss: 3244549.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1434855.5000 - val_loss: 3244046.0000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1428908.1250 - val_loss: 3243539.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1423072.0000 - val_loss: 3243019.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1417335.7500 - val_loss: 3242485.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1411694.7500 - val_loss: 3241894.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1406145.8750 - val_loss: 3241282.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 1400687.7500 - val_loss: 3240645.2500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1395308.2500 - val_loss: 3239936.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1390017.6250 - val_loss: 3239210.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1384800.8750 - val_loss: 3238451.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1379661.5000 - val_loss: 3237720.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1374599.5000 - val_loss: 3237024.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1369605.8750 - val_loss: 3236339.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1364681.3750 - val_loss: 3235708.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1359821.8750 - val_loss: 3235109.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1355025.1250 - val_loss: 3234546.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1350291.0000 - val_loss: 3234008.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1345622.2500 - val_loss: 3233491.5000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 20ms/step - loss: 1816283.3750 - val_loss: 3276431.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1765940.5000 - val_loss: 3276098.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1736628.5000 - val_loss: 3274745.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1713387.1250 - val_loss: 3273017.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1693579.7500 - val_loss: 3271554.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1676074.7500 - val_loss: 3270415.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1660219.3750 - val_loss: 3269398.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1645671.5000 - val_loss: 3268437.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1632151.1250 - val_loss: 3267583.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1619493.2500 - val_loss: 3266808.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1607548.1250 - val_loss: 3266164.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1596215.7500 - val_loss: 3265579.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1585427.7500 - val_loss: 3265050.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1575117.3750 - val_loss: 3264530.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1565231.7500 - val_loss: 3264053.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1555719.5000 - val_loss: 3263590.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1546554.6250 - val_loss: 3263146.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1537699.5000 - val_loss: 3262706.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1529129.5000 - val_loss: 3262282.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1520823.1250 - val_loss: 3261856.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1512761.0000 - val_loss: 3261434.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1504919.3750 - val_loss: 3260983.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1497288.6250 - val_loss: 3260524.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1489851.5000 - val_loss: 3260060.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1482597.0000 - val_loss: 3259489.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1475514.6250 - val_loss: 3258942.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1468584.6250 - val_loss: 3258407.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1461810.6250 - val_loss: 3257815.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1455185.2500 - val_loss: 3257232.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1448700.0000 - val_loss: 3256664.2500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1442340.0000 - val_loss: 3256105.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1436104.0000 - val_loss: 3255585.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1429982.3750 - val_loss: 3255050.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1423973.6250 - val_loss: 3254538.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1418073.6250 - val_loss: 3254088.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1412271.5000 - val_loss: 3253651.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1406569.1250 - val_loss: 3253259.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1400961.3750 - val_loss: 3252865.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1395443.1250 - val_loss: 3252524.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1390009.8750 - val_loss: 3252182.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1384659.2500 - val_loss: 3251858.2500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 1379390.3750 - val_loss: 3251559.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1374198.8750 - val_loss: 3251266.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1369082.5000 - val_loss: 3250989.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1364038.8750 - val_loss: 3250728.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1359060.3750 - val_loss: 3250470.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1354154.0000 - val_loss: 3250228.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1349307.1250 - val_loss: 3249988.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1344527.1250 - val_loss: 3249756.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 1339809.3750 - val_loss: 3249536.0000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 10s 19ms/step - loss: 1815063.8750 - val_loss: 3277050.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1764648.0000 - val_loss: 3277946.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1735451.1250 - val_loss: 3278534.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1712257.2500 - val_loss: 3279034.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1692461.7500 - val_loss: 3279491.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1674960.1250 - val_loss: 3279872.0000\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 28ms/step - loss: 1819538.6250 - val_loss: 3276502.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1768811.0000 - val_loss: 3276978.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1739366.7500 - val_loss: 3276854.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1715972.0000 - val_loss: 3276509.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1696025.3750 - val_loss: 3275986.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1678394.6250 - val_loss: 3275521.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1662441.1250 - val_loss: 3275022.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1647793.6250 - val_loss: 3274584.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1634175.2500 - val_loss: 3274174.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1621421.8750 - val_loss: 3273736.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1609397.2500 - val_loss: 3273321.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1597994.0000 - val_loss: 3272995.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1587126.3750 - val_loss: 3272634.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1576744.7500 - val_loss: 3272336.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1566794.0000 - val_loss: 3272050.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1557219.3750 - val_loss: 3271801.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1547992.2500 - val_loss: 3271551.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1539083.5000 - val_loss: 3271352.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1530450.1250 - val_loss: 3271133.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1522089.5000 - val_loss: 3270934.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1513967.1250 - val_loss: 3270741.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1506073.2500 - val_loss: 3270558.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1498391.1250 - val_loss: 3270380.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1490909.0000 - val_loss: 3270220.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1483608.2500 - val_loss: 3270067.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1476478.0000 - val_loss: 3269917.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1469508.0000 - val_loss: 3269768.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1462693.2500 - val_loss: 3269618.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1456021.6250 - val_loss: 3269451.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1449485.5000 - val_loss: 3269278.2500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1443078.0000 - val_loss: 3269049.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1436800.5000 - val_loss: 3268784.5000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1430636.3750 - val_loss: 3268403.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1424590.3750 - val_loss: 3267973.7500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1418647.8750 - val_loss: 3267459.7500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1412809.6250 - val_loss: 3266934.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1407069.5000 - val_loss: 3266490.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1401420.2500 - val_loss: 3265985.7500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1395868.7500 - val_loss: 3265539.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1390403.3750 - val_loss: 3265150.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1385021.2500 - val_loss: 3264822.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1379719.5000 - val_loss: 3264517.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1374494.3750 - val_loss: 3264231.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1369346.1250 - val_loss: 3264010.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1364268.7500 - val_loss: 3263828.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1359262.8750 - val_loss: 3263655.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1354324.0000 - val_loss: 3263506.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1349451.6250 - val_loss: 3263371.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1344643.0000 - val_loss: 3263246.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1339893.3750 - val_loss: 3263121.2500\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 27ms/step - loss: 1836546.0000 - val_loss: 3276139.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1796613.6250 - val_loss: 3276736.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1775096.7500 - val_loss: 3277112.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1758038.5000 - val_loss: 3277350.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1743521.2500 - val_loss: 3277563.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1730654.0000 - val_loss: 3277810.5000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 30ms/step - loss: 1833675.0000 - val_loss: 3277363.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1793109.6250 - val_loss: 3278076.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1771568.1250 - val_loss: 3278532.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1754529.1250 - val_loss: 3278876.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1740006.6250 - val_loss: 3279165.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1727159.6250 - val_loss: 3279399.7500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 33ms/step - loss: 1835073.1250 - val_loss: 3276159.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1794347.6250 - val_loss: 3276515.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1772751.6250 - val_loss: 3276442.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1755688.3750 - val_loss: 3276263.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1741121.5000 - val_loss: 3276172.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1728266.6250 - val_loss: 3276005.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1716636.7500 - val_loss: 3275803.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1705915.7500 - val_loss: 3275717.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1695950.5000 - val_loss: 3275587.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1686610.1250 - val_loss: 3275551.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1677785.1250 - val_loss: 3275532.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1669385.0000 - val_loss: 3275406.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1661399.8750 - val_loss: 3275418.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1653752.0000 - val_loss: 3275383.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1646418.5000 - val_loss: 3275284.7500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1639357.7500 - val_loss: 3275210.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1632534.8750 - val_loss: 3275088.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1625935.6250 - val_loss: 3274967.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1619547.2500 - val_loss: 3274806.5000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1613342.6250 - val_loss: 3274755.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1607311.0000 - val_loss: 3274609.5000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1601446.8750 - val_loss: 3274493.2500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1595719.5000 - val_loss: 3274423.7500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1590141.1250 - val_loss: 3274326.2500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1584700.3750 - val_loss: 3274139.0000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1579376.7500 - val_loss: 3273979.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1574180.6250 - val_loss: 3273823.5000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1569076.6250 - val_loss: 3273661.7500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1564085.3750 - val_loss: 3273480.5000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1559187.7500 - val_loss: 3273314.5000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1554387.1250 - val_loss: 3273128.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1549673.7500 - val_loss: 3272935.2500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1545046.6250 - val_loss: 3272705.2500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1540496.3750 - val_loss: 3272489.2500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1536028.0000 - val_loss: 3272362.7500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1531627.0000 - val_loss: 3272142.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1527306.2500 - val_loss: 3271881.0000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1523050.7500 - val_loss: 3271410.2500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1518861.6250 - val_loss: 3271205.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1514731.3750 - val_loss: 3271019.5000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1510653.7500 - val_loss: 3270815.5000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1506638.3750 - val_loss: 3270636.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1502679.7500 - val_loss: 3270479.5000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1498774.6250 - val_loss: 3270322.5000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1494925.6250 - val_loss: 3270176.7500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1491120.5000 - val_loss: 3270049.0000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1487364.5000 - val_loss: 3269942.7500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1483653.3750 - val_loss: 3269809.2500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1479991.6250 - val_loss: 3269749.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1476360.2500 - val_loss: 3269567.0000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 36ms/step - loss: 1833905.5000 - val_loss: 3275395.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1793241.2500 - val_loss: 3275795.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1771722.1250 - val_loss: 3275864.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1754662.8750 - val_loss: 3275971.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1740125.3750 - val_loss: 3276008.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1727260.7500 - val_loss: 3276011.7500\n",
            "7/7 [==============================] - 1s 13ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 30ms/step - loss: 1839176.1250 - val_loss: 3276240.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1799219.2500 - val_loss: 3277036.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1777741.1250 - val_loss: 3277403.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1760805.6250 - val_loss: 3277551.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1746332.7500 - val_loss: 3277554.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1733567.2500 - val_loss: 3277492.0000\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1834715.5000 - val_loss: 3276488.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1793187.5000 - val_loss: 3277219.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1771564.3750 - val_loss: 3277641.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1754476.5000 - val_loss: 3277904.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1739922.8750 - val_loss: 3278080.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1727052.0000 - val_loss: 3278190.0000\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 28ms/step - loss: 1834998.6250 - val_loss: 3274075.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1793650.6250 - val_loss: 3273749.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1772061.1250 - val_loss: 3273320.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1754976.7500 - val_loss: 3272823.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1740402.6250 - val_loss: 3272187.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1727522.6250 - val_loss: 3271582.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1715861.1250 - val_loss: 3270986.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1705126.2500 - val_loss: 3270380.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1695168.6250 - val_loss: 3269818.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1685815.2500 - val_loss: 3269356.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1676970.3750 - val_loss: 3268911.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1668586.1250 - val_loss: 3268523.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1660589.8750 - val_loss: 3268124.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1652953.3750 - val_loss: 3267779.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1645619.7500 - val_loss: 3267450.2500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1638563.3750 - val_loss: 3267175.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1631741.0000 - val_loss: 3266896.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1625139.7500 - val_loss: 3266616.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1618751.1250 - val_loss: 3266327.5000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1612548.5000 - val_loss: 3266087.2500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1606513.7500 - val_loss: 3265823.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1600647.3750 - val_loss: 3265551.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1594940.5000 - val_loss: 3265274.2500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1589362.5000 - val_loss: 3264985.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1583923.8750 - val_loss: 3264694.7500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1578613.6250 - val_loss: 3264397.2500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1573409.5000 - val_loss: 3264070.0000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1568320.5000 - val_loss: 3263717.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1563317.6250 - val_loss: 3263387.7500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1558429.3750 - val_loss: 3263030.7500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1553631.1250 - val_loss: 3262699.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1548915.2500 - val_loss: 3262338.2500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1544284.5000 - val_loss: 3262003.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1539735.8750 - val_loss: 3261656.7500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1535268.2500 - val_loss: 3261340.7500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1530873.0000 - val_loss: 3261017.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1526551.2500 - val_loss: 3260741.5000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1522286.3750 - val_loss: 3260429.2500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1518096.3750 - val_loss: 3260130.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1513965.0000 - val_loss: 3259835.5000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1509892.2500 - val_loss: 3259567.2500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1505878.6250 - val_loss: 3259285.5000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1501927.7500 - val_loss: 3259068.7500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1498021.2500 - val_loss: 3258795.7500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1494177.1250 - val_loss: 3258470.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1490378.2500 - val_loss: 3258168.2500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1486629.3750 - val_loss: 3257877.7500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1482920.3750 - val_loss: 3257639.7500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1479255.8750 - val_loss: 3257395.7500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1475632.8750 - val_loss: 3257081.5000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 25ms/step - loss: 1832704.1250 - val_loss: 3275461.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1791343.2500 - val_loss: 3276061.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1769689.1250 - val_loss: 3276118.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1752617.1250 - val_loss: 3275947.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1738079.1250 - val_loss: 3275695.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1725192.1250 - val_loss: 3275217.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1713572.1250 - val_loss: 3274810.7500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1702875.1250 - val_loss: 3274397.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1692923.5000 - val_loss: 3274018.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1683573.7500 - val_loss: 3273587.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1674753.6250 - val_loss: 3273152.0000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1666393.0000 - val_loss: 3272744.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1658417.7500 - val_loss: 3272375.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1650769.2500 - val_loss: 3272016.5000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1643439.2500 - val_loss: 3271676.7500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1636371.8750 - val_loss: 3271282.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1629566.6250 - val_loss: 3270914.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1622961.2500 - val_loss: 3270526.7500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1616576.5000 - val_loss: 3270105.0000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1610388.2500 - val_loss: 3269716.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1604370.5000 - val_loss: 3269371.0000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1598508.7500 - val_loss: 3269056.2500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1592803.3750 - val_loss: 3268805.0000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1587220.0000 - val_loss: 3268566.0000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1581769.7500 - val_loss: 3268337.5000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1576452.7500 - val_loss: 3268139.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1571246.8750 - val_loss: 3267941.7500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1566154.8750 - val_loss: 3267750.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1561161.6250 - val_loss: 3267551.5000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1556276.2500 - val_loss: 3267341.2500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1551485.5000 - val_loss: 3267107.2500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1546780.7500 - val_loss: 3266857.0000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1542160.8750 - val_loss: 3266576.2500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1537617.1250 - val_loss: 3266232.2500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1533157.0000 - val_loss: 3265868.2500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1528756.8750 - val_loss: 3265501.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1524431.8750 - val_loss: 3265123.5000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1520182.8750 - val_loss: 3264735.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1515987.0000 - val_loss: 3264434.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1511844.5000 - val_loss: 3264149.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1507770.0000 - val_loss: 3263853.2500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1503747.3750 - val_loss: 3263550.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1499789.5000 - val_loss: 3263284.2500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1495877.6250 - val_loss: 3262938.7500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1492034.1250 - val_loss: 3262523.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1488235.5000 - val_loss: 3262112.7500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1484485.5000 - val_loss: 3261780.5000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1480772.2500 - val_loss: 3261387.7500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1477110.3750 - val_loss: 3261050.2500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1473499.1250 - val_loss: 3260767.5000\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 23ms/step - loss: 1836631.2500 - val_loss: 3275931.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1796606.0000 - val_loss: 3276455.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1775059.5000 - val_loss: 3276622.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1757804.1250 - val_loss: 3276141.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1743219.8750 - val_loss: 3275464.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1730322.2500 - val_loss: 3274758.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1718629.0000 - val_loss: 3274104.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1707900.7500 - val_loss: 3273553.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1697933.6250 - val_loss: 3273063.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1688579.0000 - val_loss: 3272656.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1679731.6250 - val_loss: 3272288.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1671342.2500 - val_loss: 3271949.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1663348.0000 - val_loss: 3271657.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1655702.0000 - val_loss: 3271408.7500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1648362.1250 - val_loss: 3271196.5000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1641286.6250 - val_loss: 3271005.5000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1634459.3750 - val_loss: 3270815.5000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1627861.8750 - val_loss: 3270654.2500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1621458.3750 - val_loss: 3270488.2500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1615247.2500 - val_loss: 3270316.0000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1609222.6250 - val_loss: 3270162.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1603351.1250 - val_loss: 3270003.7500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1597636.5000 - val_loss: 3269852.2500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1592054.2500 - val_loss: 3269721.0000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1586593.5000 - val_loss: 3269571.2500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1581261.5000 - val_loss: 3269419.5000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1576046.2500 - val_loss: 3269282.0000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1570939.3750 - val_loss: 3269116.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1565953.1250 - val_loss: 3268984.2500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1561047.6250 - val_loss: 3268807.7500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1556246.2500 - val_loss: 3268598.7500\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1551526.3750 - val_loss: 3268444.5000\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1546892.0000 - val_loss: 3268218.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1542342.0000 - val_loss: 3267996.5000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1537865.5000 - val_loss: 3267749.0000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1533459.1250 - val_loss: 3267513.5000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1529131.6250 - val_loss: 3267212.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1524872.8750 - val_loss: 3266926.2500\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1520682.2500 - val_loss: 3266587.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1516554.0000 - val_loss: 3266370.5000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1512470.3750 - val_loss: 3266074.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1508460.1250 - val_loss: 3265845.0000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1504495.7500 - val_loss: 3265571.7500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1500587.7500 - val_loss: 3265338.2500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1496735.2500 - val_loss: 3265107.2500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1492926.5000 - val_loss: 3264948.2500\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1489161.1250 - val_loss: 3264729.0000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1485455.6250 - val_loss: 3264510.2500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1481793.3750 - val_loss: 3264329.7500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1478173.2500 - val_loss: 3264076.7500\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 26ms/step - loss: 1836792.7500 - val_loss: 3276474.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1796117.0000 - val_loss: 3277158.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1774511.5000 - val_loss: 3277508.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1757441.8750 - val_loss: 3277675.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1742891.6250 - val_loss: 3277704.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1729996.5000 - val_loss: 3277666.5000\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 12ms/step - loss: 1901288.1250 - val_loss: 3274649.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1868359.0000 - val_loss: 3275104.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1852504.6250 - val_loss: 3274589.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1846488.0000 - val_loss: 3274313.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1842376.1250 - val_loss: 3274173.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1839049.3750 - val_loss: 3274103.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1836175.2500 - val_loss: 3274067.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1833607.0000 - val_loss: 3274051.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1831263.7500 - val_loss: 3274045.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1829094.1250 - val_loss: 3274046.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1827064.7500 - val_loss: 3274050.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1825150.8750 - val_loss: 3274055.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1823336.1250 - val_loss: 3274061.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1821606.6250 - val_loss: 3274068.5000\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 15ms/step - loss: 1900234.3750 - val_loss: 3275438.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1867095.7500 - val_loss: 3275451.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1851937.2500 - val_loss: 3274938.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1845751.6250 - val_loss: 3274660.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1841559.8750 - val_loss: 3274541.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1838188.5000 - val_loss: 3274491.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1835285.6250 - val_loss: 3274477.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1832694.8750 - val_loss: 3274479.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1830332.6250 - val_loss: 3274489.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1828146.8750 - val_loss: 3274505.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1826103.6250 - val_loss: 3274521.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1824175.8750 - val_loss: 3274538.0000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 10ms/step - loss: 1898622.0000 - val_loss: 3275946.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1864812.0000 - val_loss: 3276115.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1851166.7500 - val_loss: 3275393.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1845339.1250 - val_loss: 3274907.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1841274.3750 - val_loss: 3274649.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1837970.8750 - val_loss: 3274512.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1835110.7500 - val_loss: 3274436.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1832549.8750 - val_loss: 3274394.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1830210.0000 - val_loss: 3274372.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1828042.3750 - val_loss: 3274359.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1826013.1250 - val_loss: 3274354.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1824098.5000 - val_loss: 3274352.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1822281.0000 - val_loss: 3274353.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1820547.2500 - val_loss: 3274356.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1818888.6250 - val_loss: 3274359.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1817294.1250 - val_loss: 3274362.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1815756.7500 - val_loss: 3274366.5000\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 13ms/step - loss: 1899125.1250 - val_loss: 3275442.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1865566.3750 - val_loss: 3275714.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1850120.8750 - val_loss: 3275030.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1843864.0000 - val_loss: 3274656.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1839682.8750 - val_loss: 3274497.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1836331.7500 - val_loss: 3274437.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1833449.0000 - val_loss: 3274423.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1830877.7500 - val_loss: 3274436.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1828532.3750 - val_loss: 3274462.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1826363.1250 - val_loss: 3274496.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1824334.1250 - val_loss: 3274535.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1822421.2500 - val_loss: 3274575.5000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 14ms/step - loss: 1900780.2500 - val_loss: 3276241.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1866919.7500 - val_loss: 3276738.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1851437.0000 - val_loss: 3275943.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1845364.0000 - val_loss: 3275483.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1841221.3750 - val_loss: 3275265.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1837884.6250 - val_loss: 3275171.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1835004.3750 - val_loss: 3275143.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1832403.2500 - val_loss: 3275151.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1830011.7500 - val_loss: 3275168.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1827809.2500 - val_loss: 3275192.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1825755.2500 - val_loss: 3275220.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1823821.7500 - val_loss: 3275250.2500\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 12ms/step - loss: 1899607.0000 - val_loss: 3275803.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1866606.8750 - val_loss: 3276497.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1851556.1250 - val_loss: 3275891.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1845246.7500 - val_loss: 3275317.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1841009.1250 - val_loss: 3274995.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1837624.3750 - val_loss: 3274826.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1834717.7500 - val_loss: 3274736.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1832126.6250 - val_loss: 3274689.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1829765.8750 - val_loss: 3274666.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1827581.8750 - val_loss: 3274656.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1825539.8750 - val_loss: 3274655.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1823614.3750 - val_loss: 3274658.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1821788.1250 - val_loss: 3274663.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1820048.3750 - val_loss: 3274669.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1818381.3750 - val_loss: 3274675.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1816782.1250 - val_loss: 3274681.0000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 11ms/step - loss: 1900233.3750 - val_loss: 3276242.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1866818.8750 - val_loss: 3276514.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1852074.8750 - val_loss: 3275674.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1846049.8750 - val_loss: 3275190.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1841915.3750 - val_loss: 3274966.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1838573.7500 - val_loss: 3274857.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1835689.1250 - val_loss: 3274804.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1833111.7500 - val_loss: 3274781.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1830759.3750 - val_loss: 3274773.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1828581.5000 - val_loss: 3274774.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1826543.5000 - val_loss: 3274779.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1824622.3750 - val_loss: 3274785.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1822798.8750 - val_loss: 3274792.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1821059.8750 - val_loss: 3274800.7500\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 15ms/step - loss: 1901698.2500 - val_loss: 3274622.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1870209.5000 - val_loss: 3274765.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1856034.7500 - val_loss: 3274315.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1850284.1250 - val_loss: 3274133.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1846242.1250 - val_loss: 3274071.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1842926.3750 - val_loss: 3274061.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1840046.3750 - val_loss: 3274074.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1837470.8750 - val_loss: 3274099.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1835117.1250 - val_loss: 3274130.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1832938.8750 - val_loss: 3274162.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1830900.5000 - val_loss: 3274194.7500\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 10ms/step - loss: 1900292.6250 - val_loss: 3275290.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1866186.6250 - val_loss: 3275468.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1849264.2500 - val_loss: 3274975.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1843074.6250 - val_loss: 3274597.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1838910.3750 - val_loss: 3274367.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1835552.2500 - val_loss: 3274219.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1832654.1250 - val_loss: 3274114.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1830065.2500 - val_loss: 3274038.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1827702.3750 - val_loss: 3273978.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1825517.0000 - val_loss: 3273928.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1823472.3750 - val_loss: 3273885.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1821545.7500 - val_loss: 3273847.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1819717.6250 - val_loss: 3273812.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1817975.0000 - val_loss: 3273778.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1816307.7500 - val_loss: 3273746.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1814705.6250 - val_loss: 3273714.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1813161.6250 - val_loss: 3273683.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1811671.6250 - val_loss: 3273653.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1810228.2500 - val_loss: 3273622.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1808829.1250 - val_loss: 3273592.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1807469.8750 - val_loss: 3273561.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1806147.6250 - val_loss: 3273530.2500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1804857.7500 - val_loss: 3273499.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1803601.0000 - val_loss: 3273467.7500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1802372.5000 - val_loss: 3273435.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1801171.6250 - val_loss: 3273403.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1799997.5000 - val_loss: 3273371.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1798846.1250 - val_loss: 3273337.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1797718.0000 - val_loss: 3273304.5000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1796611.6250 - val_loss: 3273270.7500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1795525.8750 - val_loss: 3273236.2500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1794458.5000 - val_loss: 3273202.0000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1793409.6250 - val_loss: 3273166.7500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1792378.6250 - val_loss: 3273132.0000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1791363.2500 - val_loss: 3273096.5000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1790364.1250 - val_loss: 3273059.7500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1789380.6250 - val_loss: 3273023.7500\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1788411.0000 - val_loss: 3272987.2500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1787456.6250 - val_loss: 3272949.5000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1786513.6250 - val_loss: 3272912.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1785584.5000 - val_loss: 3272875.5000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1784668.6250 - val_loss: 3272837.2500\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1783762.8750 - val_loss: 3272799.0000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1782870.2500 - val_loss: 3272760.7500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1781986.8750 - val_loss: 3272721.7500\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1781114.6250 - val_loss: 3272682.5000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1780253.0000 - val_loss: 3272643.7500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1779401.6250 - val_loss: 3272603.2500\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1778559.2500 - val_loss: 3272564.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1777725.3750 - val_loss: 3272524.2500\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 12ms/step - loss: 1901358.3750 - val_loss: 3275664.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1868659.7500 - val_loss: 3275919.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1852371.6250 - val_loss: 3275327.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1846146.5000 - val_loss: 3275000.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1841926.3750 - val_loss: 3274842.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1838532.0000 - val_loss: 3274763.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1835611.0000 - val_loss: 3274721.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1833007.7500 - val_loss: 3274702.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1830635.6250 - val_loss: 3274693.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1828441.7500 - val_loss: 3274689.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1826390.5000 - val_loss: 3274690.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1824458.1250 - val_loss: 3274691.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1822624.7500 - val_loss: 3274690.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1820878.5000 - val_loss: 3274690.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1819207.5000 - val_loss: 3274689.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1817602.7500 - val_loss: 3274686.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1816056.3750 - val_loss: 3274681.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1814562.5000 - val_loss: 3274675.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1813117.1250 - val_loss: 3274668.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1811716.5000 - val_loss: 3274659.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1810354.3750 - val_loss: 3274648.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1809029.5000 - val_loss: 3274636.7500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1807739.5000 - val_loss: 3274624.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1806480.3750 - val_loss: 3274608.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1805249.8750 - val_loss: 3274593.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1804048.3750 - val_loss: 3274575.5000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1802871.7500 - val_loss: 3274557.2500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1801720.6250 - val_loss: 3274537.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1800590.2500 - val_loss: 3274517.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1799482.1250 - val_loss: 3274494.7500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1798394.7500 - val_loss: 3274472.7500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1797327.1250 - val_loss: 3274449.5000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1796277.8750 - val_loss: 3274425.5000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1795245.5000 - val_loss: 3274400.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1794229.1250 - val_loss: 3274375.0000\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1793229.5000 - val_loss: 3274347.7500\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1792245.1250 - val_loss: 3274321.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1791275.6250 - val_loss: 3274293.5000\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1790318.5000 - val_loss: 3274265.5000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1789376.1250 - val_loss: 3274236.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1788445.8750 - val_loss: 3274207.5000\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1787528.0000 - val_loss: 3274177.5000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1786622.3750 - val_loss: 3274147.5000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1785727.8750 - val_loss: 3274116.5000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1784844.5000 - val_loss: 3274086.0000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1783971.8750 - val_loss: 3274054.0000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1783108.0000 - val_loss: 3274022.5000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1782255.2500 - val_loss: 3273990.0000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1781412.6250 - val_loss: 3273957.7500\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1780578.8750 - val_loss: 3273925.5000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 25ms/step - loss: 1905160.6250 - val_loss: 3275475.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1886952.6250 - val_loss: 3276982.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1866807.0000 - val_loss: 3276965.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1857923.8750 - val_loss: 3276570.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1853292.8750 - val_loss: 3276141.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1850122.8750 - val_loss: 3275810.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 21ms/step - loss: 1904925.1250 - val_loss: 3275248.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1885036.1250 - val_loss: 3276910.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1863093.1250 - val_loss: 3276855.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1854372.5000 - val_loss: 3276457.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1849947.7500 - val_loss: 3276102.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1846868.6250 - val_loss: 3275862.2500\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 27ms/step - loss: 1904763.2500 - val_loss: 3275208.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1885368.2500 - val_loss: 3276968.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1863703.0000 - val_loss: 3276660.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1854106.5000 - val_loss: 3276111.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1849304.7500 - val_loss: 3275727.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1846076.5000 - val_loss: 3275496.7500\n",
            "7/7 [==============================] - 1s 12ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 20ms/step - loss: 1903148.1250 - val_loss: 3276567.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1881118.3750 - val_loss: 3277409.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1861908.0000 - val_loss: 3277147.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1853892.6250 - val_loss: 3276761.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1849539.8750 - val_loss: 3276441.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1846485.2500 - val_loss: 3276209.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1844044.2500 - val_loss: 3276055.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1841955.0000 - val_loss: 3275951.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1840099.5000 - val_loss: 3275882.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1838413.7500 - val_loss: 3275835.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1836856.3750 - val_loss: 3275805.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1835402.7500 - val_loss: 3275787.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1834033.7500 - val_loss: 3275777.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1832736.7500 - val_loss: 3275774.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1831500.7500 - val_loss: 3275775.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1830318.2500 - val_loss: 3275781.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1829182.6250 - val_loss: 3275788.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1828088.5000 - val_loss: 3275799.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1827032.0000 - val_loss: 3275811.0000\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 24ms/step - loss: 1904644.0000 - val_loss: 3275568.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1885251.8750 - val_loss: 3277085.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1865899.6250 - val_loss: 3277010.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1857426.3750 - val_loss: 3276577.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1852907.5000 - val_loss: 3276170.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1849767.3750 - val_loss: 3275897.5000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 21ms/step - loss: 1905016.5000 - val_loss: 3274409.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1885725.0000 - val_loss: 3275924.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1864458.6250 - val_loss: 3275729.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1855404.0000 - val_loss: 3275318.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1850843.0000 - val_loss: 3275030.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1847718.8750 - val_loss: 3274842.2500\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 25ms/step - loss: 1904321.2500 - val_loss: 3275864.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1884375.8750 - val_loss: 3277571.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1863538.8750 - val_loss: 3277758.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1854455.3750 - val_loss: 3277498.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1849735.6250 - val_loss: 3277097.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1846498.5000 - val_loss: 3276742.5000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 18ms/step - loss: 1904470.5000 - val_loss: 3275461.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1883929.0000 - val_loss: 3276675.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1863985.7500 - val_loss: 3276559.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1855426.0000 - val_loss: 3276140.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1850933.6250 - val_loss: 3275785.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1847817.5000 - val_loss: 3275563.5000\n",
            "7/7 [==============================] - 1s 12ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 26ms/step - loss: 1904978.3750 - val_loss: 3274612.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1887253.8750 - val_loss: 3276478.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1867035.1250 - val_loss: 3276560.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 1857756.3750 - val_loss: 3276171.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1852991.2500 - val_loss: 3275803.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1849760.6250 - val_loss: 3275538.2500\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 25ms/step - loss: 1905352.3750 - val_loss: 3274532.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1888737.1250 - val_loss: 3276357.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1866243.8750 - val_loss: 3276604.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1855932.3750 - val_loss: 3276286.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1850967.1250 - val_loss: 3275951.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 1847665.8750 - val_loss: 3275698.5000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 26ms/step - loss: 1906946.2500 - val_loss: 3272592.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1901296.5000 - val_loss: 3274742.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1888818.3750 - val_loss: 3276101.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1873747.1250 - val_loss: 3276477.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1864313.2500 - val_loss: 3276439.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1859239.2500 - val_loss: 3276265.0000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 34ms/step - loss: 1906709.3750 - val_loss: 3273856.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1900071.2500 - val_loss: 3275583.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1886516.8750 - val_loss: 3276602.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1872303.7500 - val_loss: 3277016.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1863056.5000 - val_loss: 3277051.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1857592.6250 - val_loss: 3276884.5000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 24ms/step - loss: 1906761.0000 - val_loss: 3273812.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1899691.3750 - val_loss: 3275541.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1885814.5000 - val_loss: 3276278.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1872312.3750 - val_loss: 3276463.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1864037.5000 - val_loss: 3276374.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1859364.2500 - val_loss: 3276191.5000\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 25ms/step - loss: 1906435.8750 - val_loss: 3274095.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1898790.6250 - val_loss: 3275980.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1884603.2500 - val_loss: 3277016.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1870484.6250 - val_loss: 3277440.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1861162.2500 - val_loss: 3277528.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1855617.5000 - val_loss: 3277428.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 32ms/step - loss: 1906876.5000 - val_loss: 3273130.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1900223.1250 - val_loss: 3274805.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1887408.3750 - val_loss: 3275673.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1875086.3750 - val_loss: 3275990.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1867159.2500 - val_loss: 3276005.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1862346.6250 - val_loss: 3275846.0000\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 26ms/step - loss: 1906948.2500 - val_loss: 3273379.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1900024.7500 - val_loss: 3275250.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1886208.2500 - val_loss: 3276146.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1873056.5000 - val_loss: 3276403.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1864930.0000 - val_loss: 3276342.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1860122.7500 - val_loss: 3276143.2500\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 37ms/step - loss: 1906865.8750 - val_loss: 3273203.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1900475.2500 - val_loss: 3275069.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1888166.1250 - val_loss: 3276136.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1876101.8750 - val_loss: 3276564.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1867674.5000 - val_loss: 3276654.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1861933.5000 - val_loss: 3276547.2500\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 25ms/step - loss: 1907191.3750 - val_loss: 3272630.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1901074.3750 - val_loss: 3274821.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1887935.7500 - val_loss: 3275950.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1873691.1250 - val_loss: 3276308.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1864051.5000 - val_loss: 3276268.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1858416.1250 - val_loss: 3275991.2500\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 28ms/step - loss: 1906946.8750 - val_loss: 3273111.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1901033.0000 - val_loss: 3276077.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1887458.8750 - val_loss: 3277614.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1872198.8750 - val_loss: 3277985.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1862530.7500 - val_loss: 3277872.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 1856980.5000 - val_loss: 3277593.5000\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 25ms/step - loss: 1906876.0000 - val_loss: 3272351.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1900431.2500 - val_loss: 3274512.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1886794.7500 - val_loss: 3275966.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1871647.3750 - val_loss: 3276570.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1862160.8750 - val_loss: 3276658.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1856915.0000 - val_loss: 3276558.7500\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 14ms/step - loss: 520571.9062 - val_loss: 975884.3125\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 30276.2344 - val_loss: 2483163.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 5270.9009 - val_loss: 2692880.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 2776.0461 - val_loss: 2427230.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1864.2334 - val_loss: 2495796.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1405.9722 - val_loss: 2405497.0000\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 14ms/step - loss: 481837.9688 - val_loss: 610691.1875\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 33057.4727 - val_loss: 1434589.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 6575.7705 - val_loss: 1650599.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 3074.5823 - val_loss: 1649064.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 2380.1692 - val_loss: 1197197.8750\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 4268.5962 - val_loss: 1078541.5000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 15ms/step - loss: 404884.2188 - val_loss: 1396552.6250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 21708.4277 - val_loss: 1000866.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 4474.1602 - val_loss: 725827.6250\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 2662.1235 - val_loss: 1262171.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 2301.5542 - val_loss: 1283152.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 2120.3958 - val_loss: 1526180.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1571.9374 - val_loss: 2144810.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1633.0872 - val_loss: 1931312.8750\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 13ms/step - loss: 473671.8750 - val_loss: 1119742.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 32113.9238 - val_loss: 1693336.6250\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 7161.1841 - val_loss: 2946305.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 4964.4463 - val_loss: 2725478.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 5588.3750 - val_loss: 2724918.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 2824.3018 - val_loss: 2752381.5000\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 14ms/step - loss: 446606.1875 - val_loss: 1802952.1250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 29974.2012 - val_loss: 1122294.1250\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 5035.5586 - val_loss: 502372.7188\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 2073.9197 - val_loss: 1057910.8750\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1885.3796 - val_loss: 1020790.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1801.1305 - val_loss: 1536421.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 2012.1511 - val_loss: 1031892.0625\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1556.1152 - val_loss: 1752342.3750\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 18ms/step - loss: 455835.9062 - val_loss: 2535870.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 31395.5430 - val_loss: 2580705.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 6423.2749 - val_loss: 2552299.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 3483.3000 - val_loss: 2546096.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 3868.8333 - val_loss: 2548381.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 3110.3081 - val_loss: 2712223.2500\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 13ms/step - loss: 408242.5938 - val_loss: 354768.2188\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 24158.7520 - val_loss: 330013.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 5653.5347 - val_loss: 262997.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3839.5029 - val_loss: 228961.3750\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 2461.6816 - val_loss: 222820.0312\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 2183.5627 - val_loss: 215598.2969\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 2404.2441 - val_loss: 276883.4062\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 2479.9929 - val_loss: 327676.3125\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1626.7793 - val_loss: 289292.8750\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1473.0474 - val_loss: 289570.3125\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1522.3359 - val_loss: 261012.8750\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 14ms/step - loss: 481392.4062 - val_loss: 2181283.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 32972.8047 - val_loss: 2667862.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 10795.4189 - val_loss: 2779170.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 5473.6348 - val_loss: 2978282.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 3839.8652 - val_loss: 2835915.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 2591.5867 - val_loss: 2967141.0000\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 13ms/step - loss: 567370.5000 - val_loss: 1196994.1250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 40462.4023 - val_loss: 2003380.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 7982.4316 - val_loss: 2233952.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 3370.4734 - val_loss: 1776158.1250\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 2937.2190 - val_loss: 955843.3125\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 2640.8760 - val_loss: 655615.3750\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 2782.2026 - val_loss: 946131.0625\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 2163.4253 - val_loss: 710822.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1898.0146 - val_loss: 633316.1250\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1586.5367 - val_loss: 988629.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 17ms/step - loss: 1344.6562 - val_loss: 944109.6875\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1366.8994 - val_loss: 1012622.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1707.6133 - val_loss: 1469132.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 2488.6707 - val_loss: 1518831.7500\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 21ms/step - loss: 586824.2500 - val_loss: 455462.8750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 33818.5781 - val_loss: 325425.1562\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 7195.9585 - val_loss: 285571.1562\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 2401.9585 - val_loss: 233961.3594\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1608.4127 - val_loss: 365540.7188\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1468.6555 - val_loss: 235914.4062\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1767.1959 - val_loss: 286734.0625\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1464.5226 - val_loss: 288644.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1989.2947 - val_loss: 559836.2500\n",
            "7/7 [==============================] - 1s 13ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 26ms/step - loss: 849542.1875 - val_loss: 2314008.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 74654.4766 - val_loss: 2217114.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 41108.8984 - val_loss: 2105202.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 25509.8301 - val_loss: 2782036.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 6917.5288 - val_loss: 2409049.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 4567.5981 - val_loss: 2621333.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 2188.0332 - val_loss: 2309328.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 2041.9114 - val_loss: 2078039.3750\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 2286.0676 - val_loss: 2544958.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 2288.8652 - val_loss: 2416398.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 2239.3745 - val_loss: 2259536.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1845.7476 - val_loss: 2311232.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1495.3334 - val_loss: 2458625.0000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 23ms/step - loss: 903317.1875 - val_loss: 2864414.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 105410.9688 - val_loss: 2966852.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 42644.7383 - val_loss: 2529720.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 16750.9336 - val_loss: 2574530.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 7113.0767 - val_loss: 1649864.8750\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 3354.6213 - val_loss: 1165488.8750\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1884.9808 - val_loss: 545845.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1570.6840 - val_loss: 539238.8125\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1501.2458 - val_loss: 793430.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1455.2943 - val_loss: 1040535.1875\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1401.0371 - val_loss: 996435.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1449.3252 - val_loss: 1063952.1250\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1284.5200 - val_loss: 1347420.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 28ms/step - loss: 905379.0000 - val_loss: 3326555.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 110640.7266 - val_loss: 3461985.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 41405.3750 - val_loss: 1175812.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 14426.7373 - val_loss: 784011.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 7041.4121 - val_loss: 846436.4375\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 3363.1089 - val_loss: 963052.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 2179.9360 - val_loss: 901662.0625\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1662.2678 - val_loss: 879327.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1395.4520 - val_loss: 1074104.3750\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 29ms/step - loss: 1032618.6250 - val_loss: 1206333.1250\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 184547.7344 - val_loss: 588126.5625\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 50230.3125 - val_loss: 461807.8750\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 35341.0664 - val_loss: 370746.4062\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 7412.1665 - val_loss: 332560.4688\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 3746.1853 - val_loss: 324081.1250\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 3119.2083 - val_loss: 253734.5781\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 2190.9526 - val_loss: 314812.4062\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1983.0454 - val_loss: 301515.9375\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1739.5924 - val_loss: 270392.2188\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1903.0846 - val_loss: 271838.6875\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1665.4634 - val_loss: 262723.1875\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 22ms/step - loss: 711136.4375 - val_loss: 2897817.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 48373.7578 - val_loss: 2964786.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 41390.7617 - val_loss: 3320063.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 19927.1602 - val_loss: 2863728.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 7322.6479 - val_loss: 3008822.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 3885.5088 - val_loss: 2821091.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 3107.8960 - val_loss: 2563342.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 2638.8735 - val_loss: 2548831.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1807.9402 - val_loss: 2556506.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1870.8306 - val_loss: 2622578.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1771.6642 - val_loss: 2318340.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 2035.1715 - val_loss: 2493738.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1833.0530 - val_loss: 2382668.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1869.4629 - val_loss: 2436590.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1458.2074 - val_loss: 2386273.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1444.1423 - val_loss: 2518693.7500\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 19ms/step - loss: 836591.2500 - val_loss: 3211231.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 80481.8828 - val_loss: 3355476.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 88718.6875 - val_loss: 1778162.3750\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 11383.1689 - val_loss: 1905924.6250\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 5243.7524 - val_loss: 1987930.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 3520.5520 - val_loss: 1925555.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 2778.9148 - val_loss: 1806930.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 2656.0129 - val_loss: 1627852.8750\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 2181.9456 - val_loss: 1777702.6250\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 2125.7610 - val_loss: 1919385.8750\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1808.9388 - val_loss: 1879875.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1663.5579 - val_loss: 1891532.8750\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1616.6018 - val_loss: 2106297.5000\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 7s 29ms/step - loss: 820150.8750 - val_loss: 1062990.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 73479.0078 - val_loss: 655074.6250\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 48893.6094 - val_loss: 1409210.1250\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 11175.9561 - val_loss: 1622256.8750\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 4187.2651 - val_loss: 1417770.1250\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 3299.4858 - val_loss: 1366035.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 2378.1428 - val_loss: 1411502.2500\n",
            "7/7 [==============================] - 1s 12ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 22ms/step - loss: 915405.8750 - val_loss: 1005310.0625\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 116078.2109 - val_loss: 485761.4688\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 43055.7305 - val_loss: 369464.3750\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 25642.6523 - val_loss: 1087354.1250\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 7396.8521 - val_loss: 1748752.3750\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 2462.8845 - val_loss: 1618752.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1506.4243 - val_loss: 1422770.6250\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1364.8237 - val_loss: 1631603.8750\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 20ms/step - loss: 896908.8125 - val_loss: 3306377.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 106289.3906 - val_loss: 3530246.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 82557.0547 - val_loss: 1468362.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 58178.1914 - val_loss: 1613049.6250\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 4366.1846 - val_loss: 1679789.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 2585.8059 - val_loss: 1676206.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 2113.0469 - val_loss: 1699188.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1520.8350 - val_loss: 1763160.0000\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 24ms/step - loss: 951879.6250 - val_loss: 3515846.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 131785.3438 - val_loss: 3698395.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 51470.3555 - val_loss: 798566.8125\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 11717.5547 - val_loss: 768303.3750\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 6457.6016 - val_loss: 1055568.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 3904.4731 - val_loss: 848911.3750\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 3715.3472 - val_loss: 707244.1250\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 2976.0906 - val_loss: 701152.1250\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 2633.7876 - val_loss: 672503.4375\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 2071.8579 - val_loss: 638622.8750\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 2431.9517 - val_loss: 666545.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1571.8992 - val_loss: 566852.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1786.7611 - val_loss: 415512.4062\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1707.7321 - val_loss: 506135.2812\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1497.7108 - val_loss: 573083.5625\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1428.0048 - val_loss: 549599.8125\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1346.6847 - val_loss: 742138.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1565.9646 - val_loss: 513407.7188\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 25ms/step - loss: 1271733.0000 - val_loss: 2248419.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 385722.7188 - val_loss: 2171455.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 100303.6172 - val_loss: 2105284.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 46538.4297 - val_loss: 2048574.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 41094.7500 - val_loss: 1952108.1250\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 40236.8555 - val_loss: 2124692.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 30584.5293 - val_loss: 2870514.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 14728.8730 - val_loss: 2610991.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 7604.2241 - val_loss: 2851842.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 5494.5874 - val_loss: 2830729.0000\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 42ms/step - loss: 1344136.6250 - val_loss: 2925423.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 517889.5625 - val_loss: 2788528.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 173342.6562 - val_loss: 2742785.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 67087.4453 - val_loss: 2780665.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 43754.3164 - val_loss: 2492926.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 19975.0254 - val_loss: 2571638.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 5427.0801 - val_loss: 2850295.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 3169.2419 - val_loss: 2374700.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 2702.0081 - val_loss: 1836336.8750\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1781.4576 - val_loss: 1788249.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1280.4839 - val_loss: 2096083.5000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1444.3159 - val_loss: 1845501.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1436.0392 - val_loss: 2183584.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1064.6696 - val_loss: 2112531.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1067.9336 - val_loss: 2019629.6250\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 6s 41ms/step - loss: 1296263.5000 - val_loss: 2871946.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 430337.2188 - val_loss: 2872136.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 124585.8828 - val_loss: 2905198.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 53067.2969 - val_loss: 2907542.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 46779.1484 - val_loss: 2095455.1250\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 16105.3047 - val_loss: 2055424.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 7723.5820 - val_loss: 2041074.6250\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 4589.6245 - val_loss: 2196191.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 3036.2065 - val_loss: 2198708.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 2454.3167 - val_loss: 2169471.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1843.6455 - val_loss: 2156878.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1670.2360 - val_loss: 2150922.0000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 25ms/step - loss: 1343074.1250 - val_loss: 1914312.1250\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 504928.5625 - val_loss: 1092396.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 166933.8750 - val_loss: 682795.4375\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 65727.4922 - val_loss: 527995.5625\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 44075.6211 - val_loss: 429253.7812\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 41100.5977 - val_loss: 454400.0625\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 37722.0625 - val_loss: 1109487.8750\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 11046.6611 - val_loss: 781061.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 5270.9585 - val_loss: 1130201.1250\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 3183.0769 - val_loss: 1419500.8750\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 29ms/step - loss: 1333730.6250 - val_loss: 3115742.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 492957.4688 - val_loss: 3246121.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 160069.4219 - val_loss: 3317990.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 64556.8672 - val_loss: 3354876.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 42446.5938 - val_loss: 1210775.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 9235.3867 - val_loss: 1355112.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 4884.1650 - val_loss: 1103672.6250\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 3186.1248 - val_loss: 1124188.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2540.5627 - val_loss: 1202721.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 2215.9827 - val_loss: 1775760.3750\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1642.0563 - val_loss: 1961170.6250\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1273.4796 - val_loss: 2006358.6250\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 27ms/step - loss: 1378796.7500 - val_loss: 2224948.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 561991.2500 - val_loss: 1470043.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 198137.5625 - val_loss: 1135136.8750\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 78118.7734 - val_loss: 936690.6875\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 47451.3320 - val_loss: 770648.4375\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 41690.7617 - val_loss: 697608.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 32683.1250 - val_loss: 3042873.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 13200.2002 - val_loss: 3177700.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 5747.7915 - val_loss: 3155577.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 3768.9587 - val_loss: 3363797.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 2204.4963 - val_loss: 3489711.7500\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 6s 35ms/step - loss: 1354696.7500 - val_loss: 1920414.6250\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 532119.6250 - val_loss: 1128953.3750\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 183996.1094 - val_loss: 787050.8125\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 72507.4844 - val_loss: 607268.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 46087.7500 - val_loss: 499956.3750\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 46326.0430 - val_loss: 711937.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 17003.5000 - val_loss: 529381.1250\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 8697.5039 - val_loss: 456607.9375\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 4519.2969 - val_loss: 525125.0625\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 2999.8293 - val_loss: 838612.8125\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 2240.8765 - val_loss: 745701.6875\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1690.6587 - val_loss: 664450.0000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1791.3167 - val_loss: 782888.8750\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 24ms/step - loss: 1387157.3750 - val_loss: 2940444.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 579410.6875 - val_loss: 2703965.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 213234.4844 - val_loss: 2562963.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 83872.9688 - val_loss: 2522108.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 49054.0469 - val_loss: 2565822.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 43387.3633 - val_loss: 2762032.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 33319.5781 - val_loss: 2852606.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 15343.5654 - val_loss: 2841487.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 7231.1294 - val_loss: 2803569.0000\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 25ms/step - loss: 1360711.3750 - val_loss: 2179203.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 545576.4375 - val_loss: 1850044.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 191175.7344 - val_loss: 1901833.3750\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 75519.0938 - val_loss: 1714640.1250\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 46898.6328 - val_loss: 1075487.8750\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 34160.5586 - val_loss: 2835049.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 9751.0020 - val_loss: 2725426.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 3881.6812 - val_loss: 2689243.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 2299.4856 - val_loss: 2262907.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1865.2740 - val_loss: 2051810.2500\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 26ms/step - loss: 1276832.1250 - val_loss: 3102561.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 406275.1875 - val_loss: 3118450.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 114134.9062 - val_loss: 3183162.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 50464.1953 - val_loss: 3320154.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 46013.5586 - val_loss: 3283013.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 49595.0781 - val_loss: 2759667.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 19968.9863 - val_loss: 800185.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 8024.2231 - val_loss: 357625.2188\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 4230.2617 - val_loss: 345366.9688\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 3284.1772 - val_loss: 317499.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 2303.2412 - val_loss: 307818.9375\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1828.8016 - val_loss: 287644.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1943.1564 - val_loss: 273322.1250\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1792.2112 - val_loss: 499116.8125\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1391.8362 - val_loss: 320130.1562\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1548.3955 - val_loss: 398809.6875\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1397.0020 - val_loss: 508228.8750\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1341.5844 - val_loss: 593079.6250\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 13ms/step - loss: 1485987.8750 - val_loss: 3196278.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 879957.1250 - val_loss: 3135196.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 496121.4688 - val_loss: 3109475.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 267493.4375 - val_loss: 3127852.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 142471.3281 - val_loss: 3154729.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 81129.1172 - val_loss: 3194502.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 54678.5117 - val_loss: 3238413.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 54949.7188 - val_loss: 2370863.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 93519.7891 - val_loss: 965827.6875\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 25681.1504 - val_loss: 1017121.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 17317.2266 - val_loss: 1079488.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 13535.9111 - val_loss: 1093702.3750\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 8463.5225 - val_loss: 1098084.3750\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 6156.3359 - val_loss: 1107817.2500\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 14ms/step - loss: 1478292.8750 - val_loss: 3153207.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 869358.3750 - val_loss: 3071527.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 488503.1562 - val_loss: 3032699.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 262592.5312 - val_loss: 3018489.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 140040.7969 - val_loss: 3012494.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 80256.7578 - val_loss: 3023243.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 54497.6992 - val_loss: 3014725.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 44832.2422 - val_loss: 3016309.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 95127.7188 - val_loss: 2271437.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 38499.3633 - val_loss: 1818474.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 14870.2764 - val_loss: 1628698.6250\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 10584.6445 - val_loss: 1572138.3750\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 8223.9883 - val_loss: 1366327.8750\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 6323.1016 - val_loss: 1279746.8750\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 4644.4849 - val_loss: 1357764.6250\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 3450.8740 - val_loss: 1398904.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 3036.1089 - val_loss: 1390571.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 2558.2749 - val_loss: 1366184.8750\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 2042.2441 - val_loss: 1355610.0000\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 15s 20ms/step - loss: 1488888.7500 - val_loss: 3179856.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 883202.3125 - val_loss: 3119436.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 499889.0625 - val_loss: 3105883.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 269831.8125 - val_loss: 3111282.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 143953.1562 - val_loss: 3127730.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 82515.0938 - val_loss: 3178047.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 55716.6992 - val_loss: 3199828.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 45383.9414 - val_loss: 3223877.2500\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 16ms/step - loss: 1487334.7500 - val_loss: 3172999.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 878127.6875 - val_loss: 3140480.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 493696.7188 - val_loss: 3127099.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 265463.5625 - val_loss: 3135306.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 141109.3438 - val_loss: 3146654.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 80510.9688 - val_loss: 3187662.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 54569.9844 - val_loss: 3268737.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 66280.0078 - val_loss: 685483.6250\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 59714.9766 - val_loss: 909003.1250\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 44806.4648 - val_loss: 795714.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 37849.7344 - val_loss: 835282.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 73908.7031 - val_loss: 590986.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 23829.9434 - val_loss: 507028.5312\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 17918.5840 - val_loss: 503334.1875\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 17008.2402 - val_loss: 582202.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 12439.8984 - val_loss: 574582.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 11139.0381 - val_loss: 573055.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 10176.2998 - val_loss: 577802.1250\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 9361.8359 - val_loss: 588175.0625\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 16ms/step - loss: 1488111.0000 - val_loss: 3258845.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 880455.8125 - val_loss: 3251388.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 495812.7188 - val_loss: 3270490.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 266700.8750 - val_loss: 3296807.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 142080.6250 - val_loss: 3304962.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 81059.5859 - val_loss: 3347392.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 54776.3867 - val_loss: 3388763.5000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 8s 22ms/step - loss: 1485718.2500 - val_loss: 3144029.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 879553.2500 - val_loss: 3113993.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 495735.1875 - val_loss: 3131992.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 267314.6875 - val_loss: 3190854.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 142440.3281 - val_loss: 3253974.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 81349.0312 - val_loss: 3310322.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 17ms/step - loss: 55001.5156 - val_loss: 3417844.2500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 17ms/step - loss: 1485399.7500 - val_loss: 3272828.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 876400.0625 - val_loss: 3268296.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 492748.5312 - val_loss: 3271524.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 264749.7188 - val_loss: 3293047.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 140901.3750 - val_loss: 3311381.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 80579.6953 - val_loss: 3335770.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 54562.3242 - val_loss: 3361117.5000\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 17ms/step - loss: 1480744.0000 - val_loss: 3210843.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 874660.8750 - val_loss: 3207650.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 492105.7500 - val_loss: 3236495.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 264501.8125 - val_loss: 3250047.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 140686.8281 - val_loss: 3269703.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 80331.3672 - val_loss: 3296527.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 54292.6445 - val_loss: 3321898.5000\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 14ms/step - loss: 1485105.0000 - val_loss: 3164702.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 880584.1875 - val_loss: 3109902.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 498553.4688 - val_loss: 3101413.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 269470.0625 - val_loss: 3096281.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 143831.5312 - val_loss: 3102510.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 81885.3594 - val_loss: 3162358.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 55108.3320 - val_loss: 3222057.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 45108.3008 - val_loss: 3212857.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 37701.9102 - val_loss: 2787767.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 19581.0664 - val_loss: 2122455.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 13469.7656 - val_loss: 2320977.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 8773.7285 - val_loss: 1482707.8750\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 6504.9912 - val_loss: 1150133.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 4716.4043 - val_loss: 1140674.8750\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 3742.8987 - val_loss: 1161197.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2889.3433 - val_loss: 1225660.1250\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 2366.0544 - val_loss: 1410358.3750\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1856.0544 - val_loss: 1238606.8750\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1527.4141 - val_loss: 1187835.2500\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 17ms/step - loss: 1477391.7500 - val_loss: 3235243.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 872378.9375 - val_loss: 3228507.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 490890.6875 - val_loss: 3260929.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 264043.6250 - val_loss: 3309183.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 140444.8281 - val_loss: 3384017.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 80214.0938 - val_loss: 3451480.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 54459.2734 - val_loss: 3522048.2500\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 30ms/step - loss: 1671939.2500 - val_loss: 3260525.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1296490.2500 - val_loss: 3251677.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 997790.2500 - val_loss: 3263007.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 758188.5000 - val_loss: 3268113.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 568217.0625 - val_loss: 3277983.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 420383.8750 - val_loss: 3297617.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 307819.0000 - val_loss: 3306455.5000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 25ms/step - loss: 1673384.1250 - val_loss: 3283698.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1298331.2500 - val_loss: 3290788.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 998421.1875 - val_loss: 3300292.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 757878.0625 - val_loss: 3308055.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 567646.3750 - val_loss: 3306904.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 419572.2188 - val_loss: 3320070.7500\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 22ms/step - loss: 1672709.0000 - val_loss: 3281718.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1297745.6250 - val_loss: 3286848.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 997768.6250 - val_loss: 3305575.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 757096.0625 - val_loss: 3306395.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 566722.6250 - val_loss: 3300642.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 418759.4375 - val_loss: 3303505.7500\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 22ms/step - loss: 1673066.0000 - val_loss: 3228692.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1295677.1250 - val_loss: 3196300.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 994644.7500 - val_loss: 3169768.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 754251.3125 - val_loss: 3176698.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 564187.1875 - val_loss: 3176887.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 416613.4375 - val_loss: 3203053.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 304657.5938 - val_loss: 3217760.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 221178.1406 - val_loss: 3237740.5000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 20ms/step - loss: 1672981.0000 - val_loss: 3258158.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1299754.2500 - val_loss: 3252055.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1001117.8750 - val_loss: 3242930.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 761412.3750 - val_loss: 3246766.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 571203.5000 - val_loss: 3276617.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 422990.3438 - val_loss: 3286623.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 309969.8750 - val_loss: 3305698.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 225785.1719 - val_loss: 3317222.0000\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 19ms/step - loss: 1671658.0000 - val_loss: 3280574.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1295579.7500 - val_loss: 3285579.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 995654.8125 - val_loss: 3290558.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 755119.4375 - val_loss: 3302037.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 564912.7500 - val_loss: 3313157.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 417264.6562 - val_loss: 3321600.5000\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 7s 23ms/step - loss: 1674639.6250 - val_loss: 3250758.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1299111.5000 - val_loss: 3225059.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 997583.2500 - val_loss: 3195018.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 756668.5625 - val_loss: 3180334.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 566010.8750 - val_loss: 3187882.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 418038.0625 - val_loss: 3198307.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 305611.4375 - val_loss: 3214325.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 221798.9062 - val_loss: 3235005.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 161262.2188 - val_loss: 3248493.7500\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 18ms/step - loss: 1670086.6250 - val_loss: 3264607.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1295856.3750 - val_loss: 3259183.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 996838.3750 - val_loss: 3255682.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 757014.1875 - val_loss: 3252261.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 566994.3750 - val_loss: 3247056.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 419032.9062 - val_loss: 3261712.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 306280.3438 - val_loss: 3260473.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 222594.3594 - val_loss: 3267525.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 161756.2344 - val_loss: 3285083.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 118945.0469 - val_loss: 3297737.0000\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 22ms/step - loss: 1670955.0000 - val_loss: 3214689.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1296771.8750 - val_loss: 3186998.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 997781.7500 - val_loss: 3165871.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 757666.8125 - val_loss: 3152559.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 567164.8750 - val_loss: 3180717.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 418955.4062 - val_loss: 3215845.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 306384.6250 - val_loss: 3239504.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 222560.4844 - val_loss: 3256522.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 161732.9375 - val_loss: 3269798.2500\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 28ms/step - loss: 1666147.3750 - val_loss: 3215892.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1292025.3750 - val_loss: 3180779.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 993521.3750 - val_loss: 3157979.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 753828.8125 - val_loss: 3156874.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 564169.6250 - val_loss: 3157408.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 416718.7500 - val_loss: 3165688.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 304489.1250 - val_loss: 3169382.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 221155.5625 - val_loss: 3182008.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 160707.0938 - val_loss: 3216365.7500\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 6s 38ms/step - loss: 1779596.1250 - val_loss: 3258880.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1563504.1250 - val_loss: 3259653.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1375531.0000 - val_loss: 3255193.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1207666.2500 - val_loss: 3250183.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1057482.8750 - val_loss: 3248368.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 922674.9375 - val_loss: 3246656.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 802268.8750 - val_loss: 3249192.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 695250.3750 - val_loss: 3260816.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 600377.4375 - val_loss: 3258769.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 516602.3750 - val_loss: 3254871.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 442976.3438 - val_loss: 3263093.5000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 6s 30ms/step - loss: 1775481.1250 - val_loss: 3260145.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1562951.7500 - val_loss: 3247930.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1376901.5000 - val_loss: 3243728.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1210178.1250 - val_loss: 3240459.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1060412.3750 - val_loss: 3237187.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 926547.1250 - val_loss: 3242925.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 806776.2500 - val_loss: 3242823.7500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 699821.3125 - val_loss: 3241859.0000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 605261.0625 - val_loss: 3241265.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 521601.8750 - val_loss: 3247234.2500\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 26ms/step - loss: 1782528.0000 - val_loss: 3266622.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1569043.1250 - val_loss: 3264036.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1382335.3750 - val_loss: 3254834.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1215132.8750 - val_loss: 3244679.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1064542.8750 - val_loss: 3241727.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 929894.0625 - val_loss: 3242956.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 809501.5000 - val_loss: 3246585.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 702301.0000 - val_loss: 3256266.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 607197.5000 - val_loss: 3261658.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 523291.5312 - val_loss: 3265633.7500\n",
            "7/7 [==============================] - 1s 13ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 40ms/step - loss: 1778357.0000 - val_loss: 3275113.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1567921.5000 - val_loss: 3278393.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1382019.5000 - val_loss: 3279504.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1215544.6250 - val_loss: 3277537.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1065944.1250 - val_loss: 3277610.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 931603.4375 - val_loss: 3279474.5000\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 27ms/step - loss: 1776783.8750 - val_loss: 3272552.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1563621.8750 - val_loss: 3267006.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1376746.0000 - val_loss: 3260378.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1209017.8750 - val_loss: 3257777.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1059045.1250 - val_loss: 3253211.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 924665.1875 - val_loss: 3254510.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 804472.4375 - val_loss: 3258071.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 697435.8750 - val_loss: 3265851.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 602231.7500 - val_loss: 3273984.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 518382.3438 - val_loss: 3288383.5000\n",
            "7/7 [==============================] - 1s 12ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 28ms/step - loss: 1776050.1250 - val_loss: 3240181.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1562374.8750 - val_loss: 3233339.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1375487.1250 - val_loss: 3226486.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1208223.8750 - val_loss: 3222383.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1057863.6250 - val_loss: 3227791.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 923190.1250 - val_loss: 3227468.2500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 802887.6250 - val_loss: 3230106.7500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 695699.3125 - val_loss: 3238325.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 600624.8750 - val_loss: 3243232.5000\n",
            "7/7 [==============================] - 1s 12ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 28ms/step - loss: 1777256.1250 - val_loss: 3254345.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1562911.1250 - val_loss: 3240160.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1375286.0000 - val_loss: 3228283.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1207924.6250 - val_loss: 3218083.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1057735.8750 - val_loss: 3210226.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 923064.5000 - val_loss: 3204491.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 802744.5625 - val_loss: 3200803.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 695870.3750 - val_loss: 3204049.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 600903.6875 - val_loss: 3207097.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 517339.8125 - val_loss: 3209029.5000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 443878.8750 - val_loss: 3207624.5000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 379880.6562 - val_loss: 3208191.5000\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 28ms/step - loss: 1775169.8750 - val_loss: 3276210.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1562285.7500 - val_loss: 3284590.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1375697.2500 - val_loss: 3289543.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1208516.8750 - val_loss: 3294810.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1058089.0000 - val_loss: 3301298.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 923723.5000 - val_loss: 3304894.5000\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1774068.5000 - val_loss: 3269241.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1560698.1250 - val_loss: 3268343.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1374068.5000 - val_loss: 3266843.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1206998.1250 - val_loss: 3265461.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1056967.5000 - val_loss: 3265879.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 922312.5000 - val_loss: 3266836.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 802187.6250 - val_loss: 3268009.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 695149.9375 - val_loss: 3267920.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 600406.1875 - val_loss: 3267675.2500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 27ms/step - loss: 1771157.8750 - val_loss: 3276242.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1558602.6250 - val_loss: 3282636.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1372163.6250 - val_loss: 3287453.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1205135.7500 - val_loss: 3290907.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1055325.0000 - val_loss: 3294668.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 921028.1250 - val_loss: 3298570.5000\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 19ms/step - loss: 1829715.0000 - val_loss: 3276641.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1727747.5000 - val_loss: 3275344.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1645061.8750 - val_loss: 3272521.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1566981.0000 - val_loss: 3269452.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1492302.7500 - val_loss: 3265722.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1420578.6250 - val_loss: 3262022.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1351575.1250 - val_loss: 3256735.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1285078.5000 - val_loss: 3253488.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1220925.5000 - val_loss: 3250737.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1159059.3750 - val_loss: 3248203.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1099387.1250 - val_loss: 3245882.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1041768.5625 - val_loss: 3243824.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 986189.5000 - val_loss: 3244717.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 932576.5625 - val_loss: 3245342.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 880871.8750 - val_loss: 3242615.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 831022.9375 - val_loss: 3239471.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 783024.3125 - val_loss: 3236404.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 736849.5000 - val_loss: 3236899.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 692420.5625 - val_loss: 3236473.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 649753.6250 - val_loss: 3241885.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 608816.0625 - val_loss: 3246838.2500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 569535.1875 - val_loss: 3243677.7500\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 14s 20ms/step - loss: 1833111.7500 - val_loss: 3273530.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1730259.8750 - val_loss: 3270898.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1646810.1250 - val_loss: 3266100.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1568132.0000 - val_loss: 3261298.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1492933.5000 - val_loss: 3257038.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1420734.0000 - val_loss: 3251285.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1351289.2500 - val_loss: 3246504.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1284350.0000 - val_loss: 3242255.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1219783.3750 - val_loss: 3237761.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1157544.2500 - val_loss: 3233511.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1097499.6250 - val_loss: 3230169.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1039612.1875 - val_loss: 3227431.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 983777.1250 - val_loss: 3225510.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 929928.3750 - val_loss: 3222178.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 878018.0000 - val_loss: 3218834.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 828004.4375 - val_loss: 3215327.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 779842.6875 - val_loss: 3211683.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 733507.1250 - val_loss: 3209635.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 688973.6250 - val_loss: 3213699.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 646191.2500 - val_loss: 3217676.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 605139.9375 - val_loss: 3214408.2500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 565785.1250 - val_loss: 3211597.5000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 528127.1250 - val_loss: 3210988.5000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 19ms/step - loss: 1831596.1250 - val_loss: 3275183.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1728422.0000 - val_loss: 3273932.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1644989.3750 - val_loss: 3270167.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1566353.6250 - val_loss: 3264483.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1491204.8750 - val_loss: 3259480.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1419060.0000 - val_loss: 3254435.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1349620.3750 - val_loss: 3247266.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1282739.8750 - val_loss: 3242463.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1218295.0000 - val_loss: 3235545.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1156153.8750 - val_loss: 3229507.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1096184.3750 - val_loss: 3224866.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1038323.7500 - val_loss: 3221449.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 982505.8750 - val_loss: 3220052.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 928689.7500 - val_loss: 3218953.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 876819.1875 - val_loss: 3218851.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 826829.0625 - val_loss: 3216178.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 778700.8750 - val_loss: 3212327.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 732410.9375 - val_loss: 3208750.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 687913.1250 - val_loss: 3210106.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 645170.3125 - val_loss: 3216805.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 604162.3750 - val_loss: 3220619.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 564870.1875 - val_loss: 3217242.0000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 527268.1250 - val_loss: 3214240.5000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 15ms/step - loss: 1830387.5000 - val_loss: 3277605.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1729943.1250 - val_loss: 3279306.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1647092.2500 - val_loss: 3277191.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1568698.5000 - val_loss: 3273521.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1493655.2500 - val_loss: 3269052.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1421547.0000 - val_loss: 3265310.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1352156.6250 - val_loss: 3259506.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1285258.0000 - val_loss: 3254673.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1220718.3750 - val_loss: 3250282.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1158473.3750 - val_loss: 3246858.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1098435.2500 - val_loss: 3243481.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 3s 17ms/step - loss: 1040537.1250 - val_loss: 3239868.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 984708.3125 - val_loss: 3237311.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 930841.8125 - val_loss: 3236308.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 878876.5000 - val_loss: 3236101.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 828845.5000 - val_loss: 3234543.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 780666.3125 - val_loss: 3232912.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 734310.6875 - val_loss: 3235155.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 689765.7500 - val_loss: 3236642.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 646965.1875 - val_loss: 3234050.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 605912.0625 - val_loss: 3231648.2500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 3s 17ms/step - loss: 566563.0000 - val_loss: 3237264.2500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 528866.0625 - val_loss: 3234253.7500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 492823.8750 - val_loss: 3232212.0000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 458435.1250 - val_loss: 3236116.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 425669.1562 - val_loss: 3234126.7500\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 8s 20ms/step - loss: 1832849.0000 - val_loss: 3273047.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1729371.1250 - val_loss: 3269927.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 17ms/step - loss: 1645918.5000 - val_loss: 3264160.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1567295.8750 - val_loss: 3256973.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1492129.3750 - val_loss: 3248582.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1419930.3750 - val_loss: 3237966.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1350457.3750 - val_loss: 3228082.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1283529.1250 - val_loss: 3218037.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1219015.0000 - val_loss: 3208306.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1156825.2500 - val_loss: 3198938.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1096800.8750 - val_loss: 3191211.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1038926.2500 - val_loss: 3186934.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 983106.3125 - val_loss: 3182872.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 929274.1250 - val_loss: 3178328.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 877372.3750 - val_loss: 3179531.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 827369.1875 - val_loss: 3182106.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 779242.5000 - val_loss: 3183011.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 732920.9375 - val_loss: 3185595.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 688405.7500 - val_loss: 3189247.7500\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 19ms/step - loss: 1829779.2500 - val_loss: 3275756.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1728959.5000 - val_loss: 3274576.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1646151.0000 - val_loss: 3270032.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1567164.0000 - val_loss: 3266195.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1491897.1250 - val_loss: 3262835.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1419719.5000 - val_loss: 3258081.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1350240.5000 - val_loss: 3253144.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1283337.5000 - val_loss: 3247008.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1218829.0000 - val_loss: 3243250.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1156649.3750 - val_loss: 3239230.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1096655.2500 - val_loss: 3234739.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1038723.4375 - val_loss: 3231620.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 982876.6875 - val_loss: 3228880.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 929057.9375 - val_loss: 3226324.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 877194.1875 - val_loss: 3223770.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 827207.3750 - val_loss: 3222377.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 779084.3125 - val_loss: 3222721.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 732777.4375 - val_loss: 3219778.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 688269.7500 - val_loss: 3218458.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 645521.4375 - val_loss: 3218413.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 604505.6875 - val_loss: 3217400.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 565186.5000 - val_loss: 3219500.0000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 527529.9375 - val_loss: 3222251.7500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 491553.8125 - val_loss: 3225733.2500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 457231.9375 - val_loss: 3223255.2500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 424542.1875 - val_loss: 3220878.5000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 14ms/step - loss: 1832295.2500 - val_loss: 3275583.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1730341.0000 - val_loss: 3274725.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1647862.3750 - val_loss: 3272123.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1570067.0000 - val_loss: 3268506.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1495755.7500 - val_loss: 3263077.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1424337.7500 - val_loss: 3258413.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1355626.0000 - val_loss: 3254113.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1289450.0000 - val_loss: 3250322.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1225565.7500 - val_loss: 3245032.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1163892.6250 - val_loss: 3241059.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1104396.1250 - val_loss: 3238172.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1046979.8125 - val_loss: 3235468.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 991553.6875 - val_loss: 3232760.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 938087.0625 - val_loss: 3230164.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 886513.0625 - val_loss: 3227638.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 836802.6875 - val_loss: 3229284.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 788887.1250 - val_loss: 3230780.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 742760.8750 - val_loss: 3234019.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 698398.6250 - val_loss: 3231204.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 655751.0625 - val_loss: 3228573.5000\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 15ms/step - loss: 1831629.3750 - val_loss: 3275691.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1729698.7500 - val_loss: 3274028.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1646891.7500 - val_loss: 3269131.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1568774.3750 - val_loss: 3262866.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1494019.8750 - val_loss: 3257790.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1422223.1250 - val_loss: 3250885.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1353152.6250 - val_loss: 3243981.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1286591.5000 - val_loss: 3237352.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1222414.2500 - val_loss: 3232595.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1160471.1250 - val_loss: 3226590.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1100696.0000 - val_loss: 3219736.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1043026.7500 - val_loss: 3214412.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 987413.8125 - val_loss: 3210667.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 933782.1875 - val_loss: 3210716.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 882079.3750 - val_loss: 3210840.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 832258.2500 - val_loss: 3210465.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 784234.8750 - val_loss: 3207504.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 737994.5625 - val_loss: 3204832.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 693509.0000 - val_loss: 3204331.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 650809.9375 - val_loss: 3205113.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 609822.5000 - val_loss: 3201783.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 570511.0625 - val_loss: 3199189.5000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 532855.5000 - val_loss: 3203288.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 496867.2188 - val_loss: 3200335.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 462464.1875 - val_loss: 3207019.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 429654.0000 - val_loss: 3213155.2500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 398425.1875 - val_loss: 3210380.0000\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 19ms/step - loss: 1831794.3750 - val_loss: 3276017.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1729577.6250 - val_loss: 3274827.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1646333.5000 - val_loss: 3269161.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1567720.7500 - val_loss: 3263316.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1492533.1250 - val_loss: 3258393.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1420323.6250 - val_loss: 3252157.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1350868.5000 - val_loss: 3246037.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1283962.7500 - val_loss: 3239243.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1219434.3750 - val_loss: 3232441.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1157186.8750 - val_loss: 3223427.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1097141.1250 - val_loss: 3212266.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1039207.8750 - val_loss: 3206178.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 983367.8125 - val_loss: 3201559.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 929514.5000 - val_loss: 3196748.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 877595.1875 - val_loss: 3192957.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 827599.2500 - val_loss: 3190440.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 779479.5625 - val_loss: 3197073.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 733180.1250 - val_loss: 3195845.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 688683.4375 - val_loss: 3197132.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 645906.1250 - val_loss: 3199924.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 604873.4375 - val_loss: 3199238.7500\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 16ms/step - loss: 1829544.7500 - val_loss: 3277088.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1727821.5000 - val_loss: 3278381.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1644647.3750 - val_loss: 3274587.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1566160.5000 - val_loss: 3268904.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1491126.8750 - val_loss: 3264413.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1419043.8750 - val_loss: 3259339.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1349641.7500 - val_loss: 3253049.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 1282801.5000 - val_loss: 3245215.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1218353.2500 - val_loss: 3239855.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1156180.0000 - val_loss: 3233358.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1096222.3750 - val_loss: 3229434.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1038379.8750 - val_loss: 3226036.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 982581.8750 - val_loss: 3222801.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 928775.8750 - val_loss: 3219544.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 876917.8750 - val_loss: 3216308.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 826946.0625 - val_loss: 3212812.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 778818.9375 - val_loss: 3209044.0000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 732516.8750 - val_loss: 3205132.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 688038.1250 - val_loss: 3201293.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 645296.6875 - val_loss: 3197766.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 604271.3750 - val_loss: 3197560.7500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 564965.0625 - val_loss: 3195848.0000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 527335.5000 - val_loss: 3191830.7500\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 491368.3125 - val_loss: 3188306.2500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 457047.5312 - val_loss: 3186573.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 424338.2188 - val_loss: 3190423.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 3s 14ms/step - loss: 393221.0000 - val_loss: 3198027.0000\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 363672.0312 - val_loss: 3200541.0000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 335665.3750 - val_loss: 3201227.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 309189.5938 - val_loss: 3199263.0000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 24ms/step - loss: 1862160.1250 - val_loss: 3274729.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1794445.3750 - val_loss: 3276394.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1748773.3750 - val_loss: 3277284.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1705336.7500 - val_loss: 3277697.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1663616.1250 - val_loss: 3277576.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1623138.7500 - val_loss: 3277083.5000\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 23ms/step - loss: 1863048.8750 - val_loss: 3275588.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1794752.0000 - val_loss: 3277572.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1748689.1250 - val_loss: 3278497.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1705478.3750 - val_loss: 3278636.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1663893.2500 - val_loss: 3278201.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1623499.1250 - val_loss: 3277679.7500\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 31ms/step - loss: 1863082.0000 - val_loss: 3275689.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1794999.1250 - val_loss: 3277441.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1749206.2500 - val_loss: 3277811.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1706293.6250 - val_loss: 3277665.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1664979.1250 - val_loss: 3277104.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1624830.6250 - val_loss: 3276841.7500\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 24ms/step - loss: 1861965.7500 - val_loss: 3275713.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1794462.8750 - val_loss: 3277785.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1748641.5000 - val_loss: 3279119.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1705522.5000 - val_loss: 3279927.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1663992.2500 - val_loss: 3280712.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1623632.3750 - val_loss: 3281432.7500\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 24ms/step - loss: 1860970.1250 - val_loss: 3275608.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1794483.7500 - val_loss: 3277695.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1748834.1250 - val_loss: 3278629.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1705823.8750 - val_loss: 3278959.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1664363.6250 - val_loss: 3278507.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1624088.6250 - val_loss: 3277889.0000\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 21ms/step - loss: 1862597.5000 - val_loss: 3275065.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1794933.3750 - val_loss: 3276940.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1749046.6250 - val_loss: 3277500.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1705910.6250 - val_loss: 3276972.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 1664342.6250 - val_loss: 3275704.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1623970.2500 - val_loss: 3274374.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1584613.0000 - val_loss: 3272961.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1546128.3750 - val_loss: 3271614.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1508437.7500 - val_loss: 3269718.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1471513.1250 - val_loss: 3267905.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1435296.5000 - val_loss: 3266316.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1399779.3750 - val_loss: 3264830.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1364950.6250 - val_loss: 3263492.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1330748.7500 - val_loss: 3261855.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1297156.6250 - val_loss: 3260581.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1264144.8750 - val_loss: 3259266.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1231766.5000 - val_loss: 3257889.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1199974.3750 - val_loss: 3256361.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1168738.6250 - val_loss: 3254765.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1138080.3750 - val_loss: 3252956.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1107954.0000 - val_loss: 3251449.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1078354.8750 - val_loss: 3251626.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1049286.2500 - val_loss: 3251610.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1020740.6875 - val_loss: 3252895.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 992710.9375 - val_loss: 3254418.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 965204.3750 - val_loss: 3254508.0000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 7s 24ms/step - loss: 1862185.7500 - val_loss: 3275110.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1796175.5000 - val_loss: 3276964.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1750500.8750 - val_loss: 3277589.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1707653.8750 - val_loss: 3277071.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1666074.5000 - val_loss: 3276639.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1625355.0000 - val_loss: 3275674.7500\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 22ms/step - loss: 1862656.1250 - val_loss: 3275296.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1795886.7500 - val_loss: 3277184.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1750019.8750 - val_loss: 3277603.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1706918.6250 - val_loss: 3277141.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1665375.8750 - val_loss: 3276201.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1624994.6250 - val_loss: 3274851.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1585605.2500 - val_loss: 3273399.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1547091.6250 - val_loss: 3272169.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1509408.7500 - val_loss: 3270252.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1472494.1250 - val_loss: 3267636.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1436317.7500 - val_loss: 3265639.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1400779.6250 - val_loss: 3263315.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1365919.5000 - val_loss: 3260975.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1331700.2500 - val_loss: 3259089.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1298114.2500 - val_loss: 3255980.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1265124.6250 - val_loss: 3253475.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1232737.3750 - val_loss: 3251018.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1200935.8750 - val_loss: 3249338.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1169704.2500 - val_loss: 3247856.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1139027.1250 - val_loss: 3245200.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 1108895.7500 - val_loss: 3243468.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1079292.6250 - val_loss: 3242465.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1050229.2500 - val_loss: 3241496.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1021678.3750 - val_loss: 3240736.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 993625.9375 - val_loss: 3240974.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 966084.4375 - val_loss: 3242249.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 939042.0000 - val_loss: 3242629.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 912470.1250 - val_loss: 3242886.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 886414.6875 - val_loss: 3242244.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 20ms/step - loss: 1865618.1250 - val_loss: 3275276.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1799799.0000 - val_loss: 3277155.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1753869.0000 - val_loss: 3277806.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1710681.6250 - val_loss: 3277754.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1669082.3750 - val_loss: 3277247.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1628697.3750 - val_loss: 3276533.2500\n",
            "7/7 [==============================] - 1s 7ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 20ms/step - loss: 1862411.3750 - val_loss: 3274983.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1794059.5000 - val_loss: 3276974.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1748063.2500 - val_loss: 3278099.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 1704905.5000 - val_loss: 3278309.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1663372.1250 - val_loss: 3277519.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1623013.0000 - val_loss: 3276510.0000\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 39ms/step - loss: 1888254.8750 - val_loss: 3275876.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1836069.0000 - val_loss: 3275480.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1809389.0000 - val_loss: 3276646.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1785402.0000 - val_loss: 3277467.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1762569.7500 - val_loss: 3278090.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1740429.0000 - val_loss: 3278530.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1718812.0000 - val_loss: 3278713.0000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1888117.0000 - val_loss: 3275263.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1835027.0000 - val_loss: 3275201.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1808760.7500 - val_loss: 3276233.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1785126.8750 - val_loss: 3277029.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1762312.1250 - val_loss: 3277476.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1740208.1250 - val_loss: 3277525.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1718658.1250 - val_loss: 3277464.2500\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 26ms/step - loss: 1886910.0000 - val_loss: 3275650.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1833162.6250 - val_loss: 3275952.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1806806.0000 - val_loss: 3277073.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1783014.6250 - val_loss: 3277891.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1760396.7500 - val_loss: 3278506.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1738442.8750 - val_loss: 3278981.5000\n",
            "7/7 [==============================] - 1s 12ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 25ms/step - loss: 1887667.5000 - val_loss: 3275795.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1836402.2500 - val_loss: 3275938.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1810041.2500 - val_loss: 3277185.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1786093.7500 - val_loss: 3278133.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1763262.1250 - val_loss: 3278893.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1741133.8750 - val_loss: 3279506.7500\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 6s 38ms/step - loss: 1890700.8750 - val_loss: 3275315.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1836301.3750 - val_loss: 3275197.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1809184.1250 - val_loss: 3276305.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1784990.7500 - val_loss: 3277111.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1762019.2500 - val_loss: 3277696.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1739782.3750 - val_loss: 3278132.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1718065.8750 - val_loss: 3278296.5000\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 6s 37ms/step - loss: 1886968.6250 - val_loss: 3275125.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1833993.3750 - val_loss: 3275713.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1807717.0000 - val_loss: 3276887.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1784023.6250 - val_loss: 3277809.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1761422.2500 - val_loss: 3278582.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1739513.8750 - val_loss: 3279313.7500\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 29ms/step - loss: 1885878.5000 - val_loss: 3275966.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1831484.6250 - val_loss: 3276197.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1805255.3750 - val_loss: 3277396.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1781284.0000 - val_loss: 3278342.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1758493.1250 - val_loss: 3279173.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1736382.1250 - val_loss: 3279935.7500\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 25ms/step - loss: 1887496.1250 - val_loss: 3275417.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1832328.6250 - val_loss: 3275842.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 1805926.2500 - val_loss: 3276844.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1782164.0000 - val_loss: 3277549.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1759506.2500 - val_loss: 3278074.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1737527.1250 - val_loss: 3278449.0000\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 39ms/step - loss: 1889077.2500 - val_loss: 3275121.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1835104.5000 - val_loss: 3275160.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1808168.1250 - val_loss: 3276285.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1784067.0000 - val_loss: 3277119.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1761223.5000 - val_loss: 3277676.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1739127.7500 - val_loss: 3277946.0000\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 27ms/step - loss: 1890791.5000 - val_loss: 3274675.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 1835275.3750 - val_loss: 3275083.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1808298.6250 - val_loss: 3276092.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 1784268.3750 - val_loss: 3276802.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1761400.2500 - val_loss: 3277384.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1738971.8750 - val_loss: 3277794.2500\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Best_hyper_parameters: \n",
            " {'model': [150], 'optimizer': 'Adam', 'learning_rate': 0.1, 'batch_size': 4, 'best_avg_rmse': 1052.4199906111176}\n",
            "all_avg_rmse: \n",
            " [[[1052.41999061 1193.58744646 1193.37298441]\n",
            "  [1283.0063919  1388.70421049 1458.75863482]\n",
            "  [1506.01080227 1544.00904907 1573.67720731]]\n",
            "\n",
            " [[1567.61852962 1568.43448382 1584.48631584]\n",
            "  [1599.90596825 1614.31632113 1627.28271497]\n",
            "  [1638.67133238 1648.74341494 1657.70894125]]\n",
            "\n",
            " [[1637.95031265 1615.18210937 1604.02061811]\n",
            "  [1599.70791424 1608.94346502 1617.21117658]\n",
            "  [1624.2448727  1631.34177597 1637.98472847]]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': [150],\n",
              " 'optimizer': 'Adam',\n",
              " 'learning_rate': 0.1,\n",
              " 'batch_size': 4,\n",
              " 'best_avg_rmse': 1052.4199906111176}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case VI: Tuning parameters of 200 neuron single layer LSTM"
      ],
      "metadata": {
        "id": "BAQhM0EUO-YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [200]\n",
        "time_step = 5\n",
        "optimizers_names = ['Adam', 'Adagrad', 'Nadam']\n",
        "learning_rates =  [0.1, 0.01, 0.001]\n",
        "batch_sizes =  [4, 8, 16]\n",
        "epochs = 50\n",
        "num_replicates = 10\n",
        "\n",
        "\n",
        "N200_best_hyper_parameters = hyper_parameter_tuning(layers,  optimizers_names, learning_rates, batch_sizes, epochs = epochs, num_replicates = num_replicates)\n",
        "N200_best_hyper_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhPXuwplO1cW",
        "outputId": "ac6377ac-dde0-4a96-fa5c-0d514500378b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "209/209 [==============================] - 7s 22ms/step - loss: 1764620.8750 - val_loss: 3272122.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1678483.2500 - val_loss: 3266199.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1626683.0000 - val_loss: 3261615.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1585825.8750 - val_loss: 3257946.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1551206.2500 - val_loss: 3255073.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 17ms/step - loss: 1520770.2500 - val_loss: 3252376.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1493401.0000 - val_loss: 3249400.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1468396.1250 - val_loss: 3246276.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1445293.8750 - val_loss: 3243316.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1423763.2500 - val_loss: 3239175.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1403553.5000 - val_loss: 3235837.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1384481.8750 - val_loss: 3233711.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1366398.8750 - val_loss: 3231839.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1349190.6250 - val_loss: 3229408.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1332757.0000 - val_loss: 3226385.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1317019.5000 - val_loss: 3223868.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1301911.1250 - val_loss: 3221771.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1287374.7500 - val_loss: 3219425.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1273360.5000 - val_loss: 3216261.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1259826.1250 - val_loss: 3213170.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1246735.7500 - val_loss: 3210672.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1234055.0000 - val_loss: 3208598.2500\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1221756.0000 - val_loss: 3206666.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1209813.7500 - val_loss: 3204689.2500\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1198205.0000 - val_loss: 3202585.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1186908.7500 - val_loss: 3200375.5000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1175906.8750 - val_loss: 3198095.2500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1165183.1250 - val_loss: 3195840.5000\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1154721.5000 - val_loss: 3193638.2500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1144508.5000 - val_loss: 3191555.2500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1134531.2500 - val_loss: 3189609.2500\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1124778.5000 - val_loss: 3187837.0000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1115239.0000 - val_loss: 3186234.2500\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1105902.7500 - val_loss: 3184802.5000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1096761.3750 - val_loss: 3183548.7500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1087804.7500 - val_loss: 3182481.5000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1079026.3750 - val_loss: 3181613.0000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1070418.1250 - val_loss: 3180969.7500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1061972.6250 - val_loss: 3180541.2500\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1053684.2500 - val_loss: 3180259.7500\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1045546.6250 - val_loss: 3180018.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1037554.3750 - val_loss: 3179706.0000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1029702.0000 - val_loss: 3179333.5000\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1021984.6875 - val_loss: 3178979.2500\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1014396.6875 - val_loss: 3178734.5000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1006935.1875 - val_loss: 3178626.2500\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 999594.6250 - val_loss: 3178633.0000\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 992371.5000 - val_loss: 3178679.5000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 985261.8750 - val_loss: 3178672.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 978262.5000 - val_loss: 3178576.2500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 28ms/step - loss: 1790374.0000 - val_loss: 3276840.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1725820.0000 - val_loss: 3276390.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1687942.0000 - val_loss: 3275359.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1657947.7500 - val_loss: 3273819.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1632439.3750 - val_loss: 3272364.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1609934.1250 - val_loss: 3270670.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1589611.1250 - val_loss: 3269039.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1570980.2500 - val_loss: 3267568.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1553709.7500 - val_loss: 3265624.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1537563.0000 - val_loss: 3263466.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1522364.5000 - val_loss: 3261489.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1507973.3750 - val_loss: 3260072.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1494289.5000 - val_loss: 3259009.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1481230.5000 - val_loss: 3257946.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1468726.0000 - val_loss: 3256841.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1456721.6250 - val_loss: 3255640.0000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1445168.2500 - val_loss: 3254489.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1434028.0000 - val_loss: 3253441.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1423256.6250 - val_loss: 3252431.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1412828.3750 - val_loss: 3251374.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1402721.3750 - val_loss: 3250222.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1392903.0000 - val_loss: 3249034.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1383360.7500 - val_loss: 3247698.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1374074.0000 - val_loss: 3246211.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1365025.1250 - val_loss: 3244633.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1356205.3750 - val_loss: 3243155.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1347592.6250 - val_loss: 3241816.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1339187.5000 - val_loss: 3240605.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1330965.6250 - val_loss: 3239614.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1322922.8750 - val_loss: 3238670.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1315045.0000 - val_loss: 3237728.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1307331.3750 - val_loss: 3236785.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1299766.2500 - val_loss: 3235773.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1292353.8750 - val_loss: 3234930.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1285077.1250 - val_loss: 3234105.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1277932.1250 - val_loss: 3233314.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1270920.3750 - val_loss: 3232607.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1264033.2500 - val_loss: 3231959.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1257258.0000 - val_loss: 3231331.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1250602.3750 - val_loss: 3230750.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1244049.3750 - val_loss: 3230193.2500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1237603.0000 - val_loss: 3229678.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1231253.1250 - val_loss: 3229183.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1225004.5000 - val_loss: 3228703.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1218851.6250 - val_loss: 3228236.2500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1212783.6250 - val_loss: 3227769.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1206804.1250 - val_loss: 3227309.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1200912.5000 - val_loss: 3226833.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1195100.7500 - val_loss: 3226327.2500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1189373.8750 - val_loss: 3225813.2500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 28ms/step - loss: 1801035.6250 - val_loss: 3275348.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1736366.2500 - val_loss: 3274909.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1698190.1250 - val_loss: 3273823.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1668029.0000 - val_loss: 3272694.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1642423.3750 - val_loss: 3271139.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1619815.5000 - val_loss: 3269482.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1599422.3750 - val_loss: 3267488.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1580720.3750 - val_loss: 3265942.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1563394.8750 - val_loss: 3264561.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1547193.1250 - val_loss: 3262341.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1531943.6250 - val_loss: 3260094.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1517503.2500 - val_loss: 3258416.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1503779.3750 - val_loss: 3257191.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1490674.8750 - val_loss: 3256142.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1478124.8750 - val_loss: 3255206.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1466081.5000 - val_loss: 3254318.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1454487.0000 - val_loss: 3253443.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1443297.6250 - val_loss: 3252478.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1432484.7500 - val_loss: 3251371.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1422016.7500 - val_loss: 3250236.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1411876.8750 - val_loss: 3249176.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1402025.0000 - val_loss: 3248271.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1392443.3750 - val_loss: 3247455.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1383126.3750 - val_loss: 3246734.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1374046.5000 - val_loss: 3246073.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1365182.3750 - val_loss: 3245436.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1356535.8750 - val_loss: 3244836.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1348088.7500 - val_loss: 3244264.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1339839.1250 - val_loss: 3243714.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1331759.6250 - val_loss: 3243190.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1323855.1250 - val_loss: 3242686.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1316108.0000 - val_loss: 3242200.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1308517.8750 - val_loss: 3241733.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1301071.8750 - val_loss: 3241290.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1293768.3750 - val_loss: 3240860.2500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1286603.3750 - val_loss: 3240445.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1279566.5000 - val_loss: 3240041.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1272644.3750 - val_loss: 3239652.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1265848.2500 - val_loss: 3239272.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1259164.2500 - val_loss: 3238898.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1252590.7500 - val_loss: 3238523.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1246124.7500 - val_loss: 3238141.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1239753.5000 - val_loss: 3237746.2500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1233473.5000 - val_loss: 3237331.2500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1227297.3750 - val_loss: 3236877.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1221213.2500 - val_loss: 3236425.7500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1215212.3750 - val_loss: 3235939.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1209293.3750 - val_loss: 3235393.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1203458.0000 - val_loss: 3234871.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1197706.3750 - val_loss: 3234292.0000\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 30ms/step - loss: 1793316.5000 - val_loss: 3277960.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1729546.3750 - val_loss: 3278326.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1691567.1250 - val_loss: 3277852.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1661484.8750 - val_loss: 3276741.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1635874.6250 - val_loss: 3275775.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1613274.7500 - val_loss: 3275239.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1592871.7500 - val_loss: 3274604.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1574166.3750 - val_loss: 3273885.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1556811.3750 - val_loss: 3272749.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1540575.1250 - val_loss: 3271436.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1525295.6250 - val_loss: 3270584.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1510830.3750 - val_loss: 3269704.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1497077.8750 - val_loss: 3268597.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1483959.6250 - val_loss: 3267318.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1471394.0000 - val_loss: 3266055.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1459324.6250 - val_loss: 3264649.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1447713.1250 - val_loss: 3263538.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1436510.5000 - val_loss: 3262729.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1425677.0000 - val_loss: 3262091.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1415189.0000 - val_loss: 3261415.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1405024.1250 - val_loss: 3260146.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1395153.7500 - val_loss: 3258728.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1385559.3750 - val_loss: 3257832.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1376222.7500 - val_loss: 3257189.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1367124.5000 - val_loss: 3256666.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1358248.6250 - val_loss: 3256191.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1349589.2500 - val_loss: 3255769.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1341127.7500 - val_loss: 3255381.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1332859.5000 - val_loss: 3254872.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1324778.1250 - val_loss: 3253798.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1316866.8750 - val_loss: 3252449.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1309108.2500 - val_loss: 3251528.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1301506.1250 - val_loss: 3250919.0000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1294047.3750 - val_loss: 3250430.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1286730.6250 - val_loss: 3249984.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1279549.8750 - val_loss: 3249532.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1272503.6250 - val_loss: 3249021.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1265578.5000 - val_loss: 3248413.7500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1258770.1250 - val_loss: 3247677.2500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1252077.6250 - val_loss: 3246869.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1245495.2500 - val_loss: 3246111.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1239017.6250 - val_loss: 3245473.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1232637.3750 - val_loss: 3244933.2500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1226352.7500 - val_loss: 3244475.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1220164.5000 - val_loss: 3244055.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1214068.5000 - val_loss: 3243623.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1208063.3750 - val_loss: 3243175.5000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1202141.7500 - val_loss: 3242633.0000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1196306.1250 - val_loss: 3242008.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1190550.6250 - val_loss: 3241328.0000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 30ms/step - loss: 1794307.5000 - val_loss: 3269531.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1729326.8750 - val_loss: 3266993.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1690936.5000 - val_loss: 3265085.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1660546.1250 - val_loss: 3263632.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1634676.2500 - val_loss: 3262653.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1611837.3750 - val_loss: 3261784.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1591233.2500 - val_loss: 3261073.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1572340.8750 - val_loss: 3260364.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1554831.2500 - val_loss: 3259646.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1538446.3750 - val_loss: 3258879.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1523023.5000 - val_loss: 3258048.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1508434.6250 - val_loss: 3257118.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1494553.3750 - val_loss: 3256035.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1481310.6250 - val_loss: 3254875.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1468628.2500 - val_loss: 3253787.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1456453.6250 - val_loss: 3252864.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1444736.7500 - val_loss: 3252066.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1433430.6250 - val_loss: 3251339.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1422514.3750 - val_loss: 3250652.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1411939.2500 - val_loss: 3249958.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1401686.8750 - val_loss: 3249130.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1391732.6250 - val_loss: 3248050.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1382061.0000 - val_loss: 3246788.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1372643.3750 - val_loss: 3245422.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1363471.6250 - val_loss: 3244329.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1354534.2500 - val_loss: 3243400.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1345811.2500 - val_loss: 3242543.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1337285.3750 - val_loss: 3241795.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1328953.1250 - val_loss: 3241141.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1320793.2500 - val_loss: 3240500.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1312810.8750 - val_loss: 3239863.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1305001.3750 - val_loss: 3239269.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1297347.0000 - val_loss: 3238723.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1289836.3750 - val_loss: 3238218.7500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1282470.2500 - val_loss: 3237731.7500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1275238.6250 - val_loss: 3237273.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1268128.1250 - val_loss: 3236828.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1261150.2500 - val_loss: 3236411.7500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1254292.6250 - val_loss: 3236020.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1247546.1250 - val_loss: 3235644.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1240911.8750 - val_loss: 3235276.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1234383.1250 - val_loss: 3234922.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1227956.8750 - val_loss: 3234593.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1221626.8750 - val_loss: 3234272.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1215394.6250 - val_loss: 3233960.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1209257.7500 - val_loss: 3233659.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1203202.7500 - val_loss: 3233368.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1197240.0000 - val_loss: 3233085.0000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1191357.1250 - val_loss: 3232806.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1185558.8750 - val_loss: 3232533.2500\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 26ms/step - loss: 1792696.7500 - val_loss: 3273632.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1727117.7500 - val_loss: 3271985.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1688862.5000 - val_loss: 3268819.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1658583.8750 - val_loss: 3265928.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1632826.7500 - val_loss: 3263987.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1610108.7500 - val_loss: 3262603.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1589584.8750 - val_loss: 3261416.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1570782.5000 - val_loss: 3260315.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1553352.3750 - val_loss: 3259218.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1537043.1250 - val_loss: 3258029.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1521704.1250 - val_loss: 3256720.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1507178.1250 - val_loss: 3255309.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1493362.2500 - val_loss: 3253855.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1480184.7500 - val_loss: 3252451.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1467569.6250 - val_loss: 3251288.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1455444.0000 - val_loss: 3250240.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1443785.6250 - val_loss: 3249318.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1432538.6250 - val_loss: 3248474.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1421663.7500 - val_loss: 3247687.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1411146.8750 - val_loss: 3246954.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1400945.8750 - val_loss: 3246265.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1391048.0000 - val_loss: 3245614.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1381414.6250 - val_loss: 3244994.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1372050.1250 - val_loss: 3244406.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1362919.2500 - val_loss: 3243843.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1354020.8750 - val_loss: 3243303.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1345338.7500 - val_loss: 3242772.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1336850.3750 - val_loss: 3242227.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1328558.2500 - val_loss: 3241635.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1320438.3750 - val_loss: 3240946.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1312496.8750 - val_loss: 3240146.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1304720.5000 - val_loss: 3239245.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1297086.3750 - val_loss: 3238321.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1289606.2500 - val_loss: 3237437.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1282272.1250 - val_loss: 3236537.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1275071.7500 - val_loss: 3235639.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1267996.8750 - val_loss: 3234703.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1261046.6250 - val_loss: 3233649.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1254215.6250 - val_loss: 3232562.7500\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1247506.5000 - val_loss: 3231471.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1240902.8750 - val_loss: 3230496.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1234405.8750 - val_loss: 3229570.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1228003.8750 - val_loss: 3228741.2500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1221711.1250 - val_loss: 3227992.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1215507.5000 - val_loss: 3227327.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1209392.7500 - val_loss: 3226734.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1203366.3750 - val_loss: 3226147.7500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1197424.2500 - val_loss: 3225604.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1191569.1250 - val_loss: 3225117.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1185797.1250 - val_loss: 3224649.5000\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 24ms/step - loss: 1794941.2500 - val_loss: 3273460.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1730141.7500 - val_loss: 3270862.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1692242.3750 - val_loss: 3268067.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1662233.2500 - val_loss: 3265182.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1636631.1250 - val_loss: 3262238.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1613677.7500 - val_loss: 3259598.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1593099.5000 - val_loss: 3257231.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1574286.8750 - val_loss: 3254934.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1556873.6250 - val_loss: 3252641.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1540593.8750 - val_loss: 3250403.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1525276.3750 - val_loss: 3248320.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1510781.5000 - val_loss: 3246135.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1497009.8750 - val_loss: 3243777.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1483853.3750 - val_loss: 3241236.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1471265.1250 - val_loss: 3238621.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1459183.0000 - val_loss: 3235743.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1447541.0000 - val_loss: 3232966.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1436319.1250 - val_loss: 3230443.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1425477.2500 - val_loss: 3228299.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1414982.6250 - val_loss: 3226341.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1404796.1250 - val_loss: 3224486.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1394912.1250 - val_loss: 3222833.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1385306.3750 - val_loss: 3221309.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1375965.5000 - val_loss: 3219947.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1366856.6250 - val_loss: 3218695.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1357978.1250 - val_loss: 3217516.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1349314.0000 - val_loss: 3216343.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1340851.8750 - val_loss: 3215105.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1332579.8750 - val_loss: 3213809.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1324487.5000 - val_loss: 3212380.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1316567.1250 - val_loss: 3210932.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1308806.3750 - val_loss: 3209516.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1301204.5000 - val_loss: 3208071.2500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1293748.8750 - val_loss: 3206634.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1286437.6250 - val_loss: 3205239.0000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1279257.2500 - val_loss: 3203916.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1272205.6250 - val_loss: 3202717.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1265275.5000 - val_loss: 3201601.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1258458.1250 - val_loss: 3200591.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1251759.1250 - val_loss: 3199639.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1245172.6250 - val_loss: 3198748.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1238688.8750 - val_loss: 3197901.7500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1232304.0000 - val_loss: 3197076.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1226019.6250 - val_loss: 3196278.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1219832.6250 - val_loss: 3195507.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1213734.0000 - val_loss: 3194752.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1207725.1250 - val_loss: 3193995.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1201796.5000 - val_loss: 3193255.0000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1195959.0000 - val_loss: 3192535.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1190196.2500 - val_loss: 3191820.0000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 29ms/step - loss: 1793892.0000 - val_loss: 3275251.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1729921.8750 - val_loss: 3272932.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1691583.1250 - val_loss: 3271382.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1661262.1250 - val_loss: 3270228.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1635491.8750 - val_loss: 3269098.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1612364.8750 - val_loss: 3267768.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1591571.1250 - val_loss: 3265486.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1572568.5000 - val_loss: 3263293.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1555000.6250 - val_loss: 3261539.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1538569.1250 - val_loss: 3259354.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1523107.2500 - val_loss: 3257287.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1508484.1250 - val_loss: 3255527.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1494590.5000 - val_loss: 3253892.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1481331.7500 - val_loss: 3252460.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1468635.0000 - val_loss: 3251336.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1456440.7500 - val_loss: 3250400.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1444712.0000 - val_loss: 3249567.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1433393.6250 - val_loss: 3248674.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1422462.8750 - val_loss: 3246929.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1411882.0000 - val_loss: 3244526.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1401619.8750 - val_loss: 3242340.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1391663.0000 - val_loss: 3240020.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1381986.6250 - val_loss: 3237408.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1372571.8750 - val_loss: 3234939.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1363400.1250 - val_loss: 3232907.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1354457.1250 - val_loss: 3231412.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1345724.0000 - val_loss: 3230132.7500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1337195.5000 - val_loss: 3229004.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1328858.3750 - val_loss: 3227962.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1320704.7500 - val_loss: 3226825.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1312723.5000 - val_loss: 3225622.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1304905.1250 - val_loss: 3224467.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1297244.1250 - val_loss: 3223312.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1289726.0000 - val_loss: 3222339.7500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1282353.3750 - val_loss: 3221377.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1275114.3750 - val_loss: 3220519.2500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1268008.7500 - val_loss: 3219754.7500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1261027.0000 - val_loss: 3219050.2500\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1254164.0000 - val_loss: 3218389.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1247416.7500 - val_loss: 3217769.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1240782.5000 - val_loss: 3217183.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1234253.0000 - val_loss: 3216630.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1227828.8750 - val_loss: 3216086.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1221500.8750 - val_loss: 3215528.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1215271.3750 - val_loss: 3214915.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1209125.8750 - val_loss: 3214153.2500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1203073.8750 - val_loss: 3213215.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1197110.5000 - val_loss: 3212118.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1191231.7500 - val_loss: 3211019.0000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1185431.2500 - val_loss: 3210065.7500\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 10s 32ms/step - loss: 1796323.2500 - val_loss: 3277369.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1731407.8750 - val_loss: 3276963.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1692845.8750 - val_loss: 3275709.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1662355.0000 - val_loss: 3274566.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1636436.0000 - val_loss: 3274064.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1613574.1250 - val_loss: 3273867.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1592935.2500 - val_loss: 3273746.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1574005.6250 - val_loss: 3273651.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1556468.6250 - val_loss: 3273568.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1540073.0000 - val_loss: 3273465.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1524633.7500 - val_loss: 3273289.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1510035.0000 - val_loss: 3272963.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1496158.3750 - val_loss: 3272547.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1482908.1250 - val_loss: 3272190.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1470220.5000 - val_loss: 3271904.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1458042.3750 - val_loss: 3271722.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1446317.1250 - val_loss: 3271555.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1435012.0000 - val_loss: 3271304.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1424081.6250 - val_loss: 3270819.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1413502.3750 - val_loss: 3269836.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1403253.1250 - val_loss: 3268774.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1393303.1250 - val_loss: 3268081.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1383619.8750 - val_loss: 3267630.2500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1374208.8750 - val_loss: 3267347.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1365031.6250 - val_loss: 3267068.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1356089.0000 - val_loss: 3266618.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1347358.3750 - val_loss: 3265869.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1338829.0000 - val_loss: 3265260.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1330492.0000 - val_loss: 3264798.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1322337.1250 - val_loss: 3264493.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1314348.5000 - val_loss: 3264295.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1306529.1250 - val_loss: 3264149.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1298867.0000 - val_loss: 3264044.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1291354.0000 - val_loss: 3263986.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1283979.2500 - val_loss: 3263942.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1276740.0000 - val_loss: 3263918.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1269624.8750 - val_loss: 3263898.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1262646.0000 - val_loss: 3263882.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1255782.3750 - val_loss: 3263875.0000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1249031.7500 - val_loss: 3263872.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1242393.7500 - val_loss: 3263866.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1235863.0000 - val_loss: 3263861.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1229434.0000 - val_loss: 3263858.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1223105.0000 - val_loss: 3263847.0000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1216870.6250 - val_loss: 3263839.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1210727.6250 - val_loss: 3263832.7500\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1204674.1250 - val_loss: 3263819.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1198709.0000 - val_loss: 3263806.7500\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1192825.0000 - val_loss: 3263790.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1187022.2500 - val_loss: 3263775.0000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 7s 36ms/step - loss: 1797540.8750 - val_loss: 3276938.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1733417.3750 - val_loss: 3276419.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1695552.8750 - val_loss: 3274969.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1665507.6250 - val_loss: 3273275.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1639965.8750 - val_loss: 3271611.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1617422.7500 - val_loss: 3269857.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1597070.2500 - val_loss: 3268448.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1578407.5000 - val_loss: 3267434.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1561108.6250 - val_loss: 3266582.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1544932.8750 - val_loss: 3265745.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1529699.6250 - val_loss: 3264772.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1515287.8750 - val_loss: 3263235.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1501574.1250 - val_loss: 3261707.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1488484.7500 - val_loss: 3260205.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1475950.7500 - val_loss: 3258152.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 1463921.1250 - val_loss: 3255659.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1452335.6250 - val_loss: 3253825.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1441165.6250 - val_loss: 3252457.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1430367.3750 - val_loss: 3251335.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1419907.6250 - val_loss: 3250364.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1409771.0000 - val_loss: 3249493.2500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1399932.5000 - val_loss: 3248696.0000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1390366.0000 - val_loss: 3247916.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1381054.8750 - val_loss: 3247060.2500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1371991.0000 - val_loss: 3245969.7500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1363145.7500 - val_loss: 3244666.0000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1354510.5000 - val_loss: 3243083.7500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1346080.5000 - val_loss: 3241667.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1337836.0000 - val_loss: 3240459.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1329772.3750 - val_loss: 3239458.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1321873.5000 - val_loss: 3238524.7500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1314142.7500 - val_loss: 3237702.7500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1306555.8750 - val_loss: 3236971.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1299115.6250 - val_loss: 3236293.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1291819.6250 - val_loss: 3235692.7500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1284661.8750 - val_loss: 3235130.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1277626.5000 - val_loss: 3234594.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1270717.7500 - val_loss: 3234090.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1263919.0000 - val_loss: 3233591.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1257240.2500 - val_loss: 3233116.7500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1250671.2500 - val_loss: 3232658.0000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1244203.7500 - val_loss: 3232201.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1237842.1250 - val_loss: 3231755.7500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1231573.2500 - val_loss: 3231306.7500\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1225397.6250 - val_loss: 3230841.0000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1219315.8750 - val_loss: 3230358.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1213321.3750 - val_loss: 3229803.2500\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1207415.2500 - val_loss: 3229231.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1201588.0000 - val_loss: 3228682.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1195838.5000 - val_loss: 3228026.2500\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 29ms/step - loss: 1791374.1250 - val_loss: 3273331.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1726318.2500 - val_loss: 3271572.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1687728.7500 - val_loss: 3269243.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1657264.3750 - val_loss: 3267292.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1631378.3750 - val_loss: 3265628.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1608563.1250 - val_loss: 3264187.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1587959.8750 - val_loss: 3262661.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1569073.1250 - val_loss: 3260816.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1551558.8750 - val_loss: 3259195.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1535191.0000 - val_loss: 3257683.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1519778.6250 - val_loss: 3255827.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1505194.0000 - val_loss: 3254134.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1491333.0000 - val_loss: 3252866.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1478097.0000 - val_loss: 3251734.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1465428.6250 - val_loss: 3250637.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1453268.0000 - val_loss: 3249583.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1441555.2500 - val_loss: 3248528.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1430256.3750 - val_loss: 3247485.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1419348.5000 - val_loss: 3246496.7500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1408787.5000 - val_loss: 3245579.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1398547.6250 - val_loss: 3244727.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1388607.1250 - val_loss: 3243940.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1378944.0000 - val_loss: 3243196.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1369541.8750 - val_loss: 3242493.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1360377.2500 - val_loss: 3241831.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1351443.5000 - val_loss: 3241200.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1342726.7500 - val_loss: 3240597.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1334208.6250 - val_loss: 3240021.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1325883.1250 - val_loss: 3239467.7500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1317734.8750 - val_loss: 3238934.0000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1309760.0000 - val_loss: 3238419.0000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1301948.1250 - val_loss: 3237921.0000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1294285.1250 - val_loss: 3237439.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1286785.1250 - val_loss: 3236973.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1279428.2500 - val_loss: 3236520.7500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1272198.8750 - val_loss: 3236081.0000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1265100.5000 - val_loss: 3235653.0000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1258125.5000 - val_loss: 3235237.0000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1251262.8750 - val_loss: 3234829.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1244525.5000 - val_loss: 3234433.2500\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1237895.3750 - val_loss: 3234045.7500\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1231376.6250 - val_loss: 3233664.2500\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1224961.5000 - val_loss: 3233295.2500\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1218637.8750 - val_loss: 3232932.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1212413.2500 - val_loss: 3232574.7500\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1206282.1250 - val_loss: 3232221.0000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1200242.8750 - val_loss: 3231872.0000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1194284.1250 - val_loss: 3231536.0000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1188413.5000 - val_loss: 3231212.7500\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1182616.6250 - val_loss: 3230903.5000\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 32ms/step - loss: 1815709.2500 - val_loss: 3277147.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1764373.3750 - val_loss: 3277638.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1736310.2500 - val_loss: 3277564.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1714149.5000 - val_loss: 3277397.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 2s 30ms/step - loss: 1695259.0000 - val_loss: 3277278.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 2s 28ms/step - loss: 1678532.1250 - val_loss: 3277186.5000\n",
            "7/7 [==============================] - 1s 14ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1817613.0000 - val_loss: 3276138.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1765406.1250 - val_loss: 3276540.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1737074.3750 - val_loss: 3276425.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1714731.1250 - val_loss: 3276176.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1695701.3750 - val_loss: 3275928.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1678896.8750 - val_loss: 3275700.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1663701.3750 - val_loss: 3275465.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1649779.7500 - val_loss: 3275178.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1636836.0000 - val_loss: 3274883.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1624702.8750 - val_loss: 3274536.7500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1613270.6250 - val_loss: 3274167.0000\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1602429.1250 - val_loss: 3273825.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1592098.2500 - val_loss: 3273448.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1582206.0000 - val_loss: 3273004.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1572717.1250 - val_loss: 3272292.7500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1563608.0000 - val_loss: 3271482.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1554813.1250 - val_loss: 3270619.7500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1546325.2500 - val_loss: 3269976.2500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1538117.6250 - val_loss: 3269381.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1530157.0000 - val_loss: 3268863.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1522415.2500 - val_loss: 3268429.5000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1514899.7500 - val_loss: 3268053.7500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1507568.8750 - val_loss: 3267692.0000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 2s 29ms/step - loss: 1500439.1250 - val_loss: 3267350.2500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1493466.6250 - val_loss: 3266971.7500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1486663.2500 - val_loss: 3266474.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1480016.2500 - val_loss: 3265799.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1473516.7500 - val_loss: 3265175.5000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1467153.7500 - val_loss: 3264625.5000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1460929.1250 - val_loss: 3264202.0000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1454827.6250 - val_loss: 3263871.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1448839.2500 - val_loss: 3263578.7500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1442964.0000 - val_loss: 3263317.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1437182.8750 - val_loss: 3263054.7500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1431516.5000 - val_loss: 3262783.0000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1425943.0000 - val_loss: 3262468.2500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1420456.7500 - val_loss: 3262075.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1415065.1250 - val_loss: 3261604.5000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1409766.2500 - val_loss: 3261051.5000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1404531.2500 - val_loss: 3260429.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 2s 30ms/step - loss: 1399387.7500 - val_loss: 3259931.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1394326.5000 - val_loss: 3259435.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1389335.2500 - val_loss: 3258995.7500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1384406.6250 - val_loss: 3258502.5000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1379552.1250 - val_loss: 3257948.5000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1374764.2500 - val_loss: 3257290.5000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1370049.3750 - val_loss: 3256670.0000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1365376.8750 - val_loss: 3255944.2500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1360782.2500 - val_loss: 3255255.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1356250.3750 - val_loss: 3254477.5000\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 44ms/step - loss: 1817623.3750 - val_loss: 3276349.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1765066.2500 - val_loss: 3276123.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1736842.8750 - val_loss: 3275467.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1714549.6250 - val_loss: 3274757.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1695618.5000 - val_loss: 3274175.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1678845.0000 - val_loss: 3273722.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1663707.5000 - val_loss: 3273170.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1649806.3750 - val_loss: 3272770.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1636918.6250 - val_loss: 3272357.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1624838.6250 - val_loss: 3272011.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1613192.1250 - val_loss: 3271726.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1602194.2500 - val_loss: 3271359.0000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 2s 29ms/step - loss: 1591786.8750 - val_loss: 3270939.5000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1581863.6250 - val_loss: 3270600.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 2s 30ms/step - loss: 1572335.5000 - val_loss: 3270270.2500\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1563182.8750 - val_loss: 3269871.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1554366.7500 - val_loss: 3269538.5000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1545844.5000 - val_loss: 3269285.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1537593.0000 - val_loss: 3268933.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1529606.8750 - val_loss: 3268547.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1521855.2500 - val_loss: 3268185.0000\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1514313.3750 - val_loss: 3267794.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1506959.2500 - val_loss: 3267172.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1499814.0000 - val_loss: 3266564.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1492840.6250 - val_loss: 3266007.2500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1486026.3750 - val_loss: 3265437.0000\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1479375.7500 - val_loss: 3264937.0000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1472873.3750 - val_loss: 3264366.5000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 2s 29ms/step - loss: 1466505.1250 - val_loss: 3264084.2500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1460257.5000 - val_loss: 3263635.0000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1454134.2500 - val_loss: 3263211.5000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1448148.2500 - val_loss: 3262870.2500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1442263.8750 - val_loss: 3262583.7500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1436480.5000 - val_loss: 3262159.0000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1430809.0000 - val_loss: 3261788.2500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1425243.2500 - val_loss: 3261440.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1419762.2500 - val_loss: 3261178.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1414360.6250 - val_loss: 3260895.5000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1409053.0000 - val_loss: 3260577.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1403826.6250 - val_loss: 3260148.2500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1398688.7500 - val_loss: 3259746.2500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1393622.0000 - val_loss: 3259365.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1388630.2500 - val_loss: 3259029.2500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1383713.1250 - val_loss: 3258637.2500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1378861.1250 - val_loss: 3258181.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1374074.3750 - val_loss: 3257787.0000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1369354.8750 - val_loss: 3257238.7500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1364691.5000 - val_loss: 3256758.0000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1360097.2500 - val_loss: 3256536.2500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1355545.2500 - val_loss: 3256231.2500\n",
            "7/7 [==============================] - 0s 12ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 32ms/step - loss: 1815345.5000 - val_loss: 3276734.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1764361.1250 - val_loss: 3277293.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1736631.0000 - val_loss: 3277497.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1714393.8750 - val_loss: 3277595.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1695485.5000 - val_loss: 3277619.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1678790.2500 - val_loss: 3277522.0000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1818310.0000 - val_loss: 3277569.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1767539.6250 - val_loss: 3278288.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1739183.6250 - val_loss: 3278655.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1716814.1250 - val_loss: 3278817.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1697792.6250 - val_loss: 3278825.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1681003.7500 - val_loss: 3278736.5000\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1815327.3750 - val_loss: 3276410.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1764012.1250 - val_loss: 3276447.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1735950.5000 - val_loss: 3276187.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1713722.0000 - val_loss: 3275826.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1694839.1250 - val_loss: 3275387.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1678165.6250 - val_loss: 3275088.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1662839.2500 - val_loss: 3274948.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1648714.7500 - val_loss: 3274724.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1635696.5000 - val_loss: 3274430.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 2s 28ms/step - loss: 1623543.3750 - val_loss: 3274237.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1612053.8750 - val_loss: 3274003.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1601190.0000 - val_loss: 3273808.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1590851.0000 - val_loss: 3273624.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1580958.7500 - val_loss: 3273514.2500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1571468.2500 - val_loss: 3273174.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1562357.2500 - val_loss: 3273037.2500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1553548.3750 - val_loss: 3272829.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1545050.3750 - val_loss: 3272664.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1536834.7500 - val_loss: 3272461.2500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1528840.3750 - val_loss: 3272265.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1521106.1250 - val_loss: 3272063.7500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1513591.3750 - val_loss: 3271912.5000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1506264.5000 - val_loss: 3271751.7500\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1499127.3750 - val_loss: 3271593.2500\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1492173.1250 - val_loss: 3271460.2500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1485386.0000 - val_loss: 3271335.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1478749.3750 - val_loss: 3271225.2500\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1472263.5000 - val_loss: 3271134.0000\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1465894.1250 - val_loss: 3271046.0000\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1459659.5000 - val_loss: 3270967.0000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1453552.5000 - val_loss: 3270873.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1447553.8750 - val_loss: 3270732.7500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1441680.5000 - val_loss: 3270491.2500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1435926.3750 - val_loss: 3270129.5000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1430265.3750 - val_loss: 3269607.5000\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1424706.6250 - val_loss: 3269202.0000\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1419236.2500 - val_loss: 3268878.0000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1413843.5000 - val_loss: 3268593.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1408541.8750 - val_loss: 3268417.0000\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1403319.8750 - val_loss: 3268274.2500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1398185.0000 - val_loss: 3268150.0000\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1393119.8750 - val_loss: 3268029.2500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1388138.0000 - val_loss: 3267921.7500\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1383202.1250 - val_loss: 3267711.7500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1378349.5000 - val_loss: 3267462.5000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1373568.1250 - val_loss: 3267099.5000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1368847.5000 - val_loss: 3266737.2500\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1364183.0000 - val_loss: 3266262.0000\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1359580.7500 - val_loss: 3265844.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1355032.5000 - val_loss: 3265559.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 44ms/step - loss: 1818919.3750 - val_loss: 3277358.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1768036.7500 - val_loss: 3277926.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1740001.2500 - val_loss: 3278202.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1717890.5000 - val_loss: 3278323.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1699078.7500 - val_loss: 3278317.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1682449.0000 - val_loss: 3278231.5000\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 30ms/step - loss: 1815236.8750 - val_loss: 3276134.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1763966.7500 - val_loss: 3276319.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1735767.3750 - val_loss: 3276057.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1713459.1250 - val_loss: 3275407.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1694472.2500 - val_loss: 3274318.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1677722.5000 - val_loss: 3273126.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1662536.7500 - val_loss: 3272014.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1648610.8750 - val_loss: 3271040.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1635692.1250 - val_loss: 3270050.5000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1623572.2500 - val_loss: 3269193.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1612133.8750 - val_loss: 3268462.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1601291.3750 - val_loss: 3267807.7500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1590945.3750 - val_loss: 3267018.0000\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1581071.7500 - val_loss: 3266101.0000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1571616.0000 - val_loss: 3265050.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1562504.8750 - val_loss: 3264012.7500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1553732.7500 - val_loss: 3263165.2500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1545249.1250 - val_loss: 3262315.2500\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1537045.6250 - val_loss: 3261495.7500\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1529089.5000 - val_loss: 3260711.0000\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1521371.8750 - val_loss: 3260050.2500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1513852.0000 - val_loss: 3259433.0000\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1506540.2500 - val_loss: 3258809.5000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1499414.8750 - val_loss: 3258273.5000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1492457.3750 - val_loss: 3257778.2500\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1485648.8750 - val_loss: 3257314.2500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 2s 30ms/step - loss: 1479018.3750 - val_loss: 3256906.0000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1472525.6250 - val_loss: 3256512.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1466150.7500 - val_loss: 3256131.2500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1459917.6250 - val_loss: 3255735.5000\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1453814.8750 - val_loss: 3255383.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1447824.3750 - val_loss: 3255030.7500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1441953.3750 - val_loss: 3254691.7500\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1436188.0000 - val_loss: 3254371.7500\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1430525.3750 - val_loss: 3254065.2500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1424945.8750 - val_loss: 3253761.7500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1419470.8750 - val_loss: 3253457.5000\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1414078.5000 - val_loss: 3253177.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 2s 28ms/step - loss: 1408776.1250 - val_loss: 3252903.7500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1403556.2500 - val_loss: 3252635.7500\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1398419.5000 - val_loss: 3252379.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1393352.7500 - val_loss: 3252128.7500\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1388356.5000 - val_loss: 3251883.5000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1383437.8750 - val_loss: 3251644.2500\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1378588.5000 - val_loss: 3251409.7500\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1373806.5000 - val_loss: 3251181.0000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1369073.1250 - val_loss: 3250959.0000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1364413.0000 - val_loss: 3250740.7500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1359818.2500 - val_loss: 3250527.7500\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1355279.7500 - val_loss: 3250320.2500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 30ms/step - loss: 1819138.7500 - val_loss: 3277422.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1767841.2500 - val_loss: 3277781.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1739744.5000 - val_loss: 3277596.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1717536.0000 - val_loss: 3277439.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1698588.0000 - val_loss: 3277175.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1681869.7500 - val_loss: 3276923.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1666760.1250 - val_loss: 3276786.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1652902.3750 - val_loss: 3276662.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1640023.2500 - val_loss: 3276607.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1627923.7500 - val_loss: 3276571.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1616534.5000 - val_loss: 3276517.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1605742.3750 - val_loss: 3276469.5000\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1595470.5000 - val_loss: 3276426.7500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1585622.6250 - val_loss: 3276387.7500\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1576194.8750 - val_loss: 3276342.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1567125.3750 - val_loss: 3276295.0000\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1558373.2500 - val_loss: 3276250.0000\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1549910.0000 - val_loss: 3276209.0000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1541732.0000 - val_loss: 3276168.5000\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1533773.5000 - val_loss: 3276128.7500\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1526051.8750 - val_loss: 3276090.7500\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1518570.2500 - val_loss: 3276044.7500\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1511279.8750 - val_loss: 3275974.0000\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1504167.2500 - val_loss: 3275800.0000\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1497236.6250 - val_loss: 3275549.0000\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1490470.1250 - val_loss: 3275262.7500\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1483839.1250 - val_loss: 3274845.5000\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1477368.2500 - val_loss: 3274391.2500\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1471031.8750 - val_loss: 3273938.7500\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1464829.1250 - val_loss: 3273383.7500\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1458740.8750 - val_loss: 3272692.0000\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1452767.5000 - val_loss: 3272112.7500\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1446915.6250 - val_loss: 3271543.5000\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1441166.2500 - val_loss: 3271097.0000\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1435515.8750 - val_loss: 3270666.7500\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1429967.5000 - val_loss: 3270261.2500\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1424507.7500 - val_loss: 3269988.7500\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1419136.1250 - val_loss: 3269662.0000\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1413851.3750 - val_loss: 3269412.2500\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1408637.0000 - val_loss: 3269208.0000\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1403513.7500 - val_loss: 3268935.7500\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1398469.5000 - val_loss: 3268751.5000\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1393491.5000 - val_loss: 3268510.0000\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1388594.6250 - val_loss: 3268305.5000\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1383754.0000 - val_loss: 3268165.0000\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1378978.6250 - val_loss: 3268067.0000\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1374274.2500 - val_loss: 3267910.5000\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1369629.5000 - val_loss: 3267800.2500\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1365039.7500 - val_loss: 3267690.0000\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1360512.6250 - val_loss: 3267605.2500\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Running for Adagrad optimizer 0.01 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 38ms/step - loss: 1812901.0000 - val_loss: 3275830.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1761315.3750 - val_loss: 3274851.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1733063.2500 - val_loss: 3273987.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1710746.0000 - val_loss: 3273567.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1691726.2500 - val_loss: 3273161.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1674958.8750 - val_loss: 3272920.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1659810.6250 - val_loss: 3272859.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1645858.7500 - val_loss: 3272795.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1632918.6250 - val_loss: 3272709.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1620795.2500 - val_loss: 3272754.0000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1609389.3750 - val_loss: 3272836.2500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1598566.0000 - val_loss: 3272899.2500\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1588253.0000 - val_loss: 3272954.2500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1578395.2500 - val_loss: 3273021.7500\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 21ms/step - loss: 1889824.6250 - val_loss: 3277858.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1847384.2500 - val_loss: 3276794.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1835894.0000 - val_loss: 3276037.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1829687.3750 - val_loss: 3275791.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 17ms/step - loss: 1824911.7500 - val_loss: 3275717.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1820885.7500 - val_loss: 3275709.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1817334.3750 - val_loss: 3275729.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1814118.6250 - val_loss: 3275762.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1811153.2500 - val_loss: 3275806.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1808357.5000 - val_loss: 3275853.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1805723.7500 - val_loss: 3275891.2500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 19ms/step - loss: 1888356.0000 - val_loss: 3277955.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1846447.7500 - val_loss: 3276816.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1836052.2500 - val_loss: 3276264.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1830053.3750 - val_loss: 3276134.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1825359.6250 - val_loss: 3276124.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1821378.1250 - val_loss: 3276163.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 17ms/step - loss: 1817856.1250 - val_loss: 3276222.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1814662.3750 - val_loss: 3276291.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1811719.6250 - val_loss: 3276363.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1808975.0000 - val_loss: 3276438.2500\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 17ms/step - loss: 1890961.5000 - val_loss: 3276228.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1850409.3750 - val_loss: 3275735.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1838214.8750 - val_loss: 3275201.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1831966.5000 - val_loss: 3275046.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1827186.8750 - val_loss: 3275018.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1823148.8750 - val_loss: 3275034.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1819584.0000 - val_loss: 3275068.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1816353.5000 - val_loss: 3275108.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1813379.6250 - val_loss: 3275148.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1810609.2500 - val_loss: 3275186.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 18ms/step - loss: 1889760.1250 - val_loss: 3276971.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1848996.0000 - val_loss: 3276676.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1835974.2500 - val_loss: 3275672.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1829472.5000 - val_loss: 3275234.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1824628.5000 - val_loss: 3275080.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1820533.2500 - val_loss: 3275028.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1816940.7500 - val_loss: 3275019.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1813700.8750 - val_loss: 3275030.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1810724.1250 - val_loss: 3275050.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1807954.2500 - val_loss: 3275073.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1805354.1250 - val_loss: 3275097.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1802896.8750 - val_loss: 3275117.7500\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 21ms/step - loss: 1886617.2500 - val_loss: 3277975.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1845760.7500 - val_loss: 3277058.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1835361.3750 - val_loss: 3276244.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1829379.8750 - val_loss: 3275889.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1824738.5000 - val_loss: 3275742.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1820786.2500 - val_loss: 3275689.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1817275.8750 - val_loss: 3275674.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1814093.8750 - val_loss: 3275679.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1811163.7500 - val_loss: 3275693.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1808432.7500 - val_loss: 3275712.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1805866.3750 - val_loss: 3275732.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1803438.3750 - val_loss: 3275751.7500\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 24ms/step - loss: 1892375.2500 - val_loss: 3275894.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1850072.3750 - val_loss: 3275074.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1837907.1250 - val_loss: 3274362.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1831641.6250 - val_loss: 3274066.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1826844.3750 - val_loss: 3273922.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1822785.1250 - val_loss: 3273837.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1819203.2500 - val_loss: 3273781.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1815953.6250 - val_loss: 3273741.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1812933.0000 - val_loss: 3273709.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1810116.6250 - val_loss: 3273676.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1807479.7500 - val_loss: 3273641.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1804989.2500 - val_loss: 3273607.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1802624.1250 - val_loss: 3273571.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1800365.5000 - val_loss: 3273534.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1798200.5000 - val_loss: 3273496.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1796118.6250 - val_loss: 3273458.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1794110.8750 - val_loss: 3273417.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1792170.6250 - val_loss: 3273375.0000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 3s 17ms/step - loss: 1790291.1250 - val_loss: 3273332.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1788466.1250 - val_loss: 3273289.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1786692.1250 - val_loss: 3273243.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1784966.8750 - val_loss: 3273198.0000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1783284.0000 - val_loss: 3273151.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1781641.1250 - val_loss: 3273103.5000\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1780037.0000 - val_loss: 3273054.0000\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1778468.1250 - val_loss: 3273004.0000\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1776932.5000 - val_loss: 3272954.2500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1775427.5000 - val_loss: 3272902.7500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1773952.5000 - val_loss: 3272851.0000\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1772505.8750 - val_loss: 3272798.0000\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1771084.3750 - val_loss: 3272744.5000\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1769688.5000 - val_loss: 3272690.5000\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1768316.5000 - val_loss: 3272635.5000\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1766967.3750 - val_loss: 3272580.0000\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1765639.3750 - val_loss: 3272524.2500\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1764332.1250 - val_loss: 3272468.0000\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1763044.5000 - val_loss: 3272411.5000\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1761776.2500 - val_loss: 3272353.7500\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1760526.3750 - val_loss: 3272295.5000\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1759292.6250 - val_loss: 3272238.0000\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1758076.6250 - val_loss: 3272179.2500\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1756876.1250 - val_loss: 3272119.0000\n",
            "Epoch 43/50\n",
            "209/209 [==============================] - 3s 17ms/step - loss: 1755691.7500 - val_loss: 3272060.7500\n",
            "Epoch 44/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1754521.7500 - val_loss: 3272000.5000\n",
            "Epoch 45/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1753367.2500 - val_loss: 3271941.0000\n",
            "Epoch 46/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1752225.5000 - val_loss: 3271881.0000\n",
            "Epoch 47/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1751097.7500 - val_loss: 3271820.2500\n",
            "Epoch 48/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1749982.1250 - val_loss: 3271759.5000\n",
            "Epoch 49/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1748879.7500 - val_loss: 3271699.0000\n",
            "Epoch 50/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1747789.6250 - val_loss: 3271638.2500\n",
            "7/7 [==============================] - 1s 12ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 18ms/step - loss: 1889521.6250 - val_loss: 3277912.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1850094.2500 - val_loss: 3277336.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1839113.0000 - val_loss: 3276359.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1832964.5000 - val_loss: 3275910.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1828226.5000 - val_loss: 3275730.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1824215.3750 - val_loss: 3275661.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1820670.3750 - val_loss: 3275645.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1817455.0000 - val_loss: 3275654.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1814494.6250 - val_loss: 3275677.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 17ms/step - loss: 1811734.6250 - val_loss: 3275708.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1809141.0000 - val_loss: 3275741.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1806685.5000 - val_loss: 3275774.2500\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 21ms/step - loss: 1893361.8750 - val_loss: 3275315.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1850106.7500 - val_loss: 3274611.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1838186.6250 - val_loss: 3274395.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1831964.0000 - val_loss: 3274381.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1827177.6250 - val_loss: 3274421.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 17ms/step - loss: 1823129.8750 - val_loss: 3274475.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1819558.1250 - val_loss: 3274535.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1816321.8750 - val_loss: 3274594.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1813343.7500 - val_loss: 3274648.2500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 21ms/step - loss: 1887859.6250 - val_loss: 3277580.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1849783.2500 - val_loss: 3276376.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1839563.5000 - val_loss: 3275879.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1833623.8750 - val_loss: 3275746.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1828972.8750 - val_loss: 3275733.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1825011.7500 - val_loss: 3275765.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1821499.0000 - val_loss: 3275815.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1818307.6250 - val_loss: 3275873.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1815364.7500 - val_loss: 3275934.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1812620.0000 - val_loss: 3275995.2500\n",
            "7/7 [==============================] - 0s 11ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 17ms/step - loss: 1886409.5000 - val_loss: 3277989.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1845962.2500 - val_loss: 3276712.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1835807.3750 - val_loss: 3276250.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1829834.6250 - val_loss: 3276126.2500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1825174.2500 - val_loss: 3276109.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1821207.2500 - val_loss: 3276135.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 15ms/step - loss: 1817690.5000 - val_loss: 3276177.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 16ms/step - loss: 1814497.1250 - val_loss: 3276225.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1811552.8750 - val_loss: 3276276.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1808807.6250 - val_loss: 3276327.0000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 27ms/step - loss: 1902294.0000 - val_loss: 3275435.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1868494.7500 - val_loss: 3276439.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1849274.6250 - val_loss: 3275792.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1842221.7500 - val_loss: 3275273.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1837850.1250 - val_loss: 3275009.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1834466.7500 - val_loss: 3274887.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1831603.2500 - val_loss: 3274830.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1829074.1250 - val_loss: 3274806.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1826782.0000 - val_loss: 3274806.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1824669.2500 - val_loss: 3274817.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1822699.7500 - val_loss: 3274833.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1820848.8750 - val_loss: 3274853.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1819095.6250 - val_loss: 3274874.0000\n",
            "7/7 [==============================] - 5s 14ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 27ms/step - loss: 1903337.0000 - val_loss: 3275024.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1873388.2500 - val_loss: 3276300.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1852683.7500 - val_loss: 3275619.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1845103.0000 - val_loss: 3275177.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1840613.3750 - val_loss: 3274990.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1837175.0000 - val_loss: 3274915.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1834278.7500 - val_loss: 3274894.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1831729.7500 - val_loss: 3274900.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1829425.7500 - val_loss: 3274921.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1827303.7500 - val_loss: 3274949.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1825329.5000 - val_loss: 3274981.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1823473.8750 - val_loss: 3275015.2500\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 32ms/step - loss: 1900160.6250 - val_loss: 3277772.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1864254.1250 - val_loss: 3277973.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1847280.7500 - val_loss: 3277225.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1840812.3750 - val_loss: 3276620.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1836654.1250 - val_loss: 3276247.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1833393.0000 - val_loss: 3276045.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1830626.0000 - val_loss: 3275936.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1828174.2500 - val_loss: 3275881.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1825951.3750 - val_loss: 3275859.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1823901.2500 - val_loss: 3275862.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1821977.8750 - val_loss: 3275889.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1820127.8750 - val_loss: 3275930.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1818352.1250 - val_loss: 3275963.0000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1816678.2500 - val_loss: 3275994.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 25ms/step - loss: 1899462.8750 - val_loss: 3277402.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1863450.6250 - val_loss: 3277280.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1848657.1250 - val_loss: 3276602.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1842808.6250 - val_loss: 3276199.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1838828.2500 - val_loss: 3275977.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1835624.3750 - val_loss: 3275884.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1832868.6250 - val_loss: 3275855.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1830406.0000 - val_loss: 3275853.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1828162.0000 - val_loss: 3275869.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1826089.3750 - val_loss: 3275895.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1824153.7500 - val_loss: 3275925.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1822329.7500 - val_loss: 3275959.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1820601.7500 - val_loss: 3275996.2500\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 31ms/step - loss: 1901234.3750 - val_loss: 3278228.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1864934.2500 - val_loss: 3278606.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1845981.1250 - val_loss: 3277833.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1839060.2500 - val_loss: 3277107.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1834730.3750 - val_loss: 3276689.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1831382.5000 - val_loss: 3276402.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1828545.2500 - val_loss: 3276269.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1826051.0000 - val_loss: 3276191.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1823794.2500 - val_loss: 3276144.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1821715.8750 - val_loss: 3276119.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1819780.1250 - val_loss: 3276108.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1817960.0000 - val_loss: 3276106.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1816236.7500 - val_loss: 3276111.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1814598.0000 - val_loss: 3276120.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1813031.0000 - val_loss: 3276132.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1811529.3750 - val_loss: 3276147.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1810082.8750 - val_loss: 3276162.7500\n",
            "7/7 [==============================] - 1s 12ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 29ms/step - loss: 1900820.5000 - val_loss: 3276677.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1865587.6250 - val_loss: 3277288.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1848614.0000 - val_loss: 3276616.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1842252.5000 - val_loss: 3276046.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1838124.1250 - val_loss: 3275713.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1834791.7500 - val_loss: 3275537.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1831960.7500 - val_loss: 3275463.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1829471.7500 - val_loss: 3275433.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1827208.3750 - val_loss: 3275430.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1825121.2500 - val_loss: 3275440.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1823178.6250 - val_loss: 3275457.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1821352.1250 - val_loss: 3275480.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1819625.0000 - val_loss: 3275507.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1817980.6250 - val_loss: 3275535.2500\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 29ms/step - loss: 1899871.7500 - val_loss: 3277695.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1862561.1250 - val_loss: 3277639.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1846205.3750 - val_loss: 3276873.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1839939.8750 - val_loss: 3276414.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1835802.7500 - val_loss: 3276197.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1832522.8750 - val_loss: 3276108.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1829721.6250 - val_loss: 3276080.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1827232.5000 - val_loss: 3276085.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1824971.6250 - val_loss: 3276108.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1822883.3750 - val_loss: 3276140.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1820934.0000 - val_loss: 3276178.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1819099.8750 - val_loss: 3276219.0000\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 25ms/step - loss: 1901835.6250 - val_loss: 3276785.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1864763.2500 - val_loss: 3277525.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1846437.6250 - val_loss: 3276981.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1840133.6250 - val_loss: 3276632.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1835997.0000 - val_loss: 3276452.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1832715.1250 - val_loss: 3276365.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1829912.6250 - val_loss: 3276327.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1827424.5000 - val_loss: 3276318.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1825164.8750 - val_loss: 3276327.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1823078.8750 - val_loss: 3276342.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1821132.0000 - val_loss: 3276370.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1819299.2500 - val_loss: 3276401.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1817564.0000 - val_loss: 3276437.2500\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 24ms/step - loss: 1901773.8750 - val_loss: 3275874.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1867395.3750 - val_loss: 3276847.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1849660.6250 - val_loss: 3276273.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1843084.3750 - val_loss: 3275734.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1838846.7500 - val_loss: 3275411.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1835519.8750 - val_loss: 3275234.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1832704.0000 - val_loss: 3275145.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1830218.8750 - val_loss: 3275100.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1827964.5000 - val_loss: 3275085.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1825876.6250 - val_loss: 3275088.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1823921.7500 - val_loss: 3275097.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1822086.8750 - val_loss: 3275114.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1820351.7500 - val_loss: 3275134.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1818699.5000 - val_loss: 3275157.5000\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 28ms/step - loss: 1900278.5000 - val_loss: 3276732.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1866452.5000 - val_loss: 3277438.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1849901.7500 - val_loss: 3276926.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1843375.8750 - val_loss: 3276312.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1839141.3750 - val_loss: 3275948.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1835819.1250 - val_loss: 3275751.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1832994.5000 - val_loss: 3275667.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1830495.3750 - val_loss: 3275631.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1828227.5000 - val_loss: 3275625.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1826134.6250 - val_loss: 3275634.7500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1824183.0000 - val_loss: 3275655.2500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1822346.6250 - val_loss: 3275683.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1820608.2500 - val_loss: 3275714.2500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1818952.3750 - val_loss: 3275747.7500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1905595.3750 - val_loss: 3275231.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1889190.7500 - val_loss: 3277054.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1866901.8750 - val_loss: 3277423.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1854457.1250 - val_loss: 3277200.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1847968.5000 - val_loss: 3276826.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1843991.6250 - val_loss: 3276459.5000\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 30ms/step - loss: 1905360.2500 - val_loss: 3275630.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1887742.5000 - val_loss: 3277169.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1864123.2500 - val_loss: 3277110.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1852630.2500 - val_loss: 3276720.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1847273.6250 - val_loss: 3276373.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1843894.6250 - val_loss: 3276139.7500\n",
            "7/7 [==============================] - 1s 13ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 37ms/step - loss: 1905228.7500 - val_loss: 3276470.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1887650.1250 - val_loss: 3278254.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1862824.6250 - val_loss: 3277924.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1851373.7500 - val_loss: 3277440.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1845944.6250 - val_loss: 3277011.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1842466.2500 - val_loss: 3276699.0000\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 38ms/step - loss: 1905026.5000 - val_loss: 3276012.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1885492.0000 - val_loss: 3278114.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1863365.2500 - val_loss: 3278446.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1852592.2500 - val_loss: 3278333.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1847032.7500 - val_loss: 3277950.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1843482.5000 - val_loss: 3277443.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1906064.2500 - val_loss: 3274080.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1891639.0000 - val_loss: 3276834.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1867662.3750 - val_loss: 3277537.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1853620.8750 - val_loss: 3277336.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1847093.3750 - val_loss: 3276997.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1843237.2500 - val_loss: 3276632.5000\n",
            "7/7 [==============================] - 1s 13ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 30ms/step - loss: 1905713.6250 - val_loss: 3275300.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1890048.7500 - val_loss: 3277222.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1866007.1250 - val_loss: 3277406.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1853534.8750 - val_loss: 3276928.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1847698.2500 - val_loss: 3276600.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1844082.6250 - val_loss: 3276349.5000\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 43ms/step - loss: 1905065.0000 - val_loss: 3276751.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1885148.1250 - val_loss: 3278311.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1863080.3750 - val_loss: 3278394.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1853806.8750 - val_loss: 3278177.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1849117.0000 - val_loss: 3277804.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1845924.6250 - val_loss: 3277417.7500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 3s 30ms/step - loss: 1905404.1250 - val_loss: 3275080.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1887488.8750 - val_loss: 3277160.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1863700.5000 - val_loss: 3277542.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1851297.3750 - val_loss: 3277270.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1845058.0000 - val_loss: 3276876.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1841254.8750 - val_loss: 3276525.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1905674.0000 - val_loss: 3275407.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1888805.3750 - val_loss: 3277612.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1866778.1250 - val_loss: 3278057.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1854164.3750 - val_loss: 3277778.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1847480.0000 - val_loss: 3277275.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1843514.7500 - val_loss: 3276770.5000\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Adagrad optimizer 0.001 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 38ms/step - loss: 1905472.0000 - val_loss: 3276603.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1888280.2500 - val_loss: 3278621.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 1863518.5000 - val_loss: 3278685.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1850924.3750 - val_loss: 3278279.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1844910.5000 - val_loss: 3277755.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1841192.0000 - val_loss: 3277291.5000\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 23ms/step - loss: 385703.8438 - val_loss: 862589.6875\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 21332.1953 - val_loss: 1572691.1250\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 4959.8784 - val_loss: 1526330.1250\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 3070.4585 - val_loss: 1950367.3750\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 2042.3571 - val_loss: 1315601.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1417.5261 - val_loss: 1216924.0000\n",
            "7/7 [==============================] - 0s 11ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 19ms/step - loss: 401406.6562 - val_loss: 458648.1562\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 13303.7725 - val_loss: 377599.5312\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 3920.0093 - val_loss: 320010.0938\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 2208.6628 - val_loss: 334858.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1708.1105 - val_loss: 286686.3438\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1296.0692 - val_loss: 296074.6250\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1312.4291 - val_loss: 331123.1250\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1396.7489 - val_loss: 328081.0625\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1410.8828 - val_loss: 327206.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1839.9316 - val_loss: 339345.2188\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 24ms/step - loss: 400669.9375 - val_loss: 821579.6875\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 16187.5605 - val_loss: 1074037.3750\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 3615.7434 - val_loss: 950395.6875\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 2414.1428 - val_loss: 953576.8125\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1930.4003 - val_loss: 973539.3125\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 2055.6433 - val_loss: 1095983.3750\n",
            "7/7 [==============================] - 1s 12ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 18ms/step - loss: 439181.2812 - val_loss: 377817.5625\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 22579.9961 - val_loss: 1273335.3750\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 3256.0347 - val_loss: 919269.8750\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1911.8693 - val_loss: 1143785.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 1579.7605 - val_loss: 1426383.8750\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1776.3243 - val_loss: 1468816.2500\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 22ms/step - loss: 475106.4375 - val_loss: 886867.8125\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 16563.3828 - val_loss: 303621.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 3565.7930 - val_loss: 242326.3906\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1843.1886 - val_loss: 373359.8438\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1605.0352 - val_loss: 345575.2812\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1433.4221 - val_loss: 307383.9688\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1208.4508 - val_loss: 318679.2188\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1021.1235 - val_loss: 300433.5312\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 8s 24ms/step - loss: 410976.3750 - val_loss: 460039.8750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 21124.4395 - val_loss: 2045101.6250\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 3074.7578 - val_loss: 2091639.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 17ms/step - loss: 1897.0519 - val_loss: 2181902.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1569.0670 - val_loss: 2171194.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1486.7402 - val_loss: 2429513.2500\n",
            "7/7 [==============================] - 5s 13ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 8s 25ms/step - loss: 420454.8438 - val_loss: 466318.0938\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 5s 25ms/step - loss: 24460.7988 - val_loss: 375363.0312\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 4184.8013 - val_loss: 313348.3750\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 2457.7090 - val_loss: 289773.4688\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 2027.8557 - val_loss: 287631.2812\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 1601.5172 - val_loss: 254540.1094\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1345.1039 - val_loss: 263638.4375\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1177.1708 - val_loss: 357934.1875\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1141.7556 - val_loss: 391413.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 998.5878 - val_loss: 321732.0625\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 955.7556 - val_loss: 386153.1250\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 25ms/step - loss: 407609.5938 - val_loss: 513878.9688\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 17321.7891 - val_loss: 421994.8438\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 5005.9312 - val_loss: 475586.4375\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 2586.7092 - val_loss: 533320.4375\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1711.7941 - val_loss: 524160.0312\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 1423.2241 - val_loss: 659065.9375\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 1453.4363 - val_loss: 814846.6875\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 22ms/step - loss: 392933.8438 - val_loss: 664699.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 10163.3926 - val_loss: 1870575.1250\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 2705.9500 - val_loss: 2036815.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 2936.4934 - val_loss: 914415.0625\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1687.6045 - val_loss: 627224.5625\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1400.5164 - val_loss: 598668.8750\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 1506.6155 - val_loss: 689628.5625\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 1925.6295 - val_loss: 653736.6250\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1670.5358 - val_loss: 604063.0625\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 2668.3645 - val_loss: 635597.1875\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 3481.1001 - val_loss: 627287.5625\n",
            "7/7 [==============================] - 0s 11ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 22ms/step - loss: 422351.2500 - val_loss: 385724.5938\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 16746.7031 - val_loss: 307452.1875\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 4381.0967 - val_loss: 234085.6250\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 2326.7749 - val_loss: 310201.1562\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1700.4193 - val_loss: 268454.5938\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 2763.6646 - val_loss: 542846.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 3137.8640 - val_loss: 1202102.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 4558.7227 - val_loss: 1176599.1250\n",
            "7/7 [==============================] - 1s 12ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 27ms/step - loss: 835469.6875 - val_loss: 773265.8125\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 77054.4766 - val_loss: 365449.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 36249.7617 - val_loss: 341549.3125\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 14538.0869 - val_loss: 277425.9375\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 5364.3530 - val_loss: 357135.3125\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 10733.2373 - val_loss: 169471.1406\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 3796.4458 - val_loss: 167278.8750\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 3403.1506 - val_loss: 176400.7656\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 2812.1914 - val_loss: 178128.3281\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 2382.3135 - val_loss: 166125.0781\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1512.1770 - val_loss: 151681.1250\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 1446.2806 - val_loss: 146710.5156\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 3s 28ms/step - loss: 1240.8049 - val_loss: 151265.7812\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1103.6899 - val_loss: 145627.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1020.6033 - val_loss: 138838.4062\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1153.3785 - val_loss: 145375.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1219.5100 - val_loss: 149386.5781\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1353.2983 - val_loss: 145373.1406\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1201.0636 - val_loss: 143811.5156\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 978.0339 - val_loss: 143269.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 26ms/step - loss: 733481.0625 - val_loss: 630268.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 54115.9766 - val_loss: 369813.7188\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 33355.6797 - val_loss: 1857807.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 5444.0195 - val_loss: 1246436.6250\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 2352.6057 - val_loss: 1030964.1875\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 28ms/step - loss: 1432.5438 - val_loss: 774445.9375\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1651.9749 - val_loss: 793345.3125\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 27ms/step - loss: 739942.6875 - val_loss: 728202.5625\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 55546.9961 - val_loss: 500870.6875\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 28ms/step - loss: 33224.9961 - val_loss: 314349.9062\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 5711.4277 - val_loss: 225865.2812\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 3233.6072 - val_loss: 245419.1719\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 3245.2483 - val_loss: 196983.9219\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 2521.6260 - val_loss: 177407.2344\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 2608.6375 - val_loss: 182510.8125\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 3500.3728 - val_loss: 205328.3281\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 2971.6663 - val_loss: 281509.9062\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 3s 28ms/step - loss: 2469.3755 - val_loss: 325182.5938\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 5206.9253 - val_loss: 354968.9062\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 32ms/step - loss: 761263.5625 - val_loss: 1416440.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 62004.6836 - val_loss: 1116773.3750\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 53879.2500 - val_loss: 936452.6875\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 6769.1519 - val_loss: 930008.1250\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 2964.3691 - val_loss: 716913.3125\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1941.6587 - val_loss: 863528.0625\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1490.5577 - val_loss: 797834.6875\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1204.5052 - val_loss: 969907.0625\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1128.6566 - val_loss: 901014.8125\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1147.2098 - val_loss: 789375.5625\n",
            "7/7 [==============================] - 1s 12ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 27ms/step - loss: 746934.8750 - val_loss: 702325.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 57519.6523 - val_loss: 428476.7188\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 31759.6426 - val_loss: 588128.4375\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 7345.0845 - val_loss: 1196198.3750\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 28ms/step - loss: 3339.3875 - val_loss: 753728.9375\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 2495.5703 - val_loss: 826651.4375\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 2079.9150 - val_loss: 954803.4375\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 26ms/step - loss: 810981.4375 - val_loss: 761624.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 73578.6172 - val_loss: 386166.9375\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 40907.2617 - val_loss: 413747.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 19465.7891 - val_loss: 249792.0625\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 4834.7896 - val_loss: 428801.2188\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 2626.3870 - val_loss: 399536.2812\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1883.0027 - val_loss: 507093.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1624.6384 - val_loss: 708910.9375\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1095.9006 - val_loss: 732655.0625\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 26ms/step - loss: 774337.3750 - val_loss: 1400488.6250\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 61484.8281 - val_loss: 963864.8750\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 28710.7754 - val_loss: 321966.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 4593.4272 - val_loss: 393906.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 2195.8535 - val_loss: 438786.3750\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1508.7035 - val_loss: 387886.4375\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1239.3881 - val_loss: 475935.8125\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1150.3356 - val_loss: 467042.0625\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 26ms/step - loss: 778192.9375 - val_loss: 1075723.1250\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 56464.2188 - val_loss: 439193.8750\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 23875.0195 - val_loss: 2146777.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 4599.4780 - val_loss: 2168501.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 3202.0627 - val_loss: 1476642.6250\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 2705.4207 - val_loss: 2019280.8750\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1945.4122 - val_loss: 1800122.5000\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 26ms/step - loss: 857564.1250 - val_loss: 2415235.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 87785.6172 - val_loss: 2330758.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 75504.0312 - val_loss: 793411.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 7061.8882 - val_loss: 824932.8125\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 6790.8823 - val_loss: 1017437.3125\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 3558.3054 - val_loss: 885483.6250\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 2725.7322 - val_loss: 1182766.8750\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 2254.8755 - val_loss: 1123021.1250\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 25ms/step - loss: 818810.4375 - val_loss: 1687724.1250\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 72107.1562 - val_loss: 1267489.6250\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 37814.6992 - val_loss: 2755524.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 11105.1816 - val_loss: 2805111.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 5165.6377 - val_loss: 2782802.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 3078.0974 - val_loss: 2735062.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 2484.1631 - val_loss: 2527976.7500\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 47ms/step - loss: 1197018.6250 - val_loss: 2459070.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 299316.9688 - val_loss: 2228240.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 74061.7109 - val_loss: 2142811.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 2s 30ms/step - loss: 42923.8984 - val_loss: 1984240.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 38177.5820 - val_loss: 1992803.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 14348.5908 - val_loss: 1942874.3750\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 6939.1348 - val_loss: 1727632.7500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 5737.1699 - val_loss: 2120330.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 4898.1616 - val_loss: 2311681.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 3104.7310 - val_loss: 1983770.5000\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 2217.0557 - val_loss: 2175046.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1718.4763 - val_loss: 1896890.0000\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 6s 42ms/step - loss: 1252747.1250 - val_loss: 2431280.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 305594.9375 - val_loss: 2345685.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 54631.5508 - val_loss: 2098709.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 47940.0938 - val_loss: 2266376.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 17944.1680 - val_loss: 2428134.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 5926.7363 - val_loss: 2651558.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 3200.7527 - val_loss: 2686579.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 2466.1931 - val_loss: 3013358.5000\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 33ms/step - loss: 1220317.6250 - val_loss: 1931234.8750\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 330398.5938 - val_loss: 1381322.1250\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 81705.7891 - val_loss: 1237411.1250\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 2s 28ms/step - loss: 43921.5312 - val_loss: 1076965.3750\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 41319.1406 - val_loss: 1011129.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 31858.1504 - val_loss: 1575981.3750\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 7582.8135 - val_loss: 1954916.1250\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 3391.7136 - val_loss: 2622323.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 2186.5291 - val_loss: 1126088.2500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1553.1381 - val_loss: 801404.6250\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1530.7412 - val_loss: 579125.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1243.9868 - val_loss: 672992.1250\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1263.8331 - val_loss: 893575.2500\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1329.8223 - val_loss: 536831.5000\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1312.0026 - val_loss: 891709.0625\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1518.2343 - val_loss: 1822802.2500\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1250.0782 - val_loss: 2565628.7500\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1426.8424 - val_loss: 2618983.5000\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 2s 30ms/step - loss: 1227.1774 - val_loss: 2163824.5000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 32ms/step - loss: 1241577.7500 - val_loss: 1587976.8750\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 353811.2188 - val_loss: 816560.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 91455.8438 - val_loss: 612319.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 45898.8281 - val_loss: 550005.3125\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 41553.7070 - val_loss: 913075.6875\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 15774.5459 - val_loss: 781728.5625\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 6793.2559 - val_loss: 1292061.1250\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 3931.6423 - val_loss: 1396300.7500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 2s 29ms/step - loss: 2253.3596 - val_loss: 1627357.7500\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 31ms/step - loss: 1267252.0000 - val_loss: 2273435.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 396595.7188 - val_loss: 2197335.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 109838.9844 - val_loss: 2089411.6250\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 49240.3789 - val_loss: 1696160.8750\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 36504.8164 - val_loss: 319627.1875\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 10674.7373 - val_loss: 242308.8281\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 4216.4800 - val_loss: 209667.0938\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 3306.3962 - val_loss: 200582.5469\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 2181.1084 - val_loss: 184603.8125\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 2076.3250 - val_loss: 188628.6719\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1671.4469 - val_loss: 188378.3750\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 2s 29ms/step - loss: 1574.5093 - val_loss: 213699.6875\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1335.0782 - val_loss: 203895.0469\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1308.3497 - val_loss: 200506.1562\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1270227.3750 - val_loss: 2191843.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 391154.9375 - val_loss: 1567826.6250\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 102730.9219 - val_loss: 1322608.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 47423.0391 - val_loss: 1627753.3750\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 45074.1016 - val_loss: 2827549.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 21871.0508 - val_loss: 2905571.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 8324.8213 - val_loss: 2978505.2500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 2s 29ms/step - loss: 4679.6396 - val_loss: 3193107.0000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 33ms/step - loss: 1239689.5000 - val_loss: 1749975.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 348055.1875 - val_loss: 1036756.1875\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 89025.6250 - val_loss: 820184.6250\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 44951.1523 - val_loss: 757887.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 39955.3477 - val_loss: 672574.6875\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 14718.2197 - val_loss: 291627.3125\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 5092.0835 - val_loss: 313256.9062\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 2880.5518 - val_loss: 236874.2969\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 2794.3555 - val_loss: 411511.8438\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 2s 29ms/step - loss: 2365.1807 - val_loss: 370190.4688\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1522.5127 - val_loss: 382719.6250\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1263.6757 - val_loss: 334118.1875\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1225.3191 - val_loss: 325718.6875\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1260250.3750 - val_loss: 2547166.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 383436.8750 - val_loss: 2268750.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 103874.5078 - val_loss: 2180114.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 48196.9727 - val_loss: 2103097.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 30806.1406 - val_loss: 520566.9688\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 9066.9541 - val_loss: 589249.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 4030.3354 - val_loss: 269900.4062\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 2374.4346 - val_loss: 236065.5312\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1814.1279 - val_loss: 218113.8594\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1497.0371 - val_loss: 232948.9219\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1201.1747 - val_loss: 271999.4688\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1036.0013 - val_loss: 261026.1562\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1449.4573 - val_loss: 201854.4688\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 923.8643 - val_loss: 183612.7969\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 872.5656 - val_loss: 181257.0000\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 897.8467 - val_loss: 200327.9688\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 787.8773 - val_loss: 192301.8125\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 722.4020 - val_loss: 222119.6562\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 663.1637 - val_loss: 256142.3125\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 889.3021 - val_loss: 326707.0000\n",
            "7/7 [==============================] - 1s 13ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 6s 38ms/step - loss: 1122475.5000 - val_loss: 3018482.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 193012.7344 - val_loss: 3167537.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 47501.0000 - val_loss: 3237947.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 41696.4414 - val_loss: 3529476.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 20079.9219 - val_loss: 3706207.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 6951.4238 - val_loss: 3492950.2500\n",
            "7/7 [==============================] - 0s 11ms/step\n",
            "Running for Nadam optimizer 0.1 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 45ms/step - loss: 1270664.8750 - val_loss: 2020906.6250\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 388565.5000 - val_loss: 1405361.6250\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 2s 30ms/step - loss: 105308.7656 - val_loss: 1225344.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 48656.5312 - val_loss: 1098505.8750\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 43633.2500 - val_loss: 1142557.8750\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 37468.5117 - val_loss: 953754.8750\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 14645.1934 - val_loss: 1282264.6250\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 6669.5762 - val_loss: 1501221.6250\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 4116.4038 - val_loss: 1833717.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 3118.9456 - val_loss: 1708361.1250\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 2036.9653 - val_loss: 1782697.1250\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 12s 22ms/step - loss: 1374065.1250 - val_loss: 3265966.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 667318.6875 - val_loss: 3266155.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 299218.1250 - val_loss: 3280961.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 131377.2500 - val_loss: 3309881.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 66947.7500 - val_loss: 3371395.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 46882.8906 - val_loss: 3476366.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 8s 26ms/step - loss: 1371174.0000 - val_loss: 3232999.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 667485.9375 - val_loss: 3238872.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 300328.9062 - val_loss: 3262131.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 131731.6875 - val_loss: 3317200.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 67111.7266 - val_loss: 3388299.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 69943.3047 - val_loss: 3215941.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 118868.8672 - val_loss: 3216520.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 54706.8164 - val_loss: 3252798.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 42660.5977 - val_loss: 3012246.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 29189.7129 - val_loss: 1054391.8750\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 8878.8203 - val_loss: 794363.6250\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 5926.7129 - val_loss: 799554.6875\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 4655.1167 - val_loss: 886163.3125\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 3524.0703 - val_loss: 910936.8125\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 2503.5964 - val_loss: 880531.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1965.6522 - val_loss: 962203.6875\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 9s 26ms/step - loss: 1374993.6250 - val_loss: 3155891.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 673990.0625 - val_loss: 3075544.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 305334.5312 - val_loss: 3102365.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 134876.7500 - val_loss: 3176951.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 68634.6875 - val_loss: 3291434.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 5s 25ms/step - loss: 47384.7812 - val_loss: 3405832.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 45095.8320 - val_loss: 581958.1250\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 27775.8125 - val_loss: 679210.6875\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 19063.5977 - val_loss: 543757.3750\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 12234.6377 - val_loss: 562653.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 8819.0420 - val_loss: 922227.6875\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 6018.5342 - val_loss: 1263604.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 4111.0142 - val_loss: 1179803.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 3346.0776 - val_loss: 1405915.5000\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 9s 25ms/step - loss: 1379470.2500 - val_loss: 3220739.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 672766.5625 - val_loss: 3205501.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 303012.9688 - val_loss: 3248166.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 133075.6719 - val_loss: 3296993.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 67419.8438 - val_loss: 3377481.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 46968.9922 - val_loss: 3421007.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 50609.0195 - val_loss: 2195419.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 28954.8496 - val_loss: 2274892.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 18547.5781 - val_loss: 2184994.5000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 13056.2080 - val_loss: 2154950.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 9508.4619 - val_loss: 1916228.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 6554.6646 - val_loss: 1712305.8750\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 5047.8379 - val_loss: 1798466.6250\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 3661.9731 - val_loss: 1683165.8750\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 2946.9031 - val_loss: 1670608.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 2428.5859 - val_loss: 1516272.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 2116.9463 - val_loss: 1502301.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 1752.7709 - val_loss: 1469072.8750\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 1477.6283 - val_loss: 1480243.6250\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1183.4679 - val_loss: 1454595.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1123.8788 - val_loss: 1460582.3750\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 1134.7347 - val_loss: 1294596.1250\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 1024.4294 - val_loss: 1382512.1250\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 844.4180 - val_loss: 1322381.3750\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 779.9045 - val_loss: 1467198.7500\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 654.2414 - val_loss: 1378210.7500\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 732.5714 - val_loss: 1242583.2500\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 706.3560 - val_loss: 1129093.2500\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 598.2842 - val_loss: 1186078.7500\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 525.8927 - val_loss: 1360819.7500\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 542.9943 - val_loss: 1171979.3750\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 510.5426 - val_loss: 1236409.3750\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 510.0882 - val_loss: 1184322.5000\n",
            "7/7 [==============================] - 0s 11ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 21ms/step - loss: 1372296.8750 - val_loss: 3160993.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 668306.9375 - val_loss: 3078304.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 300950.1562 - val_loss: 3075188.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 132288.1094 - val_loss: 3193626.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 67182.7656 - val_loss: 3289436.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 22ms/step - loss: 46943.7891 - val_loss: 3404101.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 113804.0547 - val_loss: 1333878.8750\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 26321.8105 - val_loss: 949748.8750\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 16186.3135 - val_loss: 860784.8125\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 10715.3047 - val_loss: 996698.8125\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 7180.0566 - val_loss: 884857.3125\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 5434.7427 - val_loss: 961318.1875\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 3826.3901 - val_loss: 1055033.6250\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 2973.9832 - val_loss: 1195359.5000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 8s 25ms/step - loss: 1377670.2500 - val_loss: 3264025.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 678725.1250 - val_loss: 3239453.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 309141.7812 - val_loss: 3228754.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 137478.5000 - val_loss: 3247276.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 69945.8672 - val_loss: 3290386.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 47865.4023 - val_loss: 3340238.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 40570.2500 - val_loss: 2831035.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 22837.6270 - val_loss: 2051488.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 14023.6006 - val_loss: 1689716.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 8515.9580 - val_loss: 1682623.8750\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 5820.1753 - val_loss: 1554830.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 4131.8008 - val_loss: 1658772.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 3086.9944 - val_loss: 1594486.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 2408.4971 - val_loss: 1656864.8750\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 1896.8744 - val_loss: 1586191.2500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 1529.1449 - val_loss: 1555570.2500\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 21ms/step - loss: 1372854.5000 - val_loss: 3237077.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 666043.8125 - val_loss: 3290570.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 298084.2188 - val_loss: 3350342.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 130382.3047 - val_loss: 3443306.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 66310.0312 - val_loss: 3500131.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 65631.2891 - val_loss: 1346840.2500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 77793.7266 - val_loss: 450467.7812\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 27906.6562 - val_loss: 373894.6250\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 18410.1855 - val_loss: 320309.1562\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 13638.8174 - val_loss: 303885.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 10266.0312 - val_loss: 275151.5312\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 8319.3848 - val_loss: 261777.6094\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 6550.9463 - val_loss: 243148.7344\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 4602.1826 - val_loss: 222793.9375\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 3552.6958 - val_loss: 206971.3438\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 2592.6558 - val_loss: 218828.3125\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 1986.0769 - val_loss: 190641.9688\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 1655.3071 - val_loss: 185634.9844\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1560.4998 - val_loss: 185067.2500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1355.5016 - val_loss: 175511.5000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1125.8639 - val_loss: 163239.5156\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 912.8535 - val_loss: 155761.5938\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 838.7998 - val_loss: 152200.7031\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 722.0861 - val_loss: 150279.8438\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 651.1507 - val_loss: 142931.5469\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 578.7953 - val_loss: 152698.4375\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 558.0196 - val_loss: 137546.7188\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 592.2556 - val_loss: 140972.6719\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 603.6073 - val_loss: 142019.6406\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 559.1611 - val_loss: 144121.8125\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 739.2435 - val_loss: 139360.9062\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 607.7006 - val_loss: 137399.4375\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 549.4248 - val_loss: 133872.5312\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 534.6608 - val_loss: 154266.9531\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 504.7429 - val_loss: 136751.3906\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 446.4966 - val_loss: 138510.1250\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 445.1286 - val_loss: 142772.0938\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 436.7886 - val_loss: 140496.2031\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 8s 24ms/step - loss: 1379357.2500 - val_loss: 3249234.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 676068.0625 - val_loss: 3266953.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 305337.5312 - val_loss: 3289369.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 134644.3125 - val_loss: 3332732.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 68532.3984 - val_loss: 3384041.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 56306.2344 - val_loss: 3694258.2500\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 20ms/step - loss: 1383341.3750 - val_loss: 3261563.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 678413.6250 - val_loss: 3279317.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 307290.5938 - val_loss: 3325272.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 135429.6406 - val_loss: 3388732.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 68544.2500 - val_loss: 3435267.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 88187.4609 - val_loss: 2168368.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 36408.7852 - val_loss: 2161031.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 23335.5820 - val_loss: 2193739.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 17621.8379 - val_loss: 2212380.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 14268.7695 - val_loss: 2170167.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 10658.5830 - val_loss: 2197874.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 7962.0605 - val_loss: 2197051.5000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 9s 26ms/step - loss: 1371533.3750 - val_loss: 3015418.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 668041.4375 - val_loss: 2846506.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 300663.3438 - val_loss: 2752376.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 132097.4219 - val_loss: 2707205.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 67242.4141 - val_loss: 2698587.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 47008.1250 - val_loss: 2671663.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 41864.8281 - val_loss: 2614868.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 36454.3711 - val_loss: 2698467.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 21089.1270 - val_loss: 2701436.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 13279.3564 - val_loss: 2708726.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 7958.9883 - val_loss: 2714249.5000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 5842.6616 - val_loss: 2720259.0000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 7s 30ms/step - loss: 1615098.5000 - val_loss: 3271756.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1154134.6250 - val_loss: 3258417.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 808577.7500 - val_loss: 3254416.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 554244.5625 - val_loss: 3256476.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 371922.0000 - val_loss: 3253438.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 245993.8438 - val_loss: 3280809.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 162672.5312 - val_loss: 3288999.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 109912.2188 - val_loss: 3314914.2500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 78055.3359 - val_loss: 3326302.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 59872.3828 - val_loss: 3339969.5000\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 29ms/step - loss: 1607200.2500 - val_loss: 3243559.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 3s 28ms/step - loss: 1139692.3750 - val_loss: 3220963.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 28ms/step - loss: 793189.7500 - val_loss: 3213081.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 539871.6250 - val_loss: 3215947.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 360193.6562 - val_loss: 3232640.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 236831.3125 - val_loss: 3261278.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 155872.7031 - val_loss: 3306373.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 105171.9844 - val_loss: 3321205.0000\n",
            "7/7 [==============================] - 1s 15ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 26ms/step - loss: 1610537.0000 - val_loss: 3212180.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1144970.0000 - val_loss: 3160895.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 798667.6250 - val_loss: 3134832.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 544567.2500 - val_loss: 3114325.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 363701.0000 - val_loss: 3120922.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 239293.6875 - val_loss: 3148199.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 157665.1875 - val_loss: 3187982.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 106453.8359 - val_loss: 3212276.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 75711.0078 - val_loss: 3233610.7500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 26ms/step - loss: 1604193.8750 - val_loss: 3287621.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1135910.1250 - val_loss: 3302438.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 789088.0000 - val_loss: 3308546.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 535917.0625 - val_loss: 3342361.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 356759.2500 - val_loss: 3369823.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 234343.0312 - val_loss: 3397218.2500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 27ms/step - loss: 1608720.8750 - val_loss: 3259382.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1138055.7500 - val_loss: 3238206.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 790822.5625 - val_loss: 3231052.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 537438.6250 - val_loss: 3229610.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 357638.6562 - val_loss: 3247025.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 234781.1719 - val_loss: 3266347.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 154345.8281 - val_loss: 3311502.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 104204.5391 - val_loss: 3350481.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 74424.8672 - val_loss: 3362992.5000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 7s 32ms/step - loss: 1611837.8750 - val_loss: 3267080.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1144869.5000 - val_loss: 3264507.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 798807.1875 - val_loss: 3266195.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 545705.0000 - val_loss: 3270441.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 365060.1250 - val_loss: 3273708.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 240527.5938 - val_loss: 3297976.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 158618.9219 - val_loss: 3312887.7500\n",
            "7/7 [==============================] - 1s 13ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 25ms/step - loss: 1608185.2500 - val_loss: 3149504.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1141759.7500 - val_loss: 3098817.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 796555.2500 - val_loss: 3061975.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 542688.3750 - val_loss: 3064492.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 362133.4375 - val_loss: 3098887.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 238485.3594 - val_loss: 3160546.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 157124.0781 - val_loss: 3208849.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 106087.6484 - val_loss: 3259632.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 26ms/step - loss: 1609878.3750 - val_loss: 3237012.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1143696.7500 - val_loss: 3201356.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 797762.9375 - val_loss: 3193897.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 543429.1875 - val_loss: 3224952.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 362584.5312 - val_loss: 3252052.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 238613.9062 - val_loss: 3272386.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 157148.4062 - val_loss: 3332862.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 106027.4297 - val_loss: 3387840.5000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 28ms/step - loss: 1606607.2500 - val_loss: 3175191.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1140638.3750 - val_loss: 3078454.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 795501.9375 - val_loss: 3032959.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 541024.6250 - val_loss: 3028502.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 359644.6250 - val_loss: 3056197.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 236190.7812 - val_loss: 3055733.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 155267.3281 - val_loss: 3059507.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 104714.5547 - val_loss: 3065002.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 74670.1172 - val_loss: 3075487.0000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 7s 28ms/step - loss: 1605171.7500 - val_loss: 3205024.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1135538.1250 - val_loss: 3165691.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 789092.3125 - val_loss: 3148926.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 536069.5000 - val_loss: 3157802.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 356482.1562 - val_loss: 3194472.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 233756.6250 - val_loss: 3209213.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 153787.9844 - val_loss: 3239731.2500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 103791.3906 - val_loss: 3283717.0000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 33ms/step - loss: 1742852.0000 - val_loss: 3246322.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1471301.0000 - val_loss: 3233996.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1237402.1250 - val_loss: 3239842.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1036315.0000 - val_loss: 3239908.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 862751.3125 - val_loss: 3229718.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 713822.2500 - val_loss: 3230103.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 587043.8125 - val_loss: 3245031.5000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 479872.2812 - val_loss: 3253965.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 390499.0312 - val_loss: 3261189.7500\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 2s 32ms/step - loss: 316571.5625 - val_loss: 3282948.5000\n",
            "7/7 [==============================] - 0s 11ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 29ms/step - loss: 1741792.5000 - val_loss: 3280242.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1471478.2500 - val_loss: 3291435.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 2s 29ms/step - loss: 1239685.8750 - val_loss: 3301990.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1039186.2500 - val_loss: 3315985.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 865780.5625 - val_loss: 3328761.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 717510.6875 - val_loss: 3338355.7500\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1739450.7500 - val_loss: 3267912.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1468153.0000 - val_loss: 3281716.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1234717.6250 - val_loss: 3281879.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1033145.4375 - val_loss: 3282974.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 859549.2500 - val_loss: 3288153.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 711094.4375 - val_loss: 3291185.2500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 32ms/step - loss: 1739740.1250 - val_loss: 3272982.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1469151.2500 - val_loss: 3279403.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1236168.3750 - val_loss: 3282517.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1035307.1250 - val_loss: 3284747.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 862282.2500 - val_loss: 3288135.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 713938.2500 - val_loss: 3301039.5000\n",
            "7/7 [==============================] - 1s 14ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 33ms/step - loss: 1742503.7500 - val_loss: 3266300.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1472509.1250 - val_loss: 3266439.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1241095.3750 - val_loss: 3268991.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1041033.8125 - val_loss: 3267892.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 868109.3125 - val_loss: 3269126.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 719938.2500 - val_loss: 3276862.5000\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 41ms/step - loss: 1747656.3750 - val_loss: 3228872.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1476900.6250 - val_loss: 3201444.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 2s 28ms/step - loss: 1243885.2500 - val_loss: 3176231.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1042747.6250 - val_loss: 3159679.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 869244.0000 - val_loss: 3146756.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 720219.9375 - val_loss: 3138931.5000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 593250.0000 - val_loss: 3134442.7500\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 485967.9375 - val_loss: 3141216.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 396197.7812 - val_loss: 3153049.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 321644.0312 - val_loss: 3159599.2500\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 260203.2656 - val_loss: 3173219.7500\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 210368.6719 - val_loss: 3181294.5000\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 6s 41ms/step - loss: 1742814.7500 - val_loss: 3258901.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1471293.5000 - val_loss: 3257397.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1238205.8750 - val_loss: 3249378.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1036396.1875 - val_loss: 3245967.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 862994.2500 - val_loss: 3249532.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 714771.5000 - val_loss: 3250348.0000\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 588012.0625 - val_loss: 3255126.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 481410.6562 - val_loss: 3273458.2500\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 391854.2500 - val_loss: 3283919.5000\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1744512.7500 - val_loss: 3277598.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1476235.0000 - val_loss: 3279628.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1245669.6250 - val_loss: 3281658.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1046496.4375 - val_loss: 3273517.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 874140.6250 - val_loss: 3272720.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 725463.1250 - val_loss: 3283966.7500\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 598865.8125 - val_loss: 3285147.0000\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 491451.4062 - val_loss: 3285781.5000\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 401076.7812 - val_loss: 3292535.0000\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 325886.0625 - val_loss: 3304198.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1742430.6250 - val_loss: 3276956.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1473384.1250 - val_loss: 3285664.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1241532.6250 - val_loss: 3289413.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1040844.8750 - val_loss: 3296246.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 867761.1250 - val_loss: 3305173.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 719281.0000 - val_loss: 3314858.0000\n",
            "7/7 [==============================] - 1s 14ms/step\n",
            "Running for Nadam optimizer 0.01 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 10s 37ms/step - loss: 1741528.3750 - val_loss: 3273716.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 2s 34ms/step - loss: 1469833.3750 - val_loss: 3282837.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 2s 33ms/step - loss: 1236792.1250 - val_loss: 3290719.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1035384.8750 - val_loss: 3300889.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 862000.0000 - val_loss: 3314168.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 2s 34ms/step - loss: 713171.8125 - val_loss: 3328122.0000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 22ms/step - loss: 1812780.5000 - val_loss: 3267179.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 1683309.5000 - val_loss: 3258122.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 1575994.6250 - val_loss: 3248227.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1475612.5000 - val_loss: 3238656.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1380733.1250 - val_loss: 3226564.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 1290745.2500 - val_loss: 3211311.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 1205215.2500 - val_loss: 3200747.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 1123916.0000 - val_loss: 3190857.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1046630.7500 - val_loss: 3181508.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 973113.0625 - val_loss: 3174463.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 903268.3125 - val_loss: 3168557.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 5s 26ms/step - loss: 836921.3125 - val_loss: 3163552.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 773965.6875 - val_loss: 3161217.5000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 714316.5625 - val_loss: 3161485.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 657852.8750 - val_loss: 3159190.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 604472.8750 - val_loss: 3158056.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 554069.1875 - val_loss: 3158640.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 506602.5000 - val_loss: 3171770.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 462030.5312 - val_loss: 3184702.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 420177.3750 - val_loss: 3196515.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 380998.4375 - val_loss: 3199157.2500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 8s 27ms/step - loss: 1808746.7500 - val_loss: 3277769.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 1679110.8750 - val_loss: 3274660.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 1572824.2500 - val_loss: 3268897.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1473410.1250 - val_loss: 3263132.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1379417.8750 - val_loss: 3255565.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 1290245.8750 - val_loss: 3249874.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1205470.3750 - val_loss: 3240087.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1124874.5000 - val_loss: 3235266.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1048252.2500 - val_loss: 3226527.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 975384.9375 - val_loss: 3220693.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 906081.6875 - val_loss: 3217130.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 840177.6250 - val_loss: 3214441.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 777602.4375 - val_loss: 3214874.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 718242.2500 - val_loss: 3215529.2500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 662006.0625 - val_loss: 3214176.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 608822.4375 - val_loss: 3218751.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 558614.5625 - val_loss: 3218255.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 511260.2500 - val_loss: 3216650.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 466701.3438 - val_loss: 3217390.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 424883.2812 - val_loss: 3221822.5000\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 8s 24ms/step - loss: 1805961.6250 - val_loss: 3278165.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 1677244.3750 - val_loss: 3272857.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 1570569.0000 - val_loss: 3263828.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1470627.2500 - val_loss: 3254355.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1376077.1250 - val_loss: 3243514.2500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 1286315.7500 - val_loss: 3224373.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1200990.8750 - val_loss: 3207996.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1119859.8750 - val_loss: 3188507.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1042722.0625 - val_loss: 3173267.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 969380.4375 - val_loss: 3144890.7500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 899697.6250 - val_loss: 3131958.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 833541.5000 - val_loss: 3122818.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 770784.6875 - val_loss: 3114980.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 711293.6250 - val_loss: 3107939.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 654955.0000 - val_loss: 3101665.5000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 601715.1250 - val_loss: 3095951.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 551459.5000 - val_loss: 3090896.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 504122.8750 - val_loss: 3086163.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 459640.1250 - val_loss: 3084060.5000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 417933.7812 - val_loss: 3094422.7500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 378958.5000 - val_loss: 3097466.0000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 342621.2812 - val_loss: 3107246.0000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 308804.0312 - val_loss: 3111751.0000\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 277477.3125 - val_loss: 3116536.2500\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 22ms/step - loss: 1808671.1250 - val_loss: 3277786.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 1679756.0000 - val_loss: 3275521.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 1572909.1250 - val_loss: 3271062.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1472837.8750 - val_loss: 3265994.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1378155.3750 - val_loss: 3256878.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1288304.8750 - val_loss: 3248155.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1202889.1250 - val_loss: 3241139.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 1121649.5000 - val_loss: 3237066.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1044457.2500 - val_loss: 3233920.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 971068.6875 - val_loss: 3231460.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 901316.3125 - val_loss: 3229503.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 835072.3125 - val_loss: 3227958.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 772205.3125 - val_loss: 3226655.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 712617.4375 - val_loss: 3225463.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 656189.0000 - val_loss: 3224003.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 602851.3750 - val_loss: 3222273.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 552510.0625 - val_loss: 3220188.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 505111.8750 - val_loss: 3219080.2500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 460588.3750 - val_loss: 3227966.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 418876.6250 - val_loss: 3233890.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 379847.6562 - val_loss: 3231719.5000\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 343425.5312 - val_loss: 3238675.5000\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 309573.2812 - val_loss: 3251064.2500\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 25ms/step - loss: 1808523.7500 - val_loss: 3274549.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 1679120.2500 - val_loss: 3268723.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 1572499.2500 - val_loss: 3260656.5000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1472736.6250 - val_loss: 3253712.7500\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1378394.6250 - val_loss: 3246795.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 1288843.7500 - val_loss: 3238348.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1202774.6250 - val_loss: 3229780.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1121107.8750 - val_loss: 3221374.5000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1043714.3125 - val_loss: 3210480.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 970253.3750 - val_loss: 3204693.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 900455.2500 - val_loss: 3197946.7500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 834217.8125 - val_loss: 3194322.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 771387.8125 - val_loss: 3191706.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 711811.5000 - val_loss: 3190803.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 655418.2500 - val_loss: 3191835.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 5s 25ms/step - loss: 602122.7500 - val_loss: 3192851.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 551836.7500 - val_loss: 3197678.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 504451.8750 - val_loss: 3198822.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 4s 22ms/step - loss: 459900.9375 - val_loss: 3204250.0000\n",
            "7/7 [==============================] - 1s 14ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 22ms/step - loss: 1809437.3750 - val_loss: 3276013.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1679887.5000 - val_loss: 3271920.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 1573249.5000 - val_loss: 3265853.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 1473067.7500 - val_loss: 3262290.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1377719.2500 - val_loss: 3258605.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1287601.2500 - val_loss: 3252833.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1202092.3750 - val_loss: 3249642.0000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 1120854.0000 - val_loss: 3247570.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1043649.6875 - val_loss: 3246215.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 970254.9375 - val_loss: 3245341.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 900525.0625 - val_loss: 3245063.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 834324.5000 - val_loss: 3244843.5000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 771502.7500 - val_loss: 3244942.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 711913.8750 - val_loss: 3245260.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 655476.5000 - val_loss: 3245447.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 602175.5000 - val_loss: 3245334.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 551873.6875 - val_loss: 3244818.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 504501.4062 - val_loss: 3250447.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 459969.6875 - val_loss: 3255725.0000\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 418219.3750 - val_loss: 3263581.0000\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 4s 22ms/step - loss: 379206.8125 - val_loss: 3263540.2500\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 342841.5312 - val_loss: 3277442.7500\n",
            "7/7 [==============================] - 1s 14ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 8s 24ms/step - loss: 1810784.1250 - val_loss: 3278741.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1682109.8750 - val_loss: 3279539.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1575351.0000 - val_loss: 3275112.7500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1475642.1250 - val_loss: 3268332.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1381257.3750 - val_loss: 3263618.7500\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1291624.3750 - val_loss: 3259370.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1206460.5000 - val_loss: 3255620.2500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1125536.2500 - val_loss: 3247107.7500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 1048528.3125 - val_loss: 3240987.2500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 975265.3750 - val_loss: 3238168.2500\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 905617.0000 - val_loss: 3236307.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 839472.7500 - val_loss: 3234972.2500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 776682.6875 - val_loss: 3233925.2500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 717143.8125 - val_loss: 3233047.0000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 660747.2500 - val_loss: 3232254.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 607396.6250 - val_loss: 3231522.0000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 557055.8125 - val_loss: 3234009.7500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 509596.9375 - val_loss: 3240492.7500\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 464939.5938 - val_loss: 3247588.7500\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 423043.2812 - val_loss: 3246657.2500\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 383865.5312 - val_loss: 3245708.0000\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 7s 24ms/step - loss: 1809538.1250 - val_loss: 3274996.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1680008.2500 - val_loss: 3268209.2500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1573303.8750 - val_loss: 3261743.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1473591.8750 - val_loss: 3254411.0000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1379243.7500 - val_loss: 3245100.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1289711.2500 - val_loss: 3237863.7500\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 1204628.6250 - val_loss: 3227448.7500\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1123692.5000 - val_loss: 3219160.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1046754.0000 - val_loss: 3211254.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 973576.6250 - val_loss: 3202294.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 904014.9375 - val_loss: 3197247.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 837958.0000 - val_loss: 3192820.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 775261.3750 - val_loss: 3190387.7500\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 715762.6875 - val_loss: 3189168.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 659411.4375 - val_loss: 3192099.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 606136.1250 - val_loss: 3189314.2500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 555877.5625 - val_loss: 3198082.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 508505.1562 - val_loss: 3196756.5000\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 463939.9688 - val_loss: 3200750.7500\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 9s 25ms/step - loss: 1808701.5000 - val_loss: 3274879.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1680182.6250 - val_loss: 3267282.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1573264.5000 - val_loss: 3258880.2500\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1473159.6250 - val_loss: 3251131.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1378451.1250 - val_loss: 3242241.5000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1288596.5000 - val_loss: 3229919.5000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1203215.8750 - val_loss: 3215272.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1122012.5000 - val_loss: 3203776.0000\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1044768.1250 - val_loss: 3187727.0000\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 971324.3125 - val_loss: 3170761.0000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 5s 24ms/step - loss: 901525.3750 - val_loss: 3159241.2500\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 835245.2500 - val_loss: 3153530.0000\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 772380.3750 - val_loss: 3147204.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 712819.3125 - val_loss: 3149063.7500\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 656419.8750 - val_loss: 3151562.0000\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 603102.0625 - val_loss: 3153612.7500\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 552779.7500 - val_loss: 3165235.2500\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 505374.0000 - val_loss: 3174022.7500\n",
            "7/7 [==============================] - 1s 12ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 4 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 9s 26ms/step - loss: 1811527.3750 - val_loss: 3276394.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1685061.3750 - val_loss: 3272974.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 1578784.8750 - val_loss: 3268225.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1478998.2500 - val_loss: 3262082.5000\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 1384829.1250 - val_loss: 3255319.0000\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 1295498.8750 - val_loss: 3251003.0000\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1210592.1250 - val_loss: 3243781.5000\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 1129842.6250 - val_loss: 3239407.2500\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 1052986.0000 - val_loss: 3231461.7500\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 979859.7500 - val_loss: 3224812.5000\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 910386.2500 - val_loss: 3221146.0000\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 844375.6250 - val_loss: 3218162.7500\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 4s 18ms/step - loss: 781638.1875 - val_loss: 3215691.0000\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 5s 22ms/step - loss: 722113.6875 - val_loss: 3215982.5000\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 5s 23ms/step - loss: 665711.6250 - val_loss: 3222346.7500\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 4s 20ms/step - loss: 612309.0625 - val_loss: 3220045.5000\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 4s 19ms/step - loss: 561873.5000 - val_loss: 3217702.5000\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 4s 21ms/step - loss: 514343.4375 - val_loss: 3218908.7500\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 7s 31ms/step - loss: 1846250.6250 - val_loss: 3276687.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1764619.3750 - val_loss: 3278793.0000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1705724.5000 - val_loss: 3279436.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 1650177.3750 - val_loss: 3279185.2500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1596815.7500 - val_loss: 3278860.2500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 28ms/step - loss: 1545162.8750 - val_loss: 3278384.5000\n",
            "7/7 [==============================] - 1s 12ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 7s 30ms/step - loss: 1850712.3750 - val_loss: 3275389.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1770609.7500 - val_loss: 3276322.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1711810.0000 - val_loss: 3274562.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 1656401.6250 - val_loss: 3272654.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1603161.6250 - val_loss: 3270473.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1551614.7500 - val_loss: 3268894.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1501568.0000 - val_loss: 3267129.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1452881.8750 - val_loss: 3264507.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1405212.0000 - val_loss: 3261896.2500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1358344.1250 - val_loss: 3259458.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1312896.7500 - val_loss: 3257722.0000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1268685.8750 - val_loss: 3256357.2500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1225622.3750 - val_loss: 3255177.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 1183709.1250 - val_loss: 3251708.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1142833.0000 - val_loss: 3249487.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1103001.1250 - val_loss: 3248364.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1064132.8750 - val_loss: 3247625.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1026236.6250 - val_loss: 3247078.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 989305.5625 - val_loss: 3246687.2500\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 3s 29ms/step - loss: 953294.1875 - val_loss: 3246468.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 918195.5000 - val_loss: 3246287.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 883999.8750 - val_loss: 3246115.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 850671.9375 - val_loss: 3245999.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 818190.6250 - val_loss: 3245758.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 786579.4375 - val_loss: 3246644.0000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 755783.1875 - val_loss: 3249396.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 725826.0625 - val_loss: 3251509.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 696675.3750 - val_loss: 3250994.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 668289.3750 - val_loss: 3250660.5000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 26ms/step - loss: 1848170.3750 - val_loss: 3276394.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1765677.8750 - val_loss: 3278286.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1706468.1250 - val_loss: 3278542.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1650741.0000 - val_loss: 3277859.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 28ms/step - loss: 1597230.2500 - val_loss: 3278127.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1545434.6250 - val_loss: 3277812.2500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 26ms/step - loss: 1848659.2500 - val_loss: 3274210.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1767065.7500 - val_loss: 3275101.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1708207.5000 - val_loss: 3274261.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1652829.3750 - val_loss: 3272810.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1599630.5000 - val_loss: 3271070.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1548139.6250 - val_loss: 3269407.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1498102.0000 - val_loss: 3268178.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1449480.3750 - val_loss: 3266926.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1402147.0000 - val_loss: 3265655.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1356035.0000 - val_loss: 3264480.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1311120.7500 - val_loss: 3263472.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1267308.0000 - val_loss: 3260594.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1224602.6250 - val_loss: 3258602.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1182931.8750 - val_loss: 3257522.2500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1142292.3750 - val_loss: 3256737.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1102643.7500 - val_loss: 3256017.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1063986.1250 - val_loss: 3255436.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1026284.5625 - val_loss: 3254828.7500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 989524.3125 - val_loss: 3254738.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 3s 28ms/step - loss: 953694.5625 - val_loss: 3254799.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 918787.7500 - val_loss: 3254868.7500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 884722.0625 - val_loss: 3255115.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 851500.8750 - val_loss: 3255434.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 819174.7500 - val_loss: 3255325.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 26ms/step - loss: 1851050.7500 - val_loss: 3275985.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1770397.1250 - val_loss: 3278006.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1711233.6250 - val_loss: 3278927.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1655176.2500 - val_loss: 3278190.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1601448.7500 - val_loss: 3277373.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1549549.5000 - val_loss: 3276025.5000\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 25ms/step - loss: 1844870.2500 - val_loss: 3274783.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1763206.8750 - val_loss: 3276460.7500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1704757.0000 - val_loss: 3275537.2500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1649204.8750 - val_loss: 3272488.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1595906.0000 - val_loss: 3269009.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1544421.2500 - val_loss: 3265533.0000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1494424.5000 - val_loss: 3262361.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1445840.3750 - val_loss: 3258937.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1398521.7500 - val_loss: 3255697.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1352475.0000 - val_loss: 3252545.2500\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1307576.7500 - val_loss: 3248444.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1263807.8750 - val_loss: 3242674.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1221146.0000 - val_loss: 3239135.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1179525.5000 - val_loss: 3234998.7500\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1138924.1250 - val_loss: 3230525.7500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1099357.1250 - val_loss: 3227539.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1060735.5000 - val_loss: 3224968.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1023098.9375 - val_loss: 3222370.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 986414.1875 - val_loss: 3220240.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 950636.6250 - val_loss: 3217715.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 915740.9375 - val_loss: 3216105.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 881770.2500 - val_loss: 3214955.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 848657.5000 - val_loss: 3213692.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 816395.8125 - val_loss: 3212484.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 784952.2500 - val_loss: 3211215.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 754333.7500 - val_loss: 3209967.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 724554.6250 - val_loss: 3208909.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 695560.6250 - val_loss: 3207973.2500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 667363.1875 - val_loss: 3207139.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 639945.7500 - val_loss: 3206384.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 613302.6875 - val_loss: 3205682.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 587403.7500 - val_loss: 3204949.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 562262.8750 - val_loss: 3204547.7500\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 537855.6875 - val_loss: 3206062.0000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 514160.8750 - val_loss: 3209975.7500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 491180.8125 - val_loss: 3208792.7500\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 468904.8750 - val_loss: 3207973.2500\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 447312.0312 - val_loss: 3207553.7500\n",
            "7/7 [==============================] - 0s 11ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 32ms/step - loss: 1850210.5000 - val_loss: 3275696.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1769699.0000 - val_loss: 3277483.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 29ms/step - loss: 1711363.8750 - val_loss: 3277329.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1656382.6250 - val_loss: 3275762.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1603560.7500 - val_loss: 3273398.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1552454.2500 - val_loss: 3270495.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1502821.5000 - val_loss: 3268403.7500\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1454541.7500 - val_loss: 3266572.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1407541.6250 - val_loss: 3264713.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1361723.3750 - val_loss: 3261534.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1317075.7500 - val_loss: 3258551.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1273537.3750 - val_loss: 3254577.5000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1231097.6250 - val_loss: 3252335.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1189563.6250 - val_loss: 3250783.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1148447.2500 - val_loss: 3246062.0000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1108494.7500 - val_loss: 3242538.7500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1069667.3750 - val_loss: 3239632.0000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1031888.0625 - val_loss: 3237634.2500\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 995093.6875 - val_loss: 3236134.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 959223.9375 - val_loss: 3234885.7500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 924237.3125 - val_loss: 3233758.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 890154.2500 - val_loss: 3232766.2500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 856913.3125 - val_loss: 3231839.7500\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 824552.0625 - val_loss: 3230879.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 793026.1250 - val_loss: 3229961.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 762360.2500 - val_loss: 3228987.7500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 732478.1875 - val_loss: 3227983.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 703393.6250 - val_loss: 3226943.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 675096.0625 - val_loss: 3225904.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 647590.6875 - val_loss: 3225141.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 620828.6250 - val_loss: 3224381.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 594803.6875 - val_loss: 3227310.5000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 569536.6250 - val_loss: 3226682.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 545011.1875 - val_loss: 3229117.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 521180.1875 - val_loss: 3239354.7500\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 498113.1875 - val_loss: 3241030.0000\n",
            "7/7 [==============================] - 1s 10ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 7s 30ms/step - loss: 1848446.8750 - val_loss: 3276568.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1768247.0000 - val_loss: 3278999.2500\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1709168.7500 - val_loss: 3280886.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1653408.0000 - val_loss: 3282166.7500\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1599916.7500 - val_loss: 3282731.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1548148.3750 - val_loss: 3283488.7500\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 26ms/step - loss: 1847394.8750 - val_loss: 3274385.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1765346.6250 - val_loss: 3273977.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1706502.2500 - val_loss: 3273138.7500\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1651130.7500 - val_loss: 3271409.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 1597923.3750 - val_loss: 3269006.7500\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1546414.8750 - val_loss: 3266998.2500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1496452.0000 - val_loss: 3265280.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1447820.1250 - val_loss: 3263261.0000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1400514.7500 - val_loss: 3261006.7500\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1354425.0000 - val_loss: 3257243.0000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1309525.2500 - val_loss: 3254441.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 1265791.1250 - val_loss: 3251933.0000\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1223081.0000 - val_loss: 3250162.7500\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1181450.6250 - val_loss: 3246178.0000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1140866.1250 - val_loss: 3242942.2500\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1101282.7500 - val_loss: 3241132.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1062653.6250 - val_loss: 3239648.2500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1024978.0625 - val_loss: 3238498.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 988252.5625 - val_loss: 3237490.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 952442.5625 - val_loss: 3236683.0000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 917517.7500 - val_loss: 3236036.2500\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 883486.9375 - val_loss: 3235520.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 850345.5625 - val_loss: 3235095.0000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 818040.8125 - val_loss: 3234673.0000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 786581.1875 - val_loss: 3234358.2500\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 755963.0000 - val_loss: 3234249.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 726107.5000 - val_loss: 3234101.0000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 697053.2500 - val_loss: 3236165.0000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 668829.8750 - val_loss: 3237851.2500\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 641386.5000 - val_loss: 3237167.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 614659.3750 - val_loss: 3236331.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 588723.6875 - val_loss: 3235807.2500\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 8 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 7s 31ms/step - loss: 1850064.8750 - val_loss: 3275755.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1769096.3750 - val_loss: 3277980.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1710200.7500 - val_loss: 3278825.0000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1654508.8750 - val_loss: 3277923.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1601136.5000 - val_loss: 3275770.0000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1549531.0000 - val_loss: 3273557.7500\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1499447.6250 - val_loss: 3270834.0000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1450750.1250 - val_loss: 3268452.7500\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1403360.8750 - val_loss: 3265431.0000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1357227.5000 - val_loss: 3262819.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1312239.5000 - val_loss: 3260986.7500\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1268405.8750 - val_loss: 3259157.7500\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1225664.0000 - val_loss: 3254888.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1183992.7500 - val_loss: 3252928.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1143303.7500 - val_loss: 3251548.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1103641.7500 - val_loss: 3250415.2500\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1064991.8750 - val_loss: 3249419.7500\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1027278.2500 - val_loss: 3248617.0000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 990488.0625 - val_loss: 3247930.0000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 954609.3750 - val_loss: 3247373.2500\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 919654.9375 - val_loss: 3246926.0000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 885572.5000 - val_loss: 3246636.7500\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 852362.6875 - val_loss: 3246391.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 820004.1250 - val_loss: 3246289.7500\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 788480.1250 - val_loss: 3246209.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 757779.6250 - val_loss: 3246190.2500\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 727911.6250 - val_loss: 3246088.2500\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 698810.3125 - val_loss: 3245970.7500\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 670516.6875 - val_loss: 3245895.0000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 642999.2500 - val_loss: 3245718.7500\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 616254.8750 - val_loss: 3246215.2500\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 590249.0625 - val_loss: 3251139.2500\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 565023.6875 - val_loss: 3255851.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 540536.9375 - val_loss: 3259750.2500\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 516773.0625 - val_loss: 3270398.2500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 0 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 32ms/step - loss: 1875454.6250 - val_loss: 3275553.5000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1813744.2500 - val_loss: 3276604.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1780648.7500 - val_loss: 3277867.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1750173.2500 - val_loss: 3278807.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1721032.8750 - val_loss: 3279534.5000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1692774.7500 - val_loss: 3280011.0000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 1 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1879089.6250 - val_loss: 3275916.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1815608.5000 - val_loss: 3276653.2500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1781982.7500 - val_loss: 3278061.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1751084.3750 - val_loss: 3279168.5000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1721452.8750 - val_loss: 3280035.7500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1692845.6250 - val_loss: 3280710.0000\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 2 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 33ms/step - loss: 1877888.0000 - val_loss: 3275891.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1813989.0000 - val_loss: 3276982.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1780146.3750 - val_loss: 3278356.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1749243.2500 - val_loss: 3279389.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1719721.3750 - val_loss: 3280214.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1691094.2500 - val_loss: 3280850.7500\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 3 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1875997.8750 - val_loss: 3275595.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1814297.7500 - val_loss: 3276874.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 1781243.3750 - val_loss: 3278225.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1750663.7500 - val_loss: 3279458.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1720870.0000 - val_loss: 3280338.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1692096.1250 - val_loss: 3281103.0000\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 4 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 6s 34ms/step - loss: 1877023.2500 - val_loss: 3275860.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1816571.8750 - val_loss: 3276728.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1783021.1250 - val_loss: 3278117.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1752268.7500 - val_loss: 3279120.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1722793.0000 - val_loss: 3279820.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1694169.1250 - val_loss: 3280381.5000\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 5 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 39ms/step - loss: 1874684.6250 - val_loss: 3275640.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 27ms/step - loss: 1812309.6250 - val_loss: 3277056.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 28ms/step - loss: 1779131.2500 - val_loss: 3278398.7500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1748588.1250 - val_loss: 3279371.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1719340.7500 - val_loss: 3280182.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1690918.1250 - val_loss: 3280847.2500\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 6 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 4s 31ms/step - loss: 1876229.3750 - val_loss: 3275771.0000\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1811458.2500 - val_loss: 3276999.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1777794.2500 - val_loss: 3278356.5000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 2s 29ms/step - loss: 1746974.6250 - val_loss: 3279313.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 2s 31ms/step - loss: 1717449.0000 - val_loss: 3279911.0000\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 2s 29ms/step - loss: 1688822.6250 - val_loss: 3280445.7500\n",
            "7/7 [==============================] - 1s 9ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 7 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 30ms/step - loss: 1879433.0000 - val_loss: 3274975.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1816465.5000 - val_loss: 3276211.7500\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1782830.5000 - val_loss: 3277635.2500\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1751912.8750 - val_loss: 3278448.0000\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1722457.8750 - val_loss: 3278861.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1693882.6250 - val_loss: 3278993.5000\n",
            "7/7 [==============================] - 1s 12ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 8 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 31ms/step - loss: 1876113.8750 - val_loss: 3275671.2500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1812534.6250 - val_loss: 3277140.0000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1779063.3750 - val_loss: 3278565.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1748362.2500 - val_loss: 3279654.2500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1718909.8750 - val_loss: 3280568.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1690360.6250 - val_loss: 3281402.0000\n",
            "7/7 [==============================] - 1s 8ms/step\n",
            "Running for Nadam optimizer 0.001 learning_rate 16 batch_size and 9 replicate \n",
            "\n",
            "Epoch 1/50\n",
            "53/53 [==============================] - 5s 32ms/step - loss: 1877997.0000 - val_loss: 3275380.7500\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1814329.8750 - val_loss: 3276496.5000\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 1780415.8750 - val_loss: 3278012.0000\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1749464.5000 - val_loss: 3279167.7500\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 1719840.7500 - val_loss: 3280083.2500\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1691186.6250 - val_loss: 3280836.0000\n",
            "7/7 [==============================] - 1s 11ms/step\n",
            "Best_hyper_parameters: \n",
            " {'model': [200], 'optimizer': 'Adam', 'learning_rate': 0.1, 'batch_size': 8, 'best_avg_rmse': 1178.3318398583074}\n",
            "all_avg_rmse: \n",
            " [[[1228.1005271  1178.33183986 1198.04766834]\n",
            "  [1241.44275079 1348.93487015 1422.8905854 ]\n",
            "  [1476.09174298 1517.42486296 1550.0597961 ]]\n",
            "\n",
            " [[1503.09073021 1491.69363047 1511.46586698]\n",
            "  [1532.38739173 1551.27014562 1568.36734693]\n",
            "  [1583.45517178 1596.77506342 1608.63121701]]\n",
            "\n",
            " [[1573.71457667 1541.33555551 1527.18138446]\n",
            "  [1516.34763998 1529.36382213 1541.21853309]\n",
            "  [1551.24490061 1561.00026585 1570.26807376]]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': [200],\n",
              " 'optimizer': 'Adam',\n",
              " 'learning_rate': 0.1,\n",
              " 'batch_size': 8,\n",
              " 'best_avg_rmse': 1178.3318398583074}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4191LDMl6HA"
      },
      "source": [
        "### Building and running single layer models in full scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c01nB6YCGxjy"
      },
      "outputs": [],
      "source": [
        "#========== Model hyper parameters settting ==========================#\n",
        "def LSTM_model(neurons, hyper_parameters,  epochs = 20,  num_replicates = 2):\n",
        "\n",
        "  #====== data transformation==========#\n",
        "  print(\"Progress: Performing data preparation steps.......\\n\")\n",
        "\n",
        "  #======= creating training and test data===#\n",
        "\n",
        " # train_data, test_data = data_split(data, test_split)\n",
        "  train_data, test_data = X_train, X_test\n",
        "\n",
        "  num_features = train_data.shape[1]\n",
        "\n",
        "  # min_train, max_train  = train_data[\"Close\"].min(), train_data[\"Close\"].max()\n",
        "  # min_test, max_test   =  test_data[\"Close\"].min(), test_data[\"Close\"].max()\n",
        "\n",
        "  # train_data_scaled  =  min_max_transform(train_data)\n",
        "  # test_data_scaled   = min_max_transform(test_data)\n",
        "\n",
        "\n",
        "  # X_train, y_train  =   DatasetCreation(train_data_scaled, time_step)\n",
        "  # X_test, y_test    =   DatasetCreation(test_data_scaled, time_step)\n",
        "\n",
        "  # y_train_original  =  min_max_inverse_transform(y_train, min_train, max_train) #in original scale\n",
        "  # y_test_original  =  min_max_inverse_transform(y_test, min_test, max_test) #in original scale'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print(\"Progress: Building and training models.......\\n\")\n",
        "\n",
        "  neurons = np.array(neurons)\n",
        "  #============ arrays for collecting test scores ================#\n",
        "  rmse_array = np.zeros((len(neurons), num_replicates))\n",
        "  #mae_array  = np.zeros((len(neurons), num_replicates))\n",
        "  mape_array = np.zeros((len(neurons), num_replicates))\n",
        "  #R2_array   = np.zeros((len(neurons), num_replicates))\n",
        "  R_array    = np.zeros((len(neurons), num_replicates))\n",
        "  elapsed_time_array = np.zeros((len(neurons), num_replicates))\n",
        "\n",
        "\n",
        "  #========== array for collecting history and predictions =======#\n",
        "  models_history = []\n",
        "  train_predictions = []\n",
        "  test_predictions  = []\n",
        "\n",
        "  for i in range(len(neurons)):\n",
        "\n",
        "    print(\"Model hyperparameters used: \\n \", hyper_parameters[i])\n",
        "    #========== saving history and predictions per replicate=====#\n",
        "    model_history_per_replicate = []\n",
        "    train_predictions_per_replicate = []\n",
        "    test_predictions_per_replicate  = []\n",
        "\n",
        "    hidden_nodes = np.int(neurons[i])\n",
        "\n",
        "   # print(\"Program is running for %d neurons ----->\\n\" %np.int(neurons[i]))\n",
        "\n",
        "\n",
        "    for k in range(num_replicates):\n",
        "\n",
        "      print(\"Program is running for %d neurons and %d replicate ----->\\n\" %(hidden_nodes, k))\n",
        "\n",
        "\n",
        "\n",
        "      layers = [hidden_nodes]\n",
        "\n",
        "\n",
        "      ### model = build_lstm_model(layers, time_step, num_features, optimizer = hyper_parameters[i][0], learning_rate = hyper_parameters[i][1], verbose = 0)\n",
        "      model = build_lstm_model(layers, optimizer = hyper_parameters[i][0], learning_rate = hyper_parameters[i][1], verbose = 0)\n",
        "      callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience= 5)\n",
        "      # This callback will stop the training when there is no improvement in\n",
        "      # the loss for three consecutive epochs\n",
        "      start = time.time()\n",
        "      history = model.fit(X_train, y_train, batch_size = hyper_parameters[i][2], epochs= epochs, callbacks=[callback], verbose = 1)\n",
        "      end = time.time()\n",
        "      elapsed_time = end - start\n",
        "\n",
        "      model_history_per_replicate.append(history)\n",
        "\n",
        "\n",
        "      #==============Making train and test prediction in original scales ==========\n",
        "      train_pred   =  model.predict(X_train) #in original scale\n",
        "      test_pred    =  model.predict(X_test)\n",
        "\n",
        "      train_predictions_per_replicate.append(train_pred)\n",
        "      test_predictions_per_replicate.append(test_pred)\n",
        "\n",
        "      #============== Calculating performance scores=========\n",
        "      scores =   calculate_scores(y_test, test_pred)\n",
        "      rmse_array[i][k] = scores['rmse']\n",
        "      mape_array[i][k] =  scores['mape']\n",
        "      R_array[i][k] = scores['R']\n",
        "      elapsed_time_array[i][k] = elapsed_time\n",
        "\n",
        "    models_history.append(model_history_per_replicate)\n",
        "    train_predictions.append(train_predictions_per_replicate)\n",
        "    test_predictions.append(test_predictions_per_replicate)\n",
        "\n",
        "  print(\"Progress: Collecting outputs.......\\n\")\n",
        "\n",
        "  neurons_df = pd.DataFrame(neurons)\n",
        "  rmse_df = pd.DataFrame(rmse_array)\n",
        "  #mae_df  = pd.DataFrame(mae_array)\n",
        "  mape_df  = pd.DataFrame(mape_array)\n",
        "  #R2_df   = pd.DataFrame(R2_array)\n",
        "  R_df    = pd.DataFrame(R_array)\n",
        "  elapsed_time_df =  pd.DataFrame(elapsed_time_array)\n",
        "\n",
        "  train_predictions  = np.array(train_predictions)\n",
        "  test_predictions   = np.array(test_predictions)\n",
        "\n",
        "  #==== Idendifying  the best model results based on rmse ===============#\n",
        "  min_index = pd.DataFrame(rmse_df.min(axis = 1)).idxmin()[0]\n",
        "  min_col =   pd.DataFrame(rmse_df.min(axis = 0)).idxmin()[0]\n",
        "\n",
        "  num_neurons_with_best_rmse = neurons_df.loc[min_index,0]\n",
        "\n",
        "  best_rmse = rmse_df.loc[min_index, min_col]\n",
        "  #mae_with_best_rmse = mae_df.loc[min_index, min_col]\n",
        "  mape_with_best_rmse = mape_df.loc[min_index, min_col]\n",
        "  #R2_with_best_rmse = R2_df.loc[min_index, min_col]\n",
        "  R_with_best_rmse =  R_df.loc[min_index, min_col]\n",
        "  elapsed_time_with_best_rmse = elapsed_time_df.loc[min_index, min_col]\n",
        "\n",
        "  train_predictions_with_best_rmse = train_predictions[min_index][min_col]\n",
        "  test_predictions_with_best_rmse = test_predictions[min_index][min_col]\n",
        "\n",
        "  loss_with_best_rmse = models_history[min_index][min_col].history['loss']\n",
        "  #val_loss_with_best_rmse = models_history[min_index][min_col].history['val_loss']\n",
        "\n",
        "  #======= Collecting hyperparameters=============#\n",
        "  hyper_parameters = { 'neurons': neurons,\n",
        "                       'model_specific_hyper_parameters': hyper_parameters,#additional best_hyper_parmeters for each models\n",
        "                       'epochs': epochs,\n",
        "\n",
        "                       'num_replicates': num_replicates,\n",
        "                       #'validataion_split':validation_split\n",
        "                        }\n",
        "\n",
        "  #======= Collecting test scores =============#\n",
        "  scores = {'neurons': neurons_df, 'rmse': rmse_df, 'mape': mape_df, 'R': R_df, 'elapsed_time': elapsed_time_df}\n",
        "\n",
        "  #======= Collecting average test scores =============#\n",
        "  avg_scores = pd.DataFrame({'neurons': neurons,\n",
        "                            'rmse': rmse_df.mean(axis = 1),\n",
        "                            'mape': mape_df.mean(axis = 1),\n",
        "                            'R': R_df.mean(axis = 1),\n",
        "                            'elapsed_time': elapsed_time_df.mean(axis = 1)})\n",
        "\n",
        " #======= Collecting average test scores =============#\n",
        "  all_stds = pd.DataFrame({'neurons': neurons,\n",
        "                            'rmse': rmse_df.std(axis = 1),\n",
        "                            'mape': mape_df.std(axis = 1),\n",
        "                            'R': R_df.std(axis = 1),\n",
        "                            'elapsed_time': elapsed_time_df.std(axis = 1)})\n",
        "\n",
        "\n",
        " #======= Collecting average test scores =============#\n",
        "  all_minimums = pd.DataFrame({'neurons': neurons,\n",
        "                            'rmse': rmse_df.min(axis = 1),\n",
        "                            'mape': mape_df.min(axis = 1),\n",
        "                            'R': R_df.min(axis = 1),\n",
        "                            'elapsed_time': elapsed_time_df.min(axis = 1)})\n",
        "\n",
        "  #======= Collecting average test scores =============#\n",
        "  all_maximums = pd.DataFrame({'neurons': neurons,\n",
        "                            'rmse': rmse_df.max(axis = 1),\n",
        "                            'mape': mape_df.max(axis = 1),\n",
        "                            'R': R_df.max(axis = 1),\n",
        "                            'elapsed_time': elapsed_time_df.max(axis = 1)})\n",
        "\n",
        "\n",
        "\n",
        "  #======= Collecting the best model results =============#\n",
        "  model_with_best_rmse = {  'neurons': num_neurons_with_best_rmse,\n",
        "                            'replicate': min_col,\n",
        "                            'rmse': best_rmse,\n",
        "                            'mape': mape_with_best_rmse,\n",
        "                            'R':  R_with_best_rmse,\n",
        "                            'elapsed_time': elapsed_time_with_best_rmse,\n",
        "                            'train_predictions':train_predictions_with_best_rmse,\n",
        "                            'test_predictions': test_predictions_with_best_rmse,\n",
        "                            'loss':loss_with_best_rmse,\n",
        "\n",
        "                         }\n",
        "\n",
        "\n",
        "  #======= Collecting all the outputs together =============#\n",
        "  output_dictionary = { 'hyper_parameters': hyper_parameters,\n",
        "                        'best_model': model_with_best_rmse,\n",
        "                        'scores': scores,\n",
        "                        'avg_scores': avg_scores,\n",
        "                        'all_stds': all_stds,\n",
        "                        'all_minimums': all_minimums,\n",
        "                        'all_maximums': all_maximums,\n",
        "                        'train_predictions': train_predictions,\n",
        "                        'test_predictions':  test_predictions,\n",
        "                        'models_history': models_history\n",
        "                       }\n",
        "\n",
        "  print(\"\\nBest model (neurons, replicate, rmse): \", num_neurons_with_best_rmse, min_col, best_rmse)\n",
        "  print('\\nAverage scores:\\n', avg_scores)\n",
        "  print('\\nStandard_deviations:\\n', all_stds)\n",
        "  print('\\nMinimums:\\n', all_minimums)\n",
        "  print('\\nMaximums:\\n', all_maximums)\n",
        "  print(\"\\nProgress: All works are done successfully, congratulations!!\\n\")\n",
        "\n",
        "\n",
        "\n",
        "  #Save all rmses in a file for statistical study\n",
        "  scores['rmse'].to_csv(data_path+'sl-lstm-all-rmse.csv')\n",
        "\n",
        "  #writing output dictionary in the file\n",
        "  file_name = data_path + \"sl-lstm-results.txt\"\n",
        "  write_dic_to_file(output_dictionary, file_name)\n",
        "\n",
        "  return (output_dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbXXP362-a_-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II3Oo4f6nC1r"
      },
      "source": [
        "## Final Step: Models Executions and Results Visualization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t=np.zeros(10)\n",
        "t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH0oHoa2qk5v",
        "outputId": "0bdbc780-d857-4692-b47d-6ee653165ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s=[0,0,0,0,0]\n",
        "np.array(s).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHYvwKmBqzp9",
        "outputId": "26db11bf-ad91-45a7-f94a-eb01f8271520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.empty_like(nepse.values[:,0]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QlcWInwrZJx",
        "outputId": "26f97e4d-647b-4131-a097-cd0e3885f8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1051,)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho102Ovm_3f6"
      },
      "source": [
        "#### Supporting model for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgX-7dYR_2we"
      },
      "outputs": [],
      "source": [
        "def test_scores_plot(model_output):\n",
        "  neurons = model_output['avg_scores']['neurons']\n",
        "  rmse = model_output['avg_scores']['rmse']\n",
        "  #mae =  model_output['avg_scores']['mae']\n",
        "  mape =  model_output['avg_scores']['mape']\n",
        "  #R2 =   model_output['avg_scores']['R2']\n",
        "  R =    model_output['avg_scores']['R']\n",
        "  #time =  model_output['avg_scores']['elapsed_time']\n",
        "\n",
        "  fig = plt.figure(figsize = (18, 4))\n",
        "  plt.subplot(131)\n",
        "  plt.plot(neurons, rmse, '--o', linewidth = 2, color = 'indigo')\n",
        "  plt.title(\"(a)\")\n",
        "  plt.xlabel(\"Neurons\")\n",
        "  plt.ylabel(\"Avg. RMSE\")\n",
        "  sns.set_style(\"whitegrid\")\n",
        "\n",
        "\n",
        "  plt.subplot(132)\n",
        "  plt.plot(neurons, mape, '--o', linewidth = 2, color = 'darkgreen')\n",
        "  plt.title(\"(b)\")\n",
        "  plt.xlabel(\"Neurons\")\n",
        "  plt.ylabel(\"Avg. MAPE\")\n",
        "\n",
        "\n",
        "  plt.subplot(133)\n",
        "  plt.plot(neurons, R, '--o', linewidth = 2, color = 'darkred')\n",
        "  plt.title(\"(c)\")\n",
        "  plt.xlabel(\"Neurons\")\n",
        "  plt.ylabel(\"Avg. R \")\n",
        "\n",
        "  fig.savefig(data_path+\"multiple_avg_scores_plots.png\",dpi=600)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def true_pred_plot(model_output):\n",
        "\n",
        "  train_pred = model_output['best_model']['train_predictions']\n",
        "  test_pred = model_output['best_model']['test_predictions']\n",
        "\n",
        "  ##====== Visualizing true vs predicted plots ========#\n",
        "  fig = plt.figure(figsize= (14,5))\n",
        "  plt.subplot(121)\n",
        "  #sns.relplot(x = y_train_original, y = train_pred_original)\n",
        "  plt.scatter(y_train, train_pred, marker= \"+\", color = 'mediumblue')\n",
        "  identity_line = np.linspace(max(min(y_train), min(train_pred)), min(max(y_train), max(train_pred)))\n",
        "  plt.plot(identity_line, identity_line, color=\"red\", linestyle=\"dashed\", linewidth= 2.5)\n",
        "\n",
        "  plt.xlabel(\"True\")\n",
        "  plt.ylabel(\"Predicted\")\n",
        "  plt.title(\"(a)\")\n",
        "\n",
        "  plt.subplot(122)\n",
        "  #sns.relplot(x = y_test_original, y = test_pred_original)\n",
        "  plt.scatter(y_test, test_pred, marker = \"+\", color = 'mediumblue')\n",
        "  identity_line = np.linspace(max(min(y_test), min(test_pred)), min(max(y_test), max(test_pred)))\n",
        "  plt.plot(identity_line, identity_line, color=\"red\", linestyle=\"dashed\", linewidth= 2.5)\n",
        "  plt.xlabel(\"True\")\n",
        "  plt.ylabel(\"Predicted\")\n",
        "  plt.title(\"(b)\")\n",
        "  fig.savefig(data_path+\"True_vs_predicted_plot.png\", dpi=600)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def prediction_plot(model_output):\n",
        "  time_step =  5\n",
        "  best_replicate = model_output['best_model']['replicate']\n",
        "\n",
        "  train_pred = model_output['train_predictions'][0][best_replicate]\n",
        "  test_pred = model_output['test_predictions'][0][best_replicate]\n",
        "\n",
        "  train_predict_plot_data = np.empty_like(nepse.values[:,0])# extracting closing price\n",
        "  train_predict_plot_data[:] = np.nan\n",
        "\n",
        "\n",
        "\n",
        "  test_predict_plot_data = np.empty_like(nepse.values[:,0])\n",
        "  test_predict_plot_data[:] = np.nan\n",
        "\n",
        "\n",
        "\n",
        "  fig1 = plt.figure(figsize = (18,12))\n",
        "\n",
        "  plt.subplot(231)\n",
        "\n",
        "\n",
        "\n",
        "  train_predict_plot_data[time_step:len(train_pred)+ time_step] =  train_pred.flatten()\n",
        "  test_predict_plot_data[len(train_pred)+(time_step)+1:len(nepse.values)] = test_pred.flatten()\n",
        "\n",
        "\n",
        "\n",
        "  plt.plot(nepse.values[:,0],'k',linewidth = 1.5)\n",
        "  plt.plot(train_predict_plot_data,'mediumblue',linewidth = 1.5)\n",
        "  plt.plot(test_predict_plot_data,'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"(a)\")\n",
        "  plt.legend(['True value', 'Predicted value in train set', 'Predicted value in test set'], loc = 'upper left')\n",
        "\n",
        "  plt.subplot(232)\n",
        "\n",
        "  train_pred = model_output['train_predictions'][1][best_replicate]\n",
        "  test_pred = model_output['test_predictions'][1][best_replicate]\n",
        "\n",
        "  train_predict_plot_data[time_step:len(train_pred)+ time_step] =  train_pred\n",
        "  test_predict_plot_data[len(train_pred)+(time_step*2)+1:len(data.values)-1] =  test_pred\n",
        "\n",
        "  plt.plot(nepse.values[:,0],'k',linewidth = 1.5)\n",
        "  plt.plot(train_predict_plot_data,'mediumblue',linewidth = 1.5)\n",
        "  plt.plot(test_predict_plot_data,'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"(b)\")\n",
        "  plt.legend(['True value', 'Predicted value in train set', 'Predicted value in test set'], loc = 'upper left')\n",
        "\n",
        "  plt.subplot(233)\n",
        "\n",
        "  train_pred = model_output['train_predictions'][2][best_replicate]\n",
        "  test_pred = model_output['test_predictions'][2][best_replicate]\n",
        "\n",
        "  train_predict_plot_data[time_step:len(train_pred)+ time_step] = train_pred\n",
        "  test_predict_plot_data[len(train_pred)+(time_step*2)+1:len(nepse.values)-1] =  test_pred\n",
        "\n",
        "  plt.plot(nepse.values[:,0],'k',linewidth = 1.5)\n",
        "  plt.plot(train_predict_plot_data,'mediumblue',linewidth = 1.5)\n",
        "  plt.plot(test_predict_plot_data,'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"(c)\")\n",
        "  plt.legend(['True value', 'Predicted value in train set', 'Predicted value in test set'], loc = 'upper left')\n",
        "\n",
        "\n",
        "  plt.subplot(234)\n",
        "\n",
        "  train_pred = model_output['train_predictions'][3][best_replicate]\n",
        "  test_pred = model_output['test_predictions'][3][best_replicate]\n",
        "\n",
        "  train_predict_plot_data[time_step:len(train_pred)+ time_step] = train_pred\n",
        "  test_predict_plot_data[len(train_pred)+(time_step*2)+1:len(nepse.values)-1] = test_pred\n",
        "\n",
        "  plt.plot(nepse.values[:,0],'k',linewidth = 1.5)\n",
        "  plt.plot(train_predict_plot_data,'mediumblue',linewidth = 1.5)\n",
        "  plt.plot(test_predict_plot_data,'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"(d)\")\n",
        "  plt.legend(['True value', 'Predicted value in train set', 'Predicted value in test set'], loc = 'upper left')\n",
        "\n",
        "\n",
        "  plt.subplot(235)\n",
        "\n",
        "  train_pred = model_output['train_predictions'][4][best_replicate]\n",
        "  test_pred = model_output['test_predictions'][4][best_replicate]\n",
        "\n",
        "  train_predict_plot_data[time_step:len(train_pred)+ time_step] = train_pred\n",
        "  test_predict_plot_data[len(train_pred)+(time_step*2)+1:len(nepse.values)-1] = test_pred\n",
        "\n",
        "  plt.plot(nepse.values[:,0],'k',linewidth = 1.5)\n",
        "  plt.plot(train_predict_plot_data,'mediumblue',linewidth = 1.5)\n",
        "  plt.plot(test_predict_plot_data,'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"(e)\")\n",
        "  plt.legend(['True value', 'Predicted value in train set', 'Predicted value in test set'], loc = 'upper left')\n",
        "\n",
        "  plt.subplot(236)\n",
        "\n",
        "  train_pred = model_output['train_predictions'][5][best_replicate]\n",
        "  test_pred = model_output['test_predictions'][5][best_replicate]\n",
        "\n",
        "  train_predict_plot_data[time_step:len(train_pred)+ time_step] = train_pred\n",
        "  test_predict_plot_data[len(train_pred)+(time_step*2)+1:len(nepse.values)-1] = test_pred\n",
        "\n",
        "  plt.plot(nepse.values[:,0],'k',linewidth = 1.5)\n",
        "  plt.plot(train_predict_plot_data,'mediumblue',linewidth = 1.5)\n",
        "  plt.plot(test_predict_plot_data,'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"(f)\")\n",
        "  plt.legend(['True value', 'Predicted value in train set', 'Predicted value in test set'], loc = 'upper left')\n",
        "\n",
        "\n",
        "  fig1.savefig(data_path+\"predictions_plots_fullset.png\",dpi=600)\n",
        "  plt.show()\n",
        "\n",
        "  fig2 = plt.figure(figsize = (18,12))\n",
        "\n",
        "  plt.subplot(231)\n",
        "  plt.plot(nepse.values[len(train_pred)+(time_step*2)+1:-1, 0],'mediumblue',linewidth = 1.5)\n",
        "  plt.plot(model_output['test_predictions'][0][best_replicate], 'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"(a)\")\n",
        "  plt.legend(['True value', 'Predicted value'], loc='upper left')\n",
        "\n",
        "\n",
        "  plt.subplot(232)\n",
        "\n",
        "  plt.plot(nepse.values[len(train_pred)+(time_step*2)+1:-1, 0],'mediumblue',linewidth = 1.5)\n",
        "  plt.plot(model_output['test_predictions'][1][best_replicate], 'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"(b)\")\n",
        "  plt.legend(['True value', 'Predicted value'], loc='upper left')\n",
        "\n",
        "\n",
        "  plt.subplot(233)\n",
        "\n",
        "  plt.plot(nepse.values[len(train_pred)+(time_step*2)+1:-1, 0],'mediumblue',linewidth = 1.5)\n",
        "  plt.plot(model_output['test_predictions'][2][best_replicate], 'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"(c)\")\n",
        "  plt.legend(['True value', 'Predicted value'], loc='upper left')\n",
        "\n",
        "\n",
        "\n",
        "  plt.subplot(234)\n",
        "\n",
        "  plt.plot(nepse.values[len(train_pred)+(time_step*2)+1:-1, 0],'mediumblue',linewidth = 1.5)\n",
        "  plt.plot(model_output['test_predictions'][3][best_replicate], 'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"(d)\")\n",
        "  plt.legend(['True value', 'Predicted value'], loc='upper left')\n",
        "\n",
        "  plt.subplot(235)\n",
        "\n",
        "  plt.plot(nepse.values[len(train_pred)+(time_step*2)+1:-1, 0],'mediumblue',linewidth = 1.5)\n",
        "  plt.plot(model_output['test_predictions'][4][best_replicate], 'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"(e)\")\n",
        "  plt.legend(['True value', 'Predicted value'], loc='upper left')\n",
        "\n",
        "\n",
        "  plt.subplot(236)\n",
        "\n",
        "  plt.plot(nepse.values[len(train_pred)+(time_step*2)+1:-1, 0],'mediumblue',linewidth = 1.5)\n",
        "  plt.plot(model_output['test_predictions'][5][best_replicate], 'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"(f)\")\n",
        "  plt.legend(['True value', 'Predicted value'], loc='upper left')\n",
        "\n",
        "\n",
        "\n",
        "  fig2.savefig(data_path+\"predictions_plots_testset.png\",dpi=600)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def best_model_prediction_plot(model_output):\n",
        "\n",
        "  #time_step =  model_output['hyper_parameters']['time_step']\n",
        "  time_step = 5\n",
        "\n",
        "  data = nepse\n",
        "\n",
        "  train_predict_plot_data = np.empty_like(data.values[:,0])# extracting closing price\n",
        "  train_predict_plot_data[:] = np.nan\n",
        "\n",
        "  test_predict_plot_data = np.empty_like(data.values[:,0])\n",
        "  test_predict_plot_data[:] = np.nan\n",
        "\n",
        "\n",
        "  fig = plt.figure(figsize = (14,5))\n",
        "\n",
        "  plt.subplot(121)\n",
        "\n",
        "  train_pred = model_output['best_model']['train_predictions']\n",
        "  test_pred = model_output['best_model']['test_predictions']\n",
        "\n",
        "  train_predict_plot_data[time_step:len(train_pred)+ time_step] =  np.array(train_pred)\n",
        "  test_predict_plot_data[len(train_pred)+(time_step*2)+1:len(data.values)-1] = np.array(test_pred)\n",
        "\n",
        "  plt.plot(data.values[:,0],'k', linewidth = 1.5)\n",
        "  plt.plot(train_predict_plot_data,'mediumblue',linewidth = 1.5)\n",
        "  plt.plot(test_predict_plot_data,'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"(a)\")\n",
        "  plt.legend(['True value', 'Predicted value in train set', 'Predicted value in test set'], loc = 'upper left')\n",
        "\n",
        "\n",
        "  plt.subplot(122)\n",
        "  plt.plot(data.values[len(train_pred)+(time_step*2)+1:-1, 0],'k',linewidth = 1.5)\n",
        "  plt.plot(test_pred,'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"(b)\")\n",
        "  plt.legend(['True value', 'Predicted value'], loc='upper left')\n",
        "\n",
        "  fig.savefig(data_path+\"best_model_predictions_plots.png\",dpi=600)\n",
        "\n",
        "\n",
        "def rmse_boxplots(model_output):\n",
        "  fig = plt.figure(figsize = (6,5))\n",
        "  plt.boxplot(model_output['scores']['rmse'], patch_artist=True)\n",
        "  plt.xticks([1,2,3,4,5,6], ['10', '30', '50', '100', '150', '200'])\n",
        "  plt.xlabel('Number of neurons')\n",
        "  plt.ylabel('RMSE')\n",
        "  fig.savefig(data_path+\"rmse_boxplots.png\",dpi=600)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def rmse_violinplotplots(model_output):\n",
        "  fig = plt.figure(figsize = (6,5))\n",
        "  plt.violinplot(model_output['scores']['rmse'])\n",
        "  plt.xticks([1,2,3,4,5,6], ['10', '30', '50', '100', '150', '200'])\n",
        "  plt.xlabel('Number of neurons')\n",
        "  plt.ylabel('RMSE')\n",
        "  fig.savefig(data_path+\"rmse_violinplots.png\",dpi=600)\n",
        "  plt.show()\n",
        "\n",
        "def all_scores_boxplots(model_output):\n",
        "\n",
        "  fig = plt.figure(figsize = (18,5))\n",
        "  plt.subplot(131)\n",
        "  p1 = plt.boxplot(model_output['scores']['rmse'],patch_artist=True)\n",
        "  for i, box in enumerate(p1['boxes']):\n",
        "    # change outline color\n",
        "    box.set(color= 'blue', linewidth = 1.2)\n",
        "    # change fill color\n",
        "    box.set(facecolor = 'mediumblue')\n",
        "  plt.xticks([1,2,3,4,5,6], ['10', '30', '50', '100', '150', '200'])\n",
        "  plt.title(\"(a)\")\n",
        "  plt.xlabel('Number of neurons')\n",
        "  plt.ylabel('RMSE')\n",
        "\n",
        "  plt.subplot(132)\n",
        "  p2 = plt.boxplot(model_output['scores']['mape'],patch_artist=True)\n",
        "  for i, box in enumerate(p2['boxes']):\n",
        "    #change outline color\n",
        "    box.set(color= 'blue', linewidth = 1.2)\n",
        "    # change fill color\n",
        "    box.set(facecolor = 'indigo')\n",
        "\n",
        "  plt.xticks([1,2,3,4,5,6], ['10', '30', '50', '100', '150', '200'])\n",
        "  plt.title(\"(b)\")\n",
        "  plt.xlabel('Number of neurons')\n",
        "  plt.ylabel('MAPE')\n",
        "\n",
        "  plt.subplot(133)\n",
        "  p3 = plt.boxplot(model_output['scores']['R'],patch_artist=True)\n",
        "  for i, box in enumerate(p3['boxes']):\n",
        "    #change outline color\n",
        "    box.set(color= 'blue', linewidth = 1.2)\n",
        "    # change fill color\n",
        "    box.set(facecolor = 'darkgreen')\n",
        "  plt.xticks([1,2,3,4,5,6], ['10', '30', '50', '100', '150', '200'])\n",
        "  plt.title(\"(c)\")\n",
        "  plt.xlabel('Number of neurons')\n",
        "  plt.ylabel('R')\n",
        "\n",
        "  fig.savefig(data_path+\"all_scores_boxplots.png\",dpi=600)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def create_visualization(model_output):\n",
        "  true_pred_plot(model_output)\n",
        "  test_scores_plot(model_output)\n",
        "  prediction_plot(model_output)\n",
        "  best_model_prediction_plot(model_output)\n",
        "  rmse_boxplots(model_output)\n",
        "  all_scores_boxplots(model_output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIIZLhLB-__E"
      },
      "source": [
        "#### Executing single layer models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ywOf529nCNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2871b991-4cbd-48b3-f9f7-eb09e483e7a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3711.9407\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2708.8550\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2312.3984\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1962.2721\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1643.3320\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1281.7239\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1707.7080\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1585.2644\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2029.9763\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1456.2208\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1655.4941\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 50 neurons and 8 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 5ms/step - loss: 1015336.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 200034.2656\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 54718.2383\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 36529.6211\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 12680.2412\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 5736.4897\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 5086.9150\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 4109.0674\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3103.7168\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2357.5042\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1872.7300\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1699.3237\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1814.7334\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1645.2850\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1389.1976\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1534.7015\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1351.7487\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1718.6610\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1569.7642\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1310.5713\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1248.6135\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1178.9166\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1037.7957\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1103.3309\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1089.2115\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1004.2936\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 968.3887\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 982.0039\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 958.2441\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1066.5804\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1212.8751\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2078.8242\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1443.3914\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1385.0625\n",
            "27/27 [==============================] - 1s 3ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 50 neurons and 9 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 5ms/step - loss: 995912.8750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 177361.5000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 49484.2812\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 19271.8789\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 6667.2236\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 4340.8945\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2813.5037\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2597.3467\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1903.5199\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2168.3823\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2134.3506\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2150.3188\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1742.0155\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1500.4155\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1503.6594\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1491.4229\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1430.5547\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1771.9573\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1889.3817\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2178.6360\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1846.7837\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1738.9183\n",
            "27/27 [==============================] - 1s 3ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 50 neurons and 10 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 5ms/step - loss: 952784.9375\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 147192.2812\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 43037.8281\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 15791.7441\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 8990.0488\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 6002.1733\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 5039.9951\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 4370.8613\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3829.3857\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2259.8018\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2370.4885\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2659.3027\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 3130.0303\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2891.7864\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 5439.1069\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 50 neurons and 11 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 6ms/step - loss: 975096.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 162356.2656\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 47723.6758\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 24596.2734\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 8051.3931\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 4310.1616\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3935.8003\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3007.1877\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1963.2970\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1965.5876\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1773.8942\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1576.0571\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2410.6411\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2382.1951\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1745.8835\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1428.9781\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1233.0082\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1173.1753\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 918.8615\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 989.6610\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1051.4814\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 983.3010\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1345.9701\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1215.3306\n",
            "27/27 [==============================] - 1s 3ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 50 neurons and 12 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 5ms/step - loss: 1057987.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 214715.0312\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 56345.9180\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 38157.0859\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 12691.5049\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 6586.6431\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 3574.5071\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2733.6826\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2473.3430\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2167.4915\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1698.5902\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1371.8882\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1635.7764\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1527.2821\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1389.8030\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1270.3444\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1192.0122\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1132.0398\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1312.0009\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2001.1390\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1668.0889\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1447.2395\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1335.6097\n",
            "27/27 [==============================] - 1s 3ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 50 neurons and 13 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 6ms/step - loss: 1032135.1875\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 207458.5469\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 56198.2539\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 29662.0547\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 9191.0322\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 4709.5229\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 6020.9585\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3419.5051\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2808.8572\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2440.6692\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2302.6418\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2826.6853\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2164.3455\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1964.0568\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1467.1869\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1552.9459\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3459.6453\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1809.5345\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1388.2340\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1490.1656\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1420.5707\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1250.6715\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1428.8722\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1446.4163\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1194.5317\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1148.5029\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1216.3464\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1067.8717\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1065.0472\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1006.3925\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 999.7039\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1100.2794\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1067.9790\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1062.0797\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1049.0223\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1472.9091\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 50 neurons and 14 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 6ms/step - loss: 1091925.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 231756.9219\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 54999.0000\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 29212.2539\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 8280.0215\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 4201.5845\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3004.2327\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2427.1760\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2466.0703\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1595.0092\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1411.4482\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1343.2954\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1374.2850\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1458.3342\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2512.3008\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1908.4814\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1396.3772\n",
            "27/27 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 50 neurons and 15 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 6ms/step - loss: 1117555.6250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 288344.5625\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 77084.8984\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 42204.8516\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 21947.1934\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 7968.5693\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 5198.0718\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2141.4756\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1812.8160\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1706.4821\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1304.6235\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1346.4493\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2339.8076\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2069.7358\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2552.5212\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1758.0647\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 50 neurons and 16 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 6ms/step - loss: 933197.6875\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 144785.3438\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 46521.0273\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 21690.3164\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 7855.1138\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 5411.7881\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 4119.5444\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2888.4482\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2744.2283\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3479.1902\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2798.3506\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2016.1934\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1770.2283\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2087.2754\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1754.0717\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1604.5972\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1534.2679\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1410.0117\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1380.3888\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1388.2998\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1346.4095\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1855.4148\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2171.5664\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2917.1824\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2127.2219\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2011.8763\n",
            "27/27 [==============================] - 1s 5ms/step\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Program is running for 50 neurons and 17 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 6ms/step - loss: 988928.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 175253.7344\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 50943.5156\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 17603.3086\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 8626.2607\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 5560.1543\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 4582.8091\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3257.8369\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 3006.2688\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2554.8367\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 3968.3508\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2768.2434\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2095.8718\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2245.3657\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1893.3552\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2100.4468\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1552.0862\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1392.3484\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1270.9010\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1266.1829\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1195.1312\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1991.0931\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2193.0049\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1590.5564\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1751.6676\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1889.2631\n",
            "27/27 [==============================] - 1s 3ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 50 neurons and 18 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 5ms/step - loss: 1032025.1250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 186091.5156\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 52060.8164\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 26792.0215\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 10870.7070\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 6285.9834\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 4115.3867\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2965.5515\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 3692.0718\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2728.2739\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2043.5370\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1731.7747\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1512.5175\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1845.7312\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2166.1521\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1891.9557\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2478.0168\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2461.3818\n",
            "27/27 [==============================] - 1s 3ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 50 neurons and 19 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 5ms/step - loss: 962563.8125\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 150816.4375\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 46468.0938\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 22491.1836\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 9803.0166\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 6190.5215\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3578.0261\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2942.1472\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2185.8730\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3056.6440\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3215.5188\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3275.3203\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2608.3298\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2949.1357\n",
            "27/27 [==============================] - 1s 3ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 50 neurons and 20 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 6ms/step - loss: 997513.9375\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 185102.4375\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 88320.8438\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 27353.2344\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 15398.9561\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 8840.1270\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 6751.7285\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 5006.4648\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 3059.4456\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2947.5454\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2182.9856\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2112.5833\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2032.1923\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1898.8276\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2040.3910\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1789.5790\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1750.8789\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1817.1796\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1692.0190\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1533.9043\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1313.2451\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1621.0360\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1255.3173\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1416.5248\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1378.6104\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1269.1184\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 931.3984\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1133.7675\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1302.8909\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1519.5846\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1653.6497\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1764.9612\n",
            "27/27 [==============================] - 1s 3ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 50 neurons and 21 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 5ms/step - loss: 977778.1250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 166963.2656\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 48288.0586\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 25674.0879\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 11138.6660\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 11068.7090\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 6585.3223\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 3402.4790\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2497.1238\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2252.9043\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1696.2080\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1617.8097\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1525.6680\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1277.1216\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1404.5863\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2264.7258\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1735.7778\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1636.8685\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1299.6603\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Program is running for 50 neurons and 22 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 5ms/step - loss: 940876.8750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 129970.9531\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 43344.4102\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 21412.3086\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 8435.8154\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 6020.6748\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 4806.6064\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3892.4482\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3347.5820\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 4542.2661\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2193.5378\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2138.5603\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1281.7826\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1329.2858\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1501.8323\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1829.4449\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1417.3439\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1245.5415\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1358.0905\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1275.2609\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1108.1591\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1258.2452\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1332.4889\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1197.6300\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 975.5343\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1019.9160\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 887.4031\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 957.6364\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1108.5930\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1080.8721\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 974.1566\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 864.1681\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1071.2109\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1033.2888\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 859.1910\n",
            "Epoch 36/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 716.7926\n",
            "Epoch 37/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 691.1188\n",
            "Epoch 38/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 732.2368\n",
            "Epoch 39/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 884.7493\n",
            "Epoch 40/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1101.8501\n",
            "Epoch 41/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 929.9378\n",
            "Epoch 42/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 908.8926\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 50 neurons and 23 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 6ms/step - loss: 1034007.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 209389.9844\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 56404.2695\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 34636.3398\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 11540.6846\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 5636.4272\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3989.9539\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2267.0789\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2117.9285\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1714.4264\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1466.6262\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1367.8359\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1320.5637\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1018.8740\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1119.3606\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1548.6284\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2028.0345\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1484.3605\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1337.4946\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Program is running for 50 neurons and 24 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 7ms/step - loss: 980548.5625\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 175023.5781\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 49926.4336\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 22477.3926\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 9393.5332\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 6578.0854\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 5782.2900\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3473.5256\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2980.5627\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2901.2048\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3724.3389\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2634.5027\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2420.7771\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2279.3015\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1851.8936\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3886.0044\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1809.6854\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1365.3918\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1184.1735\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1354.4181\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1341.8485\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1235.1237\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1249.3025\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1257.7979\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Program is running for 50 neurons and 25 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 7ms/step - loss: 1005562.1875\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 171445.1250\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 49528.3828\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 33961.5820\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 17469.9531\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 9243.7168\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 5376.0020\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 4555.8823\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 3213.0776\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2149.5955\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2316.6528\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2075.2190\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2051.4626\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1440.9475\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1162.3599\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1602.8467\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1410.7784\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1749.4194\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1166.4596\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1081.4873\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1752.4432\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1446.0551\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 835.9604\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 888.8984\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1495.3302\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 803.8198\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 933.0845\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1086.7982\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 973.2162\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 12059.7754\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1663.5830\n",
            "27/27 [==============================] - 1s 3ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 50 neurons and 26 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 6ms/step - loss: 1002201.5625\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 181008.7500\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 50505.4766\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 25517.3125\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 11875.9697\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 6739.3188\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 7889.0664\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 5908.8188\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 3845.9202\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3309.7317\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2745.3975\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3313.3591\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2677.0496\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3203.6692\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2400.6052\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1890.2001\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1471.7985\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1257.5927\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1120.4620\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1278.1416\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1376.4620\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1389.5464\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1142.6080\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1108.6211\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1180.5148\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1098.0480\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1148.5341\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1031.7990\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 917.4776\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 949.1417\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1074.8502\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1190.4922\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1322.3871\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1061.1583\n",
            "27/27 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 50 neurons and 27 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 5ms/step - loss: 952328.5625\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 152100.0156\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 48020.3398\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 27954.4492\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 8797.9736\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 5976.5112\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 4166.3696\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3217.0981\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3640.8303\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2841.5850\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2594.7197\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3179.9473\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3455.7512\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2314.9631\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2330.3054\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2170.6726\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1698.2054\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2037.3799\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1622.4517\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1518.2312\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1285.5306\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1092.5967\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 979.1883\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 862.1432\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 858.5332\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 820.3995\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 776.5659\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 685.7128\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 752.6762\n",
            "Epoch 30/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 633.8573\n",
            "Epoch 31/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 680.1380\n",
            "Epoch 32/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 675.1912\n",
            "Epoch 33/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 664.0067\n",
            "Epoch 34/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 758.0737\n",
            "Epoch 35/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 848.4667\n",
            "27/27 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 50 neurons and 28 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 6ms/step - loss: 936457.1250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 129276.0781\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 44546.8359\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 29049.8789\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 11706.7627\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 6397.0913\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 5381.7280\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3830.0554\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2986.1489\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3082.1963\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2078.4675\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2390.3904\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3375.0945\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2891.8994\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2459.3398\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2313.4099\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 50 neurons and 29 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 7ms/step - loss: 1104966.3750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 208531.0625\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 54603.1562\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 33547.6094\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 9286.7158\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 6393.1006\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 4789.3770\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2317.1951\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2251.0078\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2055.6160\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2361.2283\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2975.6770\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2349.2063\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2138.3455\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1945.3448\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1717.1633\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1909.6469\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1619.8901\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1638.5211\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1888.1086\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1473.8822\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 2101.7524\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 1547.9700\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1344.8604\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1474.0654\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1741.4509\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1979.5712\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1426.7527\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1433.2090\n",
            "27/27 [==============================] - 1s 3ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Model hyperparameters used: \n",
            "  ['Adam', 0.1, 4]\n",
            "Program is running for 100 neurons and 0 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 8ms/step - loss: 802755.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 82271.6484\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 27679.9492\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 6544.6997\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 4416.7012\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2410.1636\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1895.1567\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1905.3491\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2124.3687\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2092.0012\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1345.9612\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1290.8284\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1298.1337\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1699.8134\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1560.3147\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1656.6058\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1545.1674\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 100 neurons and 1 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 6ms/step - loss: 632436.3125\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 34518.0547\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 7526.8770\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3889.5156\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2692.4956\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2042.6365\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1738.8715\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1703.7633\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1986.9725\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2757.7471\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2226.8333\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2102.8457\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2017.4791\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 100 neurons and 2 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 6ms/step - loss: 664319.6875\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 49529.1406\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 12293.1758\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 5365.3623\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2957.6953\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3086.8022\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3212.6157\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2822.1692\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2663.9026\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1802.7853\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1191.5822\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1199.9387\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1177.5625\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1033.1517\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1050.8693\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1148.0586\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 979.3823\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 938.5865\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 892.7732\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 910.3890\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1022.0670\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1107.8689\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1602.1083\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1112.7006\n",
            "27/27 [==============================] - 1s 5ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 100 neurons and 3 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 8ms/step - loss: 655097.8750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 51201.3164\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 26506.5781\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 9653.5938\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 4289.2852\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2572.8765\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2054.2871\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3718.9761\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2416.8333\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2332.2869\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1800.2185\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1621.6504\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1319.6667\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1350.2985\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1816.5800\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1713.5487\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1118.3372\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1083.8324\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2198.0281\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1842.9841\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2233.5959\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2581.7903\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1857.7493\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 100 neurons and 4 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 8ms/step - loss: 730862.3750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 62652.7383\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 32992.2188\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 7715.2666\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3656.6479\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 4647.3496\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2429.3489\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2274.0457\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1933.7944\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1708.0712\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1367.5420\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1603.5983\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1873.6235\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1926.8362\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2247.4065\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2057.0261\n",
            "27/27 [==============================] - 1s 5ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 100 neurons and 5 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 6ms/step - loss: 692295.8750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 39969.9805\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 9015.7734\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 3999.3081\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 4015.7078\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2411.8899\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2245.8979\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2085.0142\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1593.4464\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1795.1396\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1879.1241\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1619.0551\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1889.5619\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2273.2869\n",
            "27/27 [==============================] - 1s 5ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 100 neurons and 6 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 8ms/step - loss: 705365.5625\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 57709.3398\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 31225.1348\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 9394.0566\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 5474.5220\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 4450.4600\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3673.6042\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2664.0916\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2466.3896\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 4326.4111\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3274.7634\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2531.1006\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1864.1624\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1987.3307\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1959.4745\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2426.3806\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1705.1649\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1667.9343\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1643.5596\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2198.5793\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1989.3140\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1792.7076\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1497.1511\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1277.4935\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1504.1016\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1512.2207\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1632.7386\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1545.2810\n",
            "Epoch 29/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1527.5421\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 100 neurons and 7 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 7ms/step - loss: 830929.1250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 87516.3359\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 39130.2266\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 13174.2920\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3291.5920\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2261.5908\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2228.0564\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1661.4940\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1369.8147\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1447.9058\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1164.0906\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1338.0065\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1376.3552\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1660.4475\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1420.0245\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1177.2252\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 100 neurons and 8 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 6ms/step - loss: 690415.5625\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 50126.2070\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 20147.3516\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 9893.2598\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 6008.2085\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 3525.1021\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2883.0039\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2453.7451\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1756.3688\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1682.9399\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2106.8542\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1564.8085\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1643.9822\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1634.1794\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1694.8738\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1306.2668\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1245.7036\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1270.5605\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1806.5048\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1690.4752\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1654.3464\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1553.5327\n",
            "27/27 [==============================] - 1s 6ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 100 neurons and 9 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 6ms/step - loss: 784714.8750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 74092.4766\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 30277.8574\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 7033.0796\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 4056.4407\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 4614.4688\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3056.4651\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1945.2585\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1628.9769\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1919.2418\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1766.4174\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2230.2808\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1681.6744\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1379.7957\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1710.6620\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1813.9552\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1953.6166\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2155.0496\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1756.2395\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 100 neurons and 10 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 6ms/step - loss: 722066.5000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 73695.7344\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 14268.1650\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 4467.3823\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2419.8049\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2061.0845\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1949.2911\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1708.8635\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2023.4783\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1881.6804\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1538.1312\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1237.1782\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1308.3403\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1430.0852\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1447.9324\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1577.2607\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1462.6581\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 100 neurons and 11 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 7ms/step - loss: 690991.9375\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 56309.0898\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 40236.4609\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 9279.8477\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3687.5635\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2841.5012\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2594.3228\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2779.6338\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2462.7444\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2933.0115\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2370.7878\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2656.2981\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1894.6982\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1948.5726\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1589.4407\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1821.4220\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 6461.0195\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 15609.5420\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 4702.3208\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 7830.8809\n",
            "27/27 [==============================] - 1s 5ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 100 neurons and 12 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 749668.8750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 70157.9141\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 25082.5254\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 7418.9619\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 5075.0044\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2796.4226\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2354.3247\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1709.5383\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1365.4692\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1759.6749\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1143.5836\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1177.9829\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1238.4943\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1509.4144\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1633.6675\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3997.5413\n",
            "27/27 [==============================] - 1s 3ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 100 neurons and 13 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 7ms/step - loss: 806954.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 75840.6250\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 37323.8125\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 14967.8604\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 4205.3423\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2501.0166\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2166.5818\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2039.1505\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1757.6700\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1396.6990\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1524.4163\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1512.1936\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1508.1595\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1768.0248\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1902.7474\n",
            "27/27 [==============================] - 1s 6ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 100 neurons and 14 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 6ms/step - loss: 685786.5625\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 44443.2539\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 12280.8926\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 7820.7974\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 4203.0620\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3687.3894\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3504.0974\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 6144.6787\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3884.3501\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 6609.8091\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3754.8586\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 6045.0747\n",
            "27/27 [==============================] - 1s 5ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Program is running for 100 neurons and 15 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 8ms/step - loss: 764062.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 72561.4609\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 34820.7188\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 12007.9287\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3055.1965\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1766.2701\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1412.3531\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1213.4004\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 985.1761\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 881.4866\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1047.0209\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 912.1694\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1620.2914\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1754.6174\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1522.2355\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Program is running for 100 neurons and 16 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 6ms/step - loss: 713258.5625\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 59697.0039\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 36728.1641\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 8363.6328\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3844.8418\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2724.5930\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2001.1710\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1575.6887\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2214.7456\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1997.9135\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2378.3340\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1847.0834\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1862.0460\n",
            "27/27 [==============================] - 1s 6ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Program is running for 100 neurons and 17 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 7ms/step - loss: 709599.1875\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 61217.2617\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 30690.0781\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 5845.8140\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 4350.2275\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3467.1108\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2455.7373\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2303.9116\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1719.1123\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2564.9561\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1808.4329\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 4023.5410\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2502.9956\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1765.4557\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Program is running for 100 neurons and 18 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 6ms/step - loss: 767568.6875\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 72200.3125\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 27241.1953\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 5142.4434\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2810.8213\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1943.0565\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1708.9028\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1710.3901\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1628.3992\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1536.0992\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1351.4370\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1192.6389\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1232.3987\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1225.7771\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1231.4233\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1112.7745\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 926.6536\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 853.5918\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1033.0083\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1073.1276\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 859.4418\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 896.3267\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 829.2963\n",
            "Epoch 24/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 918.0870\n",
            "Epoch 25/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1086.8127\n",
            "Epoch 26/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1753.9462\n",
            "Epoch 27/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2375.2446\n",
            "Epoch 28/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1770.2659\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 100 neurons and 19 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 7ms/step - loss: 642783.2500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 44156.4688\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 9383.9932\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 4350.6284\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3958.3020\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2735.2195\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 3991.5547\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3415.7588\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2730.3203\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 7660.6958\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 3008.4673\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2278.5388\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1945.2622\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1872.5359\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1603.5059\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1515.6753\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1386.3196\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1113.8599\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1459.7924\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1291.0040\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1173.7955\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1323.0880\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1240.6685\n",
            "27/27 [==============================] - 1s 6ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 100 neurons and 20 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 6ms/step - loss: 798082.4375\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 64743.4102\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 15034.8330\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 6173.2451\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3672.8779\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2921.7087\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2233.1077\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2018.5024\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2090.9927\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1808.0272\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1420.8633\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1231.4434\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1342.3578\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1230.1498\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1723.6901\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3056.6206\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2703.9351\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2214.0042\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2140.0254\n",
            "27/27 [==============================] - 1s 5ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 100 neurons and 21 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 7ms/step - loss: 793056.3750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 81213.4609\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 18924.6777\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 4415.8662\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2254.3799\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1801.2668\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1727.7179\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2261.6548\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2103.5996\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2263.6599\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2418.9226\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2178.4446\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 100 neurons and 22 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 7ms/step - loss: 776534.8125\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 86016.2891\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 19921.4434\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 5839.0884\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3466.4875\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2683.4712\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2148.8350\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1915.7250\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1915.2013\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1662.0878\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1592.5609\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1591.0734\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1411.3110\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1465.8904\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1233.1884\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1490.4366\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1892.1567\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1480.7173\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1320.4847\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1299.6003\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 100 neurons and 23 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 7ms/step - loss: 671818.8750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 51542.0000\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 15612.8652\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 4351.1812\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2863.0447\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2531.5999\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1980.4989\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1618.6259\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1579.9794\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1478.7821\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1379.8092\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1232.8101\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1266.0989\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1225.4761\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2061.2195\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1664.9088\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1701.3182\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2306.0078\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3467.5571\n",
            "27/27 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Program is running for 100 neurons and 24 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 6s 7ms/step - loss: 713714.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 59619.0273\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 25577.7773\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 4732.1191\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3542.7871\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3259.8047\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2165.4373\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2167.0137\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1415.4171\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1445.6935\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1426.9092\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1168.7323\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1212.6108\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1286.6488\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1886.5844\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2078.9038\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1820.1201\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 100 neurons and 25 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 686054.3750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 55606.4844\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 24609.5703\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 6523.9468\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 4248.3071\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 3847.5391\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3052.6499\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 2537.3276\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1839.8103\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1524.7753\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1488.5114\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1526.4401\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1524.7467\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1471.6029\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1602.1996\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1524.6940\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1213.1462\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 961.8545\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1062.1447\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 979.0153\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 988.6532\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1159.6053\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1146.0618\n",
            "27/27 [==============================] - 1s 5ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Program is running for 100 neurons and 26 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 6ms/step - loss: 854505.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 103911.8984\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 32730.3789\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 8206.9854\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2282.9470\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1974.2253\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1342.5380\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1461.7961\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1590.3862\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1145.6654\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 961.7612\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1376.0686\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1096.9048\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1409.7026\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1196.7635\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1189.0969\n",
            "27/27 [==============================] - 1s 4ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Program is running for 100 neurons and 27 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 8ms/step - loss: 680804.1250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 51470.0391\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 19142.5449\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 3969.5852\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 4228.1890\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1930.8120\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2102.9524\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1732.9976\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1433.7247\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1153.1674\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 999.5159\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1496.3788\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1441.1674\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1473.7373\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1616.3201\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1137.9698\n",
            "27/27 [==============================] - 1s 5ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Program is running for 100 neurons and 28 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 7ms/step - loss: 698910.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 57197.5938\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 29740.7480\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 10405.6768\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 8833.2920\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 4341.9395\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2532.2952\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1786.1362\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2081.9731\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1902.8623\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1542.2036\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1462.3878\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1149.3875\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1228.4480\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1110.2675\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1019.4662\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1067.6592\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 965.6793\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1010.4731\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1206.6060\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1090.9452\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1059.2048\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 1078.7880\n",
            "27/27 [==============================] - 1s 5ms/step\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Program is running for 100 neurons and 29 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 7ms/step - loss: 745412.1250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 52224.4297\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 19302.2637\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 1s 6ms/step - loss: 7844.0156\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 3851.9565\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2644.9937\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2013.0304\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2147.9077\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1845.1042\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2138.7332\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2823.1060\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2406.5261\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1977.0454\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1821.0651\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1799.8995\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1964.4548\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 1675.7539\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 1661.7739\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1945.5623\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2107.4182\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 2401.8054\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 2916.7368\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3794.1143\n",
            "27/27 [==============================] - 1s 5ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Model hyperparameters used: \n",
            "  ['Adam', 0.1, 4]\n",
            "Program is running for 150 neurons and 0 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 11ms/step - loss: 544949.3750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 37707.3945\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 8975.6338\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 6825.4819\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3035.8499\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2035.0151\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1669.6477\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1639.2292\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1588.6561\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1701.8519\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1454.1443\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1447.4490\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1501.2100\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1699.2883\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1790.3293\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1982.4121\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2216.9294\n",
            "27/27 [==============================] - 1s 10ms/step\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Program is running for 150 neurons and 1 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 603363.1875\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 46635.5078\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 19117.5703\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 4668.5464\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2538.8020\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2381.8621\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1677.5028\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1569.5574\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2339.8928\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2000.5487\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1574.0682\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1639.9025\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1876.6331\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Program is running for 150 neurons and 2 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 549592.6250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 34647.4766\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 7789.7051\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 3114.3215\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2830.1079\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1663.6949\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1777.0040\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1919.0679\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1480.3911\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1483.5944\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1436.6123\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1527.1882\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1624.8475\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1095.6558\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1149.1183\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1743.4354\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1889.8291\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1567.9902\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1734.4402\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Program is running for 150 neurons and 3 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 636793.8125\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 49953.0352\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 23371.0859\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 5849.8833\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3164.0430\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2607.9678\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2579.6318\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2345.7151\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2353.0073\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1715.2375\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2126.7905\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1841.2908\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1804.1873\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1659.9774\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1556.3810\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1448.9932\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2033.4587\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1830.6793\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1893.0986\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1913.1615\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1977.9462\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Program is running for 150 neurons and 4 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 11ms/step - loss: 502457.5625\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 29900.4668\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 8336.8691\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3076.5757\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2574.2505\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2370.9006\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2323.5305\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 4865.3403\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 9140.6641\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 6406.9897\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3734.6072\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3626.0261\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Program is running for 150 neurons and 5 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 11ms/step - loss: 417262.2812\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 9585.9932\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3752.4539\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 4118.0532\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 4363.7705\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3279.5732\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2234.6152\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2648.7283\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2342.7424\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 2490.8086\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1963.2258\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1634.3243\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2228.1799\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2492.7781\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2149.0371\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1737.1609\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2239.7922\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Program is running for 150 neurons and 6 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 549763.1250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 32953.1992\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 13877.2803\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 4716.6455\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 3103.1650\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2275.8984\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2779.3035\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2511.6133\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2706.7805\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2469.4412\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1918.6045\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1883.7904\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1823.7867\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2134.6377\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1961.3672\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2150.7263\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2133.7917\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2113.3176\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Program is running for 150 neurons and 7 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 546877.0000\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 36593.7930\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 8176.0137\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1826.9843\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1590.6483\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1406.7068\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1314.1115\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1051.0323\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1120.6338\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1254.2526\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1208.1498\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1180.6882\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1049.1686\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1063.1904\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1075.1652\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1366.1305\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1191.9247\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1155.8673\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Program is running for 150 neurons and 8 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 8ms/step - loss: 469752.6250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 25143.5410\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 6843.9087\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 4335.4937\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3539.4482\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2212.5369\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2318.4590\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2689.4829\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2958.4614\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2525.8323\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3664.0396\n",
            "27/27 [==============================] - 1s 8ms/step\n",
            "7/7 [==============================] - 0s 12ms/step\n",
            "Program is running for 150 neurons and 9 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 12ms/step - loss: 574812.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 61170.7930\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 10063.8193\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 4689.5762\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 6211.0708\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3740.8328\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3660.8538\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 3948.7070\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3837.9543\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2833.4353\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2607.5208\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2902.2288\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2758.3608\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3529.8867\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3826.4294\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 4331.5435\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Program is running for 150 neurons and 10 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 11ms/step - loss: 517046.4062\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 32969.3594\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 13217.9648\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 3586.8667\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2822.8667\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3013.5933\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2703.6941\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2214.9644\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1854.0991\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1707.9895\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1960.7521\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1817.5930\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1443.4640\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1475.2885\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1501.8702\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1729.5411\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2373.4492\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2014.5485\n",
            "27/27 [==============================] - 1s 8ms/step\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Program is running for 150 neurons and 11 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 521351.7188\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 41719.6797\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 18268.9238\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3861.9885\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2512.9968\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2138.2969\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2081.1685\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1548.6992\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1746.7307\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1545.4050\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1657.6637\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1297.7023\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1551.4677\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1315.1660\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1537.3389\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1626.9945\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1634.4004\n",
            "27/27 [==============================] - 1s 9ms/step\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Program is running for 150 neurons and 12 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 9ms/step - loss: 619927.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 47225.5820\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 18088.0195\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 4939.6616\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2708.0945\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2196.3567\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 13ms/step - loss: 1871.6497\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1472.7644\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1438.3019\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1383.6289\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1763.2897\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2027.1145\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1978.4142\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1897.7233\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 2179.2214\n",
            "27/27 [==============================] - 1s 6ms/step\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Program is running for 150 neurons and 13 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 565938.8125\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 42543.5391\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 12137.1211\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 6538.7969\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2010.9513\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1844.7520\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1814.9875\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1496.9895\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1706.1388\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1667.3491\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1528.6283\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1306.1172\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1229.4081\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 938.9903\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1070.4570\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1345.0830\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1091.4010\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1137.9819\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 986.0624\n",
            "27/27 [==============================] - 1s 9ms/step\n",
            "7/7 [==============================] - 0s 11ms/step\n",
            "Program is running for 150 neurons and 14 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 9ms/step - loss: 571346.7500\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 50082.0078\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 11689.3389\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 5247.2974\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3486.4077\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2695.2512\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 2408.1541\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2127.0647\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 2214.2190\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1734.2179\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1428.3571\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1576.6775\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1624.8438\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1542.1815\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1610.4689\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1551.4519\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 11ms/step\n",
            "Program is running for 150 neurons and 15 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 11ms/step - loss: 589406.6875\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 50544.9102\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 19638.1934\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 5646.7661\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2893.9910\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1979.1868\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1901.3997\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1448.4058\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1363.7632\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1292.5128\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1681.5643\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1224.0769\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1588.2634\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1633.5342\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1377.7595\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1346.8485\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1634.1736\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 12ms/step\n",
            "Program is running for 150 neurons and 16 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 12ms/step - loss: 626197.5625\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 47757.9180\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 13343.6934\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3724.7834\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2220.1494\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2075.6770\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2987.1995\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3211.8254\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2537.4812\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 4291.2881\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2194.2537\n",
            "27/27 [==============================] - 1s 6ms/step\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Program is running for 150 neurons and 17 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 572944.1250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 42409.6016\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 17583.7598\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 3593.4019\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2268.1880\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1767.2108\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1650.6642\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1665.8572\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1764.3456\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1276.0142\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1300.1489\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1570.9401\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1606.3843\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1958.2288\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1228.5223\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1744.8848\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 2136.1394\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2753.7278\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2905.1208\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2296.7986\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Program is running for 150 neurons and 18 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 10ms/step - loss: 677739.8750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 9819.9248\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 4298.9404\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3449.6067\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2805.4404\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2810.5701\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1948.0286\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1618.0846\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1458.0724\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1274.1428\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1351.7777\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1143.4503\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1677.4376\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1685.6654\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1602.9924\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1647.4641\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1172.9548\n",
            "27/27 [==============================] - 1s 8ms/step\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Program is running for 150 neurons and 19 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 9ms/step - loss: 555369.8125\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 28862.8281\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 9955.1172\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 4016.3938\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2937.2505\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2481.3774\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2140.6316\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2007.5247\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1770.4966\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1983.3196\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2180.6316\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2800.4734\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2097.8008\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1797.4183\n",
            "27/27 [==============================] - 1s 6ms/step\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Program is running for 150 neurons and 20 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 554404.0625\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 42046.8320\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 9369.1230\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 3768.2822\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3309.4358\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3519.3245\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3098.3506\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2395.0286\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3740.7659\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3206.1768\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3433.8328\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2703.2300\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3734.8418\n",
            "27/27 [==============================] - 5s 8ms/step\n",
            "7/7 [==============================] - 0s 11ms/step\n",
            "Program is running for 150 neurons and 21 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 568628.3125\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 42324.4219\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 24868.7051\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 4279.9551\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2579.0669\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 2159.5347\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1585.7167\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1829.8132\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1848.3273\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1551.0328\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1156.8356\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1254.0830\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1193.4053\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1289.6278\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2111.7764\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2957.8882\n",
            "27/27 [==============================] - 1s 6ms/step\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Program is running for 150 neurons and 22 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 4s 9ms/step - loss: 580369.8750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 40387.4844\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 10353.9111\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 4564.5840\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2973.0837\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3202.1956\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3539.5630\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 3787.1812\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3208.8508\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2637.8445\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2991.5239\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 4050.8818\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2146.7156\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2031.7810\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1623.2201\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1533.6671\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1589.9755\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1567.9148\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1748.6050\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1829.8446\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1817.9779\n",
            "27/27 [==============================] - 1s 9ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Program is running for 150 neurons and 23 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 610391.8750\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 36148.6836\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 10181.2373\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 4880.2251\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 3466.2583\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2172.6892\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2876.3735\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3050.6719\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2463.5549\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1993.3969\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1779.2953\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1608.5081\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 5384.3296\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2273.0874\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2932.3069\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3548.3533\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 3739.1196\n",
            "27/27 [==============================] - 1s 9ms/step\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Program is running for 150 neurons and 24 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 574011.4375\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 45255.9062\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 22963.2090\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3449.7737\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2402.4214\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2019.6188\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1856.1489\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1587.4972\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1939.9235\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2126.4851\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1749.1547\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2227.3455\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1611.5084\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 14ms/step\n",
            "Program is running for 150 neurons and 25 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 9ms/step - loss: 529010.3125\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 42733.4961\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 15294.4902\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 4574.2974\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2645.9683\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1994.8206\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1562.2112\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1727.2109\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1398.3309\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1437.8942\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1101.9644\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1099.6041\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1083.6998\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1060.5090\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1176.8088\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1577.0616\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1400.2991\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1706.8362\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1532.4347\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Program is running for 150 neurons and 26 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 11ms/step - loss: 532757.1250\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 39453.4297\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 8050.5239\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2533.5056\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1908.3104\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1778.7828\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1754.8286\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2099.1538\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1810.6295\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1624.6056\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1865.4414\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1772.8645\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 2389.3826\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1725.0148\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1716.6129\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Program is running for 150 neurons and 27 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 11ms/step - loss: 487124.0312\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 12790.9062\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 6135.5049\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 3366.4214\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 2236.6213\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2444.9990\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2575.4299\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2946.2236\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2606.9893\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2833.6152\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Program is running for 150 neurons and 28 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 3s 9ms/step - loss: 513415.6875\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 34306.6836\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 7118.3999\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2952.2583\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2193.0881\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 2604.9746\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1970.0345\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1671.3690\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1612.2069\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1610.0421\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1364.2281\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1322.4028\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1123.2543\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1177.0746\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1212.6947\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 931.5343\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 993.6675\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 886.9743\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 12ms/step - loss: 1408.3104\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1301.6625\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1489.9209\n",
            "Epoch 22/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2026.9497\n",
            "Epoch 23/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1663.3669\n",
            "27/27 [==============================] - 1s 8ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Program is running for 150 neurons and 29 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - 5s 10ms/step - loss: 502922.5312\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 38024.5625\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 13214.9082\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 6157.7148\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 3081.3359\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1862.0859\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1769.3378\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1910.1666\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 2204.4480\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 2069.8662\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 2s 9ms/step - loss: 1799.3081\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1532.6960\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 1767.5533\n",
            "Epoch 14/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1280.5806\n",
            "Epoch 15/50\n",
            "209/209 [==============================] - 2s 11ms/step - loss: 1165.4264\n",
            "Epoch 16/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1042.8118\n",
            "Epoch 17/50\n",
            "209/209 [==============================] - 2s 10ms/step - loss: 1120.5543\n",
            "Epoch 18/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1080.9019\n",
            "Epoch 19/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1056.3646\n",
            "Epoch 20/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1187.2029\n",
            "Epoch 21/50\n",
            "209/209 [==============================] - 2s 8ms/step - loss: 1391.1385\n",
            "27/27 [==============================] - 1s 6ms/step\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Model hyperparameters used: \n",
            "  ['Adam', 0.1, 8]\n",
            "Program is running for 200 neurons and 0 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 17ms/step - loss: 790138.9375\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 71604.8281\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 41315.4844\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 20721.1094\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 5625.6016\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 3130.5989\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 2217.6074\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1738.9736\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1483.7059\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1348.4662\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1485.5487\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1325.5048\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1385.7175\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1338.8318\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1269.2823\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1699.0756\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1487.1183\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1258.3190\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1204.6571\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1377.4384\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1483.9160\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1179.4620\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1564.7206\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1405.6143\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1600.9690\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1445.8983\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1107.0414\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1045.2810\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 923.3656\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1087.3417\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1192.2659\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1410.4171\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1118.7705\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1216.9270\n",
            "27/27 [==============================] - 1s 11ms/step\n",
            "7/7 [==============================] - 0s 13ms/step\n",
            "Program is running for 200 neurons and 1 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 24ms/step - loss: 881094.8125\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 105544.9766\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 41906.9727\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 27984.1699\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 7587.0020\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 6554.8491\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 2554.0867\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 2239.4043\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1924.5991\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1916.1771\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 2315.9160\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 2036.4967\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1899.1483\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1698.2133\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1840.5199\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 2282.0259\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 3109.8447\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 3782.8430\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 3388.9797\n",
            "27/27 [==============================] - 1s 10ms/step\n",
            "7/7 [==============================] - 0s 13ms/step\n",
            "Program is running for 200 neurons and 2 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 22ms/step - loss: 845188.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 91555.2656\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 45605.4531\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 11779.5996\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 4003.7771\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 2614.0823\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 2021.0093\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1749.9647\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1602.5109\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1269.3752\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1393.3358\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1521.9448\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1480.0948\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1338.0990\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1545.7010\n",
            "27/27 [==============================] - 1s 11ms/step\n",
            "7/7 [==============================] - 0s 12ms/step\n",
            "Program is running for 200 neurons and 3 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 19ms/step - loss: 768344.5625\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 63554.5820\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 37320.7422\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 22774.3281\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 9187.0713\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 3861.2263\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 2621.0242\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 2328.4465\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1897.3843\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1489.2181\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1584.4204\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1328.8826\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1254.0298\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1267.5813\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1259.7524\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1432.0135\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1054.7323\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1010.7534\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1195.2332\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1072.7980\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1490.3348\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1129.3264\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1114.4092\n",
            "27/27 [==============================] - 1s 8ms/step\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Program is running for 200 neurons and 4 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 16ms/step - loss: 805337.5625\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 73523.3047\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 38228.7969\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 10851.5098\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 3847.0681\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 2727.0640\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1945.5524\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1322.3330\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1424.0452\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1354.0758\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1174.9360\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1264.4902\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1016.7527\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1066.1837\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1095.7740\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1150.0208\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1166.9736\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1153.4052\n",
            "27/27 [==============================] - 1s 9ms/step\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Program is running for 200 neurons and 5 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 16ms/step - loss: 691207.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 33389.0742\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 6735.0508\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 3350.6743\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 2084.0403\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1721.5417\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 2172.5056\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 2175.9900\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 2237.0281\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1992.1440\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1984.2810\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Program is running for 200 neurons and 6 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 18ms/step - loss: 912648.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 120482.2969\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 45262.5508\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 27399.4590\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 8493.5879\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 4432.9458\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 3290.5784\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 2563.9937\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1927.9789\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1708.7682\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1620.7808\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1620.8450\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1367.1296\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1313.1304\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1145.4230\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1037.4978\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 924.9811\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 976.7386\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 970.3893\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1016.7448\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 798.7078\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 874.2629\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 935.9321\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1095.5134\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 873.1543\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 897.0791\n",
            "27/27 [==============================] - 1s 9ms/step\n",
            "7/7 [==============================] - 0s 11ms/step\n",
            "Program is running for 200 neurons and 7 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 21ms/step - loss: 707293.2500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 50710.5938\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 38519.8086\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 12075.0098\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 5302.3560\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 3638.6091\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 2764.5684\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 2323.1025\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1637.9968\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1417.6494\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 2063.5449\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1561.9235\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1703.9506\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1361.1920\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1588.5385\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1467.7179\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1158.4977\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1158.0880\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1507.2413\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1359.4535\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1377.7526\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1358.6897\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1792.5653\n",
            "27/27 [==============================] - 1s 8ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Program is running for 200 neurons and 8 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 22ms/step - loss: 827995.3125\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 86897.7188\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 39434.2070\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 9165.6924\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 3411.7390\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 2754.8347\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1829.3661\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1635.6809\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1580.0254\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1715.9459\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1829.8125\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 2858.1265\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 2943.8699\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 3014.5908\n",
            "27/27 [==============================] - 1s 8ms/step\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Program is running for 200 neurons and 9 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 22ms/step - loss: 748560.5625\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 56884.5547\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 32260.3477\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 11511.9980\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 4304.3394\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 3045.8628\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 2388.6379\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 2020.4354\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1846.3994\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1733.1993\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1732.5248\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1640.0275\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1503.9735\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1315.5131\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1371.0068\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1367.6821\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1201.3052\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1194.0361\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1185.1886\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1075.2318\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1195.4954\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1386.6509\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1588.6567\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1489.0160\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1414.1584\n",
            "27/27 [==============================] - 1s 9ms/step\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Program is running for 200 neurons and 10 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 21ms/step - loss: 768638.3750\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 66042.6719\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 35240.5391\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 9046.4199\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 5242.8853\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 3501.0251\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 2668.8645\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1737.9575\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1515.5742\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1357.6011\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1416.7291\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1386.3698\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1339.7355\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1286.9100\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1347.4812\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1959.2848\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1815.7565\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1991.1818\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 2102.4226\n",
            "27/27 [==============================] - 1s 10ms/step\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Program is running for 200 neurons and 11 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 17ms/step - loss: 774421.3125\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 69840.9062\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 40978.9922\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 23898.2051\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 6586.5557\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 3754.9048\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1893.4088\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1532.6404\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1381.8472\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1235.7675\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1188.1362\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1059.9994\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 976.2570\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 898.1417\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 879.5941\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1054.7252\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1437.2571\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1561.5852\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1349.5209\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 996.9999\n",
            "27/27 [==============================] - 1s 9ms/step\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Program is running for 200 neurons and 12 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 23ms/step - loss: 751958.3750\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 64392.6250\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 40353.4297\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 19384.0664\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 6981.2207\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 3807.8135\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 2308.0701\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1686.6636\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1477.1696\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1093.7974\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1079.7435\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1189.6221\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1017.9422\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 851.6168\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1041.9060\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1072.4626\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 849.2247\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 885.5323\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1000.1868\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1065.0490\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1157.4490\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1072.2090\n",
            "27/27 [==============================] - 1s 7ms/step\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Program is running for 200 neurons and 13 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 23ms/step - loss: 733450.8125\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 58450.7148\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 36808.1641\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 23773.9062\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 6842.7666\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 2651.3359\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1459.1708\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1267.8790\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1547.2621\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1522.6718\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1328.4503\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1226.1122\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1192.1025\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1162.6929\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1160.8314\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 978.6700\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 993.8319\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1018.2874\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 855.6251\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 928.5822\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 816.8296\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1028.0969\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1037.7393\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 824.7913\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1128.9108\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1108.7234\n",
            "27/27 [==============================] - 1s 10ms/step\n",
            "7/7 [==============================] - 0s 12ms/step\n",
            "Program is running for 200 neurons and 14 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 18ms/step - loss: 812541.1875\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 79100.0156\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 36213.5859\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 12753.7197\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 4571.6523\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 2843.5305\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 2487.0947\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 2361.3406\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 2100.0090\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1823.8083\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1423.0194\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1410.7219\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1490.5537\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1505.5239\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1555.2328\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1470.0099\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1175.3677\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 1170.1986\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1235.6146\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1200.2144\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1066.8302\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1184.4166\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1491.0027\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1364.9097\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1182.6395\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1206.2429\n",
            "27/27 [==============================] - 1s 9ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Program is running for 200 neurons and 15 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 19ms/step - loss: 725907.6250\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 48942.9297\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 23374.5254\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 6420.1045\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 2892.1299\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 2540.3057\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1896.5948\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1752.1497\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1290.5520\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1228.3097\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 925.9950\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1019.1573\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1040.4260\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1206.5624\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 989.2023\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 1282.6226\n",
            "27/27 [==============================] - 1s 8ms/step\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Program is running for 200 neurons and 16 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 19ms/step - loss: 760023.7500\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 55781.6758\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 30205.0449\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 10260.0000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 5032.1958\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 3517.4004\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 2620.3110\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 2047.2053\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1420.9965\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 992.1003\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 945.9604\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1101.1078\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1168.2566\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1141.4302\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1214.5277\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1063.1693\n",
            "27/27 [==============================] - 1s 8ms/step\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Program is running for 200 neurons and 17 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 15ms/step - loss: 896027.9375\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 113971.0078\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 41919.4180\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 14614.2129\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 3072.0083\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 2466.4636\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1783.6298\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1701.4115\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1678.6702\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1442.0793\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1060.7524\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1124.3702\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1235.7061\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1190.3639\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1379.5341\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1408.6577\n",
            "27/27 [==============================] - 1s 8ms/step\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Program is running for 200 neurons and 18 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 19ms/step - loss: 771449.0625\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 61488.2383\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 41338.3047\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 18692.3867\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 5294.2119\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 2873.5867\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1606.2750\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1665.5950\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1598.6057\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1431.4668\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1339.2986\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1598.6761\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1345.4503\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1227.8569\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1431.9707\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1868.5182\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1761.4211\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1621.5227\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1724.8975\n",
            "27/27 [==============================] - 1s 8ms/step\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Program is running for 200 neurons and 19 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 8s 18ms/step - loss: 691528.3750\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 39965.3008\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 23151.6562\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 11307.5381\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 5832.9331\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 3860.3228\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 3055.9153\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1848.7709\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1731.9832\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 2150.2688\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 2254.3938\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1837.8212\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 2174.1746\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 6079.6064\n",
            "27/27 [==============================] - 1s 11ms/step\n",
            "7/7 [==============================] - 0s 15ms/step\n",
            "Program is running for 200 neurons and 20 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 22ms/step - loss: 669294.6875\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 37693.0586\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 19932.4883\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 7990.5913\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 5259.2520\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 2742.2683\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1940.0240\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 2881.5005\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 2133.4990\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1831.8743\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1478.6505\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1226.8456\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1147.0386\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 968.2975\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 928.9311\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 956.8598\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1331.2875\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1000.8720\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 898.2463\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1663.6755\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1298.5087\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1193.4091\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1297.0940\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 3s 29ms/step - loss: 1592.7443\n",
            "27/27 [==============================] - 1s 9ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Program is running for 200 neurons and 21 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 20ms/step - loss: 797286.0625\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 72838.2891\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 33855.8516\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 7582.4043\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 3463.6943\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 2306.3940\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 2141.0044\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 3s 28ms/step - loss: 2671.6707\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 5s 46ms/step - loss: 2390.5911\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1720.2904\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1560.7373\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1470.7415\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1548.7079\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1531.8184\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1769.9314\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1823.6576\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 2129.5652\n",
            "27/27 [==============================] - 1s 9ms/step\n",
            "7/7 [==============================] - 0s 13ms/step\n",
            "Program is running for 200 neurons and 22 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 20ms/step - loss: 785531.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 34698.1875\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 12247.5225\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 6458.1694\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 4151.8638\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 2921.9644\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 2871.5310\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 2243.9939\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1713.4617\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1875.2188\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1614.2592\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1471.6429\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1372.9469\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1548.1455\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1425.1193\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1319.0752\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1217.8926\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1324.0483\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1223.4889\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1273.2516\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1181.0558\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1211.9429\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1274.5425\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1115.7408\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 969.3677\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 970.0880\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 985.6058\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 800.0357\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 780.3272\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 622.9993\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 678.2828\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 628.1608\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 682.9980\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 724.1769\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1309.0265\n",
            "27/27 [==============================] - 1s 8ms/step\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "Program is running for 200 neurons and 23 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 18ms/step - loss: 852436.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 93976.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 38578.7383\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 20205.0293\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 5923.2769\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 2923.8809\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1927.8141\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1461.0676\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1245.8854\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1125.7179\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1364.8174\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1476.0078\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1531.8995\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1466.3684\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1411.7441\n",
            "27/27 [==============================] - 1s 11ms/step\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Program is running for 200 neurons and 24 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 8s 27ms/step - loss: 753941.0000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 64288.9219\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 35652.1445\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 11733.7822\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 4618.4663\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 2868.2993\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1834.9111\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1815.4409\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 2389.8333\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 2902.6064\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1936.3284\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1874.5707\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1400.3508\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1241.2551\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1458.2252\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1219.6932\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1351.2539\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1108.4872\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 891.9045\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 953.7921\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1026.5480\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 994.7979\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1121.6577\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 960.5825\n",
            "27/27 [==============================] - 1s 8ms/step\n",
            "7/7 [==============================] - 0s 12ms/step\n",
            "Program is running for 200 neurons and 25 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 5s 19ms/step - loss: 842119.1250\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 86532.0547\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 41110.5039\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 29739.1465\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 11383.2852\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 3302.1387\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 2020.8771\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 2138.9080\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1491.3433\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1239.7383\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1245.7743\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1192.4668\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1448.7854\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 1238.2373\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1194.9061\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1159.3516\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1305.6039\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1325.5184\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 2667.0400\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1014.7764\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 993.7386\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 943.8146\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 869.6000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 784.4918\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 768.9438\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 840.0026\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 876.2840\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 688.3940\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 648.9209\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 588.7353\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 615.7809\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 640.9271\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 719.6387\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 792.9612\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 773.3489\n",
            "27/27 [==============================] - 1s 9ms/step\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Program is running for 200 neurons and 26 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 24ms/step - loss: 782731.6875\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 67144.6484\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 38606.6914\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 11687.4678\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 4698.7100\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 2691.6277\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 30ms/step - loss: 1825.8988\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 3s 27ms/step - loss: 1541.1428\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1103.9003\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1058.8981\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 956.2338\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1037.9712\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1033.9706\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1140.5964\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1026.8915\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1249.4354\n",
            "27/27 [==============================] - 1s 10ms/step\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "Program is running for 200 neurons and 27 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 23ms/step - loss: 786170.4375\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 56448.2695\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 16454.3047\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 3874.9775\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 2168.4871\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 2016.3091\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1153.1804\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1171.8467\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1171.9960\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1119.5210\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1193.0869\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1147.9067\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1116.8081\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1498.6039\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1345.1558\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1303.1742\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1317.3571\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1320.0208\n",
            "27/27 [==============================] - 1s 9ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Program is running for 200 neurons and 28 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 6s 22ms/step - loss: 726383.3125\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 55478.0664\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 34838.8984\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 13898.9570\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 5826.5605\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 4154.6787\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 2964.3254\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1979.7549\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1570.8052\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1716.8674\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1901.2183\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1383.0638\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1370.9633\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1357.1422\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 1656.6917\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1565.5657\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1251.7567\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 3s 26ms/step - loss: 1111.6249\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 922.4539\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 920.2363\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 924.8953\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 1004.7877\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1079.5273\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1019.3557\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 877.6258\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 934.3541\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 749.4391\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 867.3129\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1053.6179\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1225.9119\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 1456.6749\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1205.7429\n",
            "27/27 [==============================] - 1s 10ms/step\n",
            "7/7 [==============================] - 0s 13ms/step\n",
            "Program is running for 200 neurons and 29 replicate ----->\n",
            "\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 4s 17ms/step - loss: 752502.1250\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 61605.6953\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 38916.3398\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 15041.0469\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 3821.8416\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 2357.3352\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 1698.4952\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 1554.2495\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 1469.8942\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1654.4424\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1458.1887\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1192.3466\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 915.0204\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 891.4306\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 947.8710\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 818.9308\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 797.6755\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 819.0289\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 975.5649\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 919.8935\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 1159.1516\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 1240.0837\n",
            "27/27 [==============================] - 1s 8ms/step\n",
            "7/7 [==============================] - 0s 9ms/step\n",
            "Progress: Collecting outputs.......\n",
            "\n",
            "\n",
            "Best model (neurons, replicate, rmse):  150 29 690.1146800012025\n",
            "\n",
            "Average scores:\n",
            "    neurons         rmse       mape   R  elapsed_time\n",
            "0       10  1418.275846  57.335953 NaN     60.893538\n",
            "1       30  1523.124858  61.970504 NaN     36.387973\n",
            "2       50  1429.718332  55.700955 NaN     34.294601\n",
            "3      100  1246.292320  49.956805 NaN     29.306769\n",
            "4      150  1152.468208  47.175611 NaN     36.517043\n",
            "5      200  1342.629326  53.701477 NaN     48.446384\n",
            "\n",
            "Standard_deviations:\n",
            "    neurons        rmse       mape   R  elapsed_time\n",
            "0       10  167.999763  12.096470 NaN     18.458901\n",
            "1       30  150.415799  12.827726 NaN      6.811732\n",
            "2       50  193.493220  12.970503 NaN      9.651426\n",
            "3      100  263.726298  13.109802 NaN      7.055904\n",
            "4      150  288.607437  13.572447 NaN      6.767898\n",
            "5      200  244.493992  14.438479 NaN     14.315199\n",
            "\n",
            "Minimums:\n",
            "    neurons         rmse       mape   R  elapsed_time\n",
            "0       10  1007.027012  30.812314 NaN     36.593046\n",
            "1       30  1231.310299  39.167179 NaN     24.408974\n",
            "2       50   982.638330  35.203966 NaN     20.159420\n",
            "3      100   719.754035  29.002646 NaN     17.991249\n",
            "4      150   690.114680  23.966015 NaN     24.011475\n",
            "5      200   782.602141  23.400517 NaN     23.497332\n",
            "\n",
            "Maximums:\n",
            "    neurons         rmse       mape   R  elapsed_time\n",
            "0       10  1677.894579  78.603602 NaN     87.094268\n",
            "1       30  1905.754612  89.606967 NaN     50.870847\n",
            "2       50  1775.394758  81.896082 NaN     52.112366\n",
            "3      100  1624.257252  78.319822 NaN     45.826213\n",
            "4      150  1681.390212  76.561422 NaN     48.647528\n",
            "5      200  1770.079100  86.814724 NaN     81.775010\n",
            "\n",
            "Progress: All works are done successfully, congratulations!!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "neurons = np.array([10, 30, 50, 100, 150,200])\n",
        "\n",
        "best_hyper_parameters = [['Adam', 0.1, 4],# 10N model\n",
        "                      ['Adam', 0.1, 4], # 30N model\n",
        "                      ['Adam', 0.1, 4], # 50N model\n",
        "                      ['Adam', 0.1, 4], # 1000N model\n",
        "                      ['Adam', 0.1, 4], # 150N model\n",
        "                      ['Adam', 0.1, 8] # 200N model\n",
        "                   ]\n",
        "\n",
        "\n",
        "#sl_model_output = LSTM_model(neurons, best_hyper_parameters, epochs = 100, num_replicates = 30)\n",
        "\n",
        "sl_model_output = LSTM_model(neurons, best_hyper_parameters,\n",
        "                          epochs = 50, num_replicates = 30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  #plotting the true values and predited values for the best model on the training set\n",
        "  best_replicate = sl_model_output['best_model']['replicate']\n",
        "\n",
        "  plt.plot(y_train,'k',linewidth = 1.5)\n",
        "  plt.plot( sl_model_output['train_predictions'][0][best_replicate],'mediumblue',linewidth = 1.5)\n",
        "  #plt.plot(test_predict_plot_data,'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"(a)\")\n",
        "  plt.legend(['True value', 'Predicted value in train set'], loc = 'upper left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "YRR0LZbnJISH",
        "outputId": "eb5bd06d-d1fd-4fa7-ee98-c3db57a3abc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7d94464b1720>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  #plotting the true and predicted values on the test set\n",
        "  best_replicate = sl_model_output['best_model']['replicate']\n",
        "\n",
        "  plt.plot(y_test,'k',linewidth = 1.5)\n",
        "  plt.plot( sl_model_output['test_predictions'][0][best_replicate],'mediumblue',linewidth = 1.5)\n",
        "  #plt.plot(test_predict_plot_data,'darkgreen',linewidth = 1.5)\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Close price')\n",
        "  plt.title(\"True vs Predicted value of best model\")\n",
        "  plt.legend(['True value', 'Predicted value in test set'], loc = 'upper left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "TnDNQgIpKEK7",
        "outputId": "b26bb6f2-ecd8-487a-c1c7-c60a22fbacd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7d9338f81600>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tyvfu0oT_DOO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "49083f23-aea9-4132-e7ef-6b542adc9cb4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "  #creating a boxplot to visualize the distribution of RMSE scores\n",
        "  fig = plt.figure(figsize = (6,5))\n",
        "  plt.boxplot(sl_model_output['scores']['rmse'], patch_artist=True)\n",
        "  plt.xticks([1,2,3,4,5,6], ['10', '30', '50', '100', '150', '200'])\n",
        "  plt.xlabel('Number of neurons')\n",
        "  plt.ylabel('RMSE')\n",
        "  #fig.savefig(data_path+\"rmse_boxplots.png\",dpi=600)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  #creating a subplot with two boxplots to visualize the ditribution of evaluation metrices (RMSE and MAPE)\n",
        "  fig = plt.figure(figsize = (18,5))\n",
        "  plt.subplot(131)\n",
        "  p1 = plt.boxplot(sl_model_output['scores']['rmse'],patch_artist=True)\n",
        "  for i, box in enumerate(p1['boxes']):\n",
        "    # change outline color\n",
        "    box.set(color= 'blue', linewidth = 1.2)\n",
        "    # change fill color\n",
        "    box.set(facecolor = 'mediumblue')\n",
        "  plt.xticks([1,2,3,4,5,6], ['10', '30', '50', '100', '150', '200'])\n",
        "  plt.title(\"RMSE Boxplots\")\n",
        "  plt.xlabel('Number of neurons')\n",
        "  plt.ylabel('RMSE')\n",
        "\n",
        "  plt.subplot(132)\n",
        "  p2 = plt.boxplot(sl_model_output['scores']['mape'],patch_artist=True)\n",
        "  for i, box in enumerate(p2['boxes']):\n",
        "    #change outline color\n",
        "    box.set(color= 'blue', linewidth = 1.2)\n",
        "    # change fill color\n",
        "    box.set(facecolor = 'indigo')\n",
        "\n",
        "  plt.xticks([1,2,3,4,5,6], ['10', '30', '50', '100', '150', '200'])\n",
        "  plt.title(\"MAPE Box Plots\")\n",
        "  plt.xlabel('Number of neurons')\n",
        "  plt.ylabel('MAPE')\n",
        "\n",
        "  '''plt.subplot(133)\n",
        "  p3 = plt.boxplot(sl_model_output['scores']['R'],patch_artist=True)\n",
        "  for i, box in enumerate(p3['boxes']):\n",
        "    #change outline color\n",
        "    box.set(color= 'blue', linewidth = 1.2)\n",
        "    # change fill color\n",
        "    box.set(facecolor = 'darkgreen')\n",
        "  plt.xticks([1,2,3,4,5,6], ['10', '30', '50', '100', '150', '200'])\n",
        "  plt.title(\"(c)\")\n",
        "  plt.xlabel('Number of neurons')\n",
        "  plt.ylabel('R')'''\n",
        "\n",
        "  #fig.savefig(data_path+\"all_scores_boxplots.png\",dpi=600)\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "ad7AoehvMnOO",
        "outputId": "dd093afd-983c-4186-960a-95165d1e95bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Results + Conclusion##\n",
        "The analysis encompassed diverse techniques such as time series visualization, PCA for dimension reduction, and data normalization to understand the stock market index's behavior. LSTM and GRU models were constructed with varying neuron configurations (10, 30, 50, 100, 150, 200), with a focus on minimizing the root mean square error (RMSE) during training. Visualizations, including true vs. predicted plots and comprehensive prediction analyses, shed light on each model's performance. The results indicate that a single-layer LSTM with 10 neurons, trained with the Nadam optimizer, a learning rate of 0.001, and a batch size of 4, emerges as the best-performing architecture for predicting stock market behavior. Evaluation metric boxplots revealed that the 10-neuron architecture consistently outperformed others in terms of RMSE, demonstrating superior accuracy in predicting stock market behavior, offering valuable insights for stakeholders in making informed decisions for stock market analysis. In conclusion, the study underscores the importance of selecting an optimal neural network architecture for time series prediction, and the findings provide a solid foundation for deploying effective models in the stock market domain."
      ],
      "metadata": {
        "id": "HHQ1sgfdgwUW"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}